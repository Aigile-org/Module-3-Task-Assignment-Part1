{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da952263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import spacy\n",
    "import numpy\n",
    "import pandas as pd\n",
    "from spacy.tokens import Doc\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.attrs import LOWER, POS, ENT_TYPE, IS_ALPHA, LEMMA\n",
    "from parameters import data_out_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f1c9439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy model 'en_core_web_md' loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load spaCy Model ---\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_md\")\n",
    "    print(\"spaCy model 'en_core_web_md' loaded successfully.\")\n",
    "except OSError:\n",
    "    print(\"spaCy model 'en_core_web_md' not found. Downloading...\")\n",
    "    import spacy.cli\n",
    "    spacy.cli.download(\"en_core_web_md\")\n",
    "    nlp = spacy.load(\"en_core_web_md\")\n",
    "    print(\"Model downloaded and loaded successfully.\")\n",
    "\n",
    "# Pre-compile regex for HTML/XML tags for efficiency\n",
    "TAG_RE = re.compile(r'<[^>]+>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08424e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text_field(text):\n",
    "    \"\"\"\n",
    "    Applies preprocessing to a single text field (title or description)\n",
    "    as per Section 3.2 of the paper.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\" # Return empty string if input is not a string (e.g., NaN)\n",
    "\n",
    "    # 1. Remove HTML and XML tags\n",
    "    text = TAG_RE.sub('', text)\n",
    "\n",
    "    # Process with spaCy\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    processed_tokens = []\n",
    "    for token in doc:\n",
    "        # 3. Discard punctuation and special characters (is_alpha checks for letters)\n",
    "        #    Stopword removal and length check are also done here.\n",
    "        if (not token.is_punct and\n",
    "            not token.is_space and # Explicitly remove space tokens\n",
    "            not token.is_stop and  # 4. Discard stopwords\n",
    "            len(token.text) >= 3 and # 5. Discard words with less than three characters\n",
    "            token.is_alpha):        # Ensure it's alphabetic (removes numbers, most special chars)\n",
    "            \n",
    "            # 6. Convert to lowercase and 7. Lemmatize\n",
    "            processed_tokens.append(token.lemma_.lower())\n",
    "            \n",
    "    return \" \".join(processed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00a5e26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_labels(labels_str):\n",
    "    \"\"\"\n",
    "    Processes the labels string. Section 3.2 states no preprocessing needed as\n",
    "    they are 'already split into clear terms/tokens'.\n",
    "    If labels_str is a comma-separated string from previous steps,\n",
    "    this function will split and clean them.\n",
    "    \"\"\"\n",
    "    if not isinstance(labels_str, str) or pd.isna(labels_str):\n",
    "        return [] # Return empty list if no labels or NaN\n",
    "    \n",
    "    # Split if it's a comma-separated string, then strip whitespace from each label\n",
    "    # Assumes labels might have been joined by \", \" in a previous step\n",
    "    tokens = [label.strip().lower() for label in labels_str.split(',') if label.strip()]\n",
    "    # Further cleaning could be added if individual labels have noise\n",
    "    return tokens # Returns a list of clean label strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26e9f0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRIORITY_MAP = {\n",
    "    # Scale 1: Blocker-Critical-Major-Minor-Trivial\n",
    "    \"blocker\": 1, \"p0\": 1,\n",
    "    \"critical\": 2, \"p1\": 2,\n",
    "    \"major\": 3, \"p2\": 3,\n",
    "    \"minor\": 4, \"p3\": 4,\n",
    "    \"trivial\": 5, \"p4\": 5,\n",
    "    # Add other variations if they exist in your data\n",
    "}\n",
    "\n",
    "def convert_priority_to_id(priority_name):\n",
    "    if not isinstance(priority_name, str) or pd.isna(priority_name):\n",
    "        return None # Or a default ID, e.g., 3 for Major\n",
    "    return PRIORITY_MAP.get(priority_name.lower().strip(), None) # Return None if not found\n",
    "\n",
    "# Using Table 2 from the provided PDF\n",
    "ISSUE_TYPE_MAP = {\n",
    "    \"task\": 1,\n",
    "    \"bug\": 2,\n",
    "    \"sub-task\": 3, \"subtask\": 3, # Common variation\n",
    "    \"support patch\": 4,\n",
    "    \"feature request\": 5,\n",
    "    \"enhancement\": 6,\n",
    "    \"component upgrade\": 7,\n",
    "    \"quality risk\": 8,\n",
    "    \"patch\": 9,\n",
    "    \"library upgrade\": 10,\n",
    "    \"clarification\": 11,\n",
    "    \"epic\": 12,\n",
    "    \"tracker\": 13,\n",
    "    \"story\": 14,\n",
    "    # Add other types from your data, mapping them appropriately or to a default/unknown ID\n",
    "    \"new feature\": 5, # \"New Feature\" was type 5 in some contexts (e.g. Figure 2 for Cassandra)\n",
    "                      # The paper's Table 2 lists \"Feature request\" as 5.\n",
    "                      # This mapping needs to be consistent with your data's actual type names.\n",
    "}\n",
    "\n",
    "def convert_type_to_id(type_name):\n",
    "    if not isinstance(type_name, str) or pd.isna(type_name):\n",
    "        return None # Or a default ID\n",
    "    return ISSUE_TYPE_MAP.get(type_name.lower().strip(), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bf619ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting preprocessing for files in: C:\\Users\\hp\\Desktop\\Module-3-Task-assigning\\data\\data_output\n",
      "Output will be saved in: C:\\Users\\hp\\Desktop\\Module-3-Task-assigning\\data\\data_output\\step3_2_processed_data\n"
     ]
    }
   ],
   "source": [
    "print(f\"Starting preprocessing for files in: {data_out_folder}\")\n",
    "\n",
    "# Ensure output subfolder exists\n",
    "output_subfolder = os.path.join(data_out_folder, \"step3_2_processed_data\")\n",
    "os.makedirs(output_subfolder, exist_ok=True)\n",
    "print(f\"Output will be saved in: {output_subfolder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79841311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file: 2_AMBARI_5_assignees.csv\n",
      "  Preprocessing 'title'...\n",
      "  Preprocessing 'description'...\n",
      "  Processing 'labels'...\n",
      "  Warning: 'priority_name' column not found in 2_AMBARI_5_assignees.csv. Cannot map priority IDs.\n",
      "  Warning: 'type_name' column not found in 2_AMBARI_5_assignees.csv. Cannot map type IDs.\n",
      "  'assignee_id' column already present.\n",
      "  Successfully saved processed data to: C:\\Users\\hp\\Desktop\\Module-3-Task-assigning\\data\\data_output\\step3_2_processed_data\\3.2_AMBARI_5_assignees_processed.csv\n",
      "\n",
      "Processing file: 2_ARROW_5_assignees.csv\n",
      "  Preprocessing 'title'...\n",
      "  Preprocessing 'description'...\n",
      "  Processing 'labels'...\n",
      "  Warning: 'priority_name' column not found in 2_ARROW_5_assignees.csv. Cannot map priority IDs.\n",
      "  Warning: 'type_name' column not found in 2_ARROW_5_assignees.csv. Cannot map type IDs.\n",
      "  'assignee_id' column already present.\n",
      "  Successfully saved processed data to: C:\\Users\\hp\\Desktop\\Module-3-Task-assigning\\data\\data_output\\step3_2_processed_data\\3.2_ARROW_5_assignees_processed.csv\n",
      "\n",
      "Processing file: 2_CASSANDRA_5_assignees.csv\n",
      "  Preprocessing 'title'...\n",
      "  Preprocessing 'description'...\n",
      "  Processing 'labels'...\n",
      "  Warning: 'priority_name' column not found in 2_CASSANDRA_5_assignees.csv. Cannot map priority IDs.\n",
      "  Warning: 'type_name' column not found in 2_CASSANDRA_5_assignees.csv. Cannot map type IDs.\n",
      "  'assignee_id' column already present.\n",
      "  Successfully saved processed data to: C:\\Users\\hp\\Desktop\\Module-3-Task-assigning\\data\\data_output\\step3_2_processed_data\\3.2_CASSANDRA_5_assignees_processed.csv\n",
      "\n",
      "Processing file: 2_CB_5_assignees.csv\n",
      "  Preprocessing 'title'...\n",
      "  Preprocessing 'description'...\n",
      "  Processing 'labels'...\n",
      "  Warning: 'priority_name' column not found in 2_CB_5_assignees.csv. Cannot map priority IDs.\n",
      "  Warning: 'type_name' column not found in 2_CB_5_assignees.csv. Cannot map type IDs.\n",
      "  'assignee_id' column already present.\n",
      "  Successfully saved processed data to: C:\\Users\\hp\\Desktop\\Module-3-Task-assigning\\data\\data_output\\step3_2_processed_data\\3.2_CB_5_assignees_processed.csv\n",
      "\n",
      "Processing file: 2_DATALAB_5_assignees.csv\n",
      "  Preprocessing 'title'...\n",
      "  Preprocessing 'description'...\n",
      "  Processing 'labels'...\n",
      "  Warning: 'priority_name' column not found in 2_DATALAB_5_assignees.csv. Cannot map priority IDs.\n",
      "  Warning: 'type_name' column not found in 2_DATALAB_5_assignees.csv. Cannot map type IDs.\n",
      "  'assignee_id' column already present.\n",
      "  Successfully saved processed data to: C:\\Users\\hp\\Desktop\\Module-3-Task-assigning\\data\\data_output\\step3_2_processed_data\\3.2_DATALAB_5_assignees_processed.csv\n",
      "\n",
      "Processing file: 2_FLINK_10_assignees.csv\n",
      "  Preprocessing 'title'...\n",
      "  Preprocessing 'description'...\n",
      "  Processing 'labels'...\n",
      "  Warning: 'priority_name' column not found in 2_FLINK_10_assignees.csv. Cannot map priority IDs.\n",
      "  Warning: 'type_name' column not found in 2_FLINK_10_assignees.csv. Cannot map type IDs.\n",
      "  'assignee_id' column already present.\n",
      "  Successfully saved processed data to: C:\\Users\\hp\\Desktop\\Module-3-Task-assigning\\data\\data_output\\step3_2_processed_data\\3.2_FLINK_10_assignees_processed.csv\n",
      "\n",
      "Processing file: 2_FLINK_15_assignees.csv\n",
      "  Preprocessing 'title'...\n",
      "  Preprocessing 'description'...\n",
      "  Processing 'labels'...\n",
      "  Warning: 'priority_name' column not found in 2_FLINK_15_assignees.csv. Cannot map priority IDs.\n",
      "  Warning: 'type_name' column not found in 2_FLINK_15_assignees.csv. Cannot map type IDs.\n",
      "  'assignee_id' column already present.\n",
      "  Successfully saved processed data to: C:\\Users\\hp\\Desktop\\Module-3-Task-assigning\\data\\data_output\\step3_2_processed_data\\3.2_FLINK_15_assignees_processed.csv\n",
      "\n",
      "Processing file: 2_FLINK_20_assignees.csv\n",
      "  Preprocessing 'title'...\n",
      "  Preprocessing 'description'...\n",
      "  Processing 'labels'...\n",
      "  Warning: 'priority_name' column not found in 2_FLINK_20_assignees.csv. Cannot map priority IDs.\n",
      "  Warning: 'type_name' column not found in 2_FLINK_20_assignees.csv. Cannot map type IDs.\n",
      "  'assignee_id' column already present.\n",
      "  Successfully saved processed data to: C:\\Users\\hp\\Desktop\\Module-3-Task-assigning\\data\\data_output\\step3_2_processed_data\\3.2_FLINK_20_assignees_processed.csv\n",
      "\n",
      "Processing file: 2_FLINK_5_assignees.csv\n",
      "  Preprocessing 'title'...\n",
      "  Preprocessing 'description'...\n",
      "  Processing 'labels'...\n",
      "  Warning: 'priority_name' column not found in 2_FLINK_5_assignees.csv. Cannot map priority IDs.\n",
      "  Warning: 'type_name' column not found in 2_FLINK_5_assignees.csv. Cannot map type IDs.\n",
      "  'assignee_id' column already present.\n",
      "  Successfully saved processed data to: C:\\Users\\hp\\Desktop\\Module-3-Task-assigning\\data\\data_output\\step3_2_processed_data\\3.2_FLINK_5_assignees_processed.csv\n",
      "\n",
      "Processing file: 2_GEODE_5_assignees.csv\n",
      "  Preprocessing 'title'...\n",
      "  Preprocessing 'description'...\n",
      "  Processing 'labels'...\n",
      "  Warning: 'priority_name' column not found in 2_GEODE_5_assignees.csv. Cannot map priority IDs.\n",
      "  Warning: 'type_name' column not found in 2_GEODE_5_assignees.csv. Cannot map type IDs.\n",
      "  'assignee_id' column already present.\n",
      "  Successfully saved processed data to: C:\\Users\\hp\\Desktop\\Module-3-Task-assigning\\data\\data_output\\step3_2_processed_data\\3.2_GEODE_5_assignees_processed.csv\n",
      "\n",
      "Processing file: 2_HDDS_5_assignees.csv\n",
      "  Preprocessing 'title'...\n",
      "  Preprocessing 'description'...\n",
      "  Processing 'labels'...\n",
      "  Warning: 'priority_name' column not found in 2_HDDS_5_assignees.csv. Cannot map priority IDs.\n",
      "  Warning: 'type_name' column not found in 2_HDDS_5_assignees.csv. Cannot map type IDs.\n",
      "  'assignee_id' column already present.\n",
      "  Successfully saved processed data to: C:\\Users\\hp\\Desktop\\Module-3-Task-assigning\\data\\data_output\\step3_2_processed_data\\3.2_HDDS_5_assignees_processed.csv\n",
      "\n",
      "Processing file: 2_HIVE_5_assignees.csv\n",
      "  Preprocessing 'title'...\n",
      "  Preprocessing 'description'...\n",
      "  Processing 'labels'...\n",
      "  Warning: 'priority_name' column not found in 2_HIVE_5_assignees.csv. Cannot map priority IDs.\n",
      "  Warning: 'type_name' column not found in 2_HIVE_5_assignees.csv. Cannot map type IDs.\n",
      "  'assignee_id' column already present.\n",
      "  Successfully saved processed data to: C:\\Users\\hp\\Desktop\\Module-3-Task-assigning\\data\\data_output\\step3_2_processed_data\\3.2_HIVE_5_assignees_processed.csv\n",
      "\n",
      "Processing file: 2_HUDI_5_assignees.csv\n",
      "  Preprocessing 'title'...\n",
      "  Preprocessing 'description'...\n",
      "  Processing 'labels'...\n",
      "  Warning: 'priority_name' column not found in 2_HUDI_5_assignees.csv. Cannot map priority IDs.\n",
      "  Warning: 'type_name' column not found in 2_HUDI_5_assignees.csv. Cannot map type IDs.\n",
      "  'assignee_id' column already present.\n",
      "  Successfully saved processed data to: C:\\Users\\hp\\Desktop\\Module-3-Task-assigning\\data\\data_output\\step3_2_processed_data\\3.2_HUDI_5_assignees_processed.csv\n",
      "\n",
      "Processing file: 2_IGNITE_5_assignees.csv\n",
      "  Preprocessing 'title'...\n",
      "  Preprocessing 'description'...\n",
      "  Processing 'labels'...\n",
      "  Warning: 'priority_name' column not found in 2_IGNITE_5_assignees.csv. Cannot map priority IDs.\n",
      "  Warning: 'type_name' column not found in 2_IGNITE_5_assignees.csv. Cannot map type IDs.\n",
      "  'assignee_id' column already present.\n",
      "  Successfully saved processed data to: C:\\Users\\hp\\Desktop\\Module-3-Task-assigning\\data\\data_output\\step3_2_processed_data\\3.2_IGNITE_5_assignees_processed.csv\n",
      "\n",
      "Processing file: 2_IMPALA_5_assignees.csv\n",
      "  Preprocessing 'title'...\n",
      "  Preprocessing 'description'...\n",
      "  Processing 'labels'...\n",
      "  Warning: 'priority_name' column not found in 2_IMPALA_5_assignees.csv. Cannot map priority IDs.\n",
      "  Warning: 'type_name' column not found in 2_IMPALA_5_assignees.csv. Cannot map type IDs.\n",
      "  'assignee_id' column already present.\n",
      "  Successfully saved processed data to: C:\\Users\\hp\\Desktop\\Module-3-Task-assigning\\data\\data_output\\step3_2_processed_data\\3.2_IMPALA_5_assignees_processed.csv\n",
      "\n",
      "Processing file: 2_IOTDB_5_assignees.csv\n",
      "  Preprocessing 'title'...\n",
      "  Preprocessing 'description'...\n",
      "  Processing 'labels'...\n",
      "  Warning: 'priority_name' column not found in 2_IOTDB_5_assignees.csv. Cannot map priority IDs.\n",
      "  Warning: 'type_name' column not found in 2_IOTDB_5_assignees.csv. Cannot map type IDs.\n",
      "  'assignee_id' column already present.\n",
      "  Successfully saved processed data to: C:\\Users\\hp\\Desktop\\Module-3-Task-assigning\\data\\data_output\\step3_2_processed_data\\3.2_IOTDB_5_assignees_processed.csv\n",
      "\n",
      "Processing file: 2_MESOS_5_assignees.csv\n",
      "  Preprocessing 'title'...\n",
      "  Preprocessing 'description'...\n",
      "  Processing 'labels'...\n",
      "  Warning: 'priority_name' column not found in 2_MESOS_5_assignees.csv. Cannot map priority IDs.\n",
      "  Warning: 'type_name' column not found in 2_MESOS_5_assignees.csv. Cannot map type IDs.\n",
      "  'assignee_id' column already present.\n",
      "  Successfully saved processed data to: C:\\Users\\hp\\Desktop\\Module-3-Task-assigning\\data\\data_output\\step3_2_processed_data\\3.2_MESOS_5_assignees_processed.csv\n",
      "\n",
      "Processing file: 2_OAK_5_assignees.csv\n",
      "  Preprocessing 'title'...\n",
      "  Preprocessing 'description'...\n",
      "  Processing 'labels'...\n",
      "  Warning: 'priority_name' column not found in 2_OAK_5_assignees.csv. Cannot map priority IDs.\n",
      "  Warning: 'type_name' column not found in 2_OAK_5_assignees.csv. Cannot map type IDs.\n",
      "  'assignee_id' column already present.\n",
      "  Successfully saved processed data to: C:\\Users\\hp\\Desktop\\Module-3-Task-assigning\\data\\data_output\\step3_2_processed_data\\3.2_OAK_5_assignees_processed.csv\n",
      "\n",
      "Processing file: 2_SPARK_5_assignees.csv\n",
      "  Preprocessing 'title'...\n",
      "  Preprocessing 'description'...\n",
      "  Processing 'labels'...\n",
      "  Warning: 'priority_name' column not found in 2_SPARK_5_assignees.csv. Cannot map priority IDs.\n",
      "  Warning: 'type_name' column not found in 2_SPARK_5_assignees.csv. Cannot map type IDs.\n",
      "  'assignee_id' column already present.\n",
      "  Successfully saved processed data to: C:\\Users\\hp\\Desktop\\Module-3-Task-assigning\\data\\data_output\\step3_2_processed_data\\3.2_SPARK_5_assignees_processed.csv\n",
      "\n",
      "Successfully processed and saved 19 files to 'C:\\Users\\hp\\Desktop\\Module-3-Task-assigning\\data\\data_output\\step3_2_processed_data'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "files_processed_count = 0\n",
    "for f in os.listdir(data_out_folder):\n",
    "    if f.startswith(\"2_\") and f.endswith(\".csv\"): # Process files from step 2\n",
    "        print(f\"\\nProcessing file: {f}\")\n",
    "        try:\n",
    "            # Extract project_name and num_assignees from filename like \"2_PROJECT_N_assignees.csv\"\n",
    "            parts = f.replace(\".csv\", \"\").split(\"_\")\n",
    "            if len(parts) < 4 : # Basic check for filename format\n",
    "                print(f\"  Skipping {f}: Filename format incorrect.\")\n",
    "                continue\n",
    "            project_name = parts[1]\n",
    "            num_assignees = parts[2] # num_assignees might not be directly used in this script but is part of filename\n",
    "        except IndexError:\n",
    "            print(f\"  Skipping {f}: Could not parse project name or assignee number from filename.\")\n",
    "            continue\n",
    "\n",
    "        input_filepath = os.path.join(data_out_folder, f)\n",
    "        df = pd.read_csv(input_filepath, sep='\\t', encoding='utf-8')\n",
    "\n",
    "        # Drop unnamed columns if they exist\n",
    "        df.drop(df.columns[df.columns.str.contains('unnamed', case=False)], axis=1, inplace=True, errors='ignore')\n",
    "\n",
    "        # a. Apply Text Preprocessing (Title and Description)\n",
    "        print(\"  Preprocessing 'title'...\")\n",
    "        df['processed_title'] = df['title'].astype(str).apply(preprocess_text_field)\n",
    "        print(\"  Preprocessing 'description'...\")\n",
    "        df['processed_description'] = df['description'].astype(str).apply(preprocess_text_field)\n",
    "\n",
    "        # b. Process Labels (convert to list of clean tokens)\n",
    "        # Assuming 'labels' column from \"1_mongo.csv\" was carried over as a string.\n",
    "        # If it's named 'labels_str' from previous steps, use that.\n",
    "        labels_column_name = 'labels' if 'labels' in df.columns else 'labels_str'\n",
    "        if labels_column_name in df.columns:\n",
    "            print(f\"  Processing '{labels_column_name}'...\")\n",
    "            df['processed_labels'] = df[labels_column_name].apply(process_labels)\n",
    "        else:\n",
    "            print(f\"  Warning: Label column ('labels' or 'labels_str') not found in {f}. Skipping label processing.\")\n",
    "            df['processed_labels'] = pd.Series([[] for _ in range(len(df))], index=df.index)\n",
    "\n",
    "\n",
    "        # c. Convert Non-Textual Data to IDs\n",
    "        #   Priority: Assumes a column like 'priority_name' exists from \"1_mongo.csv\"\n",
    "        if 'priority_name' in df.columns:\n",
    "            print(\"  Converting 'priority_name' to 'priority_id_mapped'...\")\n",
    "            df['priority_id_mapped'] = df['priority_name'].apply(convert_priority_to_id)\n",
    "        else:\n",
    "            print(f\"  Warning: 'priority_name' column not found in {f}. Cannot map priority IDs.\")\n",
    "            # If 'priority_id' already exists and is numeric, you might want to keep it.\n",
    "            # For now, we'll create the column so it exists for downstream consistency if needed.\n",
    "            if 'priority_id' not in df.columns:\n",
    "                 df['priority_id_mapped'] = None\n",
    "\n",
    "\n",
    "        #   Type: Assumes a column like 'type_name' exists from \"1_mongo.csv\"\n",
    "        if 'type_name' in df.columns:\n",
    "            print(\"  Converting 'type_name' to 'type_id_mapped'...\")\n",
    "            df['type_id_mapped'] = df['type_name'].apply(convert_type_to_id)\n",
    "        else:\n",
    "            print(f\"  Warning: 'type_name' column not found in {f}. Cannot map type IDs.\")\n",
    "            if 'type_id' not in df.columns:\n",
    "                df['type_id_mapped'] = None\n",
    "\n",
    "        #   Assignee ID: Assumed to be already present as 'assignee_id' from the \"2_...\" files.\n",
    "        #   If it was 'assignee' (string name), you would do:\n",
    "        #   df['assignee_id_mapped'] = df['assignee'].rank(method='dense').astype(int)\n",
    "        if 'assignee_id' not in df.columns and 'assignee' in df.columns:\n",
    "            print(\"  Generating 'assignee_id' from 'assignee' column...\")\n",
    "            df['assignee_id'] = df['assignee'].rank(method='dense').astype(int)\n",
    "        elif 'assignee_id' in df.columns:\n",
    "            print(\"  'assignee_id' column already present.\")\n",
    "        else:\n",
    "            print(f\"  Warning: Neither 'assignee_id' nor 'assignee' found. Cannot ensure assignee ID.\")\n",
    "\n",
    "\n",
    "        # d. Select and reorder columns for the output\n",
    "        # Choose which columns to keep. Original IDs or mapped IDs? Processed text or original?\n",
    "        # This example keeps processed text and mapped IDs where available.\n",
    "        output_columns = []\n",
    "        for col in ['id', 'project_name', 'assignee_id', # Base IDs\n",
    "                    'processed_title', 'processed_description', 'processed_labels', # Processed text & labels\n",
    "                    'priority_id_mapped', 'type_id_mapped', # Mapped categorical IDs\n",
    "                    'status_name', # Example of other categorical data that might be useful\n",
    "                   ]: # Add any other original columns you want to keep\n",
    "            if col in df.columns:\n",
    "                output_columns.append(col)\n",
    "            elif col.replace('_mapped','') in df.columns: # If mapped version doesn't exist, use original ID if present\n",
    "                 output_columns.append(col.replace('_mapped',''))\n",
    "\n",
    "\n",
    "        df_processed = df[output_columns].copy()\n",
    "\n",
    "\n",
    "        # Save processed DataFrame\n",
    "        output_filename = f\"3.2_{project_name}_{num_assignees}_assignees_processed.csv\"\n",
    "        output_filepath = os.path.join(output_subfolder, output_filename)\n",
    "        \n",
    "        try:\n",
    "            df_processed.to_csv(output_filepath, sep='\\t', encoding='utf-8', index=False)\n",
    "            print(f\"  Successfully saved processed data to: {output_filepath}\")\n",
    "            files_processed_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"  Error saving processed CSV file {output_filename}: {e}\")\n",
    "\n",
    "if files_processed_count > 0:\n",
    "    print(f\"\\nSuccessfully processed and saved {files_processed_count} files to '{output_subfolder}'.\")\n",
    "else:\n",
    "    print(\"\\nNo files were processed. Check filenames in datafolder start with '2_' and end with '.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd8c880",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
