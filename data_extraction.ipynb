{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pymongo\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os # For handling file paths\n",
    "from parameters import db_name, connection_link, collection_name, data_out_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb233618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MongoDB URL: mongodb://localhost:27017/\n",
      "Output data folder: C:\\Users\\hp\\Desktop\\Module-3-Task-assigning\\data\\data_output\n"
     ]
    }
   ],
   "source": [
    "#!pip install pymongo\n",
    "print(f\"Using MongoDB URL: {connection_link}\")\n",
    "print(f\"Output data folder: {data_out_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28454991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to MongoDB.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    client = pymongo.MongoClient(connection_link)\n",
    "    # Ensure the client is connected, or raise an error early\n",
    "    client.admin.command('ping') # Pings the server to check connection\n",
    "    print(\"Successfully connected to MongoDB.\")\n",
    "except pymongo.errors.ConnectionFailure as e:\n",
    "    print(f\"Could not connect to MongoDB: {e}\")\n",
    "    exit() # Exit if connection fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e4e8888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessing database: 'apache_jira_data', collection: 'issues'\n"
     ]
    }
   ],
   "source": [
    "db = client[db_name]\n",
    "collection = db[collection_name]\n",
    "print(f\"Accessing database: '{db_name}', collection: '{collection_name}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fc88135",
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_filter = {\n",
    "    '$and': [\n",
    "        {'assignee': {'$exists': True, '$not': {'$size': 0}}},\n",
    "        {'labels': {'$exists': True, '$not': {'$size': 0}}},\n",
    "        {'priority.id': {'$exists': True, '$not': {'$size': 0}}}, # '$size' is unusual here if 'priority.id' is not an array.\n",
    "                                                                # Consider {'priority.id': {'$exists': True, '$ne': None}} if it's a single value.\n",
    "        {'issuetype.id': {'$exists': True, '$not': {'$size': 0}}}  # Same as above for 'issuetype.id'.\n",
    "    ]\n",
    "}\n",
    "\n",
    "mongo_projection = {\n",
    "    '_id': 1, # Keeping _id is good practice\n",
    "    'assignee': 1,\n",
    "    'summary': 1,\n",
    "    'description': 1,\n",
    "    'issuetype': 1,\n",
    "    'labels': 1,\n",
    "    'priority': 1,\n",
    "    'status': 1,\n",
    "    'projectname': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8002a0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching issues from MongoDB with the provided filter and projection...\n",
      "Found 144508 issues matching the criteria in 'apache_jira_data.issues'.\n"
     ]
    }
   ],
   "source": [
    "print(\"Fetching issues from MongoDB with the provided filter and projection...\")\n",
    "try:\n",
    "    issues_cursor = collection.find(filter=mongo_filter, projection=mongo_projection)\n",
    "    list_issues = list(issues_cursor)  # Loads all matching documents into memory\n",
    "    \n",
    "    print(f\"Found {len(list_issues)} issues matching the criteria in '{db_name}.{collection_name}'.\")\n",
    "\n",
    "    if not list_issues:\n",
    "        print(\"No issues found.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error fetching data from MongoDB: {e}\")\n",
    "    # client.close() # Consider closing connection on error\n",
    "    # exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7434aa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#poolars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52801281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# size = len(list_issues)\n",
    "# limit = 1000\n",
    "# i = 0\n",
    "# for issue in list_issues:\n",
    "#     if i % 1000 == 0:\n",
    "#         print(f\"Processing issue {i} of {size}\")\n",
    "#     i += 1    \n",
    "#     issue[\"type_id\"] = issue[\"issuetype\"][\"id\"]\n",
    "#     issue[\"priority_id\"] = issue[\"priority\"][\"id\"]\n",
    "#     issue[\"status_id\"] = issue[\"status\"][\"id\"]\n",
    "#     issue[\"type_name\"] = issue[\"issuetype\"][\"name\"]\n",
    "#     issue[\"priority_name\"] = issue[\"priority\"][\"name\"]\n",
    "#     issue[\"status_name\"] = issue[\"status\"][\"name\"]\n",
    "#     if i == limit:\n",
    "#         print(f\"Processed {i} issues, stopping at limit.\")\n",
    "#         break\n",
    "\n",
    "# # Convert data to dataframe and save to csv file\n",
    "# datapath = os.path.join(data_out_folder, \"issues.csv\")\n",
    "# mongo_df = pd.DataFrame(list_issues, columns=['_id', 'projectname', 'assignee', 'summary', 'description', 'type_id',\n",
    "#                   'type_name', 'labels', 'priority_id', 'priority_name', 'status_id', 'status_name'])\n",
    "# mongo_df.to_csv(datapath, sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b9d29ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting processing. Will process up to 1000 issues out of 144508 total.\n",
      "Processing original issue 1 (to become processed item 1)...\n",
      "Processed 1000 issues, stopping at limit.\n",
      "Finished processing loop. 1000 issues were processed and prepared for DataFrame.\n",
      "Saving 1000 issues to CSV: C:\\Users\\hp\\Desktop\\Module-3-Task-assigning\\data\\data_output\\issues_limited_user_cols.csv\n",
      "Successfully saved data to C:\\Users\\hp\\Desktop\\Module-3-Task-assigning\\data\\data_output\\issues_limited_user_cols.csv\n"
     ]
    }
   ],
   "source": [
    "size = len(list_issues)\n",
    "limit = 1000  # Set your desired limit\n",
    "i = 0\n",
    "print(f\"Starting processing. Will process up to {limit} issues out of {size} total.\")\n",
    "\n",
    "# This list will store dictionaries that only contain the keys specified by the user\n",
    "processed_issues_for_df = []\n",
    "\n",
    "for item_index, original_issue_data in enumerate(list_issues):\n",
    "    if i % 1000 == 0: # Progress printing\n",
    "        print(f\"Processing original issue {item_index+1} (to become processed item {i+1})...\")\n",
    "\n",
    "    # Create a new dictionary for the processed data to ensure clean output\n",
    "    processed_issue = {}\n",
    "\n",
    "    # Handle _id (MongoDB ObjectId to string)\n",
    "    # Your projection should have brought '_id'.\n",
    "    # Ensure it's a string if it's an ObjectId.\n",
    "    raw_id = original_issue_data.get('_id')\n",
    "    if raw_id is not None:\n",
    "        processed_issue['_id'] = str(raw_id)\n",
    "    else:\n",
    "        processed_issue['_id'] = None\n",
    "        \n",
    "    # Directly transfer fields that are expected to be at the root\n",
    "    # based on your desired columns and typical projection\n",
    "    processed_issue['projectname'] = original_issue_data.get('projectname')\n",
    "    processed_issue['summary'] = original_issue_data.get('summary')\n",
    "    processed_issue['description'] = original_issue_data.get('description')\n",
    "\n",
    "    # --- Safely access and flatten nested data ---\n",
    "    issuetype_data = original_issue_data.get(\"issuetype\")\n",
    "    if isinstance(issuetype_data, dict):\n",
    "        processed_issue[\"type_id\"] = issuetype_data.get(\"id\")\n",
    "        processed_issue[\"type_name\"] = issuetype_data.get(\"name\")\n",
    "    else:\n",
    "        processed_issue[\"type_id\"] = None\n",
    "        processed_issue[\"type_name\"] = None\n",
    "\n",
    "    priority_data = original_issue_data.get(\"priority\")\n",
    "    if isinstance(priority_data, dict):\n",
    "        processed_issue[\"priority_id\"] = priority_data.get(\"id\")\n",
    "        processed_issue[\"priority_name\"] = priority_data.get(\"name\")\n",
    "    else:\n",
    "        processed_issue[\"priority_id\"] = None\n",
    "        processed_issue[\"priority_name\"] = None\n",
    "\n",
    "    status_data = original_issue_data.get(\"status\")\n",
    "    if isinstance(status_data, dict):\n",
    "        processed_issue[\"status_id\"] = status_data.get(\"id\")\n",
    "        processed_issue[\"status_name\"] = status_data.get(\"name\")\n",
    "    else:\n",
    "        processed_issue[\"status_id\"] = None\n",
    "        processed_issue[\"status_name\"] = None\n",
    "    \n",
    "    # --- Assignee Processing Logic (output to 'assignee') ---\n",
    "    assignee_data = original_issue_data.get('assignee')\n",
    "    if isinstance(assignee_data, str):\n",
    "        processed_issue['assignee'] = assignee_data\n",
    "    elif isinstance(assignee_data, dict):\n",
    "        processed_issue['assignee'] = assignee_data.get('displayName', assignee_data.get('name'))\n",
    "    elif isinstance(assignee_data, list) and assignee_data: \n",
    "        first_assignee = assignee_data[0]\n",
    "        if isinstance(first_assignee, dict):\n",
    "            processed_issue['assignee'] = first_assignee.get('displayName', first_assignee.get('name'))\n",
    "        elif isinstance(first_assignee, str):\n",
    "            processed_issue['assignee'] = first_assignee\n",
    "        else: \n",
    "            processed_issue['assignee'] = None\n",
    "    else:\n",
    "        processed_issue['assignee'] = None\n",
    "    # --- End Assignee Processing Logic ---\n",
    "\n",
    "    # --- Labels Processing Logic (output to 'labels') ---\n",
    "    labels_data = original_issue_data.get('labels', [])\n",
    "    processed_issue[\"labels\"] = \", \".join(map(str, labels_data)) if labels_data else None\n",
    "    # --- End Labels Processing Logic ---\n",
    "    \n",
    "    processed_issues_for_df.append(processed_issue)\n",
    "    i += 1\n",
    "    if i >= limit:\n",
    "        print(f\"Processed {i} issues, stopping at limit.\")\n",
    "        break\n",
    "\n",
    "print(f\"Finished processing loop. {i} issues were processed and prepared for DataFrame.\")\n",
    "\n",
    "# --- Convert data to dataframe and save to csv file ---\n",
    "\n",
    "# Use the exact list of columns you provided\n",
    "df_columns = [\n",
    "    '_id', 'projectname', 'assignee', 'summary', 'description', 'type_id',\n",
    "    'type_name', 'labels', 'priority_id', 'priority_name', 'status_id', 'status_name'\n",
    "]\n",
    "\n",
    "if not data_out_folder or not os.path.isdir(data_out_folder):\n",
    "    print(f\"Output directory '{data_out_folder}' is not defined or does not exist. Please create it or set the 'data_out_folder' variable.\")\n",
    "else:\n",
    "    datapath = os.path.join(data_out_folder, \"issues_limited_user_cols.csv\") # New filename\n",
    "    \n",
    "    # Create DataFrame from the list of processed dictionaries\n",
    "    mongo_df = pd.DataFrame(processed_issues_for_df)\n",
    "    \n",
    "    # Ensure all df_columns are present and in order; fill missing ones with None/NaN\n",
    "    # This is important because some .get() calls might result in keys not being added\n",
    "    # if the source data was None.\n",
    "    for col in df_columns:\n",
    "        if col not in mongo_df.columns:\n",
    "            mongo_df[col] = None \n",
    "    mongo_df = mongo_df[df_columns] # Select and order columns as per your request\n",
    "\n",
    "    print(f\"Saving {len(mongo_df)} issues to CSV: {datapath}\")\n",
    "    try:\n",
    "        mongo_df.to_csv(datapath, sep='\\t', encoding='utf-8', index=False)\n",
    "        print(f\"Successfully saved data to {datapath}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving CSV file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0dfb4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
