{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pymongo\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os # For handling file paths\n",
    "from parameters import db_name, connection_link, collection_issues, data_out_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb233618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MongoDB URL: mongodb://localhost:27017/\n",
      "Output data folder: C:\\Users\\hp\\Desktop\\Module-3-Task-assigning\\data\\data_output\n"
     ]
    }
   ],
   "source": [
    "#!pip install pymongo\n",
    "print(f\"Using MongoDB URL: {connection_link}\")\n",
    "print(f\"Output data folder: {data_out_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28454991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to MongoDB.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    client = pymongo.MongoClient(connection_link)\n",
    "    # Ensure the client is connected, or raise an error early\n",
    "    client.admin.command('ping') # Pings the server to check connection\n",
    "    print(\"Successfully connected to MongoDB.\")\n",
    "except pymongo.errors.ConnectionFailure as e:\n",
    "    print(f\"Could not connect to MongoDB: {e}\")\n",
    "    exit() # Exit if connection fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e4e8888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessing database: 'apache_jira_data', collection: 'issues'\n"
     ]
    }
   ],
   "source": [
    "db = client[db_name]\n",
    "collection = db[collection_issues]\n",
    "print(f\"Accessing database: '{db_name}', collection: '{collection_issues}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fc88135",
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_filter = {\n",
    "    '$and': [\n",
    "        {'assignee': {'$exists': True, '$not': {'$size': 0}}},\n",
    "        {'labels': {'$exists': True, '$not': {'$size': 0}}},\n",
    "        {'priority.id': {'$exists': True, '$not': {'$size': 0}}}, # '$size' is unusual here if 'priority.id' is not an array.\n",
    "                                                                # Consider {'priority.id': {'$exists': True, '$ne': None}} if it's a single value.\n",
    "        {'issuetype.id': {'$exists': True, '$not': {'$size': 0}}}  # Same as above for 'issuetype.id'.\n",
    "    ]\n",
    "}\n",
    "\n",
    "mongo_projection = {\n",
    "    '_id': 1, # Keeping _id is good practice\n",
    "    'assignee': 1,\n",
    "    'summary': 1,\n",
    "    'description': 1,\n",
    "    'issuetype': 1,\n",
    "    'labels': 1,\n",
    "    'priority': 1,\n",
    "    'status': 1,\n",
    "    'projectname': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8002a0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching issues from MongoDB with the provided filter and projection...\n",
      "Found 144508 issues matching the criteria in 'apache_jira_data.issues'.\n"
     ]
    }
   ],
   "source": [
    "print(\"Fetching issues from MongoDB with the provided filter and projection...\")\n",
    "try:\n",
    "    issues_cursor = collection.find(filter=mongo_filter, projection=mongo_projection)\n",
    "    list_issues = list(issues_cursor)  # Loads all matching documents into memory\n",
    "    \n",
    "    print(f\"Found {len(list_issues)} issues matching the criteria in '{db_name}.{collection_issues}'.\")\n",
    "\n",
    "    if not list_issues:\n",
    "        print(\"No issues found.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error fetching data from MongoDB: {e}\")\n",
    "    # client.close() # Consider closing connection on error\n",
    "    # exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7434aa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#poolars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52801281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# size = len(list_issues)\n",
    "# limit = 1000\n",
    "# i = 0\n",
    "# for issue in list_issues:\n",
    "#     if i % 1000 == 0:\n",
    "#         print(f\"Processing issue {i} of {size}\")\n",
    "#     i += 1    \n",
    "#     issue[\"type_id\"] = issue[\"issuetype\"][\"id\"]\n",
    "#     issue[\"priority_id\"] = issue[\"priority\"][\"id\"]\n",
    "#     issue[\"status_id\"] = issue[\"status\"][\"id\"]\n",
    "#     issue[\"type_name\"] = issue[\"issuetype\"][\"name\"]\n",
    "#     issue[\"priority_name\"] = issue[\"priority\"][\"name\"]\n",
    "#     issue[\"status_name\"] = issue[\"status\"][\"name\"]\n",
    "#     if i == limit:\n",
    "#         print(f\"Processed {i} issues, stopping at limit.\")\n",
    "#         break\n",
    "\n",
    "# # Convert data to dataframe and save to csv file\n",
    "# datapath = os.path.join(data_out_folder, \"issues.csv\")\n",
    "# mongo_df = pd.DataFrame(list_issues, columns=['_id', 'projectname', 'assignee', 'summary', 'description', 'type_id',\n",
    "#                   'type_name', 'labels', 'priority_id', 'priority_name', 'status_id', 'status_name'])\n",
    "# mongo_df.to_csv(datapath, sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b9d29ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting processing. Will process up to None issues out of 144508 total.\n",
      "Processing original issue 1 (to become processed item 1)...\n",
      "Processing original issue 1001 (to become processed item 1001)...\n",
      "Processing original issue 2001 (to become processed item 2001)...\n",
      "Processing original issue 3001 (to become processed item 3001)...\n",
      "Processing original issue 4001 (to become processed item 4001)...\n",
      "Processing original issue 5001 (to become processed item 5001)...\n",
      "Processing original issue 6001 (to become processed item 6001)...\n",
      "Processing original issue 7001 (to become processed item 7001)...\n",
      "Processing original issue 8001 (to become processed item 8001)...\n",
      "Processing original issue 9001 (to become processed item 9001)...\n",
      "Processing original issue 10001 (to become processed item 10001)...\n",
      "Processing original issue 11001 (to become processed item 11001)...\n",
      "Processing original issue 12001 (to become processed item 12001)...\n",
      "Processing original issue 13001 (to become processed item 13001)...\n",
      "Processing original issue 14001 (to become processed item 14001)...\n",
      "Processing original issue 15001 (to become processed item 15001)...\n",
      "Processing original issue 16001 (to become processed item 16001)...\n",
      "Processing original issue 17001 (to become processed item 17001)...\n",
      "Processing original issue 18001 (to become processed item 18001)...\n",
      "Processing original issue 19001 (to become processed item 19001)...\n",
      "Processing original issue 20001 (to become processed item 20001)...\n",
      "Processing original issue 21001 (to become processed item 21001)...\n",
      "Processing original issue 22001 (to become processed item 22001)...\n",
      "Processing original issue 23001 (to become processed item 23001)...\n",
      "Processing original issue 24001 (to become processed item 24001)...\n",
      "Processing original issue 25001 (to become processed item 25001)...\n",
      "Processing original issue 26001 (to become processed item 26001)...\n",
      "Processing original issue 27001 (to become processed item 27001)...\n",
      "Processing original issue 28001 (to become processed item 28001)...\n",
      "Processing original issue 29001 (to become processed item 29001)...\n",
      "Processing original issue 30001 (to become processed item 30001)...\n",
      "Processing original issue 31001 (to become processed item 31001)...\n",
      "Processing original issue 32001 (to become processed item 32001)...\n",
      "Processing original issue 33001 (to become processed item 33001)...\n",
      "Processing original issue 34001 (to become processed item 34001)...\n",
      "Processing original issue 35001 (to become processed item 35001)...\n",
      "Processing original issue 36001 (to become processed item 36001)...\n",
      "Processing original issue 37001 (to become processed item 37001)...\n",
      "Processing original issue 38001 (to become processed item 38001)...\n",
      "Processing original issue 39001 (to become processed item 39001)...\n",
      "Processing original issue 40001 (to become processed item 40001)...\n",
      "Processing original issue 41001 (to become processed item 41001)...\n",
      "Processing original issue 42001 (to become processed item 42001)...\n",
      "Processing original issue 43001 (to become processed item 43001)...\n",
      "Processing original issue 44001 (to become processed item 44001)...\n",
      "Processing original issue 45001 (to become processed item 45001)...\n",
      "Processing original issue 46001 (to become processed item 46001)...\n",
      "Processing original issue 47001 (to become processed item 47001)...\n",
      "Processing original issue 48001 (to become processed item 48001)...\n",
      "Processing original issue 49001 (to become processed item 49001)...\n",
      "Processing original issue 50001 (to become processed item 50001)...\n",
      "Processing original issue 51001 (to become processed item 51001)...\n",
      "Processing original issue 52001 (to become processed item 52001)...\n",
      "Processing original issue 53001 (to become processed item 53001)...\n",
      "Processing original issue 54001 (to become processed item 54001)...\n",
      "Processing original issue 55001 (to become processed item 55001)...\n",
      "Processing original issue 56001 (to become processed item 56001)...\n",
      "Processing original issue 57001 (to become processed item 57001)...\n",
      "Processing original issue 58001 (to become processed item 58001)...\n",
      "Processing original issue 59001 (to become processed item 59001)...\n",
      "Processing original issue 60001 (to become processed item 60001)...\n",
      "Processing original issue 61001 (to become processed item 61001)...\n",
      "Processing original issue 62001 (to become processed item 62001)...\n",
      "Processing original issue 63001 (to become processed item 63001)...\n",
      "Processing original issue 64001 (to become processed item 64001)...\n",
      "Processing original issue 65001 (to become processed item 65001)...\n",
      "Processing original issue 66001 (to become processed item 66001)...\n",
      "Processing original issue 67001 (to become processed item 67001)...\n",
      "Processing original issue 68001 (to become processed item 68001)...\n",
      "Processing original issue 69001 (to become processed item 69001)...\n",
      "Processing original issue 70001 (to become processed item 70001)...\n",
      "Processing original issue 71001 (to become processed item 71001)...\n",
      "Processing original issue 72001 (to become processed item 72001)...\n",
      "Processing original issue 73001 (to become processed item 73001)...\n",
      "Processing original issue 74001 (to become processed item 74001)...\n",
      "Processing original issue 75001 (to become processed item 75001)...\n",
      "Processing original issue 76001 (to become processed item 76001)...\n",
      "Processing original issue 77001 (to become processed item 77001)...\n",
      "Processing original issue 78001 (to become processed item 78001)...\n",
      "Processing original issue 79001 (to become processed item 79001)...\n",
      "Processing original issue 80001 (to become processed item 80001)...\n",
      "Processing original issue 81001 (to become processed item 81001)...\n",
      "Processing original issue 82001 (to become processed item 82001)...\n",
      "Processing original issue 83001 (to become processed item 83001)...\n",
      "Processing original issue 84001 (to become processed item 84001)...\n",
      "Processing original issue 85001 (to become processed item 85001)...\n",
      "Processing original issue 86001 (to become processed item 86001)...\n",
      "Processing original issue 87001 (to become processed item 87001)...\n",
      "Processing original issue 88001 (to become processed item 88001)...\n",
      "Processing original issue 89001 (to become processed item 89001)...\n",
      "Processing original issue 90001 (to become processed item 90001)...\n",
      "Processing original issue 91001 (to become processed item 91001)...\n",
      "Processing original issue 92001 (to become processed item 92001)...\n",
      "Processing original issue 93001 (to become processed item 93001)...\n",
      "Processing original issue 94001 (to become processed item 94001)...\n",
      "Processing original issue 95001 (to become processed item 95001)...\n",
      "Processing original issue 96001 (to become processed item 96001)...\n",
      "Processing original issue 97001 (to become processed item 97001)...\n",
      "Processing original issue 98001 (to become processed item 98001)...\n",
      "Processing original issue 99001 (to become processed item 99001)...\n",
      "Processing original issue 100001 (to become processed item 100001)...\n",
      "Processing original issue 101001 (to become processed item 101001)...\n",
      "Processing original issue 102001 (to become processed item 102001)...\n",
      "Processing original issue 103001 (to become processed item 103001)...\n",
      "Processing original issue 104001 (to become processed item 104001)...\n",
      "Processing original issue 105001 (to become processed item 105001)...\n",
      "Processing original issue 106001 (to become processed item 106001)...\n",
      "Processing original issue 107001 (to become processed item 107001)...\n",
      "Processing original issue 108001 (to become processed item 108001)...\n",
      "Processing original issue 109001 (to become processed item 109001)...\n",
      "Processing original issue 110001 (to become processed item 110001)...\n",
      "Processing original issue 111001 (to become processed item 111001)...\n",
      "Processing original issue 112001 (to become processed item 112001)...\n",
      "Processing original issue 113001 (to become processed item 113001)...\n",
      "Processing original issue 114001 (to become processed item 114001)...\n",
      "Processing original issue 115001 (to become processed item 115001)...\n",
      "Processing original issue 116001 (to become processed item 116001)...\n",
      "Processing original issue 117001 (to become processed item 117001)...\n",
      "Processing original issue 118001 (to become processed item 118001)...\n",
      "Processing original issue 119001 (to become processed item 119001)...\n",
      "Processing original issue 120001 (to become processed item 120001)...\n",
      "Processing original issue 121001 (to become processed item 121001)...\n",
      "Processing original issue 122001 (to become processed item 122001)...\n",
      "Processing original issue 123001 (to become processed item 123001)...\n",
      "Processing original issue 124001 (to become processed item 124001)...\n",
      "Processing original issue 125001 (to become processed item 125001)...\n",
      "Processing original issue 126001 (to become processed item 126001)...\n",
      "Processing original issue 127001 (to become processed item 127001)...\n",
      "Processing original issue 128001 (to become processed item 128001)...\n",
      "Processing original issue 129001 (to become processed item 129001)...\n",
      "Processing original issue 130001 (to become processed item 130001)...\n",
      "Processing original issue 131001 (to become processed item 131001)...\n",
      "Processing original issue 132001 (to become processed item 132001)...\n",
      "Processing original issue 133001 (to become processed item 133001)...\n",
      "Processing original issue 134001 (to become processed item 134001)...\n",
      "Processing original issue 135001 (to become processed item 135001)...\n",
      "Processing original issue 136001 (to become processed item 136001)...\n",
      "Processing original issue 137001 (to become processed item 137001)...\n",
      "Processing original issue 138001 (to become processed item 138001)...\n",
      "Processing original issue 139001 (to become processed item 139001)...\n",
      "Processing original issue 140001 (to become processed item 140001)...\n",
      "Processing original issue 141001 (to become processed item 141001)...\n",
      "Processing original issue 142001 (to become processed item 142001)...\n",
      "Processing original issue 143001 (to become processed item 143001)...\n",
      "Processing original issue 144001 (to become processed item 144001)...\n",
      "Finished processing loop. 144508 issues were processed and prepared for DataFrame.\n",
      "Saving 144508 issues to CSV: C:\\Users\\hp\\Desktop\\Module-3-Task-assigning\\data\\data_output\\issues_limited_user_cols.csv\n",
      "Successfully saved data to C:\\Users\\hp\\Desktop\\Module-3-Task-assigning\\data\\data_output\\issues_limited_user_cols.csv\n"
     ]
    }
   ],
   "source": [
    "size = len(list_issues)\n",
    "limit = None\n",
    "i = 0\n",
    "print(f\"Starting processing. Will process up to {limit} issues out of {size} total.\")\n",
    "processed_issues_for_df = []\n",
    "\n",
    "for item_index, original_issue_data in enumerate(list_issues):\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"Processing original issue {item_index+1} (to become processed item {i+1})...\")\n",
    "\n",
    "    processed_issue = {}\n",
    "    raw_id = original_issue_data.get('_id')\n",
    "    if raw_id is not None:\n",
    "        processed_issue['_id'] = str(raw_id)\n",
    "    else:\n",
    "        processed_issue['_id'] = None\n",
    "\n",
    "    processed_issue['projectname'] = original_issue_data.get('projectname')\n",
    "    processed_issue['summary'] = original_issue_data.get('summary')\n",
    "    processed_issue['description'] = original_issue_data.get('description')\n",
    "\n",
    "    issuetype_data = original_issue_data.get(\"issuetype\")\n",
    "    if isinstance(issuetype_data, dict):\n",
    "        processed_issue[\"type_id\"] = issuetype_data.get(\"id\")\n",
    "        processed_issue[\"type_name\"] = issuetype_data.get(\"name\")\n",
    "    else:\n",
    "        processed_issue[\"type_id\"] = None\n",
    "        processed_issue[\"type_name\"] = None\n",
    "\n",
    "    priority_data = original_issue_data.get(\"priority\")\n",
    "    if isinstance(priority_data, dict):\n",
    "        processed_issue[\"priority_id\"] = priority_data.get(\"id\")\n",
    "        processed_issue[\"priority_name\"] = priority_data.get(\"name\")\n",
    "    else:\n",
    "        processed_issue[\"priority_id\"] = None\n",
    "        processed_issue[\"priority_name\"] = None\n",
    "\n",
    "    status_data = original_issue_data.get(\"status\")\n",
    "    if isinstance(status_data, dict):\n",
    "        processed_issue[\"status_id\"] = status_data.get(\"id\")\n",
    "        processed_issue[\"status_name\"] = status_data.get(\"name\")\n",
    "    else:\n",
    "        processed_issue[\"status_id\"] = None\n",
    "        processed_issue[\"status_name\"] = None\n",
    "\n",
    "    assignee_data = original_issue_data.get('assignee')\n",
    "    if isinstance(assignee_data, str):\n",
    "        processed_issue['assignee'] = assignee_data\n",
    "    elif isinstance(assignee_data, dict):\n",
    "        processed_issue['assignee'] = assignee_data.get('displayName', assignee_data.get('name'))\n",
    "    elif isinstance(assignee_data, list) and assignee_data: \n",
    "        first_assignee = assignee_data[0]\n",
    "        if isinstance(first_assignee, dict):\n",
    "            processed_issue['assignee'] = first_assignee.get('displayName', first_assignee.get('name'))\n",
    "        elif isinstance(first_assignee, str):\n",
    "            processed_issue['assignee'] = first_assignee\n",
    "        else: \n",
    "            processed_issue['assignee'] = None\n",
    "    else:\n",
    "        processed_issue['assignee'] = None\n",
    " \n",
    "    labels_data = original_issue_data.get('labels', [])\n",
    "    processed_issue[\"labels\"] = \", \".join(map(str, labels_data)) if labels_data else None\n",
    "\n",
    "    processed_issues_for_df.append(processed_issue)\n",
    "    i += 1\n",
    "    if limit and i >= limit:\n",
    "        print(f\"Processed {i} issues, stopping at limit.\")\n",
    "        break\n",
    "\n",
    "print(f\"Finished processing loop. {i} issues were processed and prepared for DataFrame.\")\n",
    "\n",
    "df_columns = [\n",
    "    '_id', 'projectname', 'assignee', 'summary', 'description', 'type_id',\n",
    "    'type_name', 'labels', 'priority_id', 'priority_name', 'status_id', 'status_name'\n",
    "]\n",
    "\n",
    "if not data_out_folder or not os.path.isdir(data_out_folder):\n",
    "    print(f\"Output directory '{data_out_folder}' is not defined or does not exist. Please create it or set the 'data_out_folder' variable.\")\n",
    "else:\n",
    "    datapath = os.path.join(data_out_folder, \"issues_limited_user_cols.csv\")\n",
    "    mongo_df = pd.DataFrame(processed_issues_for_df)\n",
    "    \n",
    "    for col in df_columns:\n",
    "        if col not in mongo_df.columns:\n",
    "            mongo_df[col] = None \n",
    "    mongo_df = mongo_df[df_columns] \n",
    "\n",
    "    print(f\"Saving {len(mongo_df)} issues to CSV: {datapath}\")\n",
    "    try:\n",
    "        mongo_df.to_csv(datapath, sep='\\t', encoding='utf-8', index=False)\n",
    "        print(f\"Successfully saved data to {datapath}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving CSV file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0dfb4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
