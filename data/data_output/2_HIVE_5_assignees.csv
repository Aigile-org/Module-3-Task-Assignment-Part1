id	title	description	project_name	status_name	priority_id	type_id	assignee_id	labels
13569844	Re-execute DAG in case of NoCurrentDAGException	This is to adapt the ReExecuteLostAMQueryPlugin to the exception introduced in TEZ-4543 to prevent scenarios when the DAGClient keeps asking for the status of a DAG that is already gone:  [^compute-1708603165-qlg5-query-coordinator-0-0-1708684369388541000.log] 	HIVE	Closed	3	4	1631	pull-request-available
13559887	Increase tez.am.resource.memory.mb for TestIcebergCliDrver to 512MB	this is HIVE-27695 for another tez drivers	HIVE	Closed	3	1	1631	pull-request-available
13563340	Set 'tez' as default value in hive.execution.engine	"Maybe this is not the first ticket addressing this, please link if it's a duplicate.
We need to set this to 'tez' to reflect that we have deprecated 'mr':
https://github.com/apache/hive/blob/bd16e0098916aa5fc2dede99492c6a240b51e677/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java#L4567

I'm expecting lots of UT failures because of this, as we're still running those on mr (which might be fine where the actual unit test is not closely related to the execution engine), so we'll see what to do.
"	HIVE	Resolved	3	7	1631	pull-request-available
13558460	LLAP: Reuse FileSystem objects from cache across different tasks in the same LLAP daemon	"Originally, when the task runner was added to HIVE-10028 ([here|https://github.com/apache/hive/blob/23f40bd88043db3cb4efe3a763cbfd5c01a81d2f/llap-server/src/java/org/apache/hadoop/hive/llap/daemon/impl/TaskRunnerCallable.java#L202]), the FileSystem.closeAllForUGI was commented out for some reasons, and then, in the scope of HIVE-9898 it was simply added back, [here|https://github.com/apache/hive/commit/91c46a44dd9fbb68d01f22e93c4ce0931a4598e0#diff-270dbe6639879ca543ae21c44a239af6145390726d45fee832be809894bfc88eR236]

A FileSystem.close call basically does the [following|https://github.com/apache/hadoop/blob/0c10bab7bb77aa4ea3ca26c899ab28131561e052/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileSystem.java#L2700-L2710]:
1. delete all paths that were marked as delete-on-exit.
2. removes the instance from the cache

I saw that we [call|https://github.com/apache/hive/blob/eb6f0b0c57dd55335927b7dde08cd47f4d00e74d/llap-server/src/java/org/apache/hadoop/hive/llap/daemon/impl/TaskRunnerCallable.java#L302]
{code:java}
FileSystem.closeAllForUGI
{code}
at the end of all task attempts, so we almost completely disable hadoop's filesystem cache during a long-running LLAP daemon lifecycle

some investigations on azure showed that creating a filesystem can be quite expensive, as it involves the recreation of a whole object hierarchy like:
{code:java}
AzureBlobFileSystem -> AzureBlobFileSystemStore --> AbfsClient -> TokenProvider(MsiTokenProvider)
{code}
which ends up pinging the token auth endpoint of azure, leading to e.g. a HTTP response 429

the other area that's really affected by this patch is the aws sdk v2, where we discovered performance degradation (github issues also imply this problem), look at:
!Screenshot 2024-07-30 at 10.18.13.png|width=808,height=425!

this screenshot is just for reference: I mean it doesn't prove the perf degradation (because it was only visible with wall clock profiling), but the problematic codepath (which was introduced in aws sdk v2) is visible here





additionally: deleteOnExit, please refer to HIVE-28335

We need to check whether we can remove this closeAllForUGI in LLAP, additionally check and remove all deleteOnExit calls that belong to hadoop FileSystem objects (doesn't necessarily apply to java.io.File.deleteOnExit calls):
{code:java}
grep -iRH ""deleteOnExit"" --include=""*.java"" | grep -v ""test""
...
ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java:        // in recent hadoop versions, use deleteOnExit to clean tmp files.
ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java:        autoDelete = fs.deleteOnExit(fsp.outPaths[filesIdx]);
ql/src/java/org/apache/hadoop/hive/ql/exec/repl/bootstrap/load/util/PathInfo.java:        fileSystem.deleteOnExit(dir);
ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/RowContainer.java:      parentDir.deleteOnExit();
ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/RowContainer.java:      tmpFile.deleteOnExit();
ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/KeyValueContainer.java:        parentDir.deleteOnExit();
ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/KeyValueContainer.java:        tmpFile.deleteOnExit();
ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/ObjectContainer.java:        tmpFile.deleteOnExit();
ql/src/java/org/apache/hadoop/hive/ql/exec/AbstractFileMergeOperator.java:        autoDelete = fs.deleteOnExit(outPath);
{code}
I believe deleteOnExit is fine if we don't want to bother with removing temp files, however, these deletions might want to go to a more hive-specific scope if we want to really reuse cached filesystems in a safe manner."	HIVE	Resolved	3	4	1631	pull-request-available
13573888	HiveSplitGenerator: send splits through filesystem instead of RPC in case of big payload	"After some investigations regarding hive iceberg issues, it turned out that in the presence of delete files, the serialized payload might be huge, like 1-4MB / split, which might lead to extreme memory pressure in the Tez AM, getting worse when having more and more splits.

Optimizing the payload is always the best option but it's not that obvious: instead, we should make hive and tez together take care of such situations without running into OOMs like this below:
{code}
ERROR : FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.tez.TezTask. Vertex failed, vertexName=Map 1, vertexId=vertex_1711290808080_0000_4_00, diagnostics=[Vertex vertex_1711290808080_0000_4_00 [Map 1] killed/failed due to:ROOT_INPUT_INIT_FAILURE, Vertex Input: web_sales_1 initializer failed, vertex=vertex_1711290808080_0000_4_00 [Map 1], java.lang.OutOfMemoryError: Java heap space
	at com.google.protobuf.ByteString$CodedBuilder.<init>(ByteString.java:907)
	at com.google.protobuf.ByteString$CodedBuilder.<init>(ByteString.java:902)
	at com.google.protobuf.ByteString.newCodedBuilder(ByteString.java:898)
	at com.google.protobuf.AbstractMessageLite.toByteString(AbstractMessageLite.java:49)
	at org.apache.hadoop.hive.ql.exec.tez.HiveSplitGenerator.createEventList(HiveSplitGenerator.java:378)
	at org.apache.hadoop.hive.ql.exec.tez.HiveSplitGenerator.initialize(HiveSplitGenerator.java:337)
	at org.apache.tez.dag.app.dag.RootInputInitializerManager.lambda$runInitializer$3(RootInputInitializerManager.java:199)
	at org.apache.tez.dag.app.dag.RootInputInitializerManager$$Lambda$319/0x0000000840942440.run(Unknown Source)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.tez.dag.app.dag.RootInputInitializerManager.runInitializer(RootInputInitializerManager.java:192)
	at org.apache.tez.dag.app.dag.RootInputInitializerManager.runInitializerAndProcessResult(RootInputInitializerManager.java:173)
	at org.apache.tez.dag.app.dag.RootInputInitializerManager.lambda$createAndStartInitializing$2(RootInputInitializerManager.java:167)
	at org.apache.tez.dag.app.dag.RootInputInitializerManager$$Lambda$318/0x0000000840942040.run(Unknown Source)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at com.google.common.util.concurrent.TrustedListenableFutureTask$TrustedFutureInterruptibleTask.runInterruptibly(TrustedListenableFutureTask.java:125)
	at com.google.common.util.concurrent.InterruptibleTask.run(InterruptibleTask.java:69)
	at com.google.common.util.concurrent.TrustedListenableFutureTask.run(TrustedListenableFutureTask.java:78)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
{code}"	HIVE	Resolved	3	4	1631	pull-request-available
13417429	Possible leak in LlapCacheAwareFs - Parquet, LLAP IO	"there is an inputstream there which is never closed:
https://github.com/apache/hive/blob/9f9844dbc881e2a9267c259b8c04e7787f7fadc4/ql/src/java/org/apache/hadoop/hive/llap/LlapCacheAwareFs.java#L243

my understanding is that in an InputStream chain, every InputStream is responsible for closing its enclosed InputStream, here the chain is like:
DelegatingSeekableInputStream -> io.DataInputStream -> LlapCacheAwareFs$CacheAwareInputStream -> io.DataInputStream -> crypto.CryptoInputStream -> hdfs.DFSInputStream

{code}
	at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:106)
	at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60)
	at java.nio.channels.SocketChannel.open(SocketChannel.java:145)
	at org.apache.hadoop.net.StandardSocketFactory.createSocket(StandardSocketFactory.java:62)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2933)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:644)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:575)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:757)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:836)
	at org.apache.hadoop.crypto.CryptoInputStream.read(CryptoInputStream.java:183)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at org.apache.hadoop.hive.llap.LlapCacheAwareFs$CacheAwareInputStream.read(LlapCacheAwareFs.java:264)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.parquet.io.DelegatingSeekableInputStream.readFully(DelegatingSeekableInputStream.java:102)
	at org.apache.parquet.io.DelegatingSeekableInputStream.readFullyHeapBuffer(DelegatingSeekableInputStream.java:127)
	at org.apache.parquet.io.DelegatingSeekableInputStream.readFully(DelegatingSeekableInputStream.java:91)
	at org.apache.parquet.hadoop.ParquetFileReader$ConsecutiveChunkList.readAll(ParquetFileReader.java:1174)
	at org.apache.parquet.hadoop.ParquetFileReader.readNextRowGroup(ParquetFileReader.java:805)
	at org.apache.hadoop.hive.ql.io.parquet.vector.VectorizedParquetRecordReader.checkEndOfRowGroup(VectorizedParquetRecordReader.java:429)
	at org.apache.hadoop.hive.ql.io.parquet.vector.VectorizedParquetRecordReader.nextBatch(VectorizedParquetRecordReader.java:407)
	at org.apache.hadoop.hive.ql.io.parquet.vector.VectorizedParquetRecordReader.next(VectorizedParquetRecordReader.java:359)
	at org.apache.hadoop.hive.ql.io.parquet.vector.VectorizedParquetRecordReader.next(VectorizedParquetRecordReader.java:93)
	at org.apache.hadoop.hive.ql.io.HiveContextAwareRecordReader.doNext(HiveContextAwareRecordReader.java:361)
	at org.apache.hadoop.hive.ql.io.HiveRecordReader.doNext(HiveRecordReader.java:79)
	at org.apache.hadoop.hive.ql.io.HiveRecordReader.doNext(HiveRecordReader.java:33)
	at org.apache.hadoop.hive.ql.io.HiveContextAwareRecordReader.next(HiveContextAwareRecordReader.java:117)
	at org.apache.hadoop.mapred.split.TezGroupedSplitsInputFormat$TezGroupedSplitsRecordReader.next(TezGroupedSplitsInputFormat.java:151)
	at org.apache.tez.mapreduce.lib.MRReaderMapred.next(MRReaderMapred.java:116)
	at org.apache.hadoop.hive.ql.exec.tez.MapRecordSource.pushRecord(MapRecordSource.java:68)
	at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.run(MapRecordProcessor.java:426)
	at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:267)
	at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:250)
	at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:374)
	at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:73)
	at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:61)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:61)
	at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:37)
	at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)
	at org.apache.hadoop.hive.llap.daemon.impl.StatsRecordingThreadPool$WrappedCallable.call(StatsRecordingThreadPool.java:118)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
{code}

usually, streams have the enclosed stream as a field in order to have a reference for the time they want to close it, but here LlapCacheAwareFs$CacheAwareInputStream.read opens a DataInputStream which is never closed, only used in the read method, which is suspicious to me"	HIVE	Closed	3	1	1631	pull-request-available
13554237	Simplify TestTezSessionState.testSymlinkedLocalFilesAreLocalizedOnce	"The unit test added in HIVE-27723 is overcomplicated: there is no need to mock a session pool manager to get a TezSessionState.
We need to simply instantiate TezSessionState directly."	HIVE	Closed	3	4	1631	pull-request-available
13414492	Ignore exceptions related to interruption when the limit is reached	The problem is well described on TEZ-4356, but it will be handled from hive instead.	HIVE	Closed	3	1	1631	pull-request-available
13404433	Put dagId to MDC once it's available in HS2	"This is about putting dagID to MDC once the DAG is submitted. This way, dagId can be easily appended to log messages by log4j.
Like:
{code}
hiveserver2 <14>1 2022-10-25T10:51:05.496Z hiveserver2-0 hiveserver2 1 24a33001-3523-415b-a6a8-7733708507af [mdc@18060 class=""monitoring.RenderStrategy$LogToFileFunction"" dagId=""dag_1666694252139_0000_3"" level=""INFO"" operationLogLevel=""EXECUTION"" queryId=""hive_20221025105055_ec8135b4-1b0e-46b8-bb3f-4b58b41cf53b"" sessionId=""6fc7adf6-d3b0-470a-813f-03c79a0ca20d"" thread=""HiveServer2-Background-Pool: Thread-196""] Map 1: 1/1    Map 2: 0(+11)/208    Map 7: 1/1    Map 8: 12(+11)/23    Map 9: 1/1    Reducer 3: 0/738    Reducer 4: 0/642    Reducer 5: 0/1    Reducer 6: 0/782    
{code}"	HIVE	Closed	3	4	1631	pull-request-available
13479070	Improve TestHiveMetastore	"{code}
    Thread.sleep(5 * 1000); // give HMS time to handle close request
    int numObjectsAfterClose =  getJDOPersistanceManagerCacheSize();
    assertTrue(numObjectsBeforeClose == numObjectsAfterClose);
{code}

1. easy fix:     assertTrue(numObjectsBeforeClose == numObjectsAfterClose);
this tells nothing in case of assertionerror:
{code}
java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:87)
	at org.junit.Assert.assertTrue(Assert.java:42)
	at org.junit.Assert.assertTrue(Assert.java:53)
	at org.apache.hadoop.hive.metastore.TestHiveMetaStore.testJDOPersistanceManagerCleanup(TestHiveMetaStore.java:3298)
{code}
should tell a more informative message with particular values

2. harder fix, maybe do it later
{code}
Thread.sleep(5 * 1000); // give HMS time to handle close request
{code}
sleep is always dangerous, cannot make sure it handled everything that we expected
"	HIVE	Closed	3	4	1631	pull-request-available
13426786	Let secret config properties to be propagated to Tez	"History in chronological order:
HIVE-10508: removed some passwords from config that's propagated to execution engines
HIVE-9013: introduced hive.conf.hidden.list, which is used instead of the hardcoded list in HIVE-10508

the problem with HIVE-9013 is it's about to introduce a common method for removing sensitive data from Configuration, which absolutely makes sense in most of the cases (set command showing sensitive data), but can cause issues e.g. while using non-secure cloud connectors on a cluster, where instead of the hadoop credential provider API (which is considered the secure and proper way), passwords/secrets appear in the Configuration object (like: ""fs.azure.account.oauth2.client.secret"")

2 possible solutions:
1. introduce a new property like: ""hive.conf.hidden.list.exec.engines"" -> which defaults to ""hive.conf.hidden.list"" (configurable, but maybe just more confusing to users, having a new config property which should be understood and maintained on a cluster)
2. simply revert DAGUtils to use to old stripHivePasswordDetails introduced by HIVE-10508 (convenient, less confusing for users, but cannot be configured)
"	HIVE	Resolved	3	1	1631	pull-request-available
13107242	remove sun.misc.Cleaner references	"according to: https://github.com/apache/hive/blob/188f7fb47aec3f98ef53965ba6ae84e23bd26f59/llap-server/src/java/org/apache/hadoop/hive/llap/cache/SimpleAllocator.java#L36

HADOOP-12760 will be the long term fix
"	HIVE	Closed	3	7	1631	pull-request-available
13551513	TestMiniTezCliDriver: save application logs for failed tests	"1. locate tez app logs for a TestMiniTezCliDriver test
{code}
ls -laR itests/qtest/target/tmp/hive/yarn-*/hive-logDir-nm-*
{code}
2. add them similarly to HIVE-27716
important to note that tez app logs files are not specific to a particular test, so we can collect those for the whole module in case of an error"	HIVE	In Progress	3	7	1631	pull-request-available
13577016	Print Tez summary by default in tests	"This is to set ""hive.tez.exec.print.summary"" by default in tests, which is quite useful.

{code}
INFO  : Query Execution Summary
INFO  : ----------------------------------------------------------------------------------------------
INFO  : OPERATION                            DURATION
INFO  : ----------------------------------------------------------------------------------------------
INFO  : Compile Query                           2.12s
INFO  : Prepare Plan                            8.65s
INFO  : Get Query Coordinator (AM)              0.01s
INFO  : Submit Plan                             0.57s
INFO  : Start DAG                               0.04s
INFO  : Run DAG                                 8.86s
INFO  : ----------------------------------------------------------------------------------------------
INFO  :
...
{code}

"	HIVE	Resolved	3	4	1631	pull-request-available
13416445	CombineHiveRecordReader: log statements in a loop leads to memory pressure	"Similar to HIVE-16150, a huge string will be built in a loop, even the log level is INFO. That leads to memory pressure when processing a big number of split files. 

From [CombineHiveRecordReader.java|https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/io/CombineHiveRecordReader.java#L116], the following needs to be fixed.



LOG.debug(""Found spec for "" + path + "" "" + otherPart + "" from "" + pathToPartInfo);


{code}
""TezChild"" #26 daemon prio=5 os_prio=0 tid=0x00007f5fd1716000 nid=0x2118a runnable [0x00007f5f8c411000]
   java.lang.Thread.State: RUNNABLE
	at java.lang.String.valueOf(String.java:2994)
	at java.lang.StringBuilder.append(StringBuilder.java:131)
	at java.util.AbstractMap.toString(AbstractMap.java:557)
	at java.lang.String.valueOf(String.java:2994)
	at java.lang.StringBuilder.append(StringBuilder.java:131)
	at org.apache.hadoop.hive.ql.io.CombineHiveRecordReader.extractSinglePartSpec(CombineHiveRecordReader.java:119)
	at org.apache.hadoop.hive.ql.io.CombineHiveRecordReader.<init>(CombineHiveRecordReader.java:88)
	at sun.reflect.GeneratedConstructorAccessor22.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileRecordReader.initNextRecordReader(HadoopShimsSecure.java:257)
	at org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileRecordReader.next(HadoopShimsSecure.java:144)
	at org.apache.tez.mapreduce.lib.MRReaderMapred.next(MRReaderMapred.java:116)
	at org.apache.hadoop.hive.ql.exec.tez.MergeFileRecordProcessor.run(MergeFileRecordProcessor.java:153)
	at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:267)
	at org.apache.hadoop.hive.ql.exec.tez.MergeFileTezProcessor.run(MergeFileTezProcessor.java:42)
	at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:374)
	at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:73)
	at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:61)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:61)
	at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:37)
	at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)
	at com.google.common.util.concurrent.TrustedListenableFutureTask$TrustedFutureInterruptibleTask.runInterruptibly(TrustedListenableFutureTask.java:125)
	at com.google.common.util.concurrent.InterruptibleTask.run(InterruptibleTask.java:69)
	at com.google.common.util.concurrent.TrustedListenableFutureTask.run(TrustedListenableFutureTask.java:78)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

{code}"	HIVE	Closed	3	1	1631	pull-request-available
13566248	Move checkLock method to TestTxnDbUtil	"Referring to a method from a different unit test class is crazy, we need to move it.
When calling a method like TestDbTxnManager2.checkLock, the @ClassRule of TestDbTxnManager2 is called which can potentially screw up things, so this is kind of blocking some stuff in HIVE-27972 as well. Unit test classes should only depend on each other in the same inheritance chain."	HIVE	Resolved	3	4	1631	pull-request-available
13594284	Eliminate a lot of metrics null check from LlapTaskSchedulerService	There are ~30 null checks in LlapTaskSchedulerService, which is more like a boilerplate. A metric collector could be a no-op dummy one in this case.	HIVE	In Progress	3	4	1631	pull-request-available
13376344	Introduce a reusable and configurable periodic/logarithmic logger with stopwatch	"This is for reusing the logic from [FileSinkOperator|https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java]:

{code}
if ((++numRows == cntr) && LOG.isInfoEnabled()) {
 cntr = logEveryNRows == 0 ? cntr * 10 : numRows + logEveryNRows;
 if (cntr < 0 || numRows < 0) {
 cntr = 0;
 numRows = 1;
 }
 LOG.info(toString() + "": records written - "" + numRows);
}

{code}

which results in:

{code}
2021-04-29 10:29:38,199 [INFO] [TezChild] |exec.FileSinkOperator|: FS[8]: records written - 1
2021-04-29 10:29:38,201 [INFO] [TezChild] |exec.FileSinkOperator|: FS[8]: records written - 10
2021-04-29 10:29:38,216 [INFO] [TezChild] |exec.FileSinkOperator|: FS[8]: records written - 100
{code}"	HIVE	Open	3	4	1631	pull-request-available
13472857	Configurable timeout for HiveSplitGenerator to wait for LLAP instances	"In some circumstances we cannot guarantee that LLAP daemons are ready as soon as Tez AMs, but don't want the query to fail immediately with:
{code}
Caused by: java.lang.IllegalArgumentException: No running LLAP daemons! Please check LLAP service status and zookeeper configuration
    com.google.common.base.Preconditions.checkArgument(Preconditions.java:142)
    org.apache.hadoop.hive.ql.exec.tez.Utils.getCustomSplitLocationProvider(Utils.java:105)
    org.apache.hadoop.hive.ql.exec.tez.Utils.getSplitLocationProvider(Utils.java:77)
    org.apache.hadoop.hive.ql.exec.tez.HiveSplitGenerator.<init>(HiveSplitGenerator.java:147)
    19 more
{code}"	HIVE	Closed	3	4	1631	pull-request-available
13581953	Save query error message on Driver level	"current call path is *SQLOperation -> Driver.run*

Instead of just throwing CommandProcessorException, Driver might save the the error message for query-tracking purposes, this is a single message for later reference, like:
{code}
FAILED: SemanticException [Error 10001]: Line 1:14 Table not found 'abcd'
{code}

2 ways to achieve this

1. wrap every occurrence of throwing CommandProcessorException inside driver
e.g. https://github.com/apache/hive/blob/98d9d22398370f817fe64449368671b978fff096/ql/src/java/org/apache/hadoop/hive/ql/Driver.java#L146
PRO: storing of error message stays inside the Driver (SQLCommand doesn't need to know about it)
CONS: looks a bit worse, not future-proof (later, anyone can miss this call while throwing a cpe), needs Driver code changes at several places

2. catch in SQLOperation and propagate back to Driver
https://github.com/apache/hive/blob/98d9d22398370f817fe64449368671b978fff096/service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java#L237
PRO: maybe it looks better, every exception can be caught in a single place 
CON: it looks weird, because SQLOperation has to call back to the driver to store the error message (which was already passed through the driver)"	HIVE	Resolved	3	4	1631	pull-request-available
13318187	Bloom filters can be merged in a parallel way in VectorUDAFBloomFilterMerge	"Merging bloom filters in semijoin reduction can become the main bottleneck in case of large number of source mapper tasks (~1000, Map 1 in below example) and a large amount of expected entries (50M) in bloom filters.

For example in TPCDS Q93:
{code}
select /*+ semi(store_returns, sr_item_sk, store_sales, 70000000)*/ ss_customer_sk
            ,sum(act_sales) sumsales
      from (select ss_item_sk
                  ,ss_ticket_number
                  ,ss_customer_sk
                  ,case when sr_return_quantity is not null then (ss_quantity-sr_return_quantity)*ss_sales_price
                                                            else (ss_quantity*ss_sales_price) end act_sales
            from store_sales left outer join store_returns on (sr_item_sk = ss_item_sk
                                                               and sr_ticket_number = ss_ticket_number)
                ,reason
            where sr_reason_sk = r_reason_sk
              and r_reason_desc = 'reason 66') t
      group by ss_customer_sk
      order by sumsales, ss_customer_sk
limit 100;
{code}

On 10TB-30TB scale there is a chance that from 3-4 mins of query runtime 1-2 mins are spent with merging bloom filters (Reducer 2), as in:  [^lipwig-output3605036885489193068.svg] 

{code}
----------------------------------------------------------------------------------------------
        VERTICES      MODE        STATUS  TOTAL  COMPLETED  RUNNING  PENDING  FAILED  KILLED
----------------------------------------------------------------------------------------------
Map 3 ..........      llap     SUCCEEDED      1          1        0        0       0       0
Map 1 ..........      llap     SUCCEEDED   1263       1263        0        0       0       0
Reducer 2             llap       RUNNING      1          0        1        0       0       0
Map 4                 llap       RUNNING   6154          0      207     5947       0       0
Reducer 5             llap        INITED     43          0        0       43       0       0
Reducer 6             llap        INITED      1          0        0        1       0       0
----------------------------------------------------------------------------------------------
VERTICES: 02/06  [====>>----------------------] 16%   ELAPSED TIME: 149.98 s
----------------------------------------------------------------------------------------------
{code}

For example, 70M entries in bloom filter leads to a 436 465 696 bits, so merging 1263 bloom filters means running ~ 1263 * 436 465 696 bitwise OR operation, which is very hot codepath, but can be parallelized.
"	HIVE	Closed	3	4	1631	pull-request-available
13567418	Bump com.jayway.jsonpath:json-path from 2.8.0 to 2.9.0	"thanks dependabot
https://github.com/apache/hive/pull/5020"	HIVE	Closed	3	4	1631	pull-request-available
13436416	TestIcebergCliDriver must have an object cache	"Similarly to TestMiniTezCliDriver, otherwise limit queries fail:
{code}
    // create a new object cache for tez-based tests which rely on that
    ObjectCache.setupObjectRegistry(new ObjectRegistryImpl());
{code}"	HIVE	Open	3	1	1631	pull-request-available
13551510	Precommit: Save log files for first 10 failures	"This is about to simply applying https://github.com/kgyrtkirk/hive-test-kube/pull/11 to hive's master [Jenkinsfile|https://github.com/apache/hive/blob/master/Jenkinsfile]
current artifacts are simply useless, flaky tests are impossible to investigate (no, they don't reproduce in flaky-check, damn)

looks like the job simply picks up Jenkinsfile from the root: http://ci.hive.apache.org/job/hive-precommit/configure
 !Screenshot 2023-09-21 at 11.49.16.png! "	HIVE	Closed	3	7	1631	pull-request-available
13357879	 StringValueBoundaryScanner ignores boundary which leads to incorrect results	"https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/udf/ptf/ValueBoundaryScanner.java#L901
{code}
  public boolean isDistanceGreater(Object v1, Object v2, int amt) {
    ...
    return s1 != null && s2 != null && s1.compareTo(s2) > 0;
{code}

Like other boundary scanners, StringValueBoundaryScanner should take amt into account, otherwise it'll result in the same range regardless of the given window size. This typically affects queries where the range is defined on a string column:
{code}
select p_mfgr, p_name, p_retailprice,
count(*) over(partition by p_mfgr order by p_name range between 1 preceding and current row) as cs1,
count(*) over(partition by p_mfgr order by p_name range between 3 preceding and current row) as cs2
from vector_ptf_part_simple_orc;
{code} 

with ""> 0"" cs1 and cs2 will be calculated on the same window, so cs1 == cs2, but actually it should be different, this is the correct result (see ""almond antique olive coral navajo""):

{code}
+-----------------+---------------------------------------------+------+------+
|     p_mfgr      |                   p_name                    | cs1  | cs2  |
+-----------------+---------------------------------------------+------+------+
| Manufacturer#1  | almond antique burnished rose metallic      | 2    | 2    |
| Manufacturer#1  | almond antique burnished rose metallic      | 2    | 2    |
| Manufacturer#1  | almond antique chartreuse lavender yellow   | 6    | 6    |
| Manufacturer#1  | almond antique chartreuse lavender yellow   | 6    | 6    |
| Manufacturer#1  | almond antique chartreuse lavender yellow   | 6    | 6    |
| Manufacturer#1  | almond antique chartreuse lavender yellow   | 6    | 6    |
| Manufacturer#1  | almond antique salmon chartreuse burlywood  | 1    | 1    |
| Manufacturer#1  | almond aquamarine burnished black steel     | 1    | 8    |
| Manufacturer#1  | almond aquamarine pink moccasin thistle     | 4    | 4    |
| Manufacturer#1  | almond aquamarine pink moccasin thistle     | 4    | 4    |
| Manufacturer#1  | almond aquamarine pink moccasin thistle     | 4    | 4    |
| Manufacturer#1  | almond aquamarine pink moccasin thistle     | 4    | 4    |
| Manufacturer#2  | almond antique violet chocolate turquoise   | 1    | 1    |
| Manufacturer#2  | almond antique violet turquoise frosted     | 3    | 3    |
| Manufacturer#2  | almond antique violet turquoise frosted     | 3    | 3    |
| Manufacturer#2  | almond antique violet turquoise frosted     | 3    | 3    |
| Manufacturer#2  | almond aquamarine midnight light salmon     | 1    | 5    |
| Manufacturer#2  | almond aquamarine rose maroon antique       | 2    | 2    |
| Manufacturer#2  | almond aquamarine rose maroon antique       | 2    | 2    |
| Manufacturer#2  | almond aquamarine sandy cyan gainsboro      | 3    | 3    |
| Manufacturer#3  | almond antique chartreuse khaki white       | 1    | 1    |
| Manufacturer#3  | almond antique forest lavender goldenrod    | 4    | 5    |
| Manufacturer#3  | almond antique forest lavender goldenrod    | 4    | 5    |
| Manufacturer#3  | almond antique forest lavender goldenrod    | 4    | 5    |
| Manufacturer#3  | almond antique forest lavender goldenrod    | 4    | 5    |
| Manufacturer#3  | almond antique metallic orange dim          | 1    | 1    |
| Manufacturer#3  | almond antique misty red olive              | 1    | 1    |
| Manufacturer#3  | almond antique olive coral navajo           | 1    | 3    |
| Manufacturer#4  | almond antique gainsboro frosted violet     | 1    | 1    |
| Manufacturer#4  | almond antique violet mint lemon            | 1    | 1    |
| Manufacturer#4  | almond aquamarine floral ivory bisque       | 2    | 4    |
| Manufacturer#4  | almond aquamarine floral ivory bisque       | 2    | 4    |
| Manufacturer#4  | almond aquamarine yellow dodger mint        | 1    | 1    |
| Manufacturer#4  | almond azure aquamarine papaya violet       | 1    | 1    |
| Manufacturer#5  | almond antique blue firebrick mint          | 1    | 1    |
| Manufacturer#5  | almond antique medium spring khaki          | 2    | 2    |
| Manufacturer#5  | almond antique medium spring khaki          | 2    | 2    |
| Manufacturer#5  | almond antique sky peru orange              | 1    | 1    |
| Manufacturer#5  | almond aquamarine dodger light gainsboro    | 1    | 5    |
| Manufacturer#5  | almond azure blanched chiffon midnight      | 1    | 1    |
+-----------------+---------------------------------------------+------+------+
{code}"	HIVE	Open	3	1	1631	pull-request-available
13356520	Shims classes override values from hive-site.xml and tez-site.xml silently	"Since HIVE-14887, [Hadoop23Shims|https://github.com/apache/hive/blob/master/shims/0.23/src/main/java/org/apache/hadoop/hive/shims/Hadoop23Shims.java] silently overrides e.g. hive.tez.container.size which is defined in data/conf/hive/llap/hive-site.xml. This way, the developer will have no idea about what happened after setting those values in the xml.
My proposal: 
1. don't set those values, unless they contain the default value (e.g.: -1 for hive.tez.container.size)
2. put an INFO level log message about the override

OR:

put a comment in hive-site.xml and tez-site.xml files that shims override it while creating a tez mini cluster
"	HIVE	Closed	3	1	1631	pull-request-available
13399557	Provide a configurable filter for removing useless properties from PartitionDesc objects before MapWork serialization	"This is due to performance considerations. When a large amount of partitions is present in MapWork, serializing useless properties (coming from metastore as a partititon metadata) could become a bottleneck, which can even lead to OOM in Tez AM if the dag plan becomes large.
"	HIVE	Closed	3	4	1631	pull-request-available
13382317	HiveQueryResultSet and client operation are not expected to be closed twice	"While testing retry scenarios of HIVE-24786, we found that HiveQueryResultSet.close() is called twice, which is not expected. There are 2 different issues here:

1. ResultSet should not handle Statement as in HiveQueryResultSet:
{code}
    if (this.statement != null && (this.statement instanceof HiveStatement)) {
      HiveStatement s = (HiveStatement) this.statement;
      s.closeClientOperation();
{code}
The hiearchy of Connection(HiveConnection) -> Statement(HiveStatement) -> ResultSet(HiveQueryResultSet) should be respected in a sense that the parent can handle child but not the opposite way, only except a single case, where the state of the result set has an effect on statement's state, which is [Statement.closeOnCompletion|https://docs.oracle.com/javase/7/docs/api/java/sql/Statement.html#closeOnCompletion()], which was introduced by HIVE-22698.
The above logic was introduced by [HIVE-4974|https://github.com/apache/hive/blame/master/jdbc/src/java/org/apache/hive/jdbc/HiveQueryResultSet.java#L276]. Its intention was to make children able to return their parents, but that doesn't mean they should handle their parents' lifecycle.

2. Also, HiveStatement should close HiveQueryResultSet only if it's not already closed, so it would make sense to check ResultSet.isClosed() before closing. This is for the very same reason as another change above, to avoid duplicated close logic. 

Background: under normal circumstances, a close operation is idempotent, we should not worry about any side effects of calling it twice, but while testing HIVE-24786, we found strange issues where in case of a SocketTimeoutException, such code path was hit in the jdbc client, that made HiveStatement.closeClientOperation() to be called twice, and it led to a WARNING on HS2 side. This is not expected as the operation close is protected by stmtHandle != null check, but yet it ran twice. To avoid situations like this, cleaning up duplicated close calls would help."	HIVE	Closed	3	1	1631	pull-request-available
13346328	jdbc.HiveStatement: Number of rows is greater than Integer.MAX_VALUE	"I found this while IOW on TPCDS 10TB:

{code}
----------------------------------------------------------------------------------------------
        VERTICES      MODE        STATUS  TOTAL  COMPLETED  RUNNING  PENDING  FAILED  KILLED
----------------------------------------------------------------------------------------------
Map 1 ..........      llap     SUCCEEDED   4210       4210        0        0       0     362
Reducer 2 ......      llap     SUCCEEDED    101        101        0        0       0       2
Reducer 3 ......      llap     SUCCEEDED   1009       1009        0        0       0       1
----------------------------------------------------------------------------------------------
VERTICES: 03/03  [==========================>>] 100%  ELAPSED TIME: 12613.62 s
----------------------------------------------------------------------------------------------
20/12/16 01:37:36 [main]: WARN jdbc.HiveStatement: Number of rows is greater than Integer.MAX_VALUE
{code}

my scenario was:
{code}
set hive.exec.max.dynamic.partitions=2000;
drop table if exists test_sales_2;
create table test_sales_2 like tpcds_bin_partitioned_acid_orc_10000.store_sales;
insert overwrite table test_sales_2 select * from tpcds_bin_partitioned_acid_orc_10000.store_sales where ss_sold_date_sk > 2451868;
{code}

regarding affected row numbers:
{code}
select count(*) from tpcds_bin_partitioned_acid_orc_10000.store_sales where ss_sold_date_sk > 2451868;
+--------------+
|     _c0      |
+--------------+
| 12287871907  |
+--------------+
{code}

I guess we should switch to long"	HIVE	Open	4	1	1631	pull-request-available
13486613	ConstantVectorExpression and ExplainTask shouldn't rely on default charset	"In HS2 (and other components) we rely on UTF8 encoding, hence while storing strings as bytes, we store the UTF8-encoded bytes. Some java APIs rely on default system encoding in different ways, which can lead to incorrect encoding (if system settings defaults other than UTF8). This patch intends to fix 2 different paths:

1. ConstantVectorExpression
in my case, this:
{code}
LOG.info(""default charset name: "" + java.nio.charset.Charset.defaultCharset().name());
LOG.info(""getBytes() = "" + ((String) constantValue).getBytes());
LOG.info(""getBytes(StandardCharsets.UTF_8) = "" + ((String) constantValue).getBytes(StandardCharsets.UTF_8));
{code}
led to:
{code}
default charset name: US-ASCII
getBytes() = [B@73dcffb0
getBytes(StandardCharsets.UTF_8) = [B@2ead0b9c
{code}

on the customer side, queries returned wrong results when the filter contained the special character (which is part of UTF8 character table):
{code}
SELECT b FROM default.rlv_test1 where b='北京';
....
??
{code}


2. Explain
Similarly, explain printed to a PrintStream of different encoding, leading to a plan like:
{code}
	            Map Operator Tree:
	                TableScan
	                  alias: test_table
	                  filterExpr: (b = '??') (type: boolean)
	                  Statistics: Num rows: 2 Data size: 352 Basic stats: COMPLETE Column stats: COMPLETE
	                  Filter Operator
	                    predicate: (b = '??') (type: boolean)
	                    Statistics: Num rows: 2 Data size: 352 Basic stats: COMPLETE Column stats: COMPLETE
	                    Select Operator
	                      expressions: a (type: int), '??' (type: string), c (type: string)
{code}"	HIVE	Closed	3	1	1631	pull-request-available
13412070	ShuffleHandler: Make sure of properly releasing netty reference counted objects	"https://netty.io/wiki/reference-counted-objects.html

ShuffleHandler log contains issues below when we're on unhappy codepath (sendError). Very easily reproducible e.g. with calling ShuffleHandler's http port without any parameters. Doesn't cause a user-facing issue, because at this point ShuffleHandler already responded to the client, but the exception is annoying and implies invalid .release() calls in netty4.

{code}
io.netty.util.IllegalReferenceCountException: refCnt: 0, decrement: 1
	at io.netty.util.internal.ReferenceCountUpdater.toLiveRealRefCnt(ReferenceCountUpdater.java:74) ~[netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.util.internal.ReferenceCountUpdater.release(ReferenceCountUpdater.java:138) ~[netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.buffer.AbstractReferenceCountedByteBuf.release(AbstractReferenceCountedByteBuf.java:100) ~[netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.handler.codec.http.DefaultFullHttpResponse.release(DefaultFullHttpResponse.java:116) ~[netty-all-4.1.65.Final.jar:4.1.65.Final]
	at org.apache.hadoop.hive.llap.shufflehandler.ShuffleHandler$Shuffle.sendError(ShuffleHandler.java:1056) ~[classes/:?]
	at org.apache.hadoop.hive.llap.shufflehandler.ShuffleHandler$Shuffle.handleRequest(ShuffleHandler.java:827) ~[classes/:?]
	at org.apache.hadoop.hive.llap.shufflehandler.ShuffleHandler$Shuffle.channelRead(ShuffleHandler.java:728) ~[classes/:?]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) [netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) [netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) [netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103) [netty-all-4.1.65.Final.jar:4.1.65.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) [netty-all-4.1.65.Final.jar:4.1.65.Final]
{code}
"	HIVE	Closed	3	1	1631	pull-request-available
13367236	Operator.setDone() short-circuit from child op is not used in vectorized codepath (if childSize == 1)	"This looks like a possible performance regression in case of limit, considering the following query:
{code}
explain vectorization detail select
  ws_item_sk item_sk, d_date,
  sum(ws_sales_price) over (partition by ws_item_sk order by d_date range between 10 preceding and current row) cume_sales,
  last_value(ws_sales_price) over (partition by ws_item_sk order by d_date range between 10 preceding and current row) last_price
from web_sales
    ,date_dim
where ws_sold_date_sk=d_date_sk
  and d_month_seq between 1214 and 1214+11
  and ws_item_sk is not NULL
group by ws_item_sk, d_date, ws_sales_price
limit 100;
{code}

in case of vectorized ptf (note: the issue is independent of ptf operator though), the whole pipeline process all the rows, which leads to serious performance regression (note 1439591782 runtime rows for all the operators except limit)

non-vectorized:
{code}
set hive.vectorized.execution.ptf.enabled=false;
...
|               Select Operator                      |
|                 Statistics: Num rows: 1415172503/1439591782 Data size: 248969569264 Basic stats: COMPLETE Column stats: COMPLETE |
|                 PTF Operator                       |
|                   Statistics: Num rows: 1415172503/449131 Data size: 248969569264 Basic stats: COMPLETE Column stats: COMPLETE |
|                   Select Operator                  |
|                     Statistics: Num rows: 1415172503/11526 Data size: 565867418560 Basic stats: COMPLETE Column stats: COMPLETE |
{code}

vectorized:
{code}
set hive.vectorized.execution.ptf.enabled=true;
...
|               Select Operator                      |
|                 Statistics: Num rows: 1415172503/1439591782 Data size: 248969569264 Basic stats: COMPLETE Column stats: COMPLETE |
|                 PTF Operator                       |
|                   Statistics: Num rows: 1415172503/1439591782 Data size: 248969569264 Basic stats: COMPLETE Column stats: COMPLETE |
|                   Select Operator                  |
|                     Statistics: Num rows: 1415172503/1439591782 Data size: 565867418560 Basic stats: COMPLETE Column stats: COMPLETE |
|                       File Output Operator         |
|                         Statistics: Num rows: 100/11300 Data size: 40000 Basic stats: COMPLETE Column stats: COMPLETE |
{code}

this is because this short-circuit is missing if childSize==1 (from vectorForward):
{code}
      // if all children are done, this operator is also done
      if (childrenDone != 0 && childrenDone == childOperatorsArray.length) {
        setDone(true);
      }
{code}"	HIVE	Closed	3	1	1631	pull-request-available
13273739	Re-Enable PreCommit test org.apache.hadoop.hive.ql.TestMTQueries.testMTQueries1	The test was disabled via HIVE-22616 because it was flaky. If the test is considered valid, it needs to be fixed and re-enabled.	HIVE	Closed	3	7	1631	test
13351756	LLAP: reader threads could be starvated if all IO elevator threads are busy to enqueue to another readers with full queue	"The root cause is that the readers cannot queue.offer items to full queues, which belong to consumers that are blocked on other consumers. 
Scenario is like below:
{code}
----------------------------------------------------------------------------------------------
        VERTICES      MODE        STATUS  TOTAL  COMPLETED  RUNNING  PENDING  FAILED  KILLED
----------------------------------------------------------------------------------------------
Map 2 ......          llap       RUNNING      3          2        1        0       0       0
Map 1                 llap       RUNNING    676          0      119      557       0       0
Map 3                 llap       RUNNING    108          0       21       87       0      21
Reducer 4             llap        INITED      1          0        0        1       0       0
Map 5                 llap        INITED    108          0        0      108       0       0
Reducer 6             llap        INITED      4          0        0        4       0       0
Reducer 7             llap        INITED      1          0        0        1       0       0
----------------------------------------------------------------------------------------------
VERTICES: 00/07  [>>--------------------------] 0%    ELAPSED TIME: 3489.83 s
----------------------------------------------------------------------------------------------
{code}

Map2 is MAPJOINed to Map1. In an LLAP daemon, the forever running Map2 task is blocked on nextCvb:
{code}
""TezTR-886270_0_1_0_1_0"" #154 daemon prio=5 os_prio=0 tid=0x00007f1b88348000 nid=0x147 waiting on condition [0x00007f0ce005d000]
   java.lang.Thread.State: TIMED_WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  <0x00007f0de8025e00> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.apache.hadoop.hive.llap.io.api.impl.LlapRecordReader.nextCvb(LlapRecordReader.java:517)
	at org.apache.hadoop.hive.llap.io.api.impl.LlapRecordReader.next(LlapRecordReader.java:372)
	at org.apache.hadoop.hive.llap.io.api.impl.LlapRecordReader.next(LlapRecordReader.java:82)
	at org.apache.hadoop.hive.ql.io.HiveContextAwareRecordReader.doNext(HiveContextAwareRecordReader.java:362)
	at org.apache.hadoop.hive.ql.io.HiveRecordReader.doNext(HiveRecordReader.java:79)
	at org.apache.hadoop.hive.ql.io.HiveRecordReader.doNext(HiveRecordReader.java:33)
	at org.apache.hadoop.hive.ql.io.HiveContextAwareRecordReader.next(HiveContextAwareRecordReader.java:117)
	at org.apache.hadoop.mapred.split.TezGroupedSplitsInputFormat$TezGroupedSplitsRecordReader.next(TezGroupedSplitsInputFormat.java:151)
	at org.apache.tez.mapreduce.lib.MRReaderMapred.next(MRReaderMapred.java:115)
	at org.apache.hadoop.hive.ql.exec.tez.MapRecordSource.pushRecord(MapRecordSource.java:68)
	at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.run(MapRecordProcessor.java:437)
	at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:267)
	at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:250)
	at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:374)
	at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:75)
	at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:62)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1898)
	at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:62)
	at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:38)
	at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)
	at org.apache.hadoop.hive.llap.daemon.impl.StatsRecordingThreadPool$WrappedCallable.call(StatsRecordingThreadPool.java:118)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
{code}

while all the elevator threads are blocked here (all of them tries to read for Map1):
{code}
""IO-Elevator-Thread-11"" #408 daemon prio=5 os_prio=0 tid=0x00007f0cddc48800 nid=0x267 waiting on condition [0x00007f0cd7af8000]
   java.lang.Thread.State: TIMED_WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  <0x00007f0e3095c480> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
	at java.util.concurrent.ArrayBlockingQueue.offer(ArrayBlockingQueue.java:379)
	at org.apache.hadoop.hive.llap.io.api.impl.LlapRecordReader.enqueueInternal(LlapRecordReader.java:607)
	at org.apache.hadoop.hive.llap.io.api.impl.LlapRecordReader.consumeData(LlapRecordReader.java:591)
	at org.apache.hadoop.hive.llap.io.api.impl.LlapRecordReader.consumeData(LlapRecordReader.java:82)
	at org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer.decodeBatch(OrcEncodedDataConsumer.java:268)
	at org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer.decodeBatch(OrcEncodedDataConsumer.java:79)
	at org.apache.hadoop.hive.llap.io.decode.EncodedDataConsumer.consumeData(EncodedDataConsumer.java:122)
	at org.apache.hadoop.hive.llap.io.decode.EncodedDataConsumer.consumeData(EncodedDataConsumer.java:42)
	at org.apache.hadoop.hive.ql.io.orc.encoded.EncodedReaderImpl.readEncodedColumns(EncodedReaderImpl.java:535)
	at org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader.performDataRead(OrcEncodedDataReader.java:430)
	at org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader$4.run(OrcEncodedDataReader.java:279)
	at org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader$4.run(OrcEncodedDataReader.java:276)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1898)
	at org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader.callInternal(OrcEncodedDataReader.java:276)
	at org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader.callInternal(OrcEncodedDataReader.java:117)
	at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)
	at org.apache.hadoop.hive.llap.io.decode.EncodedDataConsumer$CpuRecordingCallable.call(EncodedDataConsumer.java:88)
	at org.apache.hadoop.hive.llap.io.decode.EncodedDataConsumer$CpuRecordingCallable.call(EncodedDataConsumer.java:73)
	at org.apache.hadoop.hive.llap.daemon.impl.StatsRecordingThreadPool$WrappedCallable.call(StatsRecordingThreadPool.java:118)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
{code}

the problem here is that, as far as I can see, all the elevator threads try to offer to LlapRecordReaders that belong to Map 1, however, Map 1 tasks cannot progress beyond a certain point, because wait for Map 2's input
this is because the queues of LlapRecordReader instances of Map1 are full, otherwise LlapRecordReader.enqueueInternal should be able to offer the item from the elevator thread

In my example:
Map2's queue limit is: 50000 (Map2: mapjoin source)
Map1's queue limit is: 6931 (Map1: mapjoin target)
the limits are calculated according to data characteristics in LlapRecordReader.determineQueueLimit

in my case, io threads for Map1 reached their queue limit, and cannot offer new items, so holding IO elevator threads, which cannot be used for reading for more important Map2 tasks, so Map1 tasks will eventually hang here:
{code}
""TezTR-886270_0_1_1_1_0"" #281 daemon prio=5 os_prio=0 tid=0x00007f1b80366800 nid=0x1ca waiting on condition [0x00007f0cdb6d9000]
   java.lang.Thread.State: TIMED_WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  <0x00007f0de90049a8> (a java.util.concurrent.FutureTask)
	at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
	at java.util.concurrent.FutureTask.awaitDone(FutureTask.java:426)
	at java.util.concurrent.FutureTask.get(FutureTask.java:204)
	at org.apache.hadoop.hive.ql.exec.Operator.completeInitialization(Operator.java:436)
	at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:399)
	at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:572)
	at org.apache.hadoop.hive.ql.exec.Operator.initializeChildren(Operator.java:524)
	at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:385)
	at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.init(MapRecordProcessor.java:353)
	at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:266)
	at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:250)
	at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:374)
	at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:75)
	at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:62)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1898)
	at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:62)
	at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:38)
	at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)
	at org.apache.hadoop.hive.llap.daemon.impl.StatsRecordingThreadPool$WrappedCallable.call(StatsRecordingThreadPool.java:118)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
{code}
Operator.asyncInitOperations typically contains a dependency on map join input.

in my example Map2 reads small table, like microstrategy.lu_item, and Map1 reads a larger table microstrategy.order_detail

this deadlock theoretically can be solved by:
1. IO elevator threads (reading for Map1) opt out as they cannot offer new items
2. the freed elevator threads can be used for Map2
3. Map2 can finish its work, and let Map1 proceed by providing the mapjoin data to it"	HIVE	Closed	3	1	1631	pull-request-available
13502923	Request tracking: change to X-Request-ID header	this is an addendum to HIVE-26670, X-Request-ID is a more standard way to achieve this, and it's already logged by istio and most probably by other components	HIVE	Resolved	3	4	1631	pull-request-available
13319195	Upgrade to tez 0.10.0	"Tez 0.10.0 is not yet released, but this ticket is for tracking the effort and the needed hive changes.

Currently, Hive depends on 0.9.1

Hadoop dependencies:
Hive/master: *3.1.0*
Tez/master: *3.1.3*
Tez/branch-0.9:  *2.7.2*

TODOs: 
- check why HIVE-23689 broke some unit tests intermittently (0.9.2 ->0.9.3 bump), because a 0.10.x upgrade will also contain those tez changes which could be related

- maintain the needed hive changes (reflecting tez api changes):
HIVE-23190: LLAP: modify IndexCache to pass filesystem object to TezSpillRecord"	HIVE	Closed	3	4	1631	pull-request-available
13341245	Hive getUserName close db makes client operations lost metaStoreClient connection	"I'm using spark to execute a drop partition sql will always encounter a lost metastore connection warning.

 Spark ql:
{code:java}
alter table mydb.some_table drop if exists partition(dt = '2020-11-12',hh = '17');
{code}
Execution log:
{code:java}
20/11/12 19:37:57 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.20/11/12 19:37:57 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.20/11/12 19:37:57 WARN RetryingMetaStoreClient: MetaStoreClient lost connection. Attempting to reconnect (1 of 1) after 1s. listPartitionsWithAuthInfoorg.apache.thrift.transport.TTransportException: Cannot write to null outputStream at org.apache.thrift.transport.TIOStreamTransport.write(TIOStreamTransport.java:142) at org.apache.thrift.protocol.TBinaryProtocol.writeI32(TBinaryProtocol.java:185) at org.apache.thrift.protocol.TBinaryProtocol.writeMessageBegin(TBinaryProtocol.java:116) at org.apache.thrift.TServiceClient.sendBase(TServiceClient.java:70) at org.apache.thrift.TServiceClient.sendBase(TServiceClient.java:62) at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.send_get_partitions_ps_with_auth(ThriftHiveMetastore.java:2562) at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.get_partitions_ps_with_auth(ThriftHiveMetastore.java:2549) at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.listPartitionsWithAuthInfo(HiveMetaStoreClient.java:1209) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:173) at com.sun.proxy.$Proxy32.listPartitionsWithAuthInfo(Unknown Source) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.hadoop.hive.metastore.HiveMetaStoreClient$SynchronizedHandler.invoke(HiveMetaStoreClient.java:2336) at com.sun.proxy.$Proxy32.listPartitionsWithAuthInfo(Unknown Source) at org.apache.hadoop.hive.ql.metadata.Hive.getPartitions(Hive.java:2555) at org.apache.hadoop.hive.ql.metadata.Hive.getPartitions(Hive.java:2581) at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$dropPartitions$2(HiveClientImpl.scala:628) at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:245) at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62) at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55) at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49) at scala.collection.TraversableLike.flatMap(TraversableLike.scala:245) at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:242) at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108) at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$dropPartitions$1(HiveClientImpl.scala:622) at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:294) at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:227) at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:226) at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:276) at org.apache.spark.sql.hive.client.HiveClientImpl.dropPartitions(HiveClientImpl.scala:617) at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$dropPartitions$1(HiveExternalCatalog.scala:1018) at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:103) at org.apache.spark.sql.hive.HiveExternalCatalog.dropPartitions(HiveExternalCatalog.scala:1015) at org.apache.spark.sql.catalyst.catalog.ExternalCatalogWithListener.dropPartitions(ExternalCatalogWithListener.scala:211) at org.apache.spark.sql.catalyst.catalog.SessionCatalog.dropPartitions(SessionCatalog.scala:988) at org.apache.spark.sql.execution.command.AlterTableDropPartitionCommand.run(ddl.scala:581) at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:70) at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:68) at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:79) at org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:229) at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3618) at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100) at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160) at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87) at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:764) at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64) at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3616) at org.apache.spark.sql.Dataset.<init>(Dataset.scala:229) at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100) at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:764) at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97) at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:607) at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:764) at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:602) at org.apache.spark.sql.SQLContext.sql(SQLContext.scala:650) at org.apache.spark.sql.hive.thriftserver.SparkSQLDriver.run(SparkSQLDriver.scala:64) at org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.processCmd(SparkSQLCLIDriver.scala:377) at org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.$anonfun$processLine$1(SparkSQLCLIDriver.scala:496) at org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.$anonfun$processLine$1$adapted(SparkSQLCLIDriver.scala:490) at scala.collection.Iterator.foreach(Iterator.scala:941) at scala.collection.Iterator.foreach$(Iterator.scala:941) at scala.collection.AbstractIterator.foreach(Iterator.scala:1429) at scala.collection.IterableLike.foreach(IterableLike.scala:74) at scala.collection.IterableLike.foreach$(IterableLike.scala:73) at scala.collection.AbstractIterable.foreach(Iterable.scala:56) at org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.processLine(SparkSQLCLIDriver.scala:490) at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:336) at org.apache.hadoop.hive.cli.CliDriver.processReader(CliDriver.java:474) at org.apache.hadoop.hive.cli.CliDriver.processFile(CliDriver.java:490) at org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver$.main(SparkSQLCLIDriver.scala:208) at org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.main(SparkSQLCLIDriver.scala) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52) at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:928) at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180) at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203) at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90) at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1007) at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1016) at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)Response codeTime taken: 4.192 seconds
{code}
The problem raised from the getPartitions method, where the metastore client getMSC get will later been closed by the getUserName method. The getUserName method will close the current metastore in during setAuth and cause the underlying thrift transport closed.
{code:java}
public List<Partition> getPartitions(Table tbl, Map<String, String> partialPartSpec,
    short limit)
throws HiveException {
  if (!tbl.isPartitioned()) {
    throw new HiveException(ErrorMsg.TABLE_NOT_PARTITIONED, tbl.getTableName());
  }

  List<String> partialPvals = MetaStoreUtils.getPvals(tbl.getPartCols(), partialPartSpec);

  List<org.apache.hadoop.hive.metastore.api.Partition> partitions = null;
  try {
    partitions = getMSC().listPartitionsWithAuthInfo(tbl.getDbName(), tbl.getTableName(),
        partialPvals, limit, getUserName(), getGroupNames());
  } catch (Exception e) {
    throw new HiveException(e);
  }

  List<Partition> qlPartitions = new ArrayList<Partition>();
  for (org.apache.hadoop.hive.metastore.api.Partition p : partitions) {
    qlPartitions.add( new Partition(tbl, p));
  }

  return qlPartitions;
}{code}
I found another guy have raised the same issue for spark at a older version.

https://issues.apache.org/jira/browse/SPARK-29409

 "	HIVE	Closed	3	1	1631	pull-request-available
13360012	Introduce check: RANGE with offset PRECEDING/FOLLOWING requires at least one ORDER BY column	"Currently, in Hive, we can run a windowing function with range specification but without an ORDER BY clause:
{code}
create table vector_ptf_part_simple_text(p_mfgr string, p_name string, p_retailprice double, rowindex string);
select p_mfgr, p_name, rowindex,
count(*) over(partition by p_mfgr range between 1 preceding and current row) as cs1,
count(*) over(partition by p_mfgr range between 3 preceding and current row) as cs2
from vector_ptf_part_simple_text;
{code}

This is confusing, because without an order by clause, the range is out of context, we don't know by which column should we calculate the range.

Tested on Postgres, it throws an exception:
{code}
create table vector_ptf_part_simple_text(p_mfgr varchar(10), p_name varchar(10), p_retailprice integer, rowindex varchar(10));

select p_mfgr, p_name, rowindex,
count(*) over(partition by p_mfgr range between 1 preceding and current row) as cs1,
count(*) over(partition by p_mfgr range between 3 preceding and current row) as cs2
from vector_ptf_part_simple_text;

*RANGE with offset PRECEDING/FOLLOWING requires exactly one ORDER BY column*
{code}



further references:
https://cloud.google.com/bigquery/docs/reference/standard-sql/analytic-function-concepts
{code}
RANGE: Computes the window frame based on a logical range of rows around the current row, based on the current row’s ORDER BY key value. The provided range value is added or subtracted to the current row's key value to define a starting or ending range boundary for the window frame. In a range-based window frame, there must be exactly one expression in the ORDER BY clause, and the expression must have a numeric type.
{code}

https://docs.oracle.com/cd/E17952_01/mysql-8.0-en/window-functions-frames.html
{code}
Without ORDER BY: The default frame includes all partition rows (because, without ORDER BY, all partition rows are peers). The default is equivalent to this frame specification:
RANGE BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING
{code}
I believe this one could only make sense if you don't specify range, otherwise the sql statement reflects a different thing from which is returned by the engine"	HIVE	Closed	3	1	1631	pull-request-available
13543938	Print Tez processor payload insights	"When investigating TezAM OOM issues, a common problem is a huge conf. In this we usually do the following:
1. ask for heapdump
2. analyze heapdump, and finally find huge UserPayload, which is a binary :) extremely hard to read
3. deserialize userpayload
4. looks for configuration properties in payload to blame
5. figure out how to reduce the payload

I think with a handy configuration insight log message in HS2, we need to do only 5) (as 1) 2) 3) 4) can be complicated)

with the initial implementation I got this with e.g. ptf.q
{code}
2023-07-18T05:02:16,080  INFO [8e476599-63fd-4530-a007-71d92afced89 Listener at 0.0.0.0/55258] tez.DagUtils: Payload size for Map 1: 82967 bytes, # of keys in conf: 2653
2023-07-18T05:02:16,084  INFO [8e476599-63fd-4530-a007-71d92afced89 Listener at 0.0.0.0/55258] tez.DagUtils: 1. '/Users/laszlobodor/apache/hive/itests/qtest/target/tmp/localscratchdir/8e476599-63fd-4530-a007-71d92afced89/hive_2023-07-18_05-02-15_122_2130403664877939930-1/laszlobodor/_tez_scratch_dir/2d7f67a1-b7a3-413d-a027-51978f85e862/map.xml' size: 2552
2023-07-18T05:02:16,084  INFO [8e476599-63fd-4530-a007-71d92afced89 Listener at 0.0.0.0/55258] tez.DagUtils: 2. 'hive.conf.hidden.list' size: 526
2023-07-18T05:02:16,084  INFO [8e476599-63fd-4530-a007-71d92afced89 Listener at 0.0.0.0/55258] tez.DagUtils: 3. 'hadoop.security.sensitive-config-keys' size: 496
2023-07-18T05:02:16,084  INFO [8e476599-63fd-4530-a007-71d92afced89 Listener at 0.0.0.0/55258] tez.DagUtils: 4. 'hive.serdes.using.metastore.for.schema' size: 426
2023-07-18T05:02:16,084  INFO [8e476599-63fd-4530-a007-71d92afced89 Listener at 0.0.0.0/55258] tez.DagUtils: 5. 'fs.s3a.aws.credentials.provider' size: 252
2023-07-18T05:02:16,084  INFO [8e476599-63fd-4530-a007-71d92afced89 Listener at 0.0.0.0/55258] tez.DagUtils: 6. 'hive.exec.plan' size: 229
2023-07-18T05:02:16,084  INFO [8e476599-63fd-4530-a007-71d92afced89 Listener at 0.0.0.0/55258] tez.DagUtils: 7. 'io.serializations' size: 180
2023-07-18T05:02:16,084  INFO [8e476599-63fd-4530-a007-71d92afced89 Listener at 0.0.0.0/55258] tez.DagUtils: 8. 'hive.exec.post.hooks' size: 177
2023-07-18T05:02:16,084  INFO [8e476599-63fd-4530-a007-71d92afced89 Listener at 0.0.0.0/55258] tez.DagUtils: 9. '_hive_tez_tmp_dir' size: 173
2023-07-18T05:02:16,085  INFO [8e476599-63fd-4530-a007-71d92afced89 Listener at 0.0.0.0/55258] tez.DagUtils: 10. 'dfs.webhdfs.acl.provider.permission.pattern' size: 154
...
2023-07-18T05:02:19,051  INFO [8e476599-63fd-4530-a007-71d92afced89 Listener at 0.0.0.0/55258] tez.DagUtils: Payload size for Reducer 2: 90231 bytes, # of keys in conf: 2658
2023-07-18T05:02:19,052  INFO [8e476599-63fd-4530-a007-71d92afced89 Listener at 0.0.0.0/55258] tez.DagUtils: 1. '/Users/laszlobodor/apache/hive/itests/qtest/target/tmp/localscratchdir/8e476599-63fd-4530-a007-71d92afced89/hive_2023-07-18_05-02-18_172_1139677043401490299-1/laszlobodor/_tez_scratch_dir/040836dc-01a2-438b-99ff-148d1f5afd48/reduce.xml' size: 9364
2023-07-18T05:02:19,052  INFO [8e476599-63fd-4530-a007-71d92afced89 Listener at 0.0.0.0/55258] tez.DagUtils: 2. 'hive.conf.hidden.list' size: 526
2023-07-18T05:02:19,053  INFO [8e476599-63fd-4530-a007-71d92afced89 Listener at 0.0.0.0/55258] tez.DagUtils: 3. 'hadoop.security.sensitive-config-keys' size: 496
2023-07-18T05:02:19,053  INFO [8e476599-63fd-4530-a007-71d92afced89 Listener at 0.0.0.0/55258] tez.DagUtils: 4. 'hive.serdes.using.metastore.for.schema' size: 426
2023-07-18T05:02:19,053  INFO [8e476599-63fd-4530-a007-71d92afced89 Listener at 0.0.0.0/55258] tez.DagUtils: 5. 'columns.types' size: 377
2023-07-18T05:02:19,053  INFO [8e476599-63fd-4530-a007-71d92afced89 Listener at 0.0.0.0/55258] tez.DagUtils: 6. 'columns' size: 367
2023-07-18T05:02:19,053  INFO [8e476599-63fd-4530-a007-71d92afced89 Listener at 0.0.0.0/55258] tez.DagUtils: 7. 'fs.s3a.aws.credentials.provider' size: 252
2023-07-18T05:02:19,053  INFO [8e476599-63fd-4530-a007-71d92afced89 Listener at 0.0.0.0/55258] tez.DagUtils: 8. 'hive.exec.plan' size: 229
2023-07-18T05:02:19,053  INFO [8e476599-63fd-4530-a007-71d92afced89 Listener at 0.0.0.0/55258] tez.DagUtils: 9. 'io.serializations' size: 180
2023-07-18T05:02:19,053  INFO [8e476599-63fd-4530-a007-71d92afced89 Listener at 0.0.0.0/55258] tez.DagUtils: 10. 'hive.exec.post.hooks' size: 177
...
{code}"	HIVE	In Progress	3	4	1631	pull-request-available
13366359	Metastore: Create index on SDS.CD_ID for Postgres	"While investigating HIVE-24870, we found that during a long incremental replication, an SDS.CD_ID can improve the performance.
It was tested by postgres like below:
{code}
CREATE INDEX IF NOT EXISTS ""SDS_N50"" ON ""SDS"" USING btree (""CD_ID"");
EXPLAIN (ANALYZE,BUFFERS,TIMING) select count(*) from ""SDS"" where ""CD_ID""=THE_MOST_FREQUENTLY_USED_CD_ID_HERE;
DROP INDEX IF EXISTS ""SDS_N50"";
EXPLAIN (ANALYZE,BUFFERS,TIMING) select count(*) from ""SDS"" where ""CD_ID""=THE_MOST_FREQUENTLY_USED_CD_ID_HERE;
{code}

Further results can be found in:  [^command-output.txt] 

After some investigation, I found that this index is also part of the schemas for a very long time:
orcale: HIVE-2928
mysql: HIVE-2246
mssql: HIVE-6862 (or earlier)

...except Postgres.
"	HIVE	Closed	3	4	1631	pull-request-available
13474678	Use tez.local.mode.without.network for unit tests	"Since TEZ-4236 (in Tez 0.10.1), tez local mode can run without even starting an RPC server in the DAGAppMaster, which is in the same JVM as the client.
Adapting tez.local.mode.without.network=true could make tez.local.mode=true unit tests more stable.

here is an example where I had no idea why the dag app master connection was refused:
{code}
2022-07-29T07:56:24,701  INFO [main_executor] ql.Driver: Executing command(queryId=jenkins_20220729075624_b3ba4c8a-82d5-4ebd-b4b0-218325a71b10): INSERT into table default.tmp_minor_compactor_testmmminorcompaction_1659106584519_result select `a`, `b` from default.tmp_minor_compactor_testmmminorcompaction_1659106584519

2022-07-29T07:56:24,823  INFO [ServiceThread:DAGClientRPCServer] client.DAGClientServer: Instantiated DAGClientRPCServer at internal-hive-flaky-check-88-xwmrs-v2h77-knnxx/10.106.3.19:22623
2022-07-29T07:56:24,823  INFO [ServiceThread:org.apache.tez.dag.app.rm.TaskSchedulerManager] rm.TaskSchedulerManager: Creating TaskScheduler: Local TaskScheduler with clusterIdentifier=1659106584728
2022-07-29T07:56:24,825  INFO [DAGAppMaster Thread] HistoryEventHandler.criticalEvents: [HISTORY][DAG:N/A][Event:AM_STARTED]: appAttemptId=appattempt_1659106584728_0001_000000, startTime=1659106584825
2022-07-29T07:56:24,825  INFO [DAGAppMaster Thread] app.DAGAppMaster: In Session mode. Waiting for DAG over RPC
2022-07-29T07:56:24,871  INFO [main_executor] client.LocalClient: DAGAppMaster state: IDLE
2022-07-29T07:56:24,871  INFO [main_executor] client.TezClient: The url to track the Tez Session: N/A
...
2022-07-29T07:56:46,384  INFO [main_executor] client.TezClient: Failed to retrieve AM Status via proxy
com.google.protobuf.ServiceException: java.net.ConnectException: Call From internal-hive-flaky-check-88-xwmrs-v2h77-knnxx/10.106.3.19 to internal-hive-flaky-check-88-xwmrs-v2h77-knnxx:22623 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:247) ~[hadoop-common-3.1.1.7.2.15.0-147.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118) ~[hadoop-common-3.1.1.7.2.15.0-147.jar:?]
	at com.sun.proxy.$Proxy50.getAMStatus(Unknown Source) ~[?:?]
{code}

instead of diving deep into an evil environment related bug, we can simply utilize TEZ-4236 in these cases too"	HIVE	Closed	3	4	1631	pull-request-available
13546186	Fix some yarn cluster options for tests	"Currently, on apache master, running a minihs2 and trying to insert a record fails, because the memory defined for node managers are less then what a query asks for.

How to reproduce
{code}
mvn test -Dtest=StartMiniHS2Cluster -DminiHS2.clusterType=Tez -DminiHS2.run=true -DminiHS2.usePortsFromConf=true -Dpackaging.minimizeJar=false -T 1C -DskipShade -Dremoteresources.skip=true -Dmaven.javadoc.skip=true -Denforcer.skip=true -pl itests/hive-unit -Pitests

mvn clean install -DskipTests -Pitests

beeline -u ""jdbc:hive2://localhost:10000/default"" -n $USER

CREATE TABLE test_part(id int)
PARTITIONED BY(dt string)
STORED AS ORC;

insert into test_part values (1, '1');
{code}

leads to:
{code}
Error: Error while compiling statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.tez.TezTask. org.apache.hadoop.yarn.exceptions.InvalidResourceRequestException: Invalid resource request! Cannot allocate containers as requested resource is greater than maximum allowed allocation. Requested resource type=[memory-mb], Requested resource=<memory:1536, vCores:1>, maximum allowed allocation=<memory:512, vCores:4>, please note that maximum allowed allocation is calculated by scheduler based on maximum resource of registered NodeManagers, which might be less than configured maximum allocation=<memory:512, vCores:4>
{code}"	HIVE	Closed	3	1	1631	pull-request-available
13534020	Improve docker logging in AbstractExternalDB and DatabaseRule	"1. While waiting for docker container to start properly, we should print the output of docker logs command in every loop, otherwise we can miss important information about the actual startup process if the docker container was oom killed in the meantime. Not to mention the fact that we're currently not logging the output at all in case of an error:
https://github.com/apache/hive/blob/59058c65457fb7ab9d8575a555034e6633962661/itests/util/src/main/java/org/apache/hadoop/hive/ql/externalDB/AbstractExternalDB.java#L125-L127

2. We can include the output for docker events in the logs in case of an error (like: oom killed container), which might contain useful information.
We can have info like this:
{code}
2023-04-25T08:47:08.852515314-07:00 container oom 2ba12cd9cd844bb30b3158564bd68cd97f25e7a05172d111713ac9f7c1c0b1d4 (image=harbor.rke-us-west-04.kc.cloudera.com/docker_private_cache/cloudera_thirdparty/postgres:9.3, name=qtestExternalDB-PostgresExternalDB)
2023-04-25T08:47:08.893742200-07:00 container die 2ba12cd9cd844bb30b3158564bd68cd97f25e7a05172d111713ac9f7c1c0b1d4 (exitCode=1, image=harbor.rke-us-west-04.kc.cloudera.com/docker_private_cache/cloudera_thirdparty/postgres:9.3, name=qtestExternalDB-PostgresExternalDB)
{code}
"	HIVE	Closed	3	4	1631	pull-request-available
13375252	PTF: TimestampValueBoundaryScanner can be optimised during range computation pt2 - isDistanceGreater	HIVE-24746 optimized isEqual, but we can do the same optimization for isDistanceGreater.	HIVE	Closed	3	4	1631	pull-request-available
13551672	Prevent localizing the same original file more than once if symlinks are present	"We already calculate SHA hashes for the files to be localized. There is a chance, that in some setups, the hive-exec jars are symlinked so it gets localized more than once.

{code}
[root@lbodor-hiveontez-4 ~]# sudo -u hive hdfs dfs -ls -R /tmp/hive/hive/_tez_session_dir
drwx------   - hive supergroup          0 2023-09-20 12:13 /tmp/hive/hive/_tez_session_dir/0febf6f5-bacc-4055-b22b-e621c59cd1d6
drwx------   - hive supergroup          0 2023-09-20 12:19 /tmp/hive/hive/_tez_session_dir/0febf6f5-bacc-4055-b22b-e621c59cd1d6/.tez
drwx------   - hive supergroup          0 2023-09-20 11:58 /tmp/hive/hive/_tez_session_dir/0febf6f5-bacc-4055-b22b-e621c59cd1d6-resources
-rw-r--r--   3 hive supergroup   78366781 2023-09-20 11:58 /tmp/hive/hive/_tez_session_dir/0febf6f5-bacc-4055-b22b-e621c59cd1d6-resources/hive-exec-3.1.3000.7.2.18.0-334.jar
-rw-r--r--   3 hive supergroup   78366781 2023-09-20 11:58 /tmp/hive/hive/_tez_session_dir/0febf6f5-bacc-4055-b22b-e621c59cd1d6-resources/hive-exec.jar
drwx------   - hive supergroup          0 2023-09-20 11:58 /tmp/hive/hive/_tez_session_dir/21686e3c-2a00-457b-b84f-1a8db37699d1
drwx------   - hive supergroup          0 2023-09-20 12:04 /tmp/hive/hive/_tez_session_dir/21686e3c-2a00-457b-b84f-1a8db37699d1/.tez
drwx------   - hive supergroup          0 2023-09-20 11:58 /tmp/hive/hive/_tez_session_dir/21686e3c-2a00-457b-b84f-1a8db37699d1-resources
-rw-r--r--   3 hive supergroup   78366781 2023-09-20 11:58 /tmp/hive/hive/_tez_session_dir/21686e3c-2a00-457b-b84f-1a8db37699d1-resources/hive-exec-3.1.3000.7.2.18.0-334.jar
-rw-r--r--   3 hive supergroup   78366781 2023-09-20 11:58 /tmp/hive/hive/_tez_session_dir/21686e3c-2a00-457b-b84f-1a8db37699d1-resources/hive-exec.jar
drwx------   - hive supergroup          0 2023-09-20 11:58 /tmp/hive/hive/_tez_session_dir/40c7fb13-cfa1-4377-8d40-7e19503fbdad
drwx------   - hive supergroup          0 2023-09-20 13:13 /tmp/hive/hive/_tez_session_dir/40c7fb13-cfa1-4377-8d40-7e19503fbdad/.tez
drwx------   - hive supergroup          0 2023-09-20 11:58 /tmp/hive/hive/_tez_session_dir/40c7fb13-cfa1-4377-8d40-7e19503fbdad-resources
-rw-r--r--   3 hive supergroup   78366781 2023-09-20 11:58 /tmp/hive/hive/_tez_session_dir/40c7fb13-cfa1-4377-8d40-7e19503fbdad-resources/hive-exec-3.1.3000.7.2.18.0-334.jar
-rw-r--r--   3 hive supergroup   78366781 2023-09-20 11:58 /tmp/hive/hive/_tez_session_dir/40c7fb13-cfa1-4377-8d40-7e19503fbdad-resources/hive-exec.jar
drwx------   - hive supergroup          0 2023-09-20 11:58 /tmp/hive/hive/_tez_session_dir/5c48d6ab-ed8c-49c9-afe0-465de82c9c57
drwx------   - hive supergroup          0 2023-09-20 12:04 /tmp/hive/hive/_tez_session_dir/5c48d6ab-ed8c-49c9-afe0-465de82c9c57/.tez
drwx------   - hive supergroup          0 2023-09-20 11:58 /tmp/hive/hive/_tez_session_dir/5c48d6ab-ed8c-49c9-afe0-465de82c9c57-resources
-rw-r--r--   3 hive supergroup   78366781 2023-09-20 11:58 /tmp/hive/hive/_tez_session_dir/5c48d6ab-ed8c-49c9-afe0-465de82c9c57-resources/hive-exec-3.1.3000.7.2.18.0-334.jar
-rw-r--r--   3 hive supergroup   78366781 2023-09-20 11:58 /tmp/hive/hive/_tez_session_dir/5c48d6ab-ed8c-49c9-afe0-465de82c9c57-resources/hive-exec.jar
{code}

in the presence of huge amount of sessions, we cannot afford this overhead of copying this files to HDFS and localizing to all containers twice

the root cause can be solved by removing symlinks of the same hive-exec jar, -however, as we're already calculating SHA for the files, it's so easy to take care of the duplications in the localization codepath, and this takes care of any accidental duplications- so if all symlinks point to the same jar, resolving those before passing the Path objects to the localization codepath would simply solve this issue"	HIVE	Closed	3	4	1631	pull-request-available
13514226	Fix TestSQL11ReservedKeyWordsNegative test in branch-3	"Due to [HIVE-21293] Fix ambiguity in grammar warnings at compilation time (II) - ASF JIRA (apache.org), the test cases are failing with the following error :

java.lang.AssertionError: Expected ParseException
        at org.junit.Assert.fail(Assert.java:88)
        at org.apache.hadoop.hive.ql.parse.TestSQL11ReservedKeyWordsNegative$TestSQL11ReservedKeyWordsNegativeParametrized.testNegative(TestSQL11ReservedKeyWordsNegative.java:105)
        at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
        at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
        at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
        at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
        at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
        at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
        at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
        at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
        at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
        at org.junit.runners.Suite.runChild(Suite.java:127)
        at org.junit.runners.Suite.runChild(Suite.java:26)
        at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
        at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
        at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
        at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
        at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
        at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
        at org.junit.runners.Suite.runChild(Suite.java:127)
        at org.junit.runners.Suite.runChild(Suite.java:26)
        at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
        at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
        at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
        at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
        at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
        at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
        at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
        at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
        at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
        at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
        at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
        at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
        at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
        at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
        at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)"	HIVE	Resolved	2	7	1631	pull-request-available
13544171	Add programatically added DAG scoped properties to DAG Configuration	"Currently, when a user does something like this from beeline:
{code}
set tez.generate.debug.artifacts=true;
{code}
the option doesn't make its way to [dagConf|https://github.com/apache/hive/blob/8ea1d78d0dc18fec4305dd0d0a9e341ecdcaef1e/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/TezTask.java#L490], so it makes extremely painful to simply turn on/off options that would really supposed to work on DAG level
"	HIVE	Closed	3	4	1631	pull-request-available
13329852	LimitOperator can leverage ObjectCache to bail out quickly	"{noformat}
select  ss_sold_date_sk from store_sales, date_dim where date_dim.d_year in (1998,1998+1,1998+2) and store_sales.ss_sold_date_sk = date_dim.d_date_sk limit 100;

 select distinct ss_sold_date_sk from store_sales, date_dim where date_dim.d_year in (1998,1998+1,1998+2) and store_sales.ss_sold_date_sk = date_dim.d_date_sk limit 100;

 {noformat}

Queries like the above generate a large number of map tasks. Currently they don't bail out after generating enough amount of data. 

It would be good to make use of ObjectCache & retain the number of records generated. LimitOperator/VectorLimitOperator can bail out for the later tasks in the operator's init phase itself. 

https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorLimitOperator.java#L57

https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/exec/LimitOperator.java#L58"	HIVE	Closed	3	4	1631	pull-request-available
13357871	Vectorization: Support PTF - bounded start windows	"{code}
 notVectorizedReason: PTF operator: *** only UNBOUNDED start frame is supported
{code}
Currently, bounded windows are not supported in VectorPTFOperator. If we simply remove the check compile-time:
https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/Vectorizer.java#L2911
{code}
      if (!windowFrameDef.isStartUnbounded()) {
        setOperatorIssue(functionName + "" only UNBOUNDED start frame is supported"");
        return false;
      }
{code}
We get incorrect results, that's because vectorized codepath completely ignores boundaries, and simply iterates through all the input batches in [VectorPTFGroupBatches|https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/ptf/VectorPTFGroupBatches.java#L172]:
{code}
    for (VectorPTFEvaluatorBase evaluator : evaluators) {
      evaluator.evaluateGroupBatch(batch);
      if (isLastGroupBatch) {
        evaluator.doLastBatchWork();
      }
    }
{code}

"	HIVE	Closed	3	7	1631	pull-request-available
13566906	LLAP: cleanup local folders on startup and periodically	"When LLAP daemon crashes, there might be leftovers in the hive llap local dirs, which are good candidates to be cleaned up on startup/regularly. Under normal circumstances, these are cleaned up, however, as the LLAP damons is responsible for that, it cannot help in the event of a crash, so it would make sense to make it able to clean up old files.

A file listing of a problematic cluster where LLAP local dir is configured to  /apps/llap/work:
{code}
du -sh /apps/llap/work/usercache/hive/appcache/*
261M    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0005
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0043
28K     /apps/llap/work/usercache/hive/appcache/application_1702138790934_0049
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0052
2.0M    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0060
5.9G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0069
1.3G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0072
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0083
1.2G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0085
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0087
356M    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0089
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0091
429M    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0095
48K     /apps/llap/work/usercache/hive/appcache/application_1702138790934_0096
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0097
166M    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0099
1.8G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0100
369M    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0101
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0102
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0103
2.8G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0104
16K     /apps/llap/work/usercache/hive/appcache/application_1702138790934_0105
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0106
592K    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0107
2.9G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0108
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0109
60K     /apps/llap/work/usercache/hive/appcache/application_1702138790934_0110
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0111
1.6G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0112
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0113
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0114
11G     /apps/llap/work/usercache/hive/appcache/application_1702138790934_0115
3.4G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0116
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0117
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0118
646M    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0119
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0120
8.0K    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0121
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0122
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0123
164K    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0124
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0125
115M    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0126
406M    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0127
988K    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0128
8.0K    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0129
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0130
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0131
94M     /apps/llap/work/usercache/hive/appcache/application_1702138790934_0132
1.4G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0133
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0134
1.2G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0135
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0136
771M    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0137
2.0G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0138
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0139
2.2G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0140
1.2G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0141
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0142
2.0G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0143
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0144
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0145
13G     /apps/llap/work/usercache/hive/appcache/application_1702138790934_0146
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0147
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0148
1.3G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0149
3.5G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0150
12G     /apps/llap/work/usercache/hive/appcache/application_1702138790934_0151
6.6G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0152
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0153
2.7M    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0154
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0155
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0156
27G     /apps/llap/work/usercache/hive/appcache/application_1702138790934_0157
11G     /apps/llap/work/usercache/hive/appcache/application_1702138790934_0158
1.8M    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0159
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0160
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0161
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0162
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0163
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0164
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0165
1.5G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0166
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0167
2.1M    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0168
1.3G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0169
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0170
289M    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0171
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0172
18M     /apps/llap/work/usercache/hive/appcache/application_1702138790934_0173
5.4G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0174
8.2G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0175
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0176
13G     /apps/llap/work/usercache/hive/appcache/application_1702138790934_0177
6.0G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0178
7.0G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0179
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0180
28K     /apps/llap/work/usercache/hive/appcache/application_1702138790934_0181
976M    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0182
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0183
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0184
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0185
65M     /apps/llap/work/usercache/hive/appcache/application_1702138790934_0186
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0187
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0188
940K    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0189
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0190
2.3G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0191
102M    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0192
4.3G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0193
654M    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0194
3.8G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0195
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0196
830M    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0197
1.2M    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0198
332M    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0199
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0200
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0201
5.0G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0202
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0203
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0204
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0205
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0206
8.0K    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0207
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0208
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0209
5.1G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0210
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0211
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0212
3.0G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0213
43G     /apps/llap/work/usercache/hive/appcache/application_1702138790934_0214
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0215
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0216
3.4M    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0217
5.2G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0218
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0219
37M     /apps/llap/work/usercache/hive/appcache/application_1702138790934_0220
1.8M    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0221
665M    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0222
4.6G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0223
1.2G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0224
1.8G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0225
5.1G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0226
12K     /apps/llap/work/usercache/hive/appcache/application_1702138790934_0227
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0228
106M    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0229
1.5G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0230
16G     /apps/llap/work/usercache/hive/appcache/application_1702138790934_0231
1.3G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0232
940K    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0233
4.8G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0234
41M     /apps/llap/work/usercache/hive/appcache/application_1702138790934_0235
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0236
6.1G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0237
9.0G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0238
6.8G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0239
1.2M    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0240
2.1G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0241
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0242
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0243
20K     /apps/llap/work/usercache/hive/appcache/application_1702138790934_0244
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0245
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0246
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0247
431M    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0248
3.0G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0249
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0250
1.1G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0251
15G     /apps/llap/work/usercache/hive/appcache/application_1702138790934_0252
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0253
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0254
100K    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0255
20K     /apps/llap/work/usercache/hive/appcache/application_1702138790934_0256
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0257
2.7G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0258
987M    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0259
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0260
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0261
672M    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0262
8.0K    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0263
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0264
7.4G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0265
1.6G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0266
5.4M    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0267
5.6G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0268
1000M   /apps/llap/work/usercache/hive/appcache/application_1702138790934_0269
13G     /apps/llap/work/usercache/hive/appcache/application_1702138790934_0270
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0271
169M    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0272
3.0M    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0273
5.7G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0274
628K    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0275
2.0G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0276
2.3G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0277
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0278
12K     /apps/llap/work/usercache/hive/appcache/application_1702138790934_0279
95M     /apps/llap/work/usercache/hive/appcache/application_1702138790934_0280
5.3G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0281
32K     /apps/llap/work/usercache/hive/appcache/application_1702138790934_0282
2.5G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0283
244M    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0284
4.4G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0285
3.5G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0286
5.7G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0287
1.3G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0288
15G     /apps/llap/work/usercache/hive/appcache/application_1702138790934_0289
848M    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0290
19M     /apps/llap/work/usercache/hive/appcache/application_1702138790934_0291
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0292
38G     /apps/llap/work/usercache/hive/appcache/application_1702138790934_0293
326M    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0294
2.2G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0295
4.1G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0296
38G     /apps/llap/work/usercache/hive/appcache/application_1702138790934_0297
444K    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0298
28K     /apps/llap/work/usercache/hive/appcache/application_1702138790934_0299
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0300
241M    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0301
45G     /apps/llap/work/usercache/hive/appcache/application_1702138790934_0302
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0303
36M     /apps/llap/work/usercache/hive/appcache/application_1702138790934_0304
679M    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0305
27G     /apps/llap/work/usercache/hive/appcache/application_1702138790934_0306
6.4G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0307
23M     /apps/llap/work/usercache/hive/appcache/application_1702138790934_0308
490M    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0309
0       /apps/llap/work/usercache/hive/appcache/application_1702138790934_0310
1.5G    /apps/llap/work/usercache/hive/appcache/application_1702138790934_0311
{code}


regarding dates:
{code}
ls -lrth /apps/llap/work/usercache/hive/appcache/
total 4.0K
drwxr-xr-x  2 hive hive    6 Dec 29 11:17 application_1702138790934_0102
drwxr-xr-x  3 hive hive   17 Jan  1 01:37 application_1702138790934_0107
drwxr-xr-x  3 hive hive   17 Jan  1 09:04 application_1702138790934_0100
drwxr-xr-x  2 hive hive    6 Jan  2 05:13 application_1702138790934_0087
drwxr-xr-x  3 hive hive   17 Jan  2 05:14 application_1702138790934_0101
drwxr-xr-x  3 hive hive   16 Jan  2 12:31 application_1702138790934_0109
drwxr-xr-x  2 hive hive    6 Jan  2 12:50 application_1702138790934_0106
drwxr-xr-x  3 hive hive   18 Jan  2 19:58 application_1702138790934_0043
drwxr-xr-x  3 hive hive   17 Jan  2 20:05 application_1702138790934_0089
drwxr-xr-x  4 hive hive   30 Jan  2 21:45 application_1702138790934_0072
drwxr-xr-x  3 hive hive   16 Jan  2 21:56 application_1702138790934_0115
drwxr-xr-x  3 hive hive   17 Jan  3 08:48 application_1702138790934_0096
drwxr-xr-x  3 hive hive   17 Jan  3 08:56 application_1702138790934_0105
drwxr-xr-x  3 hive hive   17 Jan  3 09:05 application_1702138790934_0060
drwxr-xr-x  2 hive hive    6 Jan  3 09:08 application_1702138790934_0114
drwxr-xr-x  2 hive hive    6 Jan  3 09:08 application_1702138790934_0113
drwxr-xr-x  2 hive hive    6 Jan  3 09:28 application_1702138790934_0118
drwxr-xr-x  2 hive hive    6 Jan  3 09:40 application_1702138790934_0117
drwxr-xr-x  3 hive hive   17 Jan  3 11:51 application_1702138790934_0110
drwxr-xr-x  2 hive hive    6 Jan  3 12:03 application_1702138790934_0091
drwxr-xr-x  2 hive hive    6 Jan  3 12:05 application_1702138790934_0122
drwxr-xr-x  3 hive hive   17 Jan  3 12:42 application_1702138790934_0095
{code}

so e.g. application_1702138790934_0069 has ~6G stale data from Jan3 (file listing was made at the end of January)


these local files are typically the ones below (assuming that llap local dirs point to /apps/llap/work)
{code}
/apps/llap/work/usercache/hive/appcache/application_1707917402901_0001/3/output/attempt_1707917402901_0001_3_05_000002_0_10414:
total 16
drwxr-xr-x  2 hive hive   44 Feb 14 13:41 .
drwxr-xr-x 63 hive hive 4096 Feb 14 13:41 ..
-rw-r--r--  1 hive hive  425 Feb 14 13:41 file.out
-rw-r--r--  1 hive hive   32 Feb 14 13:41 file.out.index

/apps/llap/work/usercache/hive/appcache/application_1707917402901_0001/3/output/attempt_1707917402901_0001_3_05_000005_0_10416:
total 16
drwxr-xr-x  2 hive hive   44 Feb 14 13:41 .
drwxr-xr-x 63 hive hive 4096 Feb 14 13:41 ..
-rw-r--r--  1 hive hive  383 Feb 14 13:41 file.out
-rw-r--r--  1 hive hive   32 Feb 14 13:41 file.out.index
{code}"	HIVE	Closed	3	4	1631	pull-request-available
13563590	Tests in hive-unit module are not running again	"Fixed in HIVE-27846, went bad in an addendum of HIVE-27797:
https://github.com/apache/hive/commit/5022b85b5f50#diff-2f651f99c3a3a2dd091abda120ae33f028ba3bdfa749cc5c3aa36ebba15379e3R498-R503

currently, it only runs test if I manually remove this dependency
{code}
    <dependency>
      <groupId>org.junit.jupiter</groupId>
      <artifactId>junit-jupiter</artifactId>
      <version>${junit.jupiter.version}</version>
      <scope>test</scope>
    </dependency>
{code}"	HIVE	Closed	3	4	1631	pull-request-available
13169382	HiveServer2: SessionState has a static sync block around an AtomicBoolean	"{code}
  private static void start(SessionState startSs, boolean isAsync, LogHelper console) {
...
    synchronized(SessionState.class) {
      if (!startSs.isStarted.compareAndSet(false, true)) {
        return;
      }
    }
{code}

startSs.isStarted is an AtomicBoolean, which makes it hard to know why this code is locked with a static lock."	HIVE	Closed	3	1	1631	Branch3Candidate, Concurrency
13577041	MiniHS2: use a base folder which is more likely writable on the local FS	"we hardcode a HDFS session dir like below:
https://github.com/apache/hive/blob/2d855b27d31db6476f18870651db6987816bb5e3/itests/util/src/main/java/org/apache/hive/jdbc/miniHS2/MiniHS2.java#L307
{code}
      baseFsDir = new Path(new Path(fs.getUri()), ""/base"");
{code}

this can lead to problems with tez local mode with mini hs2, as tez [mirrors|https://github.com/apache/tez/blob/f080031f5c72bc4bfd8090ccdc670bdc0f7fd090/tez-dag/src/main/java/org/apache/tez/client/LocalClient.java#L308-L335] the hdfs contents to a local folder, and later it this leads to a confusing message like:
{code}
2024-04-24T02:03:52,101 ERROR [DAGAppMaster Thread] client.LocalClient: Error starting DAGAppMaster
java.io.FileNotFoundException: /base/scratch/laszlobodor/_tez_session_dir/b76689bc-d25e-4d65-a339-44206ff57ce2/.tez/application_1713949431891_0001_wd/tez-conf.pb (No such file or directory)
	at java.io.FileInputStream.open0(Native Method) ~[?:1.8.0_292]
	at java.io.FileInputStream.open(FileInputStream.java:195) ~[?:1.8.0_292]
	at java.io.FileInputStream.<init>(FileInputStream.java:138) ~[?:1.8.0_292]
	at org.apache.tez.common.TezUtilsInternal.readUserSpecifiedTezConfiguration(TezUtilsInternal.java:84) ~[tez-common-0.9.1.2024.0.19.0-3.jar:0.9.1.2024.0.19.0-3]
	at org.apache.tez.client.LocalClient.createDAGAppMaster(LocalClient.java:394) ~[tez-dag-0.9.1.2024.0.19.0-3.jar:0.9.1.2024.0.19.0-3]
	at org.apache.tez.client.LocalClient$1.run(LocalClient.java:357) [tez-dag-0.9.1.2024.0.19.0-3.jar:0.9.1.2024.0.19.0-3]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_292]
{code}

btw, this confusing message will be fixed in TEZ-4555, but we need to give something different than /base
it doesn't make sense to hack a different folder in tez for the local mode, instead we should change the hardcoded ""/base"" in MiniHS2 which might be more durable and solves the abovementioned problem

currently, hive's default scratch dir is [/tmp/hive|https://github.com/apache/hive/blob/2d855b27d31db6476f18870651db6987816bb5e3/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java#L498]"	HIVE	Resolved	3	4	1631	pull-request-available
13311335	Vectorization: IndexArrayOutOfBoundsException For map type column which includes null value	"{color:#de350b}start{color} and {color:#de350b}length{color} are empty arrays in MapColumnVector.values(BytesColumnVector) when values in map contain {color:#de350b}null{color}

reproduce in master branch:
{code:java}
set hive.vectorized.execution.enabled=true; 

CREATE TABLE parquet_map_type (id int,stringMap map<string, string>) 
stored as parquet; 

insert overwrite table parquet_map_typeSELECT 1, MAP('k1', null, 'k2', 'bar'); 

select id, stringMap['k1'] from parquet_map_type group by 1,2;
{code}
query explain:
{code:java}
Stage-0
  Fetch Operator
    limit:-1
    Stage-1
      Reducer 2 vectorized
      File Output Operator [FS_12]
        Group By Operator [GBY_11] (rows=5 width=2)
          Output:[""_col0"",""_col1""],keys:KEY._col0, KEY._col1
        <-Map 1 [SIMPLE_EDGE] vectorized
          SHUFFLE [RS_10]
            PartitionCols:_col0, _col1
            Group By Operator [GBY_9] (rows=10 width=2)
              Output:[""_col0"",""_col1""],keys:_col0, _col1
              Select Operator [SEL_8] (rows=10 width=2)
                Output:[""_col0"",""_col1""]
                TableScan [TS_0] (rows=10 width=2)
                  temp@parquet_map_type_fyz,parquet_map_type_fyz,Tbl:COMPLETE,Col:NONE,Output:[""id"",""stringmap""]
{code}
runtime error:
{code:java}
Vertex failed, vertexName=Map 1, vertexId=vertex_1592040015150_0001_3_00, diagnostics=[Task failed, taskId=task_1592040015150_0001_3_00_000000, diagnostics=[TaskAttempt 0 failed, info=[Error: Error while running task ( failure ) : attempt_1592040015150_0001_3_00_000000_0:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row 
	at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:296)
	at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:250)
	at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:374)
	at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:73)
	at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:61)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:61)
	at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:37)
	at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)
	at com.google.common.util.concurrent.TrustedListenableFutureTask$TrustedFutureInterruptibleTask.runInterruptibly(TrustedListenableFutureTask.java:108)
	at com.google.common.util.concurrent.InterruptibleTask.run(InterruptibleTask.java:41)
	at com.google.common.util.concurrent.TrustedListenableFutureTask.run(TrustedListenableFutureTask.java:77)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row 
	at org.apache.hadoop.hive.ql.exec.tez.MapRecordSource.processRow(MapRecordSource.java:101)
	at org.apache.hadoop.hive.ql.exec.tez.MapRecordSource.pushRecord(MapRecordSource.java:76)
	at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.run(MapRecordProcessor.java:403)
	at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:267)
	... 16 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row 
	at org.apache.hadoop.hive.ql.exec.vector.VectorMapOperator.process(VectorMapOperator.java:970)
	at org.apache.hadoop.hive.ql.exec.tez.MapRecordSource.processRow(MapRecordSource.java:92)
	... 19 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Error evaluating id
	at org.apache.hadoop.hive.ql.exec.vector.VectorSelectOperator.process(VectorSelectOperator.java:149)
	at org.apache.hadoop.hive.ql.exec.Operator.vectorForward(Operator.java:918)
	at org.apache.hadoop.hive.ql.exec.TableScanOperator.process(TableScanOperator.java:172)
	at org.apache.hadoop.hive.ql.exec.vector.VectorMapOperator.deliverVectorizedRowBatch(VectorMapOperator.java:809)
	at org.apache.hadoop.hive.ql.exec.vector.VectorMapOperator.process(VectorMapOperator.java:842)
	... 20 more
Caused by: java.lang.ArrayIndexOutOfBoundsException: 0
	at org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector.setElement(BytesColumnVector.java:506)
	at org.apache.hadoop.hive.ql.exec.vector.expressions.VectorUDFMapIndexBaseScalar.evaluate(VectorUDFMapIndexBaseScalar.java:83)
	at org.apache.hadoop.hive.ql.exec.vector.VectorSelectOperator.process(VectorSelectOperator.java:146)
	... 24 more
{code}"	HIVE	Closed	2	1	1631	pull-request-available
13560797	Clarifying comments and xml configs around tez container size	"the comment in HiveConf about hive.tez.container.size is useless, let's improve it:
https://github.com/apache/hive/blob/1e4f488394d19ea51766e0633a605e078d8558c3/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java#L2463"	HIVE	Closed	3	4	1631	pull-request-available
13375306	PTF: Improve ValueBoundaryScanner	"-First, I need to check whether TreeMap is really needed for our case.-

It turned out a binary-ish search approach could help in range calculation, as we're searching in an ordered set of values."	HIVE	Closed	3	4	1631	pull-request-available
13410910	HBaseStorageHandler: ensure that hbase properties are present in final JobConf for Tez	"After some debugging I found that in the following codepath configureJobConf is called to prepare the jobConf object for special storage handlers, however, if the jobConf hasn't contained the needed hbase props, then this code path doesn't make sure of adding that, even if the method name suggests.

 
{code:java}
HBaseConfiguration.addHbaseResources(Configuration) line: 82
HBaseConfiguration.create() line: 98
HBaseConfiguration.create(Configuration) line: 107
HBaseStorageHandler.setConf(Configuration) line: 134
ReflectionUtils.setConf(Object, Configuration) line: 77
ReflectionUtils.newInstance(Class<T>, Configuration) line: 137
HiveUtils.getStorageHandler(Configuration, String) line: 299
PlanUtils.configureJobConf(TableDesc, JobConf) line: 995
MapWork.configureJobConf(JobConf) line: 661
TezWork.configureJobConfAndExtractJars(JobConf) line: 346
TezTask.execute() line: 186
TezTask(Task<T>).executeTask(HiveHistory) line: 213
{code}
Here, addHBaseResources adds hbase xml configs to HBaseStorageHandler.hbaseConf during the reflection flow, but then they're not added to the passed jobConf in configureJobConf.

This can cause problems in secure clusters under some circumstances, where hbase props are not present in the conf which is used in TezTask.execute."	HIVE	Closed	3	1	1631	pull-request-available
13385137	TestLimitOperator fails if default engine is Tez	"need to mock an object cache there
{code:java}
java.lang.IllegalStateException: Cannot get a query cache object while working outside of HS2, this is unexpected
	at org.apache.hadoop.hive.ql.exec.LimitOperator.initializeOp(LimitOperator.java:74)
	at org.apache.hadoop.hive.ql.exec.vector.VectorLimitOperator.initializeOp(VectorLimitOperator.java:65)
	at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:375)
	at org.apache.hadoop.hive.ql.exec.vector.TestVectorLimitOperator.validateVectorLimitOperator(TestVectorLimitOperator.java:139)
	at org.apache.hadoop.hive.ql.exec.vector.TestVectorLimitOperator.testLimitLessThanBatchSize(TestVectorLimitOperator.java:48)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
... {code}"	HIVE	Closed	3	1	1631	pull-request-available
13572686	Remove HiveIOExceptionHandlerUtil	"1. old history, not really touched:
https://github.com/apache/hive/commits/master/shims/common/src/main/java/org/apache/hadoop/hive/io/HiveIOExceptionHandlerUtil.java

2. cannot see a clear usecase
{code}
    RecordReader innerReader = null;
    try {
      innerReader = inputFormat.getRecordReader(targetSplit, job,
          reporter);
    } catch (Exception e) {
      innerReader = HiveIOExceptionHandlerUtil
          .handleRecordReaderCreationException(e, job);
    }
{code}
define an exception handler to magically create a reader? this looks so hacky

3. cannot find and useful usage of ""hive.io.exception.handlers"" by googling

4. swallows exception as described in HIVE-28133

"	HIVE	Open	3	4	1631	pull-request-available
13411445	LLAP: ShuffleHandler port should respect value in config	"The problem is that private int port variable is not assigned before binding the netty channel, so as it's 0, shuffle handler port is random regardless of the config.
This issue wasn't noticeable because the shuffle host:port is put into DataMovementEvent payload, so fetchers are always aware of where to connect."	HIVE	Closed	3	1	1631	pull-request-available
13334516	Vectorized PTF with count and distinct over partition producing incorrect results.	"Vectorized PTF for count and distinct over partition is broken. It produces incorrect results.
Below is the test case.

{code}
CREATE TABLE bigd781b_new (
  id int,
  txt1 string,
  txt2 string,
  cda_date int,
  cda_job_name varchar(12));

INSERT INTO bigd781b_new VALUES 
  (1,'2010005759','7164335675012038',20200528,'load1'),
  (2,'2010005759','7164335675012038',20200528,'load2');
{code}

Running below query produces incorrect results

{code}
SELECT
    txt1,
    txt2,
    count(distinct txt1) over(partition by txt1) as n,
    count(distinct txt2) over(partition by txt2) as m
FROM bigd781b_new
{code}

as below.

{code}
+-------------+-------------------+----+----+
|    txt1     |       txt2        | n  | m  |
+-------------+-------------------+----+----+
| 2010005759  | 7164335675012038  | 2  | 2  |
| 2010005759  | 7164335675012038  | 2  | 2  |
+-------------+-------------------+----+----+
{code}

While the correct output would be

{code}
+-------------+-------------------+----+----+
|    txt1     |       txt2        | n  | m  |
+-------------+-------------------+----+----+
| 2010005759  | 7164335675012038  | 1  | 1  |
| 2010005759  | 7164335675012038  | 1  | 1  |
+-------------+-------------------+----+----+
{code}


The problem does not appear after setting below property
set hive.vectorized.execution.ptf.enabled=false;
"	HIVE	Closed	2	1	1631	pull-request-available
13581676	ProfileServlet: add html to output formats and prepare for profiler 3.0	"{code}
query-executor <14>1 2024-06-05T12:12:59.188Z query-executor-0-0 query-executor 1 8a250c32-ca6d-4fb8-a5a7-00569a3141d3 [mdc@18060 class=""util.ProcessUtils"" level=""INFO"" thread=""llap-web-49""] Running command async: [/async-profiler/async-profiler-2.9-linux-x64/profiler.sh, -e, cpu, -d, 15, -o, svg, -f, /tmp/prof-output/async-prof-pid-1-cpu-1.svg, 1]
query-executor [WARN] Unknown argument: svg
query-executor [ERROR] SVG format is obsolete, use .html for FlameGraph
{code}
https://github.com/apache/hive/blob/529fd45c6556c2e9e7f647297234b97c4060a031/common/src/java/org/apache/hive/http/ProfileServlet.java#L137-L145

in recent versions of async-profiler, SVG is not accepted at all, and unfortunately, HTML cannot even be chosen due to a strict parse:
https://github.com/apache/hive/blob/529fd45c6556c2e9e7f647297234b97c4060a031/common/src/java/org/apache/hive/http/ProfileServlet.java#L346

for backward compatibility, SVG is fine, but HTML should be added to the enum"	HIVE	Resolved	3	1	1631	hive-4.0.1-merged, pull-request-available
13378089	Classpath logging should be on DEBUG level	"This is since HIVE-21584

I have a *72M* llap executor log file, then I grepped for only ""thread class path"", piped into a separate file and a result was a *22M* file...1/3-1/4 of the file was classpath info which is not usable for most of the time. This overwhelming amount of classpath info is not needed, assuming that classpath issues are reproducible with more or less effort, user should be responsible for turning on this expensive logging on demand. Not to mention performance implications which cannot be ignored beyond a certain amount of log messages.

https://github.com/apache/hive/commit/a234475faa2cab2606f2a74eb9ca071f006998e2#diff-44b2ff3a3c4a6cfcaed0fcb40b74031844f8586e40a6f8261637e5ebcd558b73R4577"	HIVE	Closed	3	4	1631	pull-request-available
13482017	Improve TxnHandler, TxnUtils, CompactionTxnHandler logging	"TxnHandler has some bad logging, like:
{code}
LOG.debug(""Going to execute query<"" + txnsQuery + "">"");
{code}
https://github.com/apache/hive/blob/8e39937bdb577bc135579d7d34b46ba2d788ca53/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java#L533

this will involve a pretty unnecessary string concatenation in production when we're on INFO level usually, let's use string formats"	HIVE	Closed	3	4	1631	pull-request-available
13327405	Kafka storage handler broken in secure environment pt2: short-circuit on non-secure environment	"As kafka_storage_handler.q was disabled by HIVE-23985, I haven't realized upstream that the kafka qtest fails. Instead of setting up a kerberized environment in qtest (which doesn't seem to be a usual usecase, e.g. haven't seen hive.server2.authentication.kerberos.principal used in *.q files) I managed to make the test with a simple UserGroupInformation.isSecurityEnabled() check, which can be also useful for every non-secure environment.

For reference, the exception was:
{code}
2020-09-14T03:30:01,217 ERROR [a42ef4c6-190c-47a6-86ad-8bf13b8a2dc1 main] tez.TezTask: Failed to execute tez graph.
org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:451) ~[kafka-clients-2.4.1.7.1.4.0-SNAPSHOT.jar:?]
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:59) ~[kafka-clients-2.4.1.7.1.4.0-SNAPSHOT.jar:?]
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39) ~[kafka-clients-2.4.1.7.1.4.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.hive.ql.exec.tez.DagUtils.getKafkaDelegationTokenForBrokers(DagUtils.java:333) ~[hive-exec-3.1.3000.7.1.4.0-SNAPSHOT.jar:3.1.3000.7.1.4.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.exec.tez.DagUtils.getKafkaCredentials(DagUtils.java:301) ~[hive-exec-3.1.3000.7.1.4.0-SNAPSHOT.jar:3.1.3000.7.1.4.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.exec.tez.DagUtils.addCredentials(DagUtils.java:282) ~[hive-exec-3.1.3000.7.1.4.0-SNAPSHOT.jar:3.1.3000.7.1.4.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.exec.tez.TezTask.build(TezTask.java:516) ~[hive-exec-3.1.3000.7.1.4.0-SNAPSHOT.jar:3.1.3000.7.1.4.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.exec.tez.TezTask.execute(TezTask.java:223) [hive-exec-3.1.3000.7.1.4.0-SNAPSHOT.jar:3.1.3000.7.1.4.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:213) [hive-exec-3.1.3000.7.1.4.0-SNAPSHOT.jar:3.1.3000.7.1.4.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:105) [hive-exec-3.1.3000.7.1.4.0-SNAPSHOT.jar:3.1.3000.7.1.4.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Executor.launchTask(Executor.java:357) [hive-exec-3.1.3000.7.1.4.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.hive.ql.Executor.launchTasks(Executor.java:330) [hive-exec-3.1.3000.7.1.4.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.hive.ql.Executor.runTasks(Executor.java:246) [hive-exec-3.1.3000.7.1.4.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.hive.ql.Executor.execute(Executor.java:109) [hive-exec-3.1.3000.7.1.4.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:721) [hive-exec-3.1.3000.7.1.4.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:488) [hive-exec-3.1.3000.7.1.4.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:482) [hive-exec-3.1.3000.7.1.4.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:166) [hive-exec-3.1.3000.7.1.4.0-SNAPSHOT.jar:3.1.3000.7.1.4.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:232) [hive-exec-3.1.3000.7.1.4.0-SNAPSHOT.jar:3.1.3000.7.1.4.0-SNAPSHOT]
	at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:247) [hive-cli-3.1.3000.7.1.4.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:193) [hive-cli-3.1.3000.7.1.4.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:412) [hive-cli-3.1.3000.7.1.4.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:343) [hive-cli-3.1.3000.7.1.4.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.hive.ql.QTestUtil.executeClientInternal(QTestUtil.java:1465) [classes/:?]
	at org.apache.hadoop.hive.ql.QTestUtil.executeClient(QTestUtil.java:1438) [classes/:?]
	at org.apache.hadoop.hive.cli.control.CoreCliDriver.runTest(CoreCliDriver.java:194) [classes/:?]
	at org.apache.hadoop.hive.cli.control.CliAdapter.runTest(CliAdapter.java:104) [classes/:?]
	at org.apache.hadoop.hive.cli.TestMiniHiveKafkaCliDriver.testCliDriver(TestMiniHiveKafkaCliDriver.java:60) [test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_151]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_151]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_151]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_151]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47) [junit-4.11.jar:?]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) [junit-4.11.jar:?]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44) [junit-4.11.jar:?]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) [junit-4.11.jar:?]
	at org.apache.hadoop.hive.cli.control.CliAdapter$2$1.evaluate(CliAdapter.java:92) [classes/:?]
	at org.junit.rules.RunRules.evaluate(RunRules.java:20) [junit-4.11.jar:?]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271) [junit-4.11.jar:?]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70) [junit-4.11.jar:?]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50) [junit-4.11.jar:?]
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238) [junit-4.11.jar:?]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63) [junit-4.11.jar:?]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236) [junit-4.11.jar:?]
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53) [junit-4.11.jar:?]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229) [junit-4.11.jar:?]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309) [junit-4.11.jar:?]
	at org.junit.runners.Suite.runChild(Suite.java:127) [junit-4.11.jar:?]
	at org.junit.runners.Suite.runChild(Suite.java:26) [junit-4.11.jar:?]
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238) [junit-4.11.jar:?]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63) [junit-4.11.jar:?]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236) [junit-4.11.jar:?]
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53) [junit-4.11.jar:?]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229) [junit-4.11.jar:?]
	at org.apache.hadoop.hive.cli.control.CliAdapter$1$1.evaluate(CliAdapter.java:73) [classes/:?]
	at org.junit.rules.RunRules.evaluate(RunRules.java:20) [junit-4.11.jar:?]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309) [junit-4.11.jar:?]
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365) [surefire-junit4-2.21.0.jar:2.21.0]
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273) [surefire-junit4-2.21.0.jar:2.21.0]
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238) [surefire-junit4-2.21.0.jar:2.21.0]
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159) [surefire-junit4-2.21.0.jar:2.21.0]
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379) [surefire-booter-2.21.0.jar:2.21.0]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340) [surefire-booter-2.21.0.jar:2.21.0]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125) [surefire-booter-2.21.0.jar:2.21.0]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413) [surefire-booter-2.21.0.jar:2.21.0]
Caused by: org.apache.kafka.common.KafkaException: javax.security.auth.login.LoginException: java.lang.IllegalArgumentException: Empty nameString not allowed
	at sun.security.krb5.PrincipalName.validateNameStrings(PrincipalName.java:174)
	at sun.security.krb5.PrincipalName.<init>(PrincipalName.java:397)
	at sun.security.krb5.PrincipalName.<init>(PrincipalName.java:468)
	at com.sun.security.auth.module.Krb5LoginModule.attemptAuthentication(Krb5LoginModule.java:650)
	at com.sun.security.auth.module.Krb5LoginModule.login(Krb5LoginModule.java:617)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at javax.security.auth.login.LoginContext.invoke(LoginContext.java:755)
	at javax.security.auth.login.LoginContext.access$000(LoginContext.java:195)
	at javax.security.auth.login.LoginContext$4.run(LoginContext.java:682)
	at javax.security.auth.login.LoginContext$4.run(LoginContext.java:680)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.login.LoginContext.invokePriv(LoginContext.java:680)
	at javax.security.auth.login.LoginContext.login(LoginContext.java:587)
	at org.apache.kafka.common.security.authenticator.AbstractLogin.login(AbstractLogin.java:60)
	at org.apache.kafka.common.security.kerberos.KerberosLogin.login(KerberosLogin.java:103)
	at org.apache.kafka.common.security.authenticator.LoginManager.<init>(LoginManager.java:62)
	at org.apache.kafka.common.security.authenticator.LoginManager.acquireLoginManager(LoginManager.java:105)
	at org.apache.kafka.common.network.SaslChannelBuilder.configure(SaslChannelBuilder.java:147)
	at org.apache.kafka.common.network.ChannelBuilders.create(ChannelBuilders.java:146)
	at org.apache.kafka.common.network.ChannelBuilders.clientChannelBuilder(ChannelBuilders.java:67)
	at org.apache.kafka.clients.ClientUtils.createChannelBuilder(ClientUtils.java:99)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:426)
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:59)
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
	at org.apache.hadoop.hive.ql.exec.tez.DagUtils.getKafkaDelegationTokenForBrokers(DagUtils.java:333)
	at org.apache.hadoop.hive.ql.exec.tez.DagUtils.getKafkaCredentials(DagUtils.java:301)
	at org.apache.hadoop.hive.ql.exec.tez.DagUtils.addCredentials(DagUtils.java:282)
	at org.apache.hadoop.hive.ql.exec.tez.TezTask.build(TezTask.java:516)
	at org.apache.hadoop.hive.ql.exec.tez.TezTask.execute(TezTask.java:223)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:213)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:105)
	at org.apache.hadoop.hive.ql.Executor.launchTask(Executor.java:357)
	at org.apache.hadoop.hive.ql.Executor.launchTasks(Executor.java:330)
	at org.apache.hadoop.hive.ql.Executor.runTasks(Executor.java:246)
	at org.apache.hadoop.hive.ql.Executor.execute(Executor.java:109)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:721)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:488)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:482)
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:166)
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:232)
	at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:247)
	at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:193)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:412)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:343)
	at org.apache.hadoop.hive.ql.QTestUtil.executeClientInternal(QTestUtil.java:1465)
	at org.apache.hadoop.hive.ql.QTestUtil.executeClient(QTestUtil.java:1438)
	at org.apache.hadoop.hive.cli.control.CoreCliDriver.runTest(CoreCliDriver.java:194)
	at org.apache.hadoop.hive.cli.control.CliAdapter.runTest(CliAdapter.java:104)
	at org.apache.hadoop.hive.cli.TestMiniHiveKafkaCliDriver.testCliDriver(TestMiniHiveKafkaCliDriver.java:60)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.apache.hadoop.hive.cli.control.CliAdapter$2$1.evaluate(CliAdapter.java:92)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runners.Suite.runChild(Suite.java:127)
	at org.junit.runners.Suite.runChild(Suite.java:26)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.apache.hadoop.hive.cli.control.CliAdapter$1$1.evaluate(CliAdapter.java:73)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)

	at org.apache.kafka.common.network.SaslChannelBuilder.configure(SaslChannelBuilder.java:158) ~[kafka-clients-2.4.1.7.1.4.0-SNAPSHOT.jar:?]
	at org.apache.kafka.common.network.ChannelBuilders.create(ChannelBuilders.java:146) ~[kafka-clients-2.4.1.7.1.4.0-SNAPSHOT.jar:?]
	at org.apache.kafka.common.network.ChannelBuilders.clientChannelBuilder(ChannelBuilders.java:67) ~[kafka-clients-2.4.1.7.1.4.0-SNAPSHOT.jar:?]
	at org.apache.kafka.clients.ClientUtils.createChannelBuilder(ClientUtils.java:99) ~[kafka-clients-2.4.1.7.1.4.0-SNAPSHOT.jar:?]
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:426) ~[kafka-clients-2.4.1.7.1.4.0-SNAPSHOT.jar:?]
	... 64 more
{code}"	HIVE	Closed	3	4	1631	pull-request-available
13487046	MultiDelimitSerDe shouldn't rely on default charset when returning the deserialized string	Same fix as HIVE-26639 but on different codepath.	HIVE	Closed	3	4	1631	pull-request-available
13521251	Create a trackable hive configuration object	"During configuration-related investigations, I want to be able to easily find out when and how a certain configuration is changed. I'm looking for an improvement that simply logs if ""hive.a.b.c"" is changed from ""hello"" to ""asdf"" or even null and on which thread/codepath.
Not sure if there is already a trackable configuration object in hadoop that we can reuse, or we need to implement it in hive."	HIVE	In Progress	3	4	1631	pull-request-available
13407951	Hive on Tez: inserting data failing into the non native hive external table managed by kafka storage handler 	"This is the followup for HIVE-23408, repro is below:
{code}
CREATE EXTERNAL TABLE `kafka_table`(             
  `timestamp` timestamp COMMENT 'from deserializer',
  `page` string COMMENT 'from deserializer',     
  `newpage` boolean COMMENT 'from deserializer', 
  `added` int COMMENT 'from deserializer',       
  `deleted` bigint COMMENT 'from deserializer',  
  `delta` double COMMENT 'from deserializer')
ROW FORMAT SERDE                                 
  'org.apache.hadoop.hive.kafka.KafkaSerDe'      
STORED BY                                        
  'org.apache.hadoop.hive.kafka.KafkaStorageHandler'
WITH SERDEPROPERTIES (                           
  'serialization.format'='1')                    
LOCATION                                         
  'hdfs://lbodorkafkaunsec-2.lbodorkafkaunsec.root.hwx.site:8020/warehouse/tablespace/external/hive/kafka_table'
TBLPROPERTIES (                                  
  'bucketing_version'='2',                       
  'hive.kafka.max.retries'='6',                  
  'hive.kafka.metadata.poll.timeout.ms'='30000', 
  'hive.kafka.optimistic.commit'='false',        
  'hive.kafka.poll.timeout.ms'='5000',           
  'kafka.bootstrap.servers'='lbodorkafkaunsec-1.lbodorkafkaunsec.root.hwx.site:9092,lbodorkafkaunsec-2.lbodorkafkaunsec.root.hwx.site:9092,lbodorkafkaunsec-3.lbodorkafkaunsec.root.hwx.site:9092',
  'kafka.serde.class'='org.apache.hadoop.hive.serde2.JsonSerDe',
  'kafka.topic'='hit-topic-1',                   
  'kafka.write.semantic'='AT_LEAST_ONCE');

SELECT COUNT(*) FROM kafka_table WHERE `__timestamp` > 1000 * to_unix_timestamp(CURRENT_TIMESTAMP - interval '10' MINUTES); # works due to HIVE-23408

insert into kafka_table values(NULL, 'comment', 0, 1, 2, 3.0, NULL, NULL, NULL, NULL); # fails
{code}

exception I get:
{code}
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.kafkaesque.common.KafkaException: Failed to construct kafka producer
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:829)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:1004)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:937)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:95)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:937)
	at org.apache.hadoop.hive.ql.exec.UDTFOperator.forwardUDTFOutput(UDTFOperator.java:133)
	at org.apache.hadoop.hive.ql.udf.generic.UDTFCollector.collect(UDTFCollector.java:45)
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDTF.forward(GenericUDTF.java:110)
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDTFInline.process(GenericUDTFInline.java:64)
	at org.apache.hadoop.hive.ql.exec.UDTFOperator.process(UDTFOperator.java:116)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:937)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:95)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:937)
	at org.apache.hadoop.hive.ql.exec.TableScanOperator.process(TableScanOperator.java:128)
	at org.apache.hadoop.hive.ql.exec.MapOperator$MapOpCtx.forward(MapOperator.java:152)
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:552)
	... 20 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.kafkaesque.common.KafkaException: Failed to construct kafka producer
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:282)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketForFileIdx(FileSinkOperator.java:872)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:823)
	... 35 more
Caused by: org.apache.kafkaesque.common.KafkaException: Failed to construct kafka producer
	at org.apache.kafkaesque.clients.producer.KafkaProducer.<init>(KafkaProducer.java:432)
	at org.apache.kafkaesque.clients.producer.KafkaProducer.<init>(KafkaProducer.java:313)
	at org.apache.hadoop.hive.kafka.SimpleKafkaWriter.<init>(SimpleKafkaWriter.java:80)
	at org.apache.hadoop.hive.kafka.KafkaOutputFormat.getHiveRecordWriter(KafkaOutputFormat.java:60)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getRecordWriter(HiveFileFormatUtils.java:294)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:279)
	... 37 more
Caused by: org.apache.kafkaesque.common.KafkaException: javax.security.auth.login.LoginException: Could not login: the client is being asked for a password, but the Kafka client code does not currently support obtaining a password from the user. not available to garner  authentication information from the user
	at org.apache.kafkaesque.common.network.SaslChannelBuilder.configure(SaslChannelBuilder.java:158)
	at org.apache.kafkaesque.common.network.ChannelBuilders.create(ChannelBuilders.java:146)
	at org.apache.kafkaesque.common.network.ChannelBuilders.clientChannelBuilder(ChannelBuilders.java:67)
	at org.apache.kafkaesque.clients.ClientUtils.createChannelBuilder(ClientUtils.java:99)
	at org.apache.kafkaesque.clients.producer.KafkaProducer.newSender(KafkaProducer.java:450)
	at org.apache.kafkaesque.clients.producer.KafkaProducer.<init>(KafkaProducer.java:421)
	... 42 more
Caused by: javax.security.auth.login.LoginException: Could not login: the client is being asked for a password, but the Kafka client code does not currently support obtaining a password from the user. not available to garner  authentication information from the user
	at com.sun.security.auth.module.Krb5LoginModule.promptForPass(Krb5LoginModule.java:944)
	at com.sun.security.auth.module.Krb5LoginModule.attemptAuthentication(Krb5LoginModule.java:764)
	at com.sun.security.auth.module.Krb5LoginModule.login(Krb5LoginModule.java:617)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at javax.security.auth.login.LoginContext.invoke(LoginContext.java:755)
	at javax.security.auth.login.LoginContext.access$000(LoginContext.java:195)
	at javax.security.auth.login.LoginContext$4.run(LoginContext.java:682)
	at javax.security.auth.login.LoginContext$4.run(LoginContext.java:680)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.login.LoginContext.invokePriv(LoginContext.java:680)
	at javax.security.auth.login.LoginContext.login(LoginContext.java:587)
	at org.apache.kafkaesque.common.security.authenticator.AbstractLogin.login(AbstractLogin.java:60)
	at org.apache.kafkaesque.common.security.kerberos.KerberosLogin.login(KerberosLogin.java:103)
	at org.apache.kafkaesque.common.security.authenticator.LoginManager.<init>(LoginManager.java:62)
	at org.apache.kafkaesque.common.security.authenticator.LoginManager.acquireLoginManager(LoginManager.java:105)
	at org.apache.kafkaesque.common.network.SaslChannelBuilder.configure(SaslChannelBuilder.java:147)
	... 47 more
{code}"	HIVE	Closed	3	4	1631	pull-request-available
13324289	Bloom filters can be cached after deserialization in VectorInBloomFilterColDynamicValue	Same bloom filter is loaded multiple times across tasks. It would be good to check if we can optimise this, to avoid deserializing.	HIVE	Closed	3	4	1631	pull-request-available
13169364	ResultsCache: Improve logging for concurrent queries	"The logging for QueryResultsCache ends up printing information without context, like 

{code}
2018-06-30T17:48:45,502  INFO [HiveServer2-Background-Pool: Thread-166] results.QueryResultsCache: Waiting on pending cacheEntry
{code}

{code}
2018-06-30T17:50:17,963  INFO [HiveServer2-Background-Pool: Thread-145] ql.Driver: savedToCache: true
{code}

The previous lines for this are in DEBUG level, so the logging ends up being useless at INFO level to debug."	HIVE	Closed	4	4	1631	Branch3Candidate
13347186	TestCompactor fails to compile since HIVE-24477	"http://ci.hive.apache.org/blue/organizations/jenkins/hive-precommit/detail/PR-1798/1/pipeline

{code}
[2020-12-21T17:27:41.296Z] [INFO] ------------------------------------------------------------------------

[2020-12-21T17:27:41.296Z] [ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.8.1:testCompile (default-testCompile) on project hive-it-unit: Compilation failure: Compilation failure: 

[2020-12-21T17:27:41.296Z] [ERROR] /home/jenkins/agent/workspace/hive-precommit_PR-1798/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/txn/compactor/TestCompactor.java:[1257,17] cannot find symbol

[2020-12-21T17:27:41.296Z] [ERROR]   symbol:   variable TxnDbUtil

[2020-12-21T17:27:41.296Z] [ERROR]   location: class org.apache.hadoop.hive.ql.txn.compactor.TestCompactor

[2020-12-21T17:27:41.296Z] [ERROR] /home/jenkins/agent/workspace/hive-precommit_PR-1798/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/txn/compactor/TestCompactor.java:[1266,13] cannot find symbol

[2020-12-21T17:27:41.296Z] [ERROR]   symbol:   variable TxnDbUtil

[2020-12-21T17:27:41.296Z] [ERROR]   location: class org.apache.hadoop.hive.ql.txn.compactor.TestCompactor

[2020-12-21T17:27:41.296Z] [ERROR] -> [Help 1]

[2020-12-21T17:27:41.296Z] [ERROR] 

[2020-12-21T17:27:41.296Z] [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.

[2020-12-21T17:27:41.296Z] [ERROR] Re-run Maven using the -X switch to enable full debug logging.

[2020-12-21T17:27:41.296Z] [ERROR] 

[2020-12-21T17:27:41.296Z] [ERROR] For more information about the errors and possible solutions, please read the following articles:

[2020-12-21T17:27:41.296Z] [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException

[2020-12-21T17:27:41.296Z] [ERROR] 

[2020-12-21T17:27:41.296Z] [ERROR] After correcting the problems, you can resume the build with the command

[2020-12-21T17:27:41.296Z] [ERROR]   mvn <args> -rf :hive-it-unit
{code}"	HIVE	Closed	1	1	1631	pull-request-available
13400312	CLIService.closeOperation should not fail if operation handle is not present	I think, if we want the close operation to be safe and idempotent, we should not fail on client side if 2 different close requests come in (due to socket timeout + retry) for the same operation handle (and second fails because operation handle was already removed for the first request which then socket timed out)	HIVE	Closed	3	1	1631	pull-request-available
13550035	Misson union subdir should be ignored in some cases	"when a union job creates files only in specific subdirs, this can happen:

{code}
ERROR : Job Commit failed with exception 'org.apache.hadoop.hive.ql.metadata.HiveException(java.io.FileNotFoundException: File hdfs://c3857-node3.coelab.cloudera.com:8020/warehouse/tablespace/managed/hive/lbodor_test2/dt=20230817/base_0000001/HIVE_UNION_SUBDIR_1 does not exist.)'
org.apache.hadoop.hive.ql.metadata.HiveException: java.io.FileNotFoundException: File hdfs://c3857-node3.coelab.cloudera.com:8020/warehouse/tablespace/managed/hive/lbodor_test2/dt=20230817/base_0000001/HIVE_UNION_SUBDIR_1 does not exist.
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.jobCloseOp(FileSinkOperator.java:1528)
	at org.apache.hadoop.hive.ql.exec.Operator.jobClose(Operator.java:797)
	at org.apache.hadoop.hive.ql.exec.Operator.jobClose(Operator.java:802)
	at org.apache.hadoop.hive.ql.exec.Operator.jobClose(Operator.java:802)
	at org.apache.hadoop.hive.ql.exec.Operator.jobClose(Operator.java:802)
	at org.apache.hadoop.hive.ql.exec.Operator.jobClose(Operator.java:802)
	at org.apache.hadoop.hive.ql.exec.tez.TezTask.close(TezTask.java:646)
	at org.apache.hadoop.hive.ql.exec.tez.TezTask.execute(TezTask.java:344)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:213)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:105)
	at org.apache.hadoop.hive.ql.Executor.launchTask(Executor.java:357)
	at org.apache.hadoop.hive.ql.Executor.launchTasks(Executor.java:330)
	at org.apache.hadoop.hive.ql.Executor.runTasks(Executor.java:246)
	at org.apache.hadoop.hive.ql.Executor.execute(Executor.java:109)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:770)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:504)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:498)
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:166)
	at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:229)
	at org.apache.hive.service.cli.operation.SQLOperation.access$700(SQLOperation.java:91)
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:329)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1898)
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:347)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: File hdfs://c3857-node3.coelab.cloudera.com:8020/warehouse/tablespace/managed/hive/lbodor_test2/dt=20230817/base_0000001/HIVE_UNION_SUBDIR_1 does not exist.
	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatusInternal(DistributedFileSystem.java:1097)
	at org.apache.hadoop.hdfs.DistributedFileSystem.access$600(DistributedFileSystem.java:145)
	at org.apache.hadoop.hdfs.DistributedFileSystem$24.doCall(DistributedFileSystem.java:1168)
	at org.apache.hadoop.hdfs.DistributedFileSystem$24.doCall(DistributedFileSystem.java:1165)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatus(DistributedFileSystem.java:1175)
	at org.apache.hadoop.hive.ql.exec.Utilities.removeTempOrDuplicateFiles(Utilities.java:1794)
	at org.apache.hadoop.hive.ql.exec.Utilities.handleDirectInsertTableFinalPath(Utilities.java:4579)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.jobCloseOp(FileSinkOperator.java:1522)
	... 31 more
{code}

please find repro in PR"	HIVE	Resolved	3	1	1631	pull-request-available
13261553	Cluster and fs type settings can be replaced with a single minicluster setting in CliConfigs	"Fs + cluster types are already linked together in MiniClusterType, so it's confusing to set them in 2 steps, separately, if it covers an already defined minicluster type.
https://github.com/apache/hive/blob/master/itests/util/src/main/java/org/apache/hadoop/hive/cli/control/CliConfigs.java
{code}
        setClusterType(MiniClusterType.TEZ);
        setFsType(QTestMiniClusters.FsType.HDFS);
{code}"	HIVE	Closed	4	1	1631	newbie
13442021	Some improvements to make DPP more debuggable	we need to see in logs at least how many partitions have been received in the event payload	HIVE	Closed	3	4	1631	pull-request-available
13057521	Support percentile_cont / percentile_disc	"Way back in HIVE-259, a percentile function was added that provides a subset of the standard percentile_cont aggregate function.

The SQL standard provides some additional options and also a percentile_disc aggregate function with different rules. In the standard you specify an ordering with arbitrary value expression and the results are drawn from this value expression. This aggregate functions should be usable as analytic functions as well (i.e. support the over clause). The current percentile function is able to be used with an over clause.

The rough outline of how this works is:
percentile_cont(number) within group (order by expression) [ over(window spec) ]
percentile_disc(number) within group (order by expression) [ over(window spec) ]

The value of number should be between 0 and 1. The value expression is evaluated for each row of the group, nulls are discarded, and the remaining rows are ordered.

— If PERCENTILE_CONT is specified, by considering the pair of consecutive rows that are indicated by the argument, treated as a fraction of the total number of rows in the group, and interpolating the value of the value expression evaluated for these rows.

— If PERCENTILE_DISC is specified, by treating the group as a window partition of the CUME_DIST window function, using the specified ordering of the value expression as the window ordering, and returning the  first value expression whose cumulative distribution value is greater than or equal to the argument."	HIVE	Closed	3	7	1631	todoc4.0
13571287	FSCountersSummary is only printed when LLAP IO is enabled	"FSCountersSummary is only printed when LLAP IO is enabled, however, it's not LLAP IO specific as far as I know:
https://github.com/apache/hive/blob/03a76ac70370fb94a78b00496ec511e671c652f2/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/monitoring/TezJobMonitor.java#L446-L449

it gives useful summary like:
{code}
INFO  : Scheme: S3A
INFO  : ----------------------------------------------------------------------------------------------
INFO  :   VERTICES      BYTES_READ      READ_OPS     LARGE_READ_OPS      BYTES_WRITTEN     WRITE_OPS
INFO  : ----------------------------------------------------------------------------------------------
INFO  :      Map 1         68.53KB             4                  0                 0B             0
INFO  :     Map 11          5.54MB            68                  0                 0B             0
INFO  :      Map 2        238.48MB           480                  0                 0B             0
INFO  :      Map 5         10.71MB            80                  0                 0B             0
INFO  :      Map 6         60.68MB           360                  0                 0B             0
INFO  :      Map 8          2.69MB            24                  0                 0B             0
INFO  :      Map 9        120.03MB           480                  0                 0B             0
INFO  : Reducer 10              0B             0                  0                 0B             0
INFO  :  Reducer 3              0B             0                  0                 0B             0
INFO  :  Reducer 4              0B             0                  0                 0B             0
INFO  :  Reducer 7              0B             0                  0                 0B             0
INFO  : ----------------------------------------------------------------------------------------------
{code}

need to check if it prints similar data correctly in case of Tez container mode as this is specific to the tez runner callable and the TaskCounterUpdater is called from tez codepath"	HIVE	Open	3	1	1631	pull-request-available
13418806	Tez exec mode support for credential provider for jobs	HIVE-14822 introduced support to securely forward a job specific java credential store path, and a corresponding password to the backend executors. This is currently implemented for only MR2 and Spark execution engines. I propose we extend this feature by adding Tez mode to said list.	HIVE	Closed	3	4	1631	pull-request-available
13328803	LLAP: ShuffleHandler might return DISK_ERROR_EXCEPTION according to TEZ-4233	This jira is about porting the ShuffleHandler's changes to LLAP from TEZ-4233.	HIVE	Closed	3	4	1631	pull-request-available
13472148	Vectorization: Fix deallocation of scratch columns, don't reuse a child ConstantVectorExpression as an output	"This is similar to HIVE-15588. With a customer query, I reproduced a vectorized expression tree like the below one (I'll attach a simple repro query when it's possible):
{code}
selectExpressions: IfExprCondExprColumn(col 67:boolean, col 63:string, col 61:string)(children: StringColumnInList(col 13, values TermDeposit, RecurringDeposit, CertificateOfDeposit) -> 67:boolean, VectorCoalesce(columns [61, 62])(children: VectorUDFAdaptor(from_unixtime(to_unix_timestamp(CAST( _col1 AS DATE)), 'MM-dd-yyyy'))(children: VectorUDFUnixTimeStampDate(col 68)(children: CastStringToDate(col 33:string) -> 68:date) -> 69:bigint) -> 61:string, ConstantVectorExpression(val  ) -> 62:string) -> 63:string, ConstantVectorExpression(val ) -> 61:string) -> 62:string
{code}

query part was:
{code}
  CASE WHEN DLY_BAL.PDELP_VALUE in (
    'TermDeposit', 'RecurringDeposit',
    'CertificateOfDeposit'
  ) THEN NVL(
    (
      from_unixtime(
        unix_timestamp(
          cast(DLY_BAL.APATD_MTRTY_DATE as date)
        ),
        'MM-dd-yyyy'
      )
    ),
    ' '
  ) ELSE '' END AS MAT_DTE
{code}

Here is the problem described:
1. IfExprCondExprColumn has 62:string as its [outputColumn|https://github.com/apache/hive/blob/d3309c0ea9da907af4d27427805084b7331a6c24/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/IfExprCondExprColumn.java#L64], which is a reused scratch column (see 5) )
2. in evaluation time, [isRepeating is reset|https://github.com/apache/hive/blob/d3309c0ea9da907af4d27427805084b7331a6c24/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/IfExprCondExprColumn.java#L68]
3. in order to evaluate IfExprCondExprColumn, the conditional evaluation of children is required, so we go to [conditionalEvaluate|https://github.com/apache/hive/blob/d3309c0ea9da907af4d27427805084b7331a6c24/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/IfExprCondExprColumn.java#L95]
4. one of the children is ConstantVectorExpression(val  ) -> 62:string, which belongs to the second branch of VectorCoalesce, so to the '' empty string in NVL's second argument
5. in 4) 62: string column is set to an isRepeating column (and it's released by [freeNonColumns|https://github.com/apache/hive/blob/d3309c0ea9da907af4d27427805084b7331a6c24/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorizationContext.java#L2459]), so it's marked as a reusable scratch column
6. after the conditional evaluation in 3), the final output of IfExprCondExprColumn set [here|https://github.com/apache/hive/blob/d3309c0ea9da907af4d27427805084b7331a6c24/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/IfExprCondExprColumn.java#L99], but here we get an exception [here|https://github.com/apache/hive/blob/d3309c0ea9da907af4d27427805084b7331a6c24/storage-api/src/java/org/apache/hadoop/hive/ql/exec/vector/BytesColumnVector.java#L484]:
{code}
2022-07-01T04:26:24,567 ERROR [TezTR-745267_1_35_6_0_0] tez.MapRecordSource: java.lang.AssertionError: Output column number expected to be 0 when isRepeating
	at org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector.setElement(BytesColumnVector.java:494)
	at org.apache.hadoop.hive.ql.exec.vector.expressions.IfExprCondExprColumn.evaluate(IfExprCondExprColumn.java:108)
	at org.apache.hadoop.hive.ql.exec.vector.VectorSelectOperator.process(VectorSelectOperator.java:146)
	at org.apache.hadoop.hive.ql.exec.Operator.vectorForward(Operator.java:969)
	at org.apache.hadoop.hive.ql.exec.vector.mapjoin.VectorMapJoinGenerateResultOperator.forwardBigTableBatch(VectorMapJoinGenerateResultOperator.java:694)
	at org.apache.hadoop.hive.ql.exec.vector.mapjoin.VectorMapJoinInnerBigOnlyStringOperator.processBatch(VectorMapJoinInnerBigOnlyStringOperator.java:371)
	at org.apache.hadoop.hive.ql.exec.vector.mapjoin.VectorMapJoinCommonOperator.process(VectorMapJoinCommonOperator.java:839)
	at org.apache.hadoop.hive.ql.exec.Operator.vectorForward(Operator.java:969)
{code}

this is clearly an incorrect scratch column reuse, where we reused the output of some children, and got that vector in an inconsistent state
this must not be fixed by resetting vectors in more places in IfExprCondExprColumn, as it would just hide the original issue

I realized that the problem can be easily fixed by simply preventing releasing ConstantVectorExpressions, that's what I'm trying to test now"	HIVE	Closed	3	1	1631	hive-3.2.0-candidate, pull-request-available
13531697	Show Compactions failing with NPE	"{noformat}
java.lang.NullPointerException: null
	at java.io.DataOutputStream.writeBytes(DataOutputStream.java:274) ~[?:?]
	at org.apache.hadoop.hive.ql.ddl.process.show.compactions.ShowCompactionsOperation.writeRow(ShowCompactionsOperation.java:135) 
	at org.apache.hadoop.hive.ql.ddl.process.show.compactions.ShowCompactionsOperation.execute(ShowCompactionsOperation.java:57) 
	at org.apache.hadoop.hive.ql.ddl.DDLTask.execute(DDLTask.java:84)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:213) 
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:105) 
	at org.apache.hadoop.hive.ql.Executor.launchTask(Executor.java:360) 
{noformat}
"	HIVE	Closed	3	1	2469	pull-request-available
13355191	Sync ACL's for the table directory during external table replication.	Set similar ACL's to destination table directory in case the source has ACL's enabled or set.	HIVE	Resolved	3	1	2469	pull-request-available
13501607	Iceberg: Add an option to allow positional delete files without actual row data	Allow an option to have actual row data in the Iceberg PositionalDelete file as optional, to avoid reading and writing huge amount of actual row data during query executions.	HIVE	Closed	3	4	2469	pull-request-available
13580937	Attempt make the scratch directory writable before failing	"When hive is starting up it checks the tmp/hive directory privileges. Even if the Azure managed identity have write access on an Azure storage account, the rwx-wx-wx privileges still enforced, so in case rwxr-xr-x is set, the hive process startup will fail. 

See the logs of a startup that resulted in failure.
{code}
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.hadoop.hive.common.StringInternUtils (file:/usr/lib/hive/lib/hive-common-3.1.3000.2023.0.16.0-142.jar) to field java.net.URI.string
WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.hive.common.StringInternUtils
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
Exception in thread ""main"" java.lang.RuntimeException: Error applying authorization policy on hive configuration: The dir: /tmp/hive on HDFS should be writable. Current permissions are: rwxr-xr-x
    at org.apache.hive.service.cli.CLIService.init(CLIService.java:121)
    at org.apache.hive.service.cli.thrift.EmbeddedThriftBinaryCLIService.init(EmbeddedThriftBinaryCLIService.java:63)
    at org.apache.hive.jdbc.HiveConnection.<init>(HiveConnection.java:357)
    at org.apache.hive.jdbc.HiveConnection.<init>(HiveConnection.java:287)
    at org.apache.hive.jdbc.HiveDriver.connect(HiveDriver.java:107)
    at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:677)
    at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:228)
    at org.apache.hadoop.hive.metastore.tools.schematool.HiveSchemaHelper.getConnectionToMetastore(HiveSchemaHelper.java:88)
    at org.apache.hadoop.hive.metastore.tools.schematool.HiveSchemaHelper.getConnectionToMetastore(HiveSchemaHelper.java:103)
    at org.apache.hadoop.hive.metastore.CDHMetaStoreSchemaInfo.getMetaStoreSchemaVersion(CDHMetaStoreSchemaInfo.java:323)
    at org.apache.hadoop.hive.metastore.tools.schematool.SchemaToolTaskInitOrUpgrade.execute(SchemaToolTaskInitOrUpgrade.java:41)
    at org.apache.hadoop.hive.metastore.tools.schematool.MetastoreSchemaTool.run(MetastoreSchemaTool.java:482)
    at org.apache.hive.beeline.schematool.HiveSchemaTool.main(HiveSchemaTool.java:143)
    at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.base/java.lang.reflect.Method.invoke(Method.java:566)
    at org.apache.hadoop.util.RunJar.run(RunJar.java:318)
    at org.apache.hadoop.util.RunJar.main(RunJar.java:232)
Caused by: java.lang.RuntimeException: The dir: /tmp/hive on HDFS should be writable. Current permissions are: rwxr-xr-x
    at org.apache.hadoop.hive.ql.exec.Utilities.ensurePathIsWritable(Utilities.java:5088)
    at org.apache.hadoop.hive.ql.session.SessionState.createRootHDFSDir(SessionState.java:896)
    at org.apache.hadoop.hive.ql.session.SessionState.createSessionDirs(SessionState.java:837)
    at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:749)
    at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:708)
    at org.apache.hive.service.cli.CLIService.applyAuthorizationConfigPolicy(CLIService.java:133)
    at org.apache.hive.service.cli.CLIService.init(CLIService.java:118)
    ... 18 more
Information schema initialization failed!
+ '[' 1 -eq 0 ']'
+ echo 'Information schema initialization failed!'
+ exit 1
{code}

To overcome this issue one approach could be to try to set the tmp/hive folder privileges to rwx-wx-wx before failing the startup."	HIVE	Resolved	3	1	2469	hive-4.0.1-merged, pull-request-available
13430822	Optimise multiple copies in case of CTAS in external tables for Object stores	"Presently for CTAS with external tables, there are two renames, operations, one from tmp to _ext and then from _ext to actual target.
In case of object stores, the renames lead to actual copy. Avoid renaming by avoiding rename from tmp to _ext, but by creating a list of files to be copied in that directly, which can be consumed in the move task, to copy directly from tmp to actual target."	HIVE	Closed	3	4	2469	pull-request-available
13580168	Iceberg: Add support for 'If Not Exists' and 'or Replace' for Create Branch	"Add support for 
{noformat}
-- CREATE audit-branch at current snapshot with default retention if it doesn't exist.
ALTER TABLE prod.db.sample CREATE BRANCH IF NOT EXISTS `audit-branch`

-- CREATE audit-branch at current snapshot with default retention or REPLACE it if it already exists.
ALTER TABLE prod.db.sample CREATE OR REPLACE BRANCH `audit-branch`{noformat}
Like Spark:

https://iceberg.apache.org/docs/1.5.1/spark-ddl/#branching-and-tagging-ddl"	HIVE	Resolved	3	7	2469	pull-request-available
13259051	HiveHFileOutputFormat throws FileNotFoundException when partition's task output empty	"When partition's task output empty, HiveHFileOutputFormat throws FileNotFoundException like this:
{code:java}
2019-09-24 19:15:55,886 INFO [main] org.apache.hadoop.hive.ql.exec.FileSinkOperator: 1 finished. closing... 
2019-09-24 19:15:55,886 INFO [main] org.apache.hadoop.hive.ql.exec.FileSinkOperator: FS[1]: records written - 0
2019-09-24 19:15:55,886 INFO [main] org.apache.hadoop.hive.ql.exec.FileSinkOperator: Final Path: FS hdfs://Hdptest-mini-nmg/tmp/hive-staging/hadoop_hive_2019-09-24_19-15-26_453_1697529445006435790-5/_tmp.-ext-10002/000002_0
2019-09-24 19:15:55,886 INFO [main] org.apache.hadoop.hive.ql.exec.FileSinkOperator: Writing to temp file: FS hdfs://Hdptest-mini-nmg/tmp/hive-staging/hadoop_hive_2019-09-24_19-15-26_453_1697529445006435790-5/_task_tmp.-ext-10002/_tmp.000002_0
2019-09-24 19:15:55,886 INFO [main] org.apache.hadoop.hive.ql.exec.FileSinkOperator: New Final Path: FS hdfs://Hdptest-mini-nmg/tmp/hive-staging/hadoop_hive_2019-09-24_19-15-26_453_1697529445006435790-5/_tmp.-ext-10002/000002_0
2019-09-24 19:15:55,915 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-09-24 19:15:55,954 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: hadoop.native.lib is deprecated. Instead, use io.native.lib.available
2019-09-24 19:15:56,089 ERROR [main] ExecReducer: Hit error while closing operators - failing tree
2019-09-24 19:15:56,090 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.lang.RuntimeException: Hive Runtime Error while closing operators: java.io.FileNotFoundException: File hdfs://Hdptest-mini-nmg/tmp/hive-staging/hadoop_hive_2019-09-24_19-15-26_453_1697529445006435790-5/_task_tmp.-ext-10002/_tmp.000002_0 does not exist.
  at org.apache.hadoop.hive.ql.exec.mr.ExecReducer.close(ExecReducer.java:287)
  at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:453)
  at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)
  at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
  at java.security.AccessController.doPrivileged(Native Method)
  at javax.security.auth.Subject.doAs(Subject.java:422)
  at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1923)
  at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.io.FileNotFoundException: File hdfs://Hdptest-mini-nmg/tmp/hive-staging/hadoop_hive_2019-09-24_19-15-26_453_1697529445006435790-5/_task_tmp.-ext-10002/_tmp.000002_0 does not exist.
  at org.apache.hadoop.hive.ql.exec.FileSinkOperator$FSPaths.closeWriters(FileSinkOperator.java:200)
  at org.apache.hadoop.hive.ql.exec.FileSinkOperator.closeOp(FileSinkOperator.java:1016)
  at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:617)
  at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:631)
  at org.apache.hadoop.hive.ql.exec.mr.ExecReducer.close(ExecReducer.java:278)
  ... 7 more
Caused by: java.io.FileNotFoundException: File hdfs://Hdptest-mini-nmg/tmp/hive-staging/hadoop_hive_2019-09-24_19-15-26_453_1697529445006435790-5/_task_tmp.-ext-10002/_tmp.000002_0 does not exist.
  at org.apache.hadoop.hdfs.DistributedFileSystem.listStatusInternal(DistributedFileSystem.java:880)
  at org.apache.hadoop.hdfs.DistributedFileSystem.access$700(DistributedFileSystem.java:109)
  at org.apache.hadoop.hdfs.DistributedFileSystem$19.doCall(DistributedFileSystem.java:938)
  at org.apache.hadoop.hdfs.DistributedFileSystem$19.doCall(DistributedFileSystem.java:934)
  at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
  at org.apache.hadoop.hdfs.DistributedFileSystem.listStatus(DistributedFileSystem.java:945)
  at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1592)
  at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1632)
  at org.apache.hadoop.hive.hbase.HiveHFileOutputFormat$1.close(HiveHFileOutputFormat.java:153)
  at org.apache.hadoop.hive.ql.exec.FileSinkOperator$FSPaths.closeWriters(FileSinkOperator.java:197)
  ... 11 more

2019-09-24 19:15:56,093 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
{code}
I think we should skip it if srcDir do not exist, fix like this:
{code:java}
@Override
public void close(boolean abort) throws IOException {
  try {

    ...

    FileStatus [] files = null;
    for (;;) {
      try {
        files = fs.listStatus(srcDir, FileUtils.STAGING_DIR_PATH_FILTER);
      } catch (FileNotFoundException fnfe) {
        LOG.error(String.format(""Output data is empty, please check Task [ %s ]"", tac.getTaskAttemptID().toString()), fnfe);
        break;
      }
    }
    if (files != null ) {
      for (FileStatus regionFile : fs.listStatus(srcDir, FileUtils.STAGING_DIR_PATH_FILTER)) {
        fs.rename(regionFile.getPath(), new Path(columnFamilyPath, regionFile.getPath().getName()));
      }
    }
    for (FileStatus regionFile : fs.listStatus(srcDir, FileUtils.STAGING_DIR_PATH_FILTER)) {
      fs.rename(
     
    ...

  } catch (InterruptedException ex) {
    throw new IOException(ex);
  }
}
{code}"	HIVE	Resolved	3	1	2469	pull-request-available
13503205	Iceberg: Fetch format version from metadata file to avoid conflicts with spark	"Spark & other engines don't set the format version for iceberg table in the HMS properties, which leads to misinterpretation of iceberg format & lead to wrong query results.

Propose to extract the format version from the metadata file always rather than relying on the HMS properties."	HIVE	Closed	3	1	2469	pull-request-available
13506796	Iceberg: Read queries with copy-on-write failing	Hive by default only supports merge-on-read, But the read queries have nothing to do with this config. The Read queries shouldn't fail due to this. The default mode set by Spark is copy-on-write, we should allow read operations on tables created via spark with copy-on-write	HIVE	Closed	3	1	2469	pull-request-available
13570425	Iceberg: Invoke validateDataFilesExist for RowDelta operations	"Hive must invoke validateDataFilesExist for RowDelta operations (DELETE/UPDATE/MERGE).

Without this a concurrent RewriteFiles (compaction) and RowDelta can corrupt a table."	HIVE	Closed	3	1	2469	iceberg, pull-request-available
13551379	Iceberg: metadata location overrides can cause data breach	"Set to bug/blocker instead of enhancement due to its security related nature, Hive4 should not be released w/o fix for this. Please reset if needed.

 

Context: 
 * There are some core tables with sensitive data that users can only query with data masking enforced (e.g. via Ranger). Let's assume this is the `default.icebergsecured` table.
 * An end-user can only access the masked form of the sensitive data as expected...
 * The users also have privilege to create new tables in their own sandbox databases - let's assume this is the `default.trojanhorse` table for now.
 * The user can create a malicious table that exposes the sensitive data non-masked leading to a possible data breach.
 * Hive runs with doAs=false to be able to enforce FGAC and prevent end-user direct file-system access needs

Repro:
 * First make sure the data is secured by the masking policy:
{noformat}
<kinit as privileged user>
beeline -e ""
DROP TABLE IF EXISTS default.icebergsecured PURGE;
CREATE EXTERNAL TABLE default.icebergsecured (txt string, secret string) STORED BY ICEBERG;
INSERT INTO default.icebergsecured VALUES ('You might be allowed to see this.','You are NOT allowed to see this!');
""

<kinit as end user>
beeline -e ""
SELECT * FROM default.icebergsecured;
""

+------------------------------------+--------------------------------+
|         icebergsecured.txt         |     icebergsecured.secret      |
+------------------------------------+--------------------------------+
| You might be allowed to see this.  | MASKED BY RANGER FOR SECURITY  |
+------------------------------------+--------------------------------+
{noformat}

 * Now let the user to create the malicious table exposing the sensitive data:
{noformat}
<kinit as end user>
SECURED_META_LOCATION=$(HADOOP_CLIENT_OPTS=""-Djline.terminal=jline.UnsupportedTerminal"" beeline -e ""DESCRIBE FORMATTED default.icebergsecured;"" 2>/dev/null |grep metadata_location  |grep -v previous_metadata_location | awk '{print $5}')
beeline -e ""
DROP TABLE IF EXISTS default.trojanhorse;
CREATE EXTERNAL TABLE default.trojanhorse (txt string, secret string) STORED BY ICEBERG
TBLPROPERTIES (
  'metadata_location'='${SECURED_META_LOCATION}');
SELECT * FROM default.trojanhorse;
""

+------------------------------------+-----------------------------------+
|          trojanhorse.txt           |        trojanhorse.secret         |
+------------------------------------+-----------------------------------+
| You might be allowed to see this.  | You are not allowed to see this!  |
+------------------------------------+-----------------------------------+
{noformat}

 

Currently - after HIVE-26707 - the rwstorage authorization only has either the dummy path or the explicit path set for uri:  
{noformat}
Permission denied: user [oozie] does not have [RWSTORAGE] privilege on 
[iceberg://default/trojanhorse?snapshot=%2Fwarehouse%2Ftablespace%2Fexternal%2Fhive%2Ftrojanhorse%2Fmetadata%2Fdummy.metadata.json]

Permission denied: user [oozie] does not have [RWSTORAGE] privilege on 
[iceberg://default/trojanhorse?snapshot=%2Fwarehouse%2Ftablespace%2Fexternal%2Fhive%2Ficebergsecured%2Fmetadata%2F00001-f4c2a428-30ce-4afd-82ff-d46ecbf02244.metadata.json] 
{noformat}
With custom location it's even not passed to the authorizer:
{noformat}
2023-05-17 19:38:51,867 INFO  org.apache.hadoop.hive.ql.Driver: [a49356b4-1b7a-4c9d-9b70-81af12c0465f HiveServer2-Handler-Pool: Thread-253]: Compiling command(queryId=hive_20230517193851_8b9f0ad7-2ae1-4078-b76a-e51c31321b0b): 
CREATE EXTERNAL TABLE default.policytestth (txt string, secret string) STORED BY ICEBERG 
TBLPROPERTIES (
  'metadata_location'='hdfs://test.local.host:8020/warehouse/tablespace/external/hive/policytest/metadata/00001-a3e46c1b-318b-4b46-886a-c6ea591f63c1.metadata.json')
...
2023-05-17 19:38:51,898 DEBUG org.apache.iceberg.mr.hive.HiveIcebergStorageHandler: [a49356b4-1b7a-4c9d-9b70-81af12c0465f HiveServer2-Handler-Pool: Thread-253]: 
Iceberg storage handler authorization URI 
iceberg://default/policytestth?snapshot=%2Fwarehouse%2Ftablespace%2Fexternal%2Fhive%2Fpolicytestth%2Fmetadata%2Fdummy.metadata.json
{noformat}
 

Mandatory changes required for securing tables:
 * Custom location needs to be passed to the Authorizer

Changes required for usability - e.g. to eliminate the need to require a policy for each tables:
 * Default location needs to be calculated based on warehouse/database def. location
 * CREATE/ALTER with default locations should not involve RWStorage Authorization or should be handled a special way in the Authorizer. "	HIVE	Closed	3	1	2469	check
13500972	Mask UDF failing with NPE	"The mask UDF fails with NPE in prod, due to unavailability of the session conf.

Trace:
{noformat}
	... 20 more
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.udf.generic.MaskHashTransformer.transform(GenericUDFMaskHash.java:50)
	at org.apache.hadoop.hive.ql.udf.generic.StringTransformerAdapter.getTransformedWritable(BaseMaskUDF.java:459)
	at org.apache.hadoop.hive.ql.udf.generic.BaseMaskUDF.evaluate(BaseMaskUDF.java:84)
	at org.apache.hadoop.hive.ql.exec.ExprNodeGenericFuncEvaluator._evaluate(ExprNodeGenericFuncEvaluator.java:235)
	at org.apache.hadoop.hive.ql.exec.ExprNodeEvaluator.evaluate(ExprNodeEvaluator.java:80)
	at org.apache.hadoop.hive.ql.exec.ExprNodeEvaluator.evaluate(ExprNodeEvaluator.java:68)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:88)
	... 24 more
], TaskAttempt 1 failed, info=[Error: Error while running task ( failure ) : attempt_1667823513257_0010_2_00_000000_1:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row
	at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:351)
	at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:280)
	at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:374){noformat}"	HIVE	Closed	3	1	2469	pull-request-available
13547543	Iceberg: Fast forward branch	"Add support to fastForward main branch to the head of feature-branch to update the main table state.
{code}
table.manageSnapshots().fastForward(""main"", ""feature-branch"").commit()
{code}"	HIVE	Closed	3	7	2469	pull-request-available
13417307	URL Mapping appends default Fs scheme even for LOCAL DIRECTORY ops	"Repro steps:

Connect to beeline

{code:java}
beeline -u ""jdbc:hive2://quasar-pxlypi-2.quasar-pxlypi.root.hwx.site:10001/;principal=hive/_HOST@ROOT.HWX.SITE;ssl=true;sslTrustStore=/var/lib/cloudera-scm-agent/agent-cert/cm-auto-global_truststore.jks;trustStorePassword=VOAnRk5l4oXsg0upJ1ApscSuNksirOKgyhJvoPv2o4j;transportMode=http;httpPath=cliservice;""
{code}

 

Create a test table and run insert on local

{code:java}
> create table dual (id int); 
> insert overwrite local directory ""/tmp/"" select * from dual;
{code}


{code:java}
Error: Error while compiling statement: FAILED: HiveAccessControlException Permission denied: user [hrt_qa] does not have [ALL] privilege on [hdfs://ns1/tmp] (state=42000,code=40000)
{code}


It always appends hdfs:// to the path even if the operation is meant for local directory."	HIVE	Closed	2	1	2469	pull-request-available
13582407	Iceberg: Allow reading tables irrespective whether they were created with hive engined enabled or not	"If a Iceberg table is created via some other engine under default conditions it won't create it with Hive engine enabled.
It will fail with

{noformat}
Error: Error while compiling statement: FAILED: SemanticException [Error 10055]: Line 1:12 Output Format must implement HiveOutputFormat, otherwise it should be either IgnoreKeyTextOutputFormat or SequenceFileOutputFormat 'ice_01': The class is class org.apache.hadoop.mapred.FileOutputFormat (state=42000,code=10055)
{noformat}

We should allow reading the iceberg table irrespective whether it has Serde/Storage Handler set wrt Iceberg.

We can still set the right one while creating the table via Hive for Backward Compatibility
"	HIVE	Resolved	3	4	2469	pull-request-available
13403996	Fix Metastore script for Oracle Database	"Error:1
{noformat}
354/359      CREATE UNIQUE INDEX DBPRIVILEGEINDEX ON DC_PRIVS (AUTHORIZER,NAME,PRINCIPAL_NAME,PRINCIPAL_TYPE,DC_PRIV,GRANTOR,GRANTOR_TYPE);
Error: ORA-00955: name is already used by an existing object (state=42000,code=955)
Aborting command set because ""force"" is false and command failed: ""CREATE UNIQUE INDEX DBPRIVILEGEINDEX ON DC_PRIVS (AUTHORIZER,NAME,PRINCIPAL_NAME,PRINCIPAL_TYPE,DC_PRIV,GRANTOR,GRANTOR_TYPE);""
[ERROR] 2021-09-29 09:18:59.075 [main] MetastoreSchemaTool - Schema initialization FAILED! Metastore state would be inconsistent!
Schema initialization FAILED! Metastore state would be inconsistent!{noformat}
Error:2
{noformat}
Error: ORA-00900: invalid SQL statement (state=42000,code=900)
Aborting command set because ""force"" is false and command failed: ""=======
-- HIVE-24396
-- Create DataCo{noformat}"	HIVE	Resolved	3	1	2469	pull-request-available
13552379	Upgrade hadoop to 3.3.6	Hadoop 3.3.6 is released and comes up with lots of improvements & CVE fixes	HIVE	Closed	3	4	2469	pull-request-available
13319400	Fetching primaryKey through beeline fails with NPE	"Fetching PrimaryKey of a table through Beeline !primarykey fails with NPE
{noformat}
0: jdbc:hive2://localhost:10000> !primarykeys Persons
Error: MetaException(message:java.lang.NullPointerException) (state=,code=0)
org.apache.hive.service.cli.HiveSQLException: MetaException(message:java.lang.NullPointerException)
	at org.apache.hive.jdbc.Utils.verifySuccess(Utils.java:360)
	at org.apache.hive.jdbc.Utils.verifySuccess(Utils.java:351)
	at org.apache.hive.jdbc.HiveDatabaseMetaData.getPrimaryKeys(HiveDatabaseMetaData.java:573)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hive.beeline.Reflector.invoke(Reflector.java:89)
	at org.apache.hive.beeline.Commands.metadata(Commands.java:125)
	at org.apache.hive.beeline.Commands.primarykeys(Commands.java:231)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hive.beeline.ReflectiveCommandHandler.execute(ReflectiveCommandHandler.java:57)
	at org.apache.hive.beeline.BeeLine.execCommandWithPrefix(BeeLine.java:1465)
	at org.apache.hive.beeline.BeeLine.dispatch(BeeLine.java:1504)
	at org.apache.hive.beeline.BeeLine.execute(BeeLine.java:1364)
	at org.apache.hive.beeline.BeeLine.begin(BeeLine.java:1134)
	at org.apache.hive.beeline.BeeLine.begin(BeeLine.java:1082)
	at org.apache.hive.beeline.BeeLine.mainWithInputRedirection(BeeLine.java:546)
	at org.apache.hive.beeline.BeeLine.main(BeeLine.java:528)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:323)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:236){noformat}"	HIVE	Closed	3	1	2469	pull-request-available
13591438	OTEL: Implement OTEL Exporter to expose query details from HiveServer2	Collect query details in Hiveserver2 and expose it via OTEL Client	HIVE	Open	3	7	2469	pull-request-available
13580169	"Iceberg: Add support for 'If Not Exists"" and 'or Replace' for Create Tag "	"Add support for If not exists and Or Replace while creating Tags
{noformat}
-- CREATE historical-tag at current snapshot with default retention if it doesn't exist.
ALTER TABLE prod.db.sample CREATE TAG IF NOT EXISTS `historical-tag`

-- CREATE historical-tag at current snapshot with default retention or REPLACE it if it already exists.
ALTER TABLE prod.db.sample CREATE OR REPLACE TAG `historical-tag`{noformat}
Like Spark:

https://iceberg.apache.org/docs/1.5.1/spark-ddl/#alter-table-create-branch"	HIVE	Resolved	3	7	2469	pull-request-available
13430533	Avoid checking for archived parts in analyze table	"Analyze table on large partitioned table is expensive due to unwanted checks on archived data.

 
{noformat}
at org.apache.hadoop.hive.metastore.HiveMetaStoreClient$SynchronizedHandler.invoke(HiveMetaStoreClient.java:3908)
    - locked <0x00000003d4c4c070> (a org.apache.hadoop.hive.metastore.HiveMetaStoreClient$SynchronizedHandler)
    at com.sun.proxy.$Proxy56.listPartitionsWithAuthInfo(Unknown Source)
    at org.apache.hadoop.hive.ql.metadata.Hive.getPartitions(Hive.java:3845)
    at org.apache.hadoop.hive.ql.exec.ArchiveUtils.conflictingArchiveNameOrNull(ArchiveUtils.java:299)
    at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.validate(SemanticAnalyzer.java:13579)
    at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:241)
    at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:104)
    at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:196)
    at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:615)
    at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:561)
    at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:555)
    at org.apache.hadoop.hive.ql.reexec.ReExecDriver.compileAndRespond(ReExecDriver.java:127)
    at org.apache.hive.service.cli.operation.SQLOperation.prepare(SQLOperation.java:204)
    at org.apache.hive.service.cli.operation.SQLOperation.runInternal(SQLOperation.java:265)
    at org.apache.hive.service.cli.operation.Operation.run(Operation.java:285)  
 {noformat}"	HIVE	Closed	3	4	2469	pull-request-available
13390013	Reduce FileSystem calls in case drop database cascade	Reduce the number of FileSystem calls made in case of drop database cascade	HIVE	Resolved	3	4	2469	pull-request-available
13523251	Iceberg: Implement Copy-On-Write for Delete queries	Implement copy on write mode for deletes for iceberg tables	HIVE	Closed	3	7	2469	pull-request-available
13314949	TestMiniLlapLocalCliDriver[replication_metrics_ingest] is flaky	"This test is flaky. See: [http://ci.hive.apache.org/job/hive-flaky-check/62/console]
{code:java}
21:59:19  [INFO] -------------------------------------------------------
21:59:19  [INFO]  T E S T S
21:59:19  [INFO] -------------------------------------------------------
21:59:19  [INFO] Running org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver
22:01:56  [ERROR] Tests run: 1, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 144.366 s <<< FAILURE! - in org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver
22:01:56  [ERROR] org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[replication_metrics_ingest]  Time elapsed: 124.174 s  <<< FAILURE!
22:01:56  java.lang.AssertionError: 
22:01:56  Client Execution succeeded but contained differences (error code = 1) after executing replication_metrics_ingest.q 
22:01:56  76c76
22:01:56  < 3	repl2	1
22:01:56  ---
22:01:56  > 2	repl2	1
 {code}"	HIVE	Resolved	3	1	2469	pull-request-available
13594900	Iceberg: Aggregate queries on translated iceberg table fails post rename	"If the iceberg table is a translated to external table then post rename the aggregate queries fail
{noformat}
INFO  : Completed executing command(queryId=hive_20241010093718_57ff7646-af20-446b-8b83-e8ad3bb974c0); Time taken: 0.058 seconds
Error: Error while compiling statement: FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.tez.TezTask. Vertex failed, vertexName=Map 1, vertexId=vertex_1728552931316_0001_3_00, diagnostics=[Vertex vertex_1728552931316_0001_3_00 [Map 1] killed/failed due to:ROOT_INPUT_INIT_FAILURE, Vertex Input: ytox initializer failed, vertex=vertex_1728552931316_0001_3_00 [Map 1], java.io.IOException: cannot find dir = file:/opt/hive/data/warehouse/xtoy in pathToPartitionInfo: [file:/opt/hive/data/warehouse/ytox]
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getFromPathRecursively(HiveFileFormatUtils.java:400)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getFromPathRecursively(HiveFileFormatUtils.java:369)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getFromPathRecursively(HiveFileFormatUtils.java:364)
	at org.apache.hadoop.hive.ql.exec.tez.SplitGrouper.schemaEvolved(SplitGrouper.java:419)
	at org.apache.hadoop.hive.ql.exec.tez.SplitGrouper.generateGroupedSplits(SplitGrouper.java:232)
	at org.apache.hadoop.hive.ql.exec.tez.SplitGrouper.generateGroupedSplits(SplitGrouper.java:177)
	at org.apache.hadoop.hive.ql.exec.tez.HiveSplitGenerator.initialize(HiveSplitGenerator.java:411)
	at org.apache.tez.dag.app.dag.RootInputInitializerManager$InputInitializerCallable$1.run(RootInputInitializerManager.java:280)
	at org.apache.tez.dag.app.dag.RootInputInitializerManager$InputInitializerCallable$1.run(RootInputInitializerManager.java:272)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.tez.dag.app.dag.RootInputInitializerManager$InputInitializerCallable.call(RootInputInitializerManager.java:272)
	at org.apache.tez.dag.app.dag.RootInputInitializerManager$InputInitializerCallable.call(RootInputInitializerManager.java:256)
	at com.google.common.util.concurrent.TrustedListenableFutureTask$TrustedFutureInterruptibleTask.runInterruptibly(TrustedListenableFutureTask.java:111)
	at com.google.common.util.concurrent.InterruptibleTask.run(InterruptibleTask.java:58)
	at com.google.common.util.concurrent.TrustedListenableFutureTask.run(TrustedListenableFutureTask.java:75)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750){noformat}"	HIVE	Resolved	3	1	2469	pull-request-available
13548922	Iceberg: Cherry-Pick commit to a branch	Implement cherry-pick functionality 	HIVE	Closed	3	7	2469	pull-request-available
13479671	Fix NoClassDefFoundError in HMS for HBaseConfiguration	"While accessing Hbase tables via PySpark, the query fails with NoClassDefFoundError due to missing Hbase Jars in Classpath
{noformat}
java.lang.NoClassDefFoundError: org/apache/hadoop/hbase/HBaseConfiguration
at org.apache.hadoop.hive.hbase.HBaseStorageHandler.setConf(HBaseStorageHandler.java:134)
at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)
at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)
at org.apache.hadoop.hive.ql.security.authorization.plugin.metastore.events.AlterTableEvent.getOutputHObjs(AlterTableEvent.java:125)
at org.apache.hadoop.hive.ql.security.authorization.plugin.metastore.events.AlterTableEvent.getAuthzContext(AlterTableEvent.java:63)
at org.apache.hadoop.hive.ql.security.authorization.plugin.metastore.HiveMetaStoreAuthorizer.buildAuthzContext(HiveMetaStoreAuthorizer.java:454)
at org.apache.hadoop.hive.ql.security.authorization.plugin.metastore.HiveMetaStoreAuthorizer.onEvent(HiveMetaStoreAuthorizer.java:105)
at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.firePreEvent(HiveMetaStore.java:4008)
at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.alter_table_core(HiveMetaStore.java:5904)
at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.alter_table_req(HiveMetaStore.java:5850){noformat}
 "	HIVE	Closed	3	1	2469	pull-request-available
13378970	Allow custom configs for database level paths in external table replication	Allow a way to provide configurations which should be used only by the external data copy task of database level paths	HIVE	Resolved	3	4	2469	pull-request-available
13519846	Iceberg: (CTLT) Create external table like V2 table is not preserving table properties	"# Create an external iceberg V2 table. e.g t1
 # ""create external table t2 like t1"" <--- This ends up creating V1 table and ""format-version=2"" is not retained and ""'format'='iceberg/parquet'"" is also not retained."	HIVE	Closed	3	4	2469	pull-request-available
13444518	Add support for ESRI GeoSpatial SERDE formats	Add support to use ESRI geospatial serde formats	HIVE	Closed	3	7	2469	pull-request-available
13402952	Schema upgrade for MSSQL fails when adding TYPE column in DBS table	"The schema upgrade is failing with:
{noformat}
      ALTER TABLE ""DBS"" ADD ""TYPE"" nvarchar(32) DEFAULT ""NATIVE"" NOT NULL;
Error: The name ""NATIVE"" is not permitted in this context. Valid expressions are constants, constant expressions, and (in some contexts) variables. Column names are not permitted. (state=S0001,code=128)
Aborting command set because ""force"" is false and command failed: ""ALTER TABLE ""DBS"" ADD ""TYPE"" nvarchar(32) DEFAULT ""NATIVE"" NOT NULL;""
[ERROR] 2021-09-23 18:34:34.917 [main] MetastoreSchemaTool - Upgrade FAILED! Metastore state would be inconsistent !!
Upgrade FAILED! Metastore state would be inconsistent !!
[ERROR] 2021-09-23 18:34:34.917 [main] MetastoreSchemaTool - Underlying cause: java.io.IOException : Schema script failed, errorcode OTHER
Underlying cause: java.io.IOException : Schema script failed, errorcode OTHER
[ERROR] 2021-09-23 18:34:34.917 [main] MetastoreSchemaTool - Use --verbose for detailed stacktrace.
Use --verbose for detailed stacktrace.
[ERROR] 2021-09-23 18:34:34.917 [main] MetastoreSchemaTool - *** schemaTool failed ***
{noformat}"	HIVE	Closed	3	7	2469	pull-request-available
13531089	Iceberg: Add support for rename table	Add support for renaming iceberg tables.	HIVE	Closed	3	4	2469	pull-request-available
13376618	Add a shell script to fetch the statistics of replication data copy tasks	Add a shell script which can fetch the statistics of the Mapred(Distcp) jobs launched as part of replication.	HIVE	Resolved	3	4	2469	pull-request-available
13577442	Split Replication Commands from HiveParser.g	"HiveParser.g is bloated and is leading to problems like in: HIVE-23857, Similarly like HIVE-23869 which split the alter commands to another file

Aim to split replication related commands to separate file to reduce HiveParser.g size"	HIVE	Resolved	3	4	2469	pull-request-available
13404215	LOAD overwrite appends rather than overwriting	"The overwrite query gets converted to append.

{noformat}
7b6-4b43-8452-52c44e8a2f71): LOAD DATA INPATH 'hdfs://ayushsaxena-1.ayushsaxena.root.hwx.site:8020/warehouse/tablespace/external/hive/test_ext/000000_0' OVERWRITE  INTO TABLE test_spark
2021-09-30 03:30:23,033 INFO  org.apache.hadoop.hive.ql.lockmgr.DbTxnManager: [db2ab9c9-bf54-4304-bc06-e3bef76f2e79 HiveServer2-Handler-Pool: Thread-2600]: Opened txnid:15
2021-09-30 03:30:23,035 INFO  org.apache.hadoop.hive.ql.parse.LoadSemanticAnalyzer: [db2ab9c9-bf54-4304-bc06-e3bef76f2e79 HiveServer2-Handler-Pool: Thread-2600]: Starting caching scope for: hive_20210930033023_bb1f6dc4-d7b6-4b43-8452-52c44e8a2f71
2021-09-30 03:30:23,042 INFO  org.apache.hadoop.hive.ql.parse.LoadSemanticAnalyzer: [db2ab9c9-bf54-4304-bc06-e3bef76f2e79 HiveServer2-Handler-Pool: Thread-2600]: Load data triggered a Tez job instead of usual file operation
2021-09-30 03:30:23,042 INFO  org.apache.hadoop.hive.ql.parse.LoadSemanticAnalyzer: [db2ab9c9-bf54-4304-bc06-e3bef76f2e79 HiveServer2-Handler-Pool: Thread-2600]: Going to reparse <LOAD DATA INPATH 'hdfs://ayushsaxena-1.ayushsaxena.root.hwx.site:8020/warehouse/tablespace/external/hive/test_ext/000000_0' OVERWRITE  INTO TABLE test_spark> as
<insert into table `default`.`test_spark` partition (`col2`) select * from test_spark__temp_table_for_load_data__>
{noformat}
"	HIVE	Resolved	2	1	2469	pull-request-available
13411740	Prevent deletion of Notification Events post restarts	In case of DR scenarios, when Hive service goes down, Prevent deletion of entries in the Notification Log immediately, Give time for ADMINs to reconfigure properties to handle further Replication process.	HIVE	Resolved	3	7	2469	pull-request-available
13524333	"Select query with LIMIT clause can fail if there are marker files like ""_SUCCESS"" and ""_MANIFEST"""	"Spark clients creates marker files like ""_SUCCESS"" and ""_MANIFEST"" under the table/partition path at the end of a write operation. For example 'hdfs://name-node-host/table/partition/_SUCCESS'
Whenever Hive is trying to read that table with the LIMIT clause, it could to the following error:
{code:java}
ERROR : Vertex failed, vertexName=Map 1, vertexId=vertex_1676095298574_0017_2_00, diagnostics=[Vertex vertex_1676095298574_0017_2_00 [Map 1] killed/failed due to:ROOT_INPUT_INIT_FAILURE, Vertex Input: trade initializer failed, vertex=vertex_1676095298574_0017_2_00 [Map 1], org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: hdfs://name-node-host/table/partition/_MANIFEST
Input path does not exist: hdfs://name-node-host/table/partition/_SUCCESS at org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:300)
at org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:240)
at org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:328)
at org.apache.hadoop.hive.ql.io.HiveInputFormat.addSplitsForGroup(HiveInputFormat.java:579) {code}
Hive execution engine should ignore these marker files while reading the table/partition data."	HIVE	Closed	3	1	2469	pull-request-available
13530348	Iceberg: Cache iceberg table while loading for stats	"Presently iceberg for stats loads the iceberg table multiple times for stats via different routes.
Cache it to avoid reading/loading the iceberg table multiple times."	HIVE	Closed	3	4	2469	pull-request-available
13480774	Iceberg: Fix VectorizedSupport support for DECIMAL_64 in HiveIcebergInputFormat.	"For supporting vectored reads in parquet, DECIMAL_64 support in ORC has been disabled in HiveIcebergInputFormat. This causes regressions in queries.

[https://github.com/apache/hive/blob/master/iceberg/iceberg-handler/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergInputFormat.java#L182]

It will be good to restore DECIMAL_64 support in iceberg input format.

 "	HIVE	Closed	3	4	2469	perfomance, pull-request-available
13517530	Iceberg: Add support for set_current_snapshotid	"Currently, hive supports ""rollback"" feature. Once rolledback,  it is not possible to move from older snapshot to newer snapshot.

It ends up throwing {color:#0747a6}""org.apache.iceberg.exceptions.ValidationException: Cannot roll back to snapshot, not an ancestor of the current state:"" {color}error.

It will be good to support ""set_current_snapshot"" function to move to different snapshot ids.

 

 "	HIVE	Closed	3	4	2469	pull-request-available
13520955	Iceberg: CTL from iceberg table should copy partition fields correctly	"# Create iceberg table. Ensure it to have a partition field.
 # run ""create external table like x""
 # Created table in #2 misses out on creating relevant partition field."	HIVE	Closed	3	4	2469	pull-request-available
13522702	Iceberg: Provide an option to enable iceberg manifest caching for all catalogs	"{color:#222222}I tried the following thinking that it would work with iceberg manifest caching; but it didn't.{color}
{noformat}
alter table store_sales set tblproperties('io.manifest.cache-enabled'='true');{noformat}


{color:#222222}Creating this ticket as a placeholder to fix the same.{color}

 "	HIVE	Closed	3	4	2469	pull-request-available
13485143	Iceberg: Allow parquet write properties to iceberg via session conf and Table Properties	Allow passing parquet.block.size & parquet.compression via TBLPROPERTIES and Session Conf.	HIVE	Closed	3	1	2469	pull-request-available
13579291	CreateTableEvent wrongly skips authorizing DFS_URI for managed table 	HIVE-27525 eased out permissions for external table but it wrongly eased out for managed tables as well by wrong check for managed tables	HIVE	Resolved	3	1	2469	hive-4.0.1-merged, hive-4.0.1-must, pull-request-available
13535359	Iceberg: Expiring old snapshots deletes files with DirectExecutorService causing runtime delays	"Expiring old snapshots takes a lot of time, as fileCleanupStrategy internally uses directExecutorService. Creating this as a placeholder ticket to fix the same. If fixed in iceberg, need to upgrade the lib here.

{noformat}
insert into store_sales_delete_9 select *, current_timestamp() as ts from tpcds_1000_update.ssv ;;

ALTER TABLE store_sales_delete_9 EXECUTE expire_snapshots('2023-05-09 00:00:00');


{noformat}


{noformat}
	at org.apache.iceberg.relocated.com.google.common.util.concurrent.AbstractListeningExecutorService.submit(AbstractListeningExecutorService.java:36)
	at org.apache.iceberg.util.Tasks$Builder.runParallel(Tasks.java:300)
	at org.apache.iceberg.util.Tasks$Builder.run(Tasks.java:194)
	at org.apache.iceberg.util.Tasks$Builder.run(Tasks.java:189)
	at org.apache.iceberg.FileCleanupStrategy.deleteFiles(FileCleanupStrategy.java:84)
	at org.apache.iceberg.IncrementalFileCleanup.cleanFiles(IncrementalFileCleanup.java:262)
	at org.apache.iceberg.RemoveSnapshots.cleanExpiredSnapshots(RemoveSnapshots.java:338)
	at org.apache.iceberg.RemoveSnapshots.commit(RemoveSnapshots.java:312)
	at org.apache.iceberg.mr.hive.HiveIcebergStorageHandler.executeOperation(HiveIcebergStorageHandler.java:560)
	at org.apache.hadoop.hive.ql.metadata.Hive.alterTableExecuteOperation(Hive.java:6844)
	at org.apache.hadoop.hive.ql.ddl.table.execute.AlterTableExecuteOperation.execute(AlterTableExecuteOperation.java:37)
	at org.apache.hadoop.hive.ql.ddl.DDLTask.execute(DDLTask.java:84)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:213)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:105)
	at org.apache.hadoop.hive.ql.Executor.launchTask(Executor.java:360)
	at org.apache.hadoop.hive.ql.Executor.launchTasks(Executor.java:333)
	at org.apache.hadoop.hive.ql.Executor.runTasks(Executor.java:250)
	at org.apache.hadoop.hive.ql.Executor.execute(Executor.java:111)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:809)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:547)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:541)
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:166)
	at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:235)
	at org.apache.hive.service.cli.operation.SQLOperation.access$700(SQLOperation.java:92)
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:340)
	at java.security.AccessController.doPrivileged(java.base@11.0.19/Native Method)
	at javax.security.auth.Subject.doAs(java.base@11.0.19/Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:360)
	at java.util.concurrent.Executors$RunnableAdapter.call(java.base@11.0.19/Executors.java:515)
	at java.util.concurrent.FutureTask.run(java.base@11.0.19/FutureTask.java:264)
	at java.util.concurrent.Executors$RunnableAdapter.call(java.base@11.0.19/Executors.java:515)
{noformat}"	HIVE	Closed	3	4	2469	iceberg, pull-request-available
13507301	Add UserName in CallerContext for queries	HDFS Audit logs if impersonation is false, tracks only the Hive user in the audit log, Can pass the actual user as part of the CallerContext, so that can be logged as well for better tracking	HIVE	Closed	3	4	2469	pull-request-available
13338089	REPL LOAD command ignores config properties set by WITH clause	"By debug messages we confirmed that REPL LOAD command ignored some config properties when they were provided in WITH clause, e.g.:
{code}
REPL LOAD bdpp01pub FROM 'hdfs://prdpdp01//apps/hive/repl/8237c7bd-ba26-4425-8659-3a0d32ab312c' WITH ('mapreduce.job.queuename'='default','hive.exec.parallel'='true','hive.exec.parallel.thread.number'='128',
...
{code}
We found that it was working on 16 threads, ignoring 'hive.exec.parallel.thread.number'='128'. Setting this property on session level worked.
"	HIVE	Resolved	3	1	2469	pull-request-available
13538184	Iceberg: Use String instead of Long for file length in HadoopInputFile	"Apply the workaround mentioned over here:

https://issues.apache.org/jira/browse/HADOOP-18724?focusedCommentId=17718087&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-17718087

 

 "	HIVE	Closed	3	1	2469	pull-request-available
13383103	Add an ability to migrate CSV generated to hive table in replstats	Add an option to replstats.sh to load the CSV generated using the replication policy into a hive table/view.	HIVE	Resolved	3	4	2469	pull-request-available
13428557	Fix S3a recursive listing logic	"To make the path relative:

Path relativePath = new Path(each.getPath().toString().replace(base.toString(), """"));

 

Here base in the FileStatus not the path. It should be base.getPath().toString() and instead of replace it should be replaceFirst()"	HIVE	Closed	3	1	2469	pull-request-available
13382754	Add a replication migration validation tool for external tables	Add a tool which can validate the migration of external tables post replication from one cluster to another.	HIVE	Resolved	3	4	2469	pull-request-available
13365800	Add a DataCopyEnd stage in ReplStateLogTask for external table replication	Add a task to mark the end of external table copy.	HIVE	Resolved	3	4	2469	pull-request-available
13565670	Add generated protobuf code	HIVE-26790 upgraded protobuf, but didn't generate the code wrt the newer version	HIVE	Closed	3	1	2469	pull-request-available
13386819	Expose notification log table through sys db	Expose the notification_log table in RDBMS through Hive sys database	HIVE	Resolved	3	4	2469	pull-request-available
13550919	Docker build from source should include iceberg profile	"Building docker image from source doesn't include iceberg profile. So, creating iceberg tables by images built by it fails
{noformat}
0: jdbc:hive2://localhost:10000/> CREATE TABLE test (ID INT) STORED BY ICEBERG TBLPROPERTIES('format-version'='2');
Error: Error while compiling statement: FAILED: SemanticException Cannot find class 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' (state=42000,code=40000){noformat}"	HIVE	Closed	3	4	2469	pull-request-available
13366984	Optimize checkpointing flow in incremental load	Attempt reducing alter calls for checkpointing during repl load	HIVE	Resolved	3	4	2469	pull-request-available
13552978	Iceberg: Allow expire snapshot by time range	"Allow expiring snapshot by time range.

Alter table ice01 execute expire_snapshot BETWEEN 'some time' AND 'some time'"	HIVE	Closed	3	4	2469	pull-request-available
13273849	Fix Replication related tests	"For TestStatsReplicationScenariosACIDNoAutogather:

this test is running ""alone"" because but still; it sometimes runs more than 40m which results in a timeout
 a jira search reveals that was pretty common: 
 [https://issues.apache.org/jira/issues/?jql=text%20~%20%22TestStatsReplicationScenariosACIDNoAutogather%22%20order%20by%20updated%20desc]

from the hive logs:
 * it seems like after a few minutes this test starts there is an exception:
{code:java}
2019-12-10T22:43:19,594 DEBUG [Finalizer] metastore.HiveMetaStoreClient: Unable to shutdown metastore client. Will try closing transport directly.
org.apache.thrift.transport.TTransportException: java.net.SocketException: Socket closed
        at org.apache.thrift.transport.TIOStreamTransport.flush(TIOStreamTransport.java:161) ~[libthrift-0.9.3-1.jar:0.9.3-1]
        at org.apache.thrift.TServiceClient.sendBase(TServiceClient.java:73) ~[libthrift-0.9.3-1.jar:0.9.3-1]
        at org.apache.thrift.TServiceClient.sendBaseOneway(TServiceClient.java:66) ~[libthrift-0.9.3-1.jar:0.9.3-1]
        at com.facebook.fb303.FacebookService$Client.send_shutdown(FacebookService.java:436) ~[libfb303-0.9.3.jar:?]
        at com.facebook.fb303.FacebookService$Client.shutdown(FacebookService.java:430) ~[libfb303-0.9.3.jar:?]
        at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.close(HiveMetaStoreClient.java:776) [hive-standalone-metastore-common-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_102]
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_102]
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_102]
        at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_102]
        at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:212) [hive-standalone-metastore-common-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
        at com.sun.proxy.$Proxy62.close(Unknown Source) [?:?]
        at org.apache.hadoop.hive.ql.metadata.Hive.close(Hive.java:542) [hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.metadata.Hive.finalize(Hive.java:514) [hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
        at java.lang.System$2.invokeFinalize(System.java:1270) [?:1.8.0_102]
        at java.lang.ref.Finalizer.runFinalizer(Finalizer.java:98) [?:1.8.0_102]
        at java.lang.ref.Finalizer.access$100(Finalizer.java:34) [?:1.8.0_102]
        at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:210) [?:1.8.0_102]
Caused by: java.net.SocketException: Socket closed
        at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:116) ~[?:1.8.0_102]
        at java.net.SocketOutputStream.write(SocketOutputStream.java:153) ~[?:1.8.0_102]
        at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82) ~[?:1.8.0_102]
        at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:140) ~[?:1.8.0_102]
        at org.apache.thrift.transport.TIOStreamTransport.flush(TIOStreamTransport.java:159) ~[libthrift-0.9.3-1.jar:0.9.3-1]
{code}

 * after that some NoSuchObjectExceptions follow
 * and then some replications seems to happen

I don't fully understand this; I'll attach the logs..."	HIVE	Resolved	3	7	2469	pull-request-available
13389800	Use single call to get tables in DropDatabaseAnalyzer	Optimise org.apache.hadoop.hive.ql.ddl.database.drop.DropDatabaseAnalyzer.analyzeInternal(DropDatabaseAnalyzer.java:61), where it fetches entire tables one by one. Move to a single call. This could save around 20+ seconds when large number of tables are present.	HIVE	Resolved	3	4	2469	pull-request-available
13480328	Iceberg: Add support for CTLT queries	Add support to run `create table Like` queries with iceberg tables	HIVE	Closed	3	4	2469	pull-request-available
13514367	Iceberg: Allow IOW on empty table with Partition Evolution	"In case an iceberg table has gone through partition evolution, we don't allow an IOW operation on it.

But if it is empty, we can allow an IOW since there ain't any data which can get messed by overwrite.

This helps to compact data, & merge the delete files into data file

via

Truncate -> IOW with Snapshot ID before Truncate.

Same flow is used by Impala for compacting Iceberg tables."	HIVE	Closed	3	4	2469	pull-request-available
13390820	Replication fails for external tables on setting owner/groups	"DirCopyTask tries to preserve user group permissions, irrespective whether they have been specified to be preserved or not.

Changing user/group requires SuperUser privileges, hence the task fails."	HIVE	Resolved	3	1	2469	pull-request-available
13353642	Set repl.source.for property in the db if db is under replication	Add repl.source.for property in the database in case not already set, if the database is under replication.	HIVE	Resolved	3	1	2469	pull-request-available
13479681	ST_GeometryProcessing is incorrectly registered as function	"ST_GeometryProcessing is registered as function, while it is an empty base class without evaluate().
https://github.com/apache/hive/blob/2d8b0a31f461a33ef2e19c0269ec44778d5ca136/ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java#L706"	HIVE	Closed	3	7	2469	pull-request-available
13382400	Expose incremental load statistics via JMX	Expose the incremental load details and statistics at per policy level in the JMX.	HIVE	Resolved	3	4	2469	pull-request-available
13208294	Allow flattening of table subdirectories resulted when using TEZ engine and UNION clause	"Right now, when writing data into a table with Tez engine and the clause UNION ALL is the last step of the query, Hive on Tez will create a subdirectory for each branch of the UNION ALL.

With this patch the subdirectories are removed, and the files are renamed and moved to the parent directory."	HIVE	Closed	3	4	2469	pull-request-available
13421889	Replication fails in case of Control Character in the table description	"In case there is a control character in the table metadata. The LOAD fails while decoding the JSON.

*Exception:*
{noformat}
Caused by: com.fasterxml.jackson.core.JsonParseException: Illegal unquoted character ((CTRL-CHAR, code 24)): has to be escaped using backslash to be included in string value
 at [Source: (String)""{""server"":"""",""servicePrincipal"":"""",""db"":""sampletestreplic"",""table"":""testlmo"",""tableType"":""MANAGED_TABLE"",""tableObjBeforeJson"":""{\""1\"":{\""str\"":\""testlmo\""},\""2\"":{\""str\"":\""sampletestreplic\""},\""3\"":{\""str\"":\""hive\""},\""4\"":{\""i32\"":1641717786},\""5\"":{\""i32\"":0},\""6\"":{\""i32\"":0},\""7\"":{\""rec\"":{\""1\"":{\""lst\"":[\""rec\"",1,{\""1\"":{\""str\"":\""dc_codeacteurcandidat\""},\""2\"":{\""str\"":\""string\""},\""3\"":{\""str\"":\""Code de l'acteur de candidature (^XA' a dterminer, ^XC' conseiller ou ^XD' candidat)\""}}]},\""[truncated 3054 chars]; line: 1, column: 445]
        at com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1840) ~[jackson-core-2.10.5.jar:2.10.5]
        at com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:712) ~[jackson-core-2.10.5.jar:2.10.5]
        at com.fasterxml.jackson.core.base.ParserBase._throwUnquotedSpace(ParserBase.java:1046) ~[jackson-core-2.10.5.jar:2.10.5]
        at com.fasterxml.jackson.core.json.ReaderBasedJsonParser._finishString2(ReaderBasedJsonParser.java:2073) ~[jackson-core-2.10.5.jar:2.10.5]
        at com.fasterxml.jackson.core.json.ReaderBasedJsonParser._finishString(ReaderBasedJsonParser.java:2044) ~[jackson-core-2.10.5.jar:2.10.5]
        at com.fasterxml.jackson.core.json.ReaderBasedJsonParser.getText(ReaderBasedJsonParser.java:293) ~[jackson-core-2.10.5.jar:2.10.5]
        at com.fasterxml.jackson.databind.deser.std.StringDeserializer.deserialize(StringDeserializer.java:35) ~[jackson-databind-2.10.5.1.jar:2.10.5.1]
        at com.fasterxml.jackson.databind.deser.std.StringDeserializer.deserialize(StringDeserializer.java:10) ~[jackson-databind-2.10.5.1.jar:2.10.5.1]
        at com.fasterxml.jackson.databind.deser.impl.FieldProperty.deserializeAndSet(FieldProperty.java:138) ~[jackson-databind-2.10.5.1.jar:2.10.5.1]
        at com.fasterxml.jackson.databind.deser.BeanDeserializer.vanillaDeserialize(BeanDeserializer.java:288) ~[jackson-databind-2.10.5.1.jar:2.10.5.1]
        at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:151) ~[jackson-databind-2.10.5.1.jar:2.10.5.1]
        at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4218) ~[jackson-databind-2.10.5.1.jar:2.10.5.1]
        at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3214) 
        at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3182) 
        at org.apache.hadoop.hive.metastore.messaging.json.JSONMessageDeserializer.getAlterTableMessage(JSONMessageDeserializer.java:111) 
        at org.apache.hadoop.hive.ql.parse.repl.load.message.TableHandler.extract(TableHandler.java:111)]
        at org.apache.hadoop.hive.ql.parse.repl.load.message.TableHandler.handle(TableHandler.java:51) 
        at org.apache.hadoop.hive.ql.exec.repl.incremental.IncrementalLoadTasksBuilder.analyzeEventLoad(IncrementalLoadTasksBuilder.java:213){noformat}"	HIVE	Resolved	3	1	2469	pull-request-available
13567436	Iceberg: Branches with non-lowercase characters can't be accessed	"Repo:

1. Let's create a branch

ALTER TABLE Devices CREATE Branch *Sandbox*

2. Check the existence for evidence

SELECT * FROM `default`.`devices`.`refs`;

The References show it properly

 

!image-2024-02-05-16-10-55-198.png!

 

3. Select from branch

SELECT * FROM default.Devices.branch_Sandbox;

But if the select it would throw an exception:

{color:#de350b}Error while compiling statement: FAILED: SemanticException Cannot use snapshotRef (does not exist): sandbox{color}

I guess the select operator does have a simple equals and does not check the cases also the cultureInvariant could be a different issue

*Exception*

INFO  : Compiling command(queryId=hive_20240205151156_891265b0-0d7c-49b6-892a-cc6f7574ed2b): SELECT * FROM default.Devices.branch_Sandbox
ERROR : FAILED: SemanticException Cannot use snapshotRef (does not exist): sandbox
org.apache.hadoop.hive.ql.parse.SemanticException: Cannot use snapshotRef (does not exist): sandbox
    at org.apache.iceberg.mr.hive.HiveIcebergStorageHandler.checkAndSetTableMetaRef(HiveIcebergStorageHandler.java:1017)
    at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:1800)
    at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:1710)
    at org.apache.hadoop.hive.ql.parse.CalcitePlanner.getTableObjectByName(CalcitePlanner.java:5657)
    at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.getMetaData(SemanticAnalyzer.java:2362)
    at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.getMetaData(SemanticAnalyzer.java:2309)
    at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genResolvedParseTree(SemanticAnalyzer.java:13295)
    at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:13403)
    at org.apache.hadoop.hive.ql.parse.CalcitePlanner.analyzeInternal(CalcitePlanner.java:482)
    at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:319)
    at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:227)
    at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:108)
    at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:202)
    at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:656)
    at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:602)
    at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:596)
    at org.apache.hadoop.hive.ql.reexec.ReExecDriver.compileAndRespond(ReExecDriver.java:126)
    at org.apache.hive.service.cli.operation.SQLOperation.prepare(SQLOperation.java:209)
    at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:338)
    at java.base/java.security.AccessController.doPrivileged(Native Method)
    at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
    at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
    at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:360)
    at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
    at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
    at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
    at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
    at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    at java.base/java.lang.Thread.run(Thread.java:829)

INFO  : Completed compiling command(queryId=hive_20240205151156_891265b0-0d7c-49b6-892a-cc6f7574ed2b); Time taken: 0.088 seconds

 "	HIVE	Closed	3	1	2469	pull-request-available
13482856	Iceberg: Properties set in HiveIcebergSerde are not propagated to jobconf	Some hive properties (ex. InputFormatConfig.CASE_SENSITIVE) are not propagated to the jobconf. This scenario can be reproduced by running TestHiveIcebergSelects#testScanTableCaseInsensitive test method. 	HIVE	Closed	3	1	2469	pull-request-available
13495546	Iceberg: Write failing due to Ranger Authorization failure	"
{noformat}
Caused by: java.lang.RuntimeException: MetaException(message:Permission denied: user [systest] does not have [RWSTORAGE] privilege on [iceberg%3A%2F%2Fspark_iceberg%2Fsimple_types_avro%3Fsnapshot%3D%2Fwarehouse%2Ftablespace%2Fexternal%2Fhive%2Fspark_iceberg.db%2Fsimple_types_avro%2Fmetadata%2F00000-50dd01bd-15d9-49bd-a970-80d89231d36c.metadata.json])
	at org.apache.iceberg.relocated.com.google.common.base.Throwables.propagate(Throwables.java:243)
	at org.apache.iceberg.common.DynMethods$UnboundMethod.invoke(DynMethods.java:80)
	at org.apache.iceberg.hive.MetastoreUtil.alterTable(MetastoreUtil.java:64)
	at org.apache.iceberg.hive.HiveTableOperations.lambda$persistTable$3(HiveTableOperations.java:322)
	at org.apache.iceberg.ClientPoolImpl.run(ClientPoolImpl.java:58)
	at org.apache.iceberg.ClientPoolImpl.run(ClientPoolImpl.java:51)
	at org.apache.iceberg.hive.CachedClientPool.run(CachedClientPool.java:76)
	at org.apache.iceberg.hive.HiveTableOperations.persistTable(HiveTableOperations.java:321)
	at org.apache.iceberg.hive.HiveTableOperations.doCommit(HiveTableOperations.java:277)
	... 36 more
Caused by: MetaException(message:Permission denied: user [systest] does not have [RWSTORAGE] privilege on [iceberg%3A%2F%2Fspark_iceberg%2Fsimple_types_avro%3Fsnapshot%3D%2Fwarehouse%2Ftablespace%2Fexternal%2Fhive%2Fspark_iceberg.db%2Fsimple_types_avro%2Fmetadata%2F00000-50dd01bd-15d9-49bd-a970-80d89231d36c.metadata.json])
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$alter_table_req_result$alter_table_req_resultStandardScheme.read(ThriftHiveMetastore.java)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$alter_table_req_result$alter_table_req_resultStandardScheme.read(ThriftHiveMetastore.java)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$alter_table_req_result.read(ThriftHiveMetastore.java)
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:88)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_alter_table_req(ThriftHiveMetastore.java:2978)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.alter_table_req(ThriftHiveMetastore.java:2965)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.alter_table_with_environmentContext(HiveMetaStoreClient.java:482)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
{noformat}


"	HIVE	Closed	3	1	2469	pull-request-available
13380491	Generate & track statistics per event type for incremental load in replication metrics	Generate and track statistics like mean, median. standard deviation, variance etc per event type during incremental load and store them in replication statistics 	HIVE	Resolved	3	4	2469	pull-request-available
13362861	Add support for Snapshots during external table replication	Add support for use of snapshot diff for external table replication.	HIVE	Resolved	2	4	2469	pull-request-available
13591603	Iceberg: Concurrent queries fail during commit with ValidationException	"{noformat}
Caused by: org.apache.iceberg.exceptions.ValidationException: Cannot commit, missing data files: [file:/Users/ayushsaxena/code/hive/iceberg/iceberg-handler/target/tmp/hive7073916777566968859/external/customers/data/00000-0-data-ayushsaxena_20240909232021_99fd025f-1e27-4541-ab3e-77c6f9905eb7-job_17259492220180_0001-6-00001.parquet]
        at org.apache.iceberg.MergingSnapshotProducer.validateDataFilesExist(MergingSnapshotProducer.java:751)
        at org.apache.iceberg.BaseRowDelta.validate(BaseRowDelta.java:116)
        at org.apache.iceberg.SnapshotProducer.apply(SnapshotProducer.java:233)
        at org.apache.iceberg.SnapshotProducer.lambda$commit$2(SnapshotProducer.java:384)
        at org.apache.iceberg.util.Tasks$Builder.runTaskWithRetry(Tasks.java:413)
        at org.apache.iceberg.util.Tasks$Builder.runSingleThreaded(Tasks.java:219)
        at org.apache.iceberg.util.Tasks$Builder.run(Tasks.java:203)
        at org.apache.iceberg.util.Tasks$Builder.run(Tasks.java:196)
        at org.apache.iceberg.SnapshotProducer.commit(SnapshotProducer.java:382)
        at org.apache.iceberg.mr.hive.HiveIcebergOutputCommitter.commitWrite(HiveIcebergOutputCommitter.java:580)
        at org.apache.iceberg.mr.hive.HiveIcebergOutputCommitter.commitTable(HiveIcebergOutputCommitter.java:494)
        at org.apache.iceberg.mr.hive.HiveIcebergOutputCommitter.lambda$commitJobs$4(HiveIcebergOutputCommitter.java:291){noformat}
Queries failing with {{ValidationException}} during commit even with retry strategy configured with {{write_conflict}}"	HIVE	Resolved	3	1	2469	hive-4.0.1-merged, hive-4.0.1-must, pull-request-available
13502178	Authorization failure for nested Views having WITH clause	"Authorization failure in case of nested views created using With clause, if the user doesn't have permissions for the inner view.

 "	HIVE	Closed	3	1	2469	pull-request-available
13421937	load_non_hdfs_path.q fails on master: .1.txt.crc does not exist	"repro
{code}
 mvn clean install -Dtest.output.overwrite=true -Pitests,hadoop-2 -Denforcer.skip=true -pl itests/qtest -pl itests/util -am -Dtest=TestMiniLlapLocalCliDriver -Dqfile=load_non_hdfs_path.q
{code}

{code}
Caused by: java.io.FileNotFoundException: File file:/Users/laszlobodor/apache/hive/itests/qtest/target/tmp/non_hdfs_path/.1.txt.crc does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:641)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:930)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:631)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:454)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:146)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:347)
	at org.apache.hadoop.fs.FilterFileSystem.open(FilterFileSystem.java:164)
	at org.apache.hadoop.fs.ProxyFileSystem.open(ProxyFileSystem.java:153)
	at org.apache.hadoop.fs.FilterFileSystem.open(FilterFileSystem.java:164)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:950)
	at org.apache.hadoop.hive.common.FileUtils.copy(FileUtils.java:695)
	at org.apache.hadoop.hive.common.FileUtils.copy(FileUtils.java:685)
	at org.apache.hadoop.hive.common.FileUtils.copy(FileUtils.java:667)
	at org.apache.hadoop.hive.common.FileUtils.copy(FileUtils.java:634)
	at org.apache.hadoop.hive.ql.metadata.Hive.moveFile(Hive.java:4809)
	... 64 more
{code}"	HIVE	Closed	1	1	2469	pull-request-available
13428501	Optimise BasicStatsNoJobTask	"When there are large number of files are present, it takes lot of time for analyzing table (for stats) takes lot longer time especially on cloud platforms. Each file is read in sequential fashion for computing stats, which can be optimized.

 
{code:java}
    at org.apache.hadoop.fs.s3a.Invoker.retry(Invoker.java:293)
    at org.apache.hadoop.fs.s3a.S3AInputStream.read(S3AInputStream.java:506)
    - locked <0x0000000642995b10> (a org.apache.hadoop.fs.s3a.S3AInputStream)
    at org.apache.hadoop.fs.s3a.S3AInputStream.readFully(S3AInputStream.java:775)
    - locked <0x0000000642995b10> (a org.apache.hadoop.fs.s3a.S3AInputStream)
    at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:116)
    at org.apache.orc.impl.RecordReaderUtils.readDiskRanges(RecordReaderUtils.java:574)
    at org.apache.orc.impl.RecordReaderUtils$DefaultDataReader.readFileData(RecordReaderUtils.java:282)
    at org.apache.orc.impl.RecordReaderImpl.readAllDataStreams(RecordReaderImpl.java:1172)
    at org.apache.orc.impl.RecordReaderImpl.readStripe(RecordReaderImpl.java:1128)
    at org.apache.orc.impl.RecordReaderImpl.advanceStripe(RecordReaderImpl.java:1281)
    at org.apache.orc.impl.RecordReaderImpl.advanceToNextRow(RecordReaderImpl.java:1316)
    at org.apache.orc.impl.RecordReaderImpl.<init>(RecordReaderImpl.java:302)
    at org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl.<init>(RecordReaderImpl.java:68)
    at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.rowsOptions(ReaderImpl.java:83)
    at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.createReaderFromFile(OrcInputFormat.java:367)
    at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat$OrcRecordReader.<init>(OrcInputFormat.java:276)
    at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.getRecordReader(OrcInputFormat.java:2027)
    at org.apache.hadoop.hive.ql.stats.BasicStatsNoJobTask$FooterStatCollector.run(BasicStatsNoJobTask.java:235)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    at java.lang.Thread.run(Thread.java:748)
""HiveServer2-Background-Pool: Thread-5161"" #5161 prio=5 os_prio=0 tid=0x00007f271217d800 nid=0x21b7 waiting on condition [0x00007f26fce88000]
   java.lang.Thread.State: TIMED_WAITING (parking)
    at sun.misc.Unsafe.park(Native Method)
    - parking to wait for  <0x00000006bee1b3a0> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
    at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1475)
    at org.apache.hadoop.hive.ql.stats.BasicStatsNoJobTask.shutdownAndAwaitTermination(BasicStatsNoJobTask.java:426)
    at org.apache.hadoop.hive.ql.stats.BasicStatsNoJobTask.aggregateStats(BasicStatsNoJobTask.java:338)
    at org.apache.hadoop.hive.ql.stats.BasicStatsNoJobTask.process(BasicStatsNoJobTask.java:121)
    at org.apache.hadoop.hive.ql.exec.StatsTask.execute(StatsTask.java:107)
    at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:213)
    at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:105)
    at org.apache.hadoop.hive.ql.Executor.launchTask(Executor.java:361)
    at org.apache.hadoop.hive.ql.Executor.launchTasks(Executor.java:334)
    at org.apache.hadoop.hive.ql.Executor.runTasks(Executor.java:250) {code}"	HIVE	Closed	3	4	2469	pull-request-available
13402159	CommitTxn replay failing during incremental run	"CommitTxn Fails during incremental run, in case the source file is deleted post copy & before checksum validation.


{noformat}
2021-09-21T07:53:40,898 ERROR [TThreadPoolServer WorkerProcess-%d] thrift.ProcessFunction: Internal error processing commit_txn
org.apache.thrift.TException: /warehouse1/replicated_testreplcommittransactiononsourcedelete_1632235978675.db/testreplcommittransactiononsourcedelete/load_date=2016-03-01/delta_0000002_0000002_0000 (is not a directory)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.resolvePath(FSDirectory.java:677)
	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:151)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1927)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:738)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:424)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:869)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:815)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2675)

	at org.apache.hadoop.hive.metastore.HMSHandler.commit_txn(HMSHandler.java:8652) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at sun.reflect.GeneratedMethodAccessor118.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_261]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_261]
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at com.sun.proxy.$Proxy55.commit_txn(Unknown Source) ~[?:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$commit_txn.getResult(ThriftHiveMetastore.java:23159) ~[hive-standalone-metastore-common-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$commit_txn.getResult(ThriftHiveMetastore.java:23138) ~[hive-standalone-metastore-common-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38) [hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111) [hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107) [hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_261]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_261]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682) [hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119) [hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248) [hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_261]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_261]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_261]
{noformat}
"	HIVE	Resolved	2	1	2469	pull-request-available
13546017	Iceberg: Fetching virtual columns failing	"Fetching virtual column fails with
{noformat}
Error: Error while compiling statement: FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.tez.TezTask. Vertex failed, vertexName=Map 1, vertexId=vertex_1691064079730_0001_3_00, diagnostics=[Task failed, taskId=task_1691064079730_0001_3_00_000000, diagnostics=[TaskAttempt 0 failed, info=[Error: Error while running task ( failure ) : attempt_1691064079730_0001_3_00_000000_0:java.lang.RuntimeException: java.lang.RuntimeException: java.io.IOException: java.lang.IndexOutOfBoundsException: start index (4) must not be greater than size (1)
	at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:348)
	at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:276)
	at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:381)
{noformat}

Or:

{noformat}
Caused by: java.lang.IllegalStateException: Not an instance of org.apache.iceberg.util.StructProjection: 2
	at org.apache.iceberg.data.GenericRecord.get(GenericRecord.java:123)
	at org.apache.iceberg.mr.hive.IcebergAcidUtil.computePartitionHash(IcebergAcidUtil.java:192)
	at org.apache.iceberg.mr.hive.IcebergAcidUtil$VirtualColumnAwareIterator.next(IcebergAcidUtil.java:255)
	at org.apache.iceberg.mr.mapreduce.IcebergInputFormat$IcebergRecordReader.nextKeyValue(IcebergInputFormat.java:279)
{noformat}
"	HIVE	Closed	3	1	2469	pull-request-available
13402950	Increase the RM_PROGRESS column max length to fit metrics stat	"Presently it fails with the following trace:
{noformat}
[[Event Name: EVENT_ALLOC_WRITE_ID; Total Number: 213; Total Time: 85347.0; Mean: 400.6901408450704; Median: 392.0; Standard Deviation: 33.99178239314741; Variance: 1155.4412702630862; Kurtosis: 83.69411620601193; Skewness: 83.69411620601193; 25th Percentile: 384.0; 50th Percentile: 392.0; 75th Percentile: 408.0; 90th Percentile: 417.0; Top 5 EventIds(EventId=Time) {1498476=791, 1498872=533, 1497805=508, 1498808=500, 1499027=492};]]}""}]}"" in column """"RM_PROGRESS"""" that has maximum length of 4000. Please correct your data!
        at org.datanucleus.store.rdbms.mapping.datastore.CharRDBMSMapping.setString(CharRDBMSMapping.java:254) ~[datanucleus-rdbms-4.1.19.jar:?]
        at org.datanucleus.store.rdbms.mapping.java.SingleFieldMapping.setString(SingleFieldMapping.java:180) ~{noformat}"	HIVE	Resolved	3	1	2469	pull-request-available
13485224	Fix adding custom jars in Job Classpath	"Custom added Jars in LocalFs throws FNF:
{noformat}
ERROR : Job Submission failed with exception 'java.io.FileNotFoundException(File does not exist: hdfs://localhost:9000/Users/ayushsaxena/code/hive-os/hive/packaging/target/apache-hive-4.0.0-alpha-2-SNAPSHOT-bin/apache-hive-4.0.0-alpha-2-SNAPSHOT-bin/lib/hive-iceberg-handler-4.0.0-alpha-2-SNAPSHOT.jar)'
java.io.FileNotFoundException: File does not exist: hdfs://localhost:9000/Users/ayushsaxena/code/hive-os/hive/packaging/target/apache-hive-4.0.0-alpha-2-SNAPSHOT-bin/apache-hive-4.0.0-alpha-2-SNAPSHOT-bin/lib/hive-iceberg-handler-4.0.0-alpha-2-SNAPSHOT.jar
	at org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1756)
	at org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1749)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1764)
	at org.apache.hadoop.fs.FileSystem.resolvePath(FileSystem.java:958)
	at org.apache.hadoop.mapreduce.v2.util.MRApps.addToClasspathIfNotJar(MRApps.java:342)
	at org.apache.hadoop.mapreduce.v2.util.MRApps.setClasspath(MRApps.java:275)
	at org.apache.hadoop.mapred.YARNRunner.setupContainerLaunchContextForAM(YARNRunner.java:525)
	at org.apache.hadoop.mapred.YARNRunner.createApplicationSubmissionContext(YARNRunner.java:584)
	at org.apache.hadoop.mapred.YARNRunner.submitJob(YARNRunner.java:326)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:251)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1571)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1568)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1568)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.hive.ql.exec.mr.ExecDriver.execute(ExecDriver.java:416)
	at org.apache.hadoop.hive.ql.exec.mr.MapRedTask.execute(MapRedTask.java:158){noformat}
Some Applications do consider every Jar Path to be in LocalFileSystem but rest follow the standard Hadoop practice to check the Fs.DefaultFs. We should better make the path qualified"	HIVE	Closed	3	1	2469	pull-request-available
13348853	Incorrect Result For Groupby With Limit	"{code:sql}
create table test(id int);
explain extended select id,count(*) from test group by id limit 10;
{code}

There is an TopN unexpectly for map phase, which casues incorrect result.


{code:sql}
STAGE PLANS:
  Stage: Stage-1
    Tez
      DagId: root_20210104141527_c599c0cd-ca2f-4c7d-a3cc-3a01d65c49a1:5
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
      DagName: root_20210104141527_c599c0cd-ca2f-4c7d-a3cc-3a01d65c49a1:5
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: test
                  Statistics: Num rows: 1 Data size: 13500 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Select Operator
                    expressions: id (type: int)
                    outputColumnNames: id
                    Statistics: Num rows: 1 Data size: 13500 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      aggregations: count()
                      keys: id (type: int)
                      mode: hash
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 1 Data size: 13500 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        null sort order: a
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Statistics: Num rows: 1 Data size: 13500 Basic stats: COMPLETE Column stats: NONE
                        tag: -1
                        TopN: 10
                        TopN Hash Memory Usage: 0.1
                        value expressions: _col1 (type: bigint)
                        auto parallelism: true
            Execution mode: vectorized
            Path -> Alias:
              file:/user/hive/warehouse/test [test]
            Path -> Partition:
              file:/user/hive/warehouse/test 
                Partition
                  base file name: test
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    COLUMN_STATS_ACCURATE {""BASIC_STATS"":""true"",""COLUMN_STATS"":{""id"":""true""}}
                    bucket_count -1
                    bucketing_version 2
                    column.name.delimiter ,
                    columns id
                    columns.comments 
                    columns.types int
                    file.inputformat org.apache.hadoop.mapred.TextInputFormat
                    file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    location file:/user/hive/warehouse/test
                    name default.test
                    numFiles 0
                    numRows 0
                    rawDataSize 0
                    serialization.ddl struct test { i32 id}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    totalSize 0
                    transient_lastDdlTime 1609730190
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      COLUMN_STATS_ACCURATE {""BASIC_STATS"":""true"",""COLUMN_STATS"":{""id"":""true""}}
                      bucket_count -1
                      bucketing_version 2
                      column.name.delimiter ,
                      columns id
                      columns.comments 
                      columns.types int
                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
                      file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      location file:/user/hive/warehouse/test
                      name default.test
                      numFiles 0
                      numRows 0
                      rawDataSize 0
                      serialization.ddl struct test { i32 id}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      totalSize 0
                      transient_lastDdlTime 1609730190
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: default.test
                  name: default.test
            Truncated Path -> Alias:
              /test [test]
        Reducer 2 
            Execution mode: vectorized
            Needs Tagging: false
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(VALUE._col0)
                keys: KEY._col0 (type: int)
                mode: mergepartial
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 13500 Basic stats: COMPLETE Column stats: NONE
                Limit
                  Number of rows: 10
                  Statistics: Num rows: 1 Data size: 13500 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    GlobalTableId: 0
                    directory: file:/tmp/root/7160ea24-52b9-47c3-aafc-c9200263a1c6/hive_2021-01-04_14-15-27_601_190083924675700904-1/-mr-10001/.hive-staging_hive_2021-01-04_14-15-27_601_190083924675700904-1/-ext-10002
                    NumFilesPerFileSink: 1
                    Statistics: Num rows: 1 Data size: 13500 Basic stats: COMPLETE Column stats: NONE
                    Stats Publishing Key Prefix: file:/tmp/root/7160ea24-52b9-47c3-aafc-c9200263a1c6/hive_2021-01-04_14-15-27_601_190083924675700904-1/-mr-10001/.hive-staging_hive_2021-01-04_14-15-27_601_190083924675700904-1/-ext-10002/
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        properties:
                          columns _col0,_col1
                          columns.types int:bigint
                          escape.delim \
                          hive.serialization.extend.additional.nesting.levels true
                          serialization.escape.crlf true
                          serialization.format 1
                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    TotalFiles: 1
                    GatherStats: false
                    MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: 10
      Processor Tree:
        ListSink

Time taken: 0.102 seconds, Fetched: 143 row(s)

{code}






 "	HIVE	Closed	3	1	6200	pull-request-available
13548548	CREATE TABLE with CHECK constraint fails with SemanticException	"When we run:
{code:java}
create table test (
    col1 int,
    `col 2` int check (`col 2` > 10) enable novalidate rely,
    constraint check_constraint check (col1 + `col 2` > 15) enable novalidate rely
);
{code}
It fails with:

 
{code:java}
 org.apache.hadoop.hive.ql.parse.SemanticException: Invalid Constraint syntax Invalid CHECK constraint expression: col 2 > 10.
    at org.apache.hadoop.hive.ql.ddl.table.constraint.ConstraintsUtils.validateCheckConstraint(ConstraintsUtils.java:462)
    at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeCreateTable(SemanticAnalyzer.java:13839)
    at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genResolvedParseTree(SemanticAnalyzer.java:12618)
    at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12787)
    at org.apache.hadoop.hive.ql.parse.CalcitePlanner.analyzeInternal(CalcitePlanner.java:467)
    at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:327)
    at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:224)
    at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:107)
    at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:519)
    at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:471)
    at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:436)
    at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:430)
    at org.apache.hadoop.hive.ql.reexec.ReExecDriver.compileAndRespond(ReExecDriver.java:121)
    at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:227)
    at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:257)
    at org.apache.hadoop.hive.cli.CliDriver.processCmd1(CliDriver.java:201)
    at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:127)
    at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:425)
    at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:356)
    at org.apache.hadoop.hive.ql.QTestUtil.executeClientInternal(QTestUtil.java:733)
    at org.apache.hadoop.hive.ql.QTestUtil.executeClient(QTestUtil.java:703)
    at org.apache.hadoop.hive.cli.control.CoreCliDriver.runTest(CoreCliDriver.java:115)
    at org.apache.hadoop.hive.cli.control.CliAdapter.runTest(CliAdapter.java:157)
    at org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver(TestMiniLlapLocalCliDriver.java:62) {code}
 

I noticed while debugging that the check constraint expression in [cc.getCheck_expression()|https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/ddl/table/constraint/ConstraintsUtils.java#L446] doesn't include the backticks (`), and this results in wrong token generation."	HIVE	Closed	3	1	6200	pull-request-available
13532629	Literals in conjunction of two IN expression are considered not equals if type precision is different	"{code}
create table r_table (
  string_col varchar(30)
);


create table l_table (
  string_col varchar(14)
);

insert into r_table VALUES ('AAA111');
insert into l_table VALUES ('AAA111');
SELECT l_table.string_col from l_table, r_table
WHERE r_table.string_col = l_table.string_col AND l_table.string_col IN ('AAA111', 'BBB222') AND r_table.string_col IN ('AAA111', 'BBB222');
{code}
Should give one row
{code}
AAA111
{code}
but it returns empty rs

Workaround
{code}
set hive.optimize.point.lookup=false;
{code}

"	HIVE	Resolved	3	1	6200	pull-request-available
13432095	TopNKey and PTF with more than one column is failing with IOBE	"{code:java}
java.lang.IndexOutOfBoundsException: toIndex = 2
at java.util.ArrayList.subListRangeCheck(ArrayList.java:1014)
at java.util.ArrayList.subList(ArrayList.java:1006)
at org.apache.hadoop.hive.ql.plan.TopNKeyDesc.combine(TopNKeyDesc.java:201)
at org.apache.hadoop.hive.ql.optimizer.topnkey.TopNKeyPushdownProcessor.pushdownThroughGroupBy(TopNKeyPushdownProcessor.java:162)
at org.apache.hadoop.hive.ql.optimizer.topnkey.TopNKeyPushdownProcessor.pushdown(TopNKeyPushdownProcessor.java:76)
at org.apache.hadoop.hive.ql.optimizer.topnkey.TopNKeyPushdownProcessor.process(TopNKeyPushdownProcessor.java:57)
at org.apache.hadoop.hive.ql.lib.DefaultRuleDispatcher.dispatch(DefaultRuleDispatcher.java:90)
at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.dispatchAndReturn(DefaultGraphWalker.java:105)
at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.dispatch(DefaultGraphWalker.java:89)
at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.walk(DefaultGraphWalker.java:158)
at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.startWalking(DefaultGraphWalker.java:120)
at org.apache.hadoop.hive.ql.parse.TezCompiler.runTopNKeyOptimization(TezCompiler.java:1305)
at org.apache.hadoop.hive.ql.parse.TezCompiler.optimizeOperatorPlan(TezCompiler.java:173)
at org.apache.hadoop.hive.ql.parse.TaskCompiler.compile(TaskCompiler.java:159)
at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12646)
at org.apache.hadoop.hive.ql.parse.CalcitePlanner.analyzeInternal(CalcitePlanner.java:358)
at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:283)
at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:219)
at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:103)
at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:215){code}"	HIVE	Open	3	1	6200	pull-request-available
13536568	Show saved snapshot of materialized view source tables	"HIVE-25745 introduced a new section into
{code:java}
DESCRIBE FORMATTED <view name>;
{code}
output:
{code:java}
# Materialized View Source table information	 	 
Table name          	I/U/D since last rebuild	 
hive.default.src_txn	0/0/0               	 
hive.default.src_txn_2	0/0/0               	 
{code}
Unfortunately transactional stats are not reliable because such stats are supposed to be saved along with basic stats.
If something blocks saving the stats like
{code:java}
set hive.stats.autogather=false;
{code}
basic stats still can be refreshed using
{code:java}
analyze table <table> compute statistics;
{code}
but it won't collect and update transactional since the amount of rows affected by recent transactions are no longer available and can not be calculated.

 

The goal of this jira is to print the saved snapshot information of each source table instead:
* writeId in case of native acid tables
* snapshotId in case of iceberg tables
 "	HIVE	Resolved	4	4	6200	pull-request-available
13534425	AssertionError in Calcite during planning for incremental rebuild of materialized view with aggregate on decimal column	"{code}
set hive.support.concurrency=true;
set hive.txn.manager=org.apache.hadoop.hive.ql.lockmgr.DbTxnManager;
set hive.materializedview.rewriting.sql=false;

create table t1(a int, b decimal(7,2)) stored as orc TBLPROPERTIES ('transactional'='true');

insert into t1(a, b) values(1, 1);

create materialized view mat1 stored as orc TBLPROPERTIES ('transactional'='true') as
select t1.a, sum(t1.b) from t1
group by t1.a;

insert into t1(a,b) values(2, 5);

explain cbo alter materialized view mat1 rebuild;
{code}
{code}
java.lang.AssertionError: 
Cannot add expression of different type to set:
set type is RecordType(INTEGER $f0, DECIMAL(17, 2) $f1) NOT NULL
expression type is RecordType(INTEGER $f0, DECIMAL(18, 2) $f1) NOT NULL
set is rel#388:HiveAggregate.HIVE.[].any(input=HepRelVertex#387,group={0},agg#0=sum($1))
expression is HiveProject($f0=[$3], $f1=[CASE(IS NULL($1), $4, IS NULL($4), $1, +($4, $1))])
  HiveFilter(condition=[OR($2, IS NULL($2))])
    HiveJoin(condition=[IS NOT DISTINCT FROM($0, $3)], joinType=[right], algorithm=[none], cost=[not available])
      HiveProject(a=[$0], _c1=[$1], $f2=[true])
        HiveTableScan(table=[[default, mat1]], table:alias=[default.mat1])
      HiveAggregate(group=[{0}], agg#0=[sum($1)])
        HiveProject($f0=[$0], $f1=[$1])
          HiveFilter(condition=[<(1, $4.writeid)])
            HiveTableScan(table=[[default, t1]], table:alias=[t1])

	at org.apache.calcite.plan.RelOptUtil.verifyTypeEquivalence(RelOptUtil.java:380)
	at org.apache.calcite.plan.hep.HepRuleCall.transformTo(HepRuleCall.java:58)
	at org.apache.calcite.plan.RelOptRuleCall.transformTo(RelOptRuleCall.java:268)
	at org.apache.calcite.plan.RelOptRuleCall.transformTo(RelOptRuleCall.java:283)
	at org.apache.hadoop.hive.ql.optimizer.calcite.rules.views.HiveAggregateIncrementalRewritingRuleBase.onMatch(HiveAggregateIncrementalRewritingRuleBase.java:161)
	at org.apache.calcite.plan.AbstractRelOptPlanner.fireRule(AbstractRelOptPlanner.java:333)
	at org.apache.calcite.plan.hep.HepPlanner.applyRule(HepPlanner.java:542)
	at org.apache.calcite.plan.hep.HepPlanner.applyRules(HepPlanner.java:407)
	at org.apache.calcite.plan.hep.HepPlanner.executeInstruction(HepPlanner.java:243)
	at org.apache.calcite.plan.hep.HepInstruction$RuleInstance.execute(HepInstruction.java:127)
	at org.apache.calcite.plan.hep.HepPlanner.executeProgram(HepPlanner.java:202)
	at org.apache.calcite.plan.hep.HepPlanner.findBestExp(HepPlanner.java:189)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner$CalcitePlannerAction.executeProgram(CalcitePlanner.java:2468)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner$CalcitePlannerAction.executeProgram(CalcitePlanner.java:2427)
	at org.apache.hadoop.hive.ql.ddl.view.materialized.alter.rebuild.AlterMaterializedViewRebuildAnalyzer$MVRebuildCalcitePlannerAction.applyIncrementalRebuild(AlterMaterializedViewRebuildAnalyzer.java:460)
	at org.apache.hadoop.hive.ql.ddl.view.materialized.alter.rebuild.AlterMaterializedViewRebuildAnalyzer$MVRebuildCalcitePlannerAction.applyAggregateInsertIncremental(AlterMaterializedViewRebuildAnalyzer.java:352)
	at org.apache.hadoop.hive.ql.ddl.view.materialized.alter.rebuild.AlterMaterializedViewRebuildAnalyzer$MVRebuildCalcitePlannerAction.applyRecordIncrementalRebuildPlan(AlterMaterializedViewRebuildAnalyzer.java:311)
	at org.apache.hadoop.hive.ql.ddl.view.materialized.alter.rebuild.AlterMaterializedViewRebuildAnalyzer$MVRebuildCalcitePlannerAction.applyMaterializedViewRewriting(AlterMaterializedViewRebuildAnalyzer.java:278)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner$CalcitePlannerAction.apply(CalcitePlanner.java:1722)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner$CalcitePlannerAction.apply(CalcitePlanner.java:1591)
	at org.apache.calcite.tools.Frameworks.lambda$withPlanner$0(Frameworks.java:131)
	at org.apache.calcite.prepare.CalcitePrepareImpl.perform(CalcitePrepareImpl.java:914)
	at org.apache.calcite.tools.Frameworks.withPrepare(Frameworks.java:180)
	at org.apache.calcite.tools.Frameworks.withPlanner(Frameworks.java:126)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.logicalPlan(CalcitePlanner.java:1343)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.genOPTree(CalcitePlanner.java:570)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12824)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.analyzeInternal(CalcitePlanner.java:465)
	at org.apache.hadoop.hive.ql.ddl.view.materialized.alter.rebuild.AlterMaterializedViewRebuildAnalyzer.analyzeInternal(AlterMaterializedViewRebuildAnalyzer.java:135)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:326)
	at org.apache.hadoop.hive.ql.parse.ExplainSemanticAnalyzer.analyzeInternal(ExplainSemanticAnalyzer.java:180)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:326)
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:224)
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:107)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:519)
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:471)
	at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:436)
	at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:430)
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.compileAndRespond(ReExecDriver.java:121)
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:227)
	at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:257)
	at org.apache.hadoop.hive.cli.CliDriver.processCmd1(CliDriver.java:201)
	at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:127)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:425)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:356)
	at org.apache.hadoop.hive.ql.QTestUtil.executeClientInternal(QTestUtil.java:733)
	at org.apache.hadoop.hive.ql.QTestUtil.executeClient(QTestUtil.java:703)
	at org.apache.hadoop.hive.cli.control.CoreCliDriver.runTest(CoreCliDriver.java:115)
	at org.apache.hadoop.hive.cli.control.CliAdapter.runTest(CliAdapter.java:157)
	at org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver(TestMiniLlapLocalCliDriver.java:62)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.apache.hadoop.hive.cli.control.CliAdapter$2$1.evaluate(CliAdapter.java:135)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.apache.hadoop.hive.cli.control.CliAdapter$1$1.evaluate(CliAdapter.java:95)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
{code}"	HIVE	Resolved	3	1	6200	pull-request-available
13270568	RS deduplication does not always enforce hive.optimize.reducededuplication.min.reducer	"For transactional tables, that property might be overriden to 1, which can lead to merging final aggregation into a single stage (hence leading to performance degradation). For instance, when autogather column stats is enabled, this can happen for the following query:

{code}
set hive.support.concurrency=true;
set hive.txn.manager=org.apache.hadoop.hive.ql.lockmgr.DbTxnManager;

EXPLAIN
CREATE TABLE x STORED AS ORC TBLPROPERTIES('transactional'='true') AS
SELECT * FROM SRC x CLUSTER BY x.key;
{code}"	HIVE	Closed	3	1	6200	pull-request-available
13469085	Remove column statistics collection task from merge statement plan 	"Merge statements may contain delete and update branches. Update is technically a delete and an insert operation. Column statistics can not be calculated in case of delete operations from the changed records. Example: min, max.

Currently Hive marks the column stats of the target table invalid after Update/Delete/Merge but for merge extra GBY operators and reducers are generated for insert branches to calculate column stats and Stats works are collecting Column stats too.
{code}
POSTHOOK: query: explain
merge into acidTbl_n0 as t using nonAcidOrcTbl_n0 s ON t.a = s.a
WHEN MATCHED AND s.a > 8 THEN DELETE
WHEN MATCHED THEN UPDATE SET b = 7
WHEN NOT MATCHED THEN INSERT VALUES(s.a, s.b)
POSTHOOK: type: QUERY
POSTHOOK: Input: default@acidtbl_n0
POSTHOOK: Input: default@nonacidorctbl_n0
POSTHOOK: Output: default@acidtbl_n0
POSTHOOK: Output: default@acidtbl_n0
POSTHOOK: Output: default@merge_tmp_table
STAGE DEPENDENCIES:
  Stage-5 is a root stage
  Stage-6 depends on stages: Stage-5
  Stage-0 depends on stages: Stage-6
  Stage-7 depends on stages: Stage-0
  Stage-1 depends on stages: Stage-6
  Stage-8 depends on stages: Stage-1
  Stage-2 depends on stages: Stage-6
  Stage-9 depends on stages: Stage-2
  Stage-3 depends on stages: Stage-6
  Stage-10 depends on stages: Stage-3
  Stage-4 depends on stages: Stage-6
  Stage-11 depends on stages: Stage-4

STAGE PLANS:
  Stage: Stage-5
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 10 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (SIMPLE_EDGE)
        Reducer 4 <- Reducer 2 (SIMPLE_EDGE)
        Reducer 5 <- Reducer 2 (SIMPLE_EDGE)
        Reducer 6 <- Reducer 5 (CUSTOM_SIMPLE_EDGE)
        Reducer 7 <- Reducer 2 (SIMPLE_EDGE)
        Reducer 8 <- Reducer 7 (CUSTOM_SIMPLE_EDGE)
        Reducer 9 <- Reducer 2 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: s
                  Statistics: Num rows: 4 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: a (type: int), b (type: int)
                    outputColumnNames: _col0, _col1
                    Statistics: Num rows: 4 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: _col0 (type: int)
                      null sort order: z
                      sort order: +
                      Map-reduce partition columns: _col0 (type: int)
                      Statistics: Num rows: 4 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                      value expressions: _col1 (type: int)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Map 10 
            Map Operator Tree:
                TableScan
                  alias: t
                  filterExpr: a is not null (type: boolean)
                  Statistics: Num rows: 2 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: a is not null (type: boolean)
                    Statistics: Num rows: 2 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: a (type: int), ROW__ID (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 2 Data size: 160 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        null sort order: z
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Statistics: Num rows: 2 Data size: 160 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col1 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
            Execution mode: vectorized, llap
            LLAP IO: may be used (ACID table)
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Left Outer Join 0 to 1
                keys:
                  0 _col0 (type: int)
                  1 _col0 (type: int)
                outputColumnNames: _col0, _col1, _col2, _col3
                Statistics: Num rows: 6 Data size: 288 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: _col3 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>), _col1 (type: int), _col2 (type: int), _col0 (type: int)
                  outputColumnNames: _col0, _col1, _col2, _col3
                  Statistics: Num rows: 6 Data size: 288 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: ((_col2 = _col3) and (_col3 > 8)) (type: boolean)
                    Statistics: Num rows: 1 Data size: 88 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: _col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                      outputColumnNames: _col0
                      Statistics: Num rows: 1 Data size: 76 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                        null sort order: z
                        sort order: +
                        Map-reduce partition columns: UDFToInteger(_col0) (type: int)
                        Statistics: Num rows: 1 Data size: 76 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: ((_col2 = _col3) and (_col3 <= 8)) (type: boolean)
                    Statistics: Num rows: 2 Data size: 176 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: _col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                      outputColumnNames: _col0
                      Statistics: Num rows: 2 Data size: 152 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                        null sort order: z
                        sort order: +
                        Map-reduce partition columns: UDFToInteger(_col0) (type: int)
                        Statistics: Num rows: 2 Data size: 152 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: ((_col2 = _col3) and (_col3 <= 8)) (type: boolean)
                    Statistics: Num rows: 2 Data size: 176 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: _col2 (type: int), 7 (type: int)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 2 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        null sort order: a
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Statistics: Num rows: 2 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col1 (type: int)
                  Filter Operator
                    predicate: _col2 is null (type: boolean)
                    Statistics: Num rows: 4 Data size: 192 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: _col3 (type: int), _col1 (type: int)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 4 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        null sort order: a
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Statistics: Num rows: 4 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col1 (type: int)
                  Filter Operator
                    predicate: (_col2 = _col3) (type: boolean)
                    Statistics: Num rows: 3 Data size: 184 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: _col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                      outputColumnNames: _col0
                      Statistics: Num rows: 3 Data size: 184 Basic stats: COMPLETE Column stats: COMPLETE
                      Group By Operator
                        aggregations: count()
                        keys: _col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                        minReductionHashAggr: 0.4
                        mode: hash
                        outputColumnNames: _col0, _col1
                        Statistics: Num rows: 2 Data size: 168 Basic stats: COMPLETE Column stats: COMPLETE
                        Reduce Output Operator
                          key expressions: _col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                          null sort order: z
                          sort order: +
                          Map-reduce partition columns: _col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                          Statistics: Num rows: 2 Data size: 168 Basic stats: COMPLETE Column stats: COMPLETE
                          value expressions: _col1 (type: bigint)
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                outputColumnNames: _col0
                Statistics: Num rows: 1 Data size: 76 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 76 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.acidtbl_n0
                  Write Type: DELETE
        Reducer 4 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                outputColumnNames: _col0
                Statistics: Num rows: 2 Data size: 152 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 2 Data size: 152 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.acidtbl_n0
                  Write Type: DELETE
        Reducer 5 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), VALUE._col0 (type: int)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 2 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 2 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.acidtbl_n0
                  Write Type: INSERT
                Select Operator
                  expressions: _col0 (type: int), _col1 (type: int)
                  outputColumnNames: a, b
                  Statistics: Num rows: 2 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
                  Group By Operator
                    aggregations: min(a), max(a), count(1), count(a), compute_bit_vector_hll(a), min(b), max(b), count(b), compute_bit_vector_hll(b)
                    minReductionHashAggr: 0.5
                    mode: hash
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
                    Statistics: Num rows: 1 Data size: 328 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      null sort order: 
                      sort order: 
                      Statistics: Num rows: 1 Data size: 328 Basic stats: COMPLETE Column stats: COMPLETE
                      value expressions: _col0 (type: int), _col1 (type: int), _col2 (type: bigint), _col3 (type: bigint), _col4 (type: binary), _col5 (type: int), _col6 (type: int), _col7 (type: bigint), _col8 (type: binary)
        Reducer 6 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
                Statistics: Num rows: 1 Data size: 328 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'LONG' (type: string), UDFToLong(_col0) (type: bigint), UDFToLong(_col1) (type: bigint), (_col2 - _col3) (type: bigint), COALESCE(ndv_compute_bit_vector(_col4),0) (type: bigint), _col4 (type: binary), 'LONG' (type: string), UDFToLong(_col5) (type: bigint), UDFToLong(_col6) (type: bigint), (_col2 - _col7) (type: bigint), COALESCE(ndv_compute_bit_vector(_col8),0) (type: bigint), _col8 (type: binary)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11
                  Statistics: Num rows: 1 Data size: 528 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 528 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
        Reducer 7 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), VALUE._col0 (type: int)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 4 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 4 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.acidtbl_n0
                  Write Type: INSERT
                Select Operator
                  expressions: _col0 (type: int), _col1 (type: int)
                  outputColumnNames: a, b
                  Statistics: Num rows: 4 Data size: 32 Basic stats: COMPLETE Column stats: COMPLETE
                  Group By Operator
                    aggregations: min(a), max(a), count(1), count(a), compute_bit_vector_hll(a), min(b), max(b), count(b), compute_bit_vector_hll(b)
                    minReductionHashAggr: 0.75
                    mode: hash
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
                    Statistics: Num rows: 1 Data size: 328 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      null sort order: 
                      sort order: 
                      Statistics: Num rows: 1 Data size: 328 Basic stats: COMPLETE Column stats: COMPLETE
                      value expressions: _col0 (type: int), _col1 (type: int), _col2 (type: bigint), _col3 (type: bigint), _col4 (type: binary), _col5 (type: int), _col6 (type: int), _col7 (type: bigint), _col8 (type: binary)
        Reducer 8 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
                Statistics: Num rows: 1 Data size: 328 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'LONG' (type: string), UDFToLong(_col0) (type: bigint), UDFToLong(_col1) (type: bigint), (_col2 - _col3) (type: bigint), COALESCE(ndv_compute_bit_vector(_col4),0) (type: bigint), _col4 (type: binary), 'LONG' (type: string), UDFToLong(_col5) (type: bigint), UDFToLong(_col6) (type: bigint), (_col2 - _col7) (type: bigint), COALESCE(ndv_compute_bit_vector(_col8),0) (type: bigint), _col8 (type: binary)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11
                  Statistics: Num rows: 1 Data size: 528 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 528 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
        Reducer 9 
            Execution mode: llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(VALUE._col0)
                keys: KEY._col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                mode: mergepartial
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 2 Data size: 168 Basic stats: COMPLETE Column stats: COMPLETE
                Filter Operator
                  predicate: (_col1 > 1L) (type: boolean)
                  Statistics: Num rows: 1 Data size: 84 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: cardinality_violation(_col0) (type: int)
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: COMPLETE
                    File Output Operator
                      compressed: false
                      Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: COMPLETE
                      table:
                          input format: org.apache.hadoop.mapred.TextInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                          name: default.merge_tmp_table

  Stage: Stage-6
    Dependency Collection

  Stage: Stage-0
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.acidtbl_n0
          Write Type: DELETE

  Stage: Stage-7
    Stats Work
      Basic Stats Work:

  Stage: Stage-1
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.acidtbl_n0
          Write Type: DELETE

  Stage: Stage-8
    Stats Work
      Basic Stats Work:

  Stage: Stage-2
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.acidtbl_n0
          Write Type: INSERT

  Stage: Stage-9
    Stats Work
      Basic Stats Work:

  Stage: Stage-3
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.acidtbl_n0
          Write Type: INSERT

  Stage: Stage-10
    Stats Work
      Basic Stats Work:
      Column Stats Desc:
          Columns: a, b
          Column Types: int, int
          Table: default.acidtbl_n0

  Stage: Stage-4
    Move Operator
      tables:
          replace: false
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.merge_tmp_table

  Stage: Stage-11
    Stats Work
      Basic Stats Work:
{code}

One of the insert Reducers and the follow-up Reducer for col stats collecting:
{code}
        Reducer 5 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: int), VALUE._col0 (type: int)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 2 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 2 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: default.acidtbl_n0
                  Write Type: INSERT
                Select Operator
                  expressions: _col0 (type: int), _col1 (type: int)
                  outputColumnNames: a, b
                  Statistics: Num rows: 2 Data size: 16 Basic stats: COMPLETE Column stats: COMPLETE
                  Group By Operator
                    aggregations: min(a), max(a), count(1), count(a), compute_bit_vector_hll(a), min(b), max(b), count(b), compute_bit_vector_hll(b)
                    minReductionHashAggr: 0.5
                    mode: hash
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
                    Statistics: Num rows: 1 Data size: 328 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      null sort order: 
                      sort order: 
                      Statistics: Num rows: 1 Data size: 328 Basic stats: COMPLETE Column stats: COMPLETE
                      value expressions: _col0 (type: int), _col1 (type: int), _col2 (type: bigint), _col3 (type: bigint), _col4 (type: binary), _col5 (type: int), _col6 (type: int), _col7 (type: bigint), _col8 (type: binary)
        Reducer 6 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), count(VALUE._col2), count(VALUE._col3), compute_bit_vector_hll(VALUE._col4), min(VALUE._col5), max(VALUE._col6), count(VALUE._col7), compute_bit_vector_hll(VALUE._col8)
                mode: mergepartial
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
                Statistics: Num rows: 1 Data size: 328 Basic stats: COMPLETE Column stats: COMPLETE
                Select Operator
                  expressions: 'LONG' (type: string), UDFToLong(_col0) (type: bigint), UDFToLong(_col1) (type: bigint), (_col2 - _col3) (type: bigint), COALESCE(ndv_compute_bit_vector(_col4),0) (type: bigint), _col4 (type: binary), 'LONG' (type: string), UDFToLong(_col5) (type: bigint), UDFToLong(_col6) (type: bigint), (_col2 - _col7) (type: bigint), COALESCE(ndv_compute_bit_vector(_col8),0) (type: bigint), _col8 (type: binary)
                  outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11
                  Statistics: Num rows: 1 Data size: 528 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 528 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
{code}
"	HIVE	Closed	3	7	6200	pull-request-available
13561416	Wrong results when using materialized views with non-deterministic/dynamic functions	"There are certain SQL functions that return different results across different executions. Usually we refer to these functions as non-deterministic or dynamic. Some examples are: UNIX_TIMESTAMP(), CURRENT_TIMESTAMP, CURRENT_DATE, etc.

When a materialized view definition contains such functions the queries that are using this view may return wrong results.

Consider the following scenario where we populate the employee table with timestamps representing the future. For making this easily reproable in self-contained test the timestamps are only a few seconds apart.
{code:sql}
CREATE TABLE EMPS (ENAME STRING, BIRTH_EPOCH_SECS INT) STORED AS ORC TBLPROPERTIES ('transactional'='true');

INSERT INTO EMPS
VALUES ('Victor', UNIX_TIMESTAMP()),
       ('Alex', UNIX_TIMESTAMP() + 2),
       ('Bob', UNIX_TIMESTAMP() + 5),
       ('Alice', UNIX_TIMESTAMP() + 10);

CREATE MATERIALIZED VIEW v_emp AS SELECT * FROM EMPS WHERE BIRTH_EPOCH_SECS <= UNIX_TIMESTAMP();
{code}
When the materialized view is created it is populated with only the rows that match the timestamp at the given time.

To demonstrate the problem run the following queries with view based rewritting disabled and enabled.
{code:sql}
set hive.materializedview.rewriting.sql=false;
SELECT * FROM EMPS WHERE BIRTH_EPOCH_SECS <= UNIX_TIMESTAMP();
{code}
{noformat}
Victor	1702302786
Alex	1702302788
Bob	1702302791
{noformat}
{code:sql}
set hive.materializedview.rewriting.sql=true;
SELECT * FROM EMPS WHERE BIRTH_EPOCH_SECS <= UNIX_TIMESTAMP();
{code}
{noformat}
Victor	1702302786
Alex	1702302788
{noformat}
Naturally the second query should return more rows than the first one since UNIX_TIMESTAMP is constantly growing. However, when view based rewritting is in use the second query will use the results from the materialized view which are by now obsolete (missing Bob entry)."	HIVE	Closed	2	1	6200	pull-request-available
13361848	Materialized View incremental rebuild produces wrong result set after compaction	"{code}
create table t1(a int, b varchar(128), c float) stored as orc TBLPROPERTIES ('transactional'='true');
insert into t1(a,b, c) values (1, 'one', 1.1), (2, 'two', 2.2), (NULL, NULL, NULL);

create materialized view mat1 stored as orc TBLPROPERTIES ('transactional'='true') as 
            select a,b,c from t1 where a > 0 or a is null;

delete from t1 where a = 1;

alter table t1 compact 'major';

-- Wait until compaction finished.
alter materialized view mat1 rebuild;
{code}

Expected result of query
{code}
select * from mat1;
{code}
{code}
2 two 2
NULL NULL NULL
{code}
but if incremental rebuild is enabled the result is
{code}
1 one 1
2 two 2
NULL NULL NULL
{code}

Cause: Incremental rebuild queries whether the source tables of a materialized view has delete or update transaction since the last rebuild from metastore from COMPLETED_TXN_COMPONENTS table. However when a major compaction is performed on the source tables the records related to these tables are deleted from COMPLETED_TXN_COMPONENTS.
"	HIVE	Closed	2	1	6200	pull-request-available
13370312	AssertionError when referencing ROW__ID.writeId	"{code}
set hive.txn.manager=org.apache.hadoop.hive.ql.lockmgr.DbTxnManager;
set hive.support.concurrency=true;

create table t1(a int, b float) stored as orc TBLPROPERTIES ('transactional'='true');

insert into t1(a, b) values (1, 1.1);
insert into t1(a, b) values (2, 2.2);

SELECT t1.ROW__ID
FROM t1
WHERE t1.ROW__ID.writeid > 1;
{code}
{code}
java.lang.AssertionError
	at org.apache.hadoop.hive.ql.parse.UnparseTranslator.addTranslation(UnparseTranslator.java:123)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.genAllRexNode(CalcitePlanner.java:5680)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.genRexNode(CalcitePlanner.java:5570)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.genRexNode(CalcitePlanner.java:5530)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner$CalcitePlannerAction.genFilterRelNode(CalcitePlanner.java:3385)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner$CalcitePlannerAction.genFilterRelNode(CalcitePlanner.java:3706)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner$CalcitePlannerAction.genFilterLogicalPlan(CalcitePlanner.java:3717)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner$CalcitePlannerAction.genLogicalPlan(CalcitePlanner.java:5281)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner$CalcitePlannerAction.apply(CalcitePlanner.java:1839)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner$CalcitePlannerAction.apply(CalcitePlanner.java:1785)
	at org.apache.calcite.tools.Frameworks.lambda$withPlanner$0(Frameworks.java:130)
	at org.apache.calcite.prepare.CalcitePrepareImpl.perform(CalcitePrepareImpl.java:915)
	at org.apache.calcite.tools.Frameworks.withPrepare(Frameworks.java:179)
	at org.apache.calcite.tools.Frameworks.withPlanner(Frameworks.java:125)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.logicalPlan(CalcitePlanner.java:1546)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.genOPTree(CalcitePlanner.java:563)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12582)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.analyzeInternal(CalcitePlanner.java:456)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:316)
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223)
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:104)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:492)
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:445)
	at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:409)
	at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:403)
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.compileAndRespond(ReExecDriver.java:125)
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:229)
	at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:258)
	at org.apache.hadoop.hive.cli.CliDriver.processCmd1(CliDriver.java:203)
	at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:129)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:424)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:355)
	at org.apache.hadoop.hive.ql.QTestUtil.executeClientInternal(QTestUtil.java:744)
	at org.apache.hadoop.hive.ql.QTestUtil.executeClient(QTestUtil.java:714)
	at org.apache.hadoop.hive.cli.control.CoreCliDriver.runTest(CoreCliDriver.java:170)
	at org.apache.hadoop.hive.cli.control.CliAdapter.runTest(CliAdapter.java:157)
	at org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver(TestMiniLlapLocalCliDriver.java:62)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.apache.hadoop.hive.cli.control.CliAdapter$2$1.evaluate(CliAdapter.java:135)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.apache.hadoop.hive.cli.control.CliAdapter$1$1.evaluate(CliAdapter.java:95)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
{code}"	HIVE	Resolved	3	1	6200	pull-request-available
13346384	Fix acid_vectorization_original	"the failure was hidden by the failed-to-read issue

the test is most likely failed first after HIVE-24274 

{code}
[ERROR] org.apache.hadoop.hive.cli.split0.TestMiniLlapLocalCliDriver.testCliDriver[acid_vectorization_original]  Time elapsed: 10.931 s  <<< FAILURE!
java.lang.AssertionError
	at org.apache.hadoop.hive.ql.parse.UnparseTranslator.addTranslation(UnparseTranslator.java:123)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genAllExprNodeDesc(SemanticAnalyzer.java:13073)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner$CalcitePlannerAction.genJoinRelNode(CalcitePlanner.java:2897)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner$CalcitePlannerAction.genJoinLogicalPlan(CalcitePlanner.java:3124)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner$CalcitePlannerAction.genLogicalPlan(CalcitePlanner.java:5298)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner$CalcitePlannerAction.apply(CalcitePlanner.java:1874)
{code}"	HIVE	Resolved	3	1	6200	pull-request-available
13524433	Apply SerDe properties when creating materialized view	"{code}
create table tbl_ice(a int, b string, c int) stored by iceberg stored as orc tblproperties ('format-version'='1');

create materialized view mat1 stored by iceberg stored as orc tblproperties ('format-version'='1') as
select tbl_ice.b, tbl_ice.c from tbl_ice where tbl_ice.c > 52;
{code}

Materialized view {{mat1}} should use {{ORC}} file format."	HIVE	Resolved	3	4	6200	pull-request-available
13537154	Fix test acid_bloom_filter_orc_file_dump	"This test dumps orc file data and the table in the test has 2 delta directories with one orc file in each
Hive has a posthook which scans all the directories of a table and dumps all orc files to the output but the order of the directory list is not deterministic.

https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/hooks/PostExecOrcFileDump.java"	HIVE	Resolved	4	1	6200	pull-request-available
13540417	Exception when rebuild materialized view incrementally in presence of delete operations	"{code}
create table cmv_basetable_n6 (a int, b varchar(256), c decimal(10,2), d int) stored as orc TBLPROPERTIES ('transactional'='true');

insert into cmv_basetable_n6 values
 (1, 'alfred', 10.30, 2),
 (2, 'bob', 3.14, 3),
 (2, 'bonnie', 172342.2, 3),
 (3, 'calvin', 978.76, 3),
 (3, 'charlie', 9.8, 1);

create table cmv_basetable_2_n3 (a int, b varchar(256), c decimal(10,2), d int) stored as orc TBLPROPERTIES ('transactional'='true');

insert into cmv_basetable_2_n3 values
 (1, 'alfred', 10.30, 2),
 (3, 'calvin', 978.76, 3);

CREATE MATERIALIZED VIEW cmv_mat_view_n6
  TBLPROPERTIES ('transactional'='true') AS
  SELECT cmv_basetable_n6.a, cmv_basetable_2_n3.c
  FROM cmv_basetable_n6 JOIN cmv_basetable_2_n3 ON (cmv_basetable_n6.a = cmv_basetable_2_n3.a)
  WHERE cmv_basetable_2_n3.c > 10.0;

DELETE from cmv_basetable_2_n3 WHERE a=1;

ALTER MATERIALIZED VIEW cmv_mat_view_n6 REBUILD;

DELETE FROM cmv_basetable_n6 WHERE a=1;

ALTER MATERIALIZED VIEW cmv_mat_view_n6 REBUILD;
{code}
The second rebuild fails
{code}
 org.apache.hadoop.hive.ql.metadata.HiveException: Vertex failed, vertexName=Reducer 3, vertexId=vertex_1686925588164_0001_7_06, diagnostics=[Task failed, taskId=task_1686925588164_0001_7_06_000000, diagnostics=[TaskAttempt 0 failed, info=[Error: Error while running task ( failure ) : attempt_1686925588164_0001_7_06_000000_0:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row
	at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:348)
	at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:276)
	at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:381)
	at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:82)
	at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:69)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:69)
	at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:39)
	at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)
	at org.apache.hadoop.hive.llap.daemon.impl.StatsRecordingThreadPool$WrappedCallable.call(StatsRecordingThreadPool.java:118)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row
	at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:313)
	at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:291)
	at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:293)
	... 15 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row
	at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource$GroupIterator.next(ReduceRecordSource.java:387)
	at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:303)
	... 17 more
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableIntObjectInspector.get(WritableIntObjectInspector.java:36)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:1183)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:94)
	at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource$GroupIterator.next(ReduceRecordSource.java:372)
	... 18 more
], TaskAttempt 1 failed, info=[Error: Error while running task ( failure ) : attempt_1686925588164_0001_7_06_000000_1:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row
	at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:348)
	at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:276)
	at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:381)
	at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:82)
	at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:69)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:69)
	at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:39)
	at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)
	at org.apache.hadoop.hive.llap.daemon.impl.StatsRecordingThreadPool$WrappedCallable.call(StatsRecordingThreadPool.java:118)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row
	at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:313)
	at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:291)
	at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:293)
	... 15 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row
	at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource$GroupIterator.next(ReduceRecordSource.java:387)
	at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:303)
	... 17 more
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableIntObjectInspector.get(WritableIntObjectInspector.java:36)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:1183)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:94)
	at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource$GroupIterator.next(ReduceRecordSource.java:372)
	... 18 more
]], Vertex did not succeed due to OWN_TASK_FAILURE, failedTasks:1 killedTasks:0, Vertex vertex_1686925588164_0001_7_06 [Reducer 3] killed/failed due to:OWN_TASK_FAILURE]DAG did not succeed due to VERTEX_FAILURE. failedVertices:1 killedVertices:0
	at org.apache.hadoop.hive.ql.exec.tez.TezTask.execute(TezTask.java:265)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:214)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:105)
	at org.apache.hadoop.hive.ql.Executor.launchTask(Executor.java:354)
	at org.apache.hadoop.hive.ql.Executor.launchTasks(Executor.java:327)
	at org.apache.hadoop.hive.ql.Executor.runTasks(Executor.java:244)
	at org.apache.hadoop.hive.ql.Executor.execute(Executor.java:105)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:367)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:205)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:154)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:149)
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:185)
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:228)
	at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:257)
	at org.apache.hadoop.hive.cli.CliDriver.processCmd1(CliDriver.java:201)
	at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:127)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:425)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:356)
	at org.apache.hadoop.hive.ql.QTestUtil.executeClientInternal(QTestUtil.java:733)
	at org.apache.hadoop.hive.ql.QTestUtil.executeClient(QTestUtil.java:703)
	at org.apache.hadoop.hive.cli.control.CoreCliDriver.runTest(CoreCliDriver.java:115)
	at org.apache.hadoop.hive.cli.control.CliAdapter.runTest(CliAdapter.java:157)
	at org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver(TestMiniLlapLocalCliDriver.java:62)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.apache.hadoop.hive.cli.control.CliAdapter$2$1.evaluate(CliAdapter.java:135)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.apache.hadoop.hive.cli.control.CliAdapter$1$1.evaluate(CliAdapter.java:95)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
{code}"	HIVE	Closed	3	1	6200	pull-request-available
13449784	Iceberg integration: Perform update split early	Extend update split early to iceberg tables like in HIVE-21160 for native acid tables	HIVE	Closed	3	7	6200	pull-request-available
13414271	Support backward compatibility of thrift struct CreationMetadata	"Old
{code}
struct CreationMetadata {
    1: required string catName
    2: required string dbName,
    3: required string tblName,
    4: required set<string> tablesUsed,
    5: optional string validTxnList,
    6: optional i64 materializationTime
}HIVE-25656 introduced a breaking change in the HiveServer2 <-> Metastore thrift api:
{code}
New
{code}
struct CreationMetadata {
    1: required string catName
    2: required string dbName,
    3: required string tblName,
    4: required set<SourceTable> tablesUsed,
    5: optional string validTxnList,
    6: optional i64 materializationTime
}
{code}
4th field type changed"	HIVE	Closed	3	3	6200	pull-request-available
13517496	MV with iceberg storage format fails when contains 'PARTITIONED ON' clause due to column number/types difference.	"MV with iceberg storage format fails when contains 'PARTITIONED ON' clause due to column number/types difference.
{code:java}
!!! annotations iceberg
>>> use iceberg_test_db_hive;
No rows affected
>>> set hive.exec.max.dynamic.partitions=2000;
>>> set hive.exec.max.dynamic.partitions.pernode=2000;
>>> drop materialized view if exists mv_agg_gby_col_partitioned;
>>> create materialized view mv_agg_gby_col_partitioned PARTITIONED ON (t) stored by iceberg stored as orc tblproperties ('format-version'='1') as select b,f,sum(b), sum(f),t from all100k group by b,f,v,c,t;
>>> analyze table mv_agg_gby_col_partitioned compute statistics for columns;
>>> set hive.explain.user=false;

>>> explain select b,f,sum(b) from all100k where t=93 group by c,v,f,b;
!!! match row_contains
          alias: iceberg_test_db_hive.mv_agg_gby_col_partitioned

>>> drop materialized view mv_agg_gby_col_partitioned;
 {code}
Error
{code:java}
2023-01-10T20:31:17,514 INFO  [pool-5-thread-1] jdbc.TestDriver: Query: create materialized view mv_agg_gby_col_partitioned PARTITIONED ON (t) stored by iceberg stored as orc tblproperties ('format-version'='1') as select b,f,sum(b), sum(f),t from all100k group by b,f,v,c,t
2023-01-10T20:31:18,099 INFO  [Thread-21] jdbc.TestDriver: INFO  : Compiling command(queryId=hive_20230110203117_6c333b6a-1642-40e7-80bc-e78dede47980): create materialized view mv_agg_gby_col_partitioned PARTITIONED ON (t) stored by iceberg stored as orc tblproperties ('format-version'='1') as select b,f,sum(b), sum(f),t from all100k group by b,f,v,c,t
2023-01-10T20:31:18,100 INFO  [Thread-21] jdbc.TestDriver: INFO  : No Stats for iceberg_test_db_hive@all100k, Columns: b, c, t, f, v
2023-01-10T20:31:18,100 INFO  [Thread-21] jdbc.TestDriver: ERROR : FAILED: SemanticException Line 0:-1 Cannot insert into target table because column number/types are different 'TOK_TMP_FILE': Table insclause-0 has 6 columns, but query has 5 columns.
2023-01-10T20:31:18,100 INFO  [Thread-21] jdbc.TestDriver: org.apache.hadoop.hive.ql.parse.SemanticException: Line 0:-1 Cannot insert into target table because column number/types are different 'TOK_TMP_FILE': Table insclause-0 has 6 columns, but query has 5 columns.
2023-01-10T20:31:18,100 INFO  [Thread-21] jdbc.TestDriver:     at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genConversionSelectOperator(SemanticAnalyzer.java:8905)
2023-01-10T20:31:18,100 INFO  [Thread-21] jdbc.TestDriver:     at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genFileSinkPlan(SemanticAnalyzer.java:8114)
2023-01-10T20:31:18,100 INFO  [Thread-21] jdbc.TestDriver:     at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPostGroupByBodyPlan(SemanticAnalyzer.java:11583)
2023-01-10T20:31:18,100 INFO  [Thread-21] jdbc.TestDriver:     at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBodyPlan(SemanticAnalyzer.java:11455)
2023-01-10T20:31:18,100 INFO  [Thread-21] jdbc.TestDriver:     at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:12424)
2023-01-10T20:31:18,100 INFO  [Thread-21] jdbc.TestDriver:     at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:12290)
2023-01-10T20:31:18,100 INFO  [Thread-21] jdbc.TestDriver:     at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genOPTree(SemanticAnalyzer.java:13038)
2023-01-10T20:31:18,100 INFO  [Thread-21] jdbc.TestDriver:     at org.apache.hadoop.hive.ql.parse.CalcitePlanner.genOPTree(CalcitePlanner.java:756)
2023-01-10T20:31:18,100 INFO  [Thread-21] jdbc.TestDriver:     at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:13154)
2023-01-10T20:31:18,100 INFO  [Thread-21] jdbc.TestDriver:     at org.apache.hadoop.hive.ql.parse.CalcitePlanner.analyzeInternal(CalcitePlanner.java:472)
2023-01-10T20:31:18,100 INFO  [Thread-21] jdbc.TestDriver:     at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:313)
2023-01-10T20:31:18,100 INFO  [Thread-21] jdbc.TestDriver:     at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:222)
2023-01-10T20:31:18,100 INFO  [Thread-21] jdbc.TestDriver:     at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:105)
2023-01-10T20:31:18,100 INFO  [Thread-21] jdbc.TestDriver:     at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:201)
2023-01-10T20:31:18,100 INFO  [Thread-21] jdbc.TestDriver:     at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:657)
2023-01-10T20:31:18,100 INFO  [Thread-21] jdbc.TestDriver:     at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:603)
2023-01-10T20:31:18,101 INFO  [Thread-21] jdbc.TestDriver:     at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:597)
2023-01-10T20:31:18,101 INFO  [Thread-21] jdbc.TestDriver:     at org.apache.hadoop.hive.ql.reexec.ReExecDriver.compileAndRespond(ReExecDriver.java:127)
2023-01-10T20:31:18,101 INFO  [Thread-21] jdbc.TestDriver:     at org.apache.hive.service.cli.operation.SQLOperation.prepare(SQLOperation.java:206)
2023-01-10T20:31:18,101 INFO  [Thread-21] jdbc.TestDriver:     at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:336)
2023-01-10T20:31:18,101 INFO  [Thread-21] jdbc.TestDriver:     at java.base/java.security.AccessController.doPrivileged(Native Method)
2023-01-10T20:31:18,101 INFO  [Thread-21] jdbc.TestDriver:     at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
2023-01-10T20:31:18,101 INFO  [Thread-21] jdbc.TestDriver:     at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
2023-01-10T20:31:18,101 INFO  [Thread-21] jdbc.TestDriver:     at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:358)
2023-01-10T20:31:18,101 INFO  [Thread-21] jdbc.TestDriver:     at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
2023-01-10T20:31:18,101 INFO  [Thread-21] jdbc.TestDriver:     at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
2023-01-10T20:31:18,101 INFO  [Thread-21] jdbc.TestDriver:     at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
2023-01-10T20:31:18,101 INFO  [Thread-21] jdbc.TestDriver:     at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
2023-01-10T20:31:18,101 INFO  [Thread-21] jdbc.TestDriver:     at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2023-01-10T20:31:18,101 INFO  [Thread-21] jdbc.TestDriver:     at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2023-01-10T20:31:18,101 INFO  [Thread-21] jdbc.TestDriver:     at java.base/java.lang.Thread.run(Thread.java:829)
2023-01-10T20:31:18,101 INFO  [Thread-21] jdbc.TestDriver:
2023-01-10T20:31:18,101 INFO  [Thread-21] jdbc.TestDriver: INFO  : Completed compiling command(queryId=hive_20230110203117_6c333b6a-1642-40e7-80bc-e78dede47980); Time taken: 0.526 seconds
2023-01-10T20:31:18,306 ERROR [pool-5-thread-1] jdbc.TestDriver: Error while compiling statement: FAILED: SemanticException Line 0:-1 Cannot insert into target table because column number/types are different 'TOK_TMP_FILE': Table insclause-0 has 6 columns, but query has 5 columns. {code}
Similar query works for Hive native materialized views."	HIVE	Resolved	2	1	6200	pull-request-available
13312999	Rewrite plan to join back tables: support function calls in project	"{code}
select
    c_first_name || ' ' || c_last_name,
    (ss_quantity * ss_list_price) * (1.0 - c_discount),
    c_customer_sk,
    ss_customer_sk
from store_sales ss
join customer c on ss_customer_sk = c_customer_sk;
{code}"	HIVE	Resolved	3	4	6200	pull-request-available
13404036	Replace clob with varchar when storing creation metadata	"Follow up of HIVE-21940.
{code}
<class name=""MCreationMetadata"" identity-type=""datastore"" table=""MV_CREATION_METADATA"" detachable=""true"">
...
      <field name=""txnList"">
        <column name=""TXN_LIST"" jdbc-type=""CLOB"" allows-null=""true""/>
      </field>
{code}"	HIVE	Resolved	3	1	6200	pull-request-available
13388426	Map partition key columns when pushing TNK op through select	"The following TPC-DS query fails at runtime when the table {{store_sales}} is an external JDBC table.

{code:sql}
SELECT ranking
FROM
    (SELECT rank() OVER (PARTITION BY ss_store_sk
        ORDER BY sum(ss_net_profit)) AS ranking
     FROM store_sales
     GROUP BY ss_store_sk) tmp1
WHERE ranking <= 5
{code}

The stacktrace below shows that problem occurs while trying to initialize the {{TopNKeyOperator}}.

{noformat}
2021-07-08T09:04:37,444 ERROR [TezTR-270335_1_3_0_0_0] tez.TezProcessor: Failed initializeAndRunProcessor
java.lang.RuntimeException: Map operator initialization failed
        at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.init(MapRecordProcessor.java:351) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:310) [hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:277) [hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
        at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:381) [tez-runtime-internals-0.10.0.jar:0.10.0]
        at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:75) [tez-runtime-internals-0.10.0.jar:0.10.0]
        at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:62) [tez-runtime-internals-0.10.0.jar:0.10.0]
        at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_261]
        at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_261]
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682) [hadoop-common-3.1.0.jar:?]
        at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:62) [tez-runtime-internals-0.10.0.jar:0.10.0]
        at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:38) [tez-runtime-internals-0.10.0.jar:0.10.0]
        at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36) [tez-common-0.10.0.jar:0.10.0]
        at org.apache.hadoop.hive.llap.daemon.impl.StatsRecordingThreadPool$WrappedCallable.call(StatsRecordingThreadPool.java:118) [hive-llap-server-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
        at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_261]
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_261]
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_261]
        at java.lang.Thread.run(Thread.java:748) [?:1.8.0_261]
Caused by: java.lang.RuntimeException: cannot find field _col0 from [0:ss_store_sk, 1:$f1]
        at org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorUtils.getStandardStructFieldRef(ObjectInspectorUtils.java:550) ~[hive-serde-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.serde2.objectinspector.StandardStructObjectInspector.getStructFieldRef(StandardStructObjectInspector.java:153) ~[hive-serde-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.exec.ExprNodeColumnEvaluator.initialize(ExprNodeColumnEvaluator.java:56) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.exec.TopNKeyOperator.initObjectInspectors(TopNKeyOperator.java:101) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.exec.TopNKeyOperator.initializeOp(TopNKeyOperator.java:82) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:360) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:549) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.exec.Operator.initializeChildren(Operator.java:503) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:369) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.exec.MapOperator.initializeMapOperator(MapOperator.java:506) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.init(MapRecordProcessor.java:314) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
        ... 16 more
{noformat}


"	HIVE	Resolved	3	1	6200	pull-request-available
13404537	SQL: Implement HAVING/QUALIFY predicates for ROW_NUMBER()=1	"The insert queries which use a row_num()=1 function are inconvenient to write or port from an existing workload, because there is no easy way to ignore a column in this pattern.

{code}
INSERT INTO main_table 
SELECT * from duplicated_table
QUALIFY ROW_NUMER() OVER (PARTITION BY event_id) = 1;
{code}

needs to be rewritten into

{code}
INSERT INTO main_table
select event_id, event_ts, event_attribute, event_metric1, event_metric2, event_metric3, event_metric4, .., event_metric43 from 
(select *, ROW_NUMBER() OVER (PARTITION BY event_id) as rnum from duplicated_table)
where rnum=1;
{code}

This is a time-consuming and error-prone rewrite (dealing with a messed up order of columns between one source and dest table).

An alternate rewrite would be to do the same or similar syntax using HAVING. 

{code}
INSERT INTO main_table 
SELECT * from duplicated_table
HAVING ROW_NUMER() OVER (PARTITION BY event_id) = 1;
{code}
"	HIVE	Resolved	3	4	6200	pull-request-available
13352499	QueryResultCache parses the query twice	"Query result cache lookup results by query text which has fully resolved table references.
In order to generate this query text currently implementation 
* transforms the AST tree back to String
* parses the String generated in above step
* traverse the new AST and replaces the table references to the fully qualified ones
* transforms the new AST tree back to String -> this will be the cache key
"	HIVE	Resolved	4	4	6200	pull-request-available
13273795	Hive allows to create a struct with duplicate attribute names	"When you create at table with a struct with twice the same attribute name, hive allow you to create it.
create table test_struct( duplicateColumn struct<id:int, id:int>);
You can insert data into it :
insert into test_struct select named_struct(""id"",1,""id"",1);

But you can not read it :
select * from test_struct;
Return : java.io.IOException: java.io.IOException: Error reading file: hdfs://.../test_struct/delta_0000001_0000001_0000/bucket_00000 ,

We can create and insert. but fail on read the Struct part of the tables. We can still read all other columns (if we have more than one) but not the struct anymore."	HIVE	Closed	3	1	6200	pull-request-available
13471141	Iceberg integration: Implement merge into iceberg table	"{code}
create external table target_ice(a int, b string, c int) partitioned by spec (bucket(16, a), truncate(3, b)) stored by iceberg stored as orc tblproperties ('format-version'='2');
create table source(a int, b string, c int);

...

merge into target_ice as t using source src ON t.a = src.a
when matched and t.a > 100 THEN DELETE
when matched then update set b = 'Merged', c = t.c + 10
when not matched then insert values (src.a, src.b, src.c);

{code}"	HIVE	Closed	3	4	6200	pull-request-available
13305734	Rewrite plan to join back tables with many projected columns joined multiple times	"Queries with a pattern where one or more tables joins with a fact table in a CTE. Many columns are projected out those tables and then grouped in the CTE.  The main query joins multiple instances of the CTE and may project a subset of these.

The optimization is to rewrite the CTE to include only key (PK, non null Unique Key) columns and join the tables back to the resultset of the main query to fetch the rest of the wide columns. This reduces the datasize of the joined back tables that is broadcast/shuffled throughout the DAG processing.

Example query, tpc-ds query4
{code}
with year_total as (
 select c_customer_id customer_id
       ,c_first_name customer_first_name
       ,c_last_name customer_last_name
       ,c_preferred_cust_flag customer_preferred_cust_flag
       ,c_birth_country customer_birth_country
       ,c_login customer_login
       ,c_email_address customer_email_address
       ,d_year dyear
       ,sum(((ss_ext_list_price-ss_ext_wholesale_cost-ss_ext_discount_amt)+ss_ext_sales_price)/2) year_total
       ,'s' sale_type
 from customer
     ,store_sales
     ,date_dim
 where c_customer_sk = ss_customer_sk
   and ss_sold_date_sk = d_date_sk
 group by c_customer_id
         ,c_first_name
         ,c_last_name
         ,c_preferred_cust_flag
         ,c_birth_country
         ,c_login
         ,c_email_address
         ,d_year
 union all
 select c_customer_id customer_id
       ,c_first_name customer_first_name
       ,c_last_name customer_last_name
       ,c_preferred_cust_flag customer_preferred_cust_flag
       ,c_birth_country customer_birth_country
       ,c_login customer_login
       ,c_email_address customer_email_address
       ,d_year dyear
       ,sum((((cs_ext_list_price-cs_ext_wholesale_cost-cs_ext_discount_amt)+cs_ext_sales_price)/2) ) year_total
       ,'c' sale_type
 from customer
     ,catalog_sales
     ,date_dim
 where c_customer_sk = cs_bill_customer_sk
   and cs_sold_date_sk = d_date_sk
 group by c_customer_id
         ,c_first_name
         ,c_last_name
         ,c_preferred_cust_flag
         ,c_birth_country
         ,c_login
         ,c_email_address
         ,d_year
union all
 select c_customer_id customer_id
       ,c_first_name customer_first_name
       ,c_last_name customer_last_name
       ,c_preferred_cust_flag customer_preferred_cust_flag
       ,c_birth_country customer_birth_country
       ,c_login customer_login
       ,c_email_address customer_email_address
       ,d_year dyear
       ,sum((((ws_ext_list_price-ws_ext_wholesale_cost-ws_ext_discount_amt)+ws_ext_sales_price)/2) ) year_total
       ,'w' sale_type
 from customer
     ,web_sales
     ,date_dim
 where c_customer_sk = ws_bill_customer_sk
   and ws_sold_date_sk = d_date_sk
 group by c_customer_id
         ,c_first_name
         ,c_last_name
         ,c_preferred_cust_flag
         ,c_birth_country
         ,c_login
         ,c_email_address
         ,d_year
         )
  select  
                  t_s_secyear.customer_id
                 ,t_s_secyear.customer_first_name
                 ,t_s_secyear.customer_last_name
                 ,t_s_secyear.customer_birth_country
 from year_total t_s_firstyear
     ,year_total t_s_secyear
     ,year_total t_c_firstyear
     ,year_total t_c_secyear
     ,year_total t_w_firstyear
     ,year_total t_w_secyear
 where t_s_secyear.customer_id = t_s_firstyear.customer_id
   and t_s_firstyear.customer_id = t_c_secyear.customer_id
   and t_s_firstyear.customer_id = t_c_firstyear.customer_id
   and t_s_firstyear.customer_id = t_w_firstyear.customer_id
   and t_s_firstyear.customer_id = t_w_secyear.customer_id
   and t_s_firstyear.sale_type = 's'
   and t_c_firstyear.sale_type = 'c'
   and t_w_firstyear.sale_type = 'w'
   and t_s_secyear.sale_type = 's'
   and t_c_secyear.sale_type = 'c'
   and t_w_secyear.sale_type = 'w'
   and t_s_firstyear.dyear =  1999
   and t_s_secyear.dyear = 1999+1
   and t_c_firstyear.dyear =  1999
   and t_c_secyear.dyear =  1999+1
   and t_w_firstyear.dyear = 1999
   and t_w_secyear.dyear = 1999+1
   and t_s_firstyear.year_total > 0
   and t_c_firstyear.year_total > 0
   and t_w_firstyear.year_total > 0
   and case when t_c_firstyear.year_total > 0 then t_c_secyear.year_total / t_c_firstyear.year_total else null end
           > case when t_s_firstyear.year_total > 0 then t_s_secyear.year_total / t_s_firstyear.year_total else null end
   and case when t_c_firstyear.year_total > 0 then t_c_secyear.year_total / t_c_firstyear.year_total else null end
           > case when t_w_firstyear.year_total > 0 then t_w_secyear.year_total / t_w_firstyear.year_total else null end
 order by t_s_secyear.customer_id
         ,t_s_secyear.customer_first_name
         ,t_s_secyear.customer_last_name
         ,t_s_secyear.customer_birth_country
limit 100;
{code}"	HIVE	Resolved	3	2	6200	pull-request-available
13532326	Support array type when query does not produce any rows	"{code}
CREATE TABLE T1 (c1 int, c2 array<int>);
CREATE TABLE T2 AS SELECT * FROM T1 LIMIT 0;
describe formatted t2;
{code}

The new {{t2}} table schema should be
{code}
POSTHOOK: Input: default@t2
# col_name            	data_type           	comment             
c1                  	int                 	                    
c2                  	array<int>          	                    
{code}"	HIVE	Resolved	3	4	6200	pull-request-available
13418029	Values query with order by position clause fails	"{code}
values(1+1, 2, 5.0, 'a') order by 1 limit 2;
{code}
{code}
java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner$CalcitePlannerAction.getFieldIndexFromColumnNumber(CalcitePlanner.java:4146)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner$CalcitePlannerAction.beginGenOBLogicalPlan(CalcitePlanner.java:4028)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner$CalcitePlannerAction.genOBLogicalPlan(CalcitePlanner.java:3933)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner$CalcitePlannerAction.genLogicalPlan(CalcitePlanner.java:5148)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner$CalcitePlannerAction.apply(CalcitePlanner.java:1651)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner$CalcitePlannerAction.apply(CalcitePlanner.java:1593)
	at org.apache.calcite.tools.Frameworks.lambda$withPlanner$0(Frameworks.java:131)
	at org.apache.calcite.prepare.CalcitePrepareImpl.perform(CalcitePrepareImpl.java:914)
	at org.apache.calcite.tools.Frameworks.withPrepare(Frameworks.java:180)
	at org.apache.calcite.tools.Frameworks.withPlanner(Frameworks.java:126)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.logicalPlan(CalcitePlanner.java:1345)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.genOPTree(CalcitePlanner.java:563)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12565)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.analyzeInternal(CalcitePlanner.java:456)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:317)
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223)
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:105)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:500)
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:453)
	at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:417)
	at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:411)
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.compileAndRespond(ReExecDriver.java:125)
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:229)
	at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:256)
	at org.apache.hadoop.hive.cli.CliDriver.processCmd1(CliDriver.java:201)
	at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:127)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:422)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:353)
	at org.apache.hadoop.hive.ql.QTestUtil.executeClientInternal(QTestUtil.java:726)
	at org.apache.hadoop.hive.ql.QTestUtil.executeClient(QTestUtil.java:696)
	at org.apache.hadoop.hive.cli.control.CoreCliDriver.runTest(CoreCliDriver.java:114)
	at org.apache.hadoop.hive.cli.control.CliAdapter.runTest(CliAdapter.java:157)
	at org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver(TestMiniLlapLocalCliDriver.java:62)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.apache.hadoop.hive.cli.control.CliAdapter$2$1.evaluate(CliAdapter.java:135)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.apache.hadoop.hive.cli.control.CliAdapter$1$1.evaluate(CliAdapter.java:95)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
{code}"	HIVE	Resolved	3	1	6200	pull-request-available
13534474	NPE when generating incremental rebuild plan of materialized view with empty Iceberg source table	"{code}
set hive.support.concurrency=true;
set hive.txn.manager=org.apache.hadoop.hive.ql.lockmgr.DbTxnManager;

create external table tbl_ice(a int, b string, c int) stored by iceberg stored as orc tblproperties ('format-version'='1');
create external table tbl_ice_v2(d int, e string, f int) stored by iceberg stored as orc tblproperties ('format-version'='2');

insert into tbl_ice_v2 values (1, 'one v2', 50), (4, 'four v2', 53), (5, 'five v2', 54);

create materialized view mat1 as
select tbl_ice.b, tbl_ice.c, tbl_ice_v2.e from tbl_ice join tbl_ice_v2 on tbl_ice.a=tbl_ice_v2.d where tbl_ice.c > 52;

-- insert some new values to one of the source tables
insert into tbl_ice values (1, 'one', 50), (2, 'two', 51), (3, 'three', 52), (4, 'four', 53), (5, 'five', 54);

alter materialized view mat1 rebuild;
{code}
{code}
2023-04-28T07:34:17,949  WARN [1fb94a8e-8d75-4a1f-8f44-a5beaa8aafb6 Listener at 0.0.0.0/36857] rebuild.AlterMaterializedViewRebuildAnalyzer: Exception loading materialized views
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.metadata.Hive.getValidMaterializedViews(Hive.java:2298) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.metadata.Hive.getMaterializedViewForRebuild(Hive.java:2204) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.ddl.view.materialized.alter.rebuild.AlterMaterializedViewRebuildAnalyzer$MVRebuildCalcitePlannerAction.applyMaterializedViewRewriting(AlterMaterializedViewRebuildAnalyzer.java:215) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner$CalcitePlannerAction.apply(CalcitePlanner.java:1722) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner$CalcitePlannerAction.apply(CalcitePlanner.java:1591) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.calcite.tools.Frameworks.lambda$withPlanner$0(Frameworks.java:131) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.calcite.prepare.CalcitePrepareImpl.perform(CalcitePrepareImpl.java:914) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.calcite.tools.Frameworks.withPrepare(Frameworks.java:180) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.calcite.tools.Frameworks.withPlanner(Frameworks.java:126) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.logicalPlan(CalcitePlanner.java:1343) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.genOPTree(CalcitePlanner.java:570) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12824) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.analyzeInternal(CalcitePlanner.java:465) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.ddl.view.materialized.alter.rebuild.AlterMaterializedViewRebuildAnalyzer.analyzeInternal(AlterMaterializedViewRebuildAnalyzer.java:135) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:326) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.ExplainSemanticAnalyzer.analyzeInternal(ExplainSemanticAnalyzer.java:180) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:326) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:224) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:107) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:519) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:471) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:436) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:430) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.compileAndRespond(ReExecDriver.java:121) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:227) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:257) ~[hive-cli-4.0.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.hive.cli.CliDriver.processCmd1(CliDriver.java:201) ~[hive-cli-4.0.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:127) ~[hive-cli-4.0.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:425) ~[hive-cli-4.0.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:356) ~[hive-cli-4.0.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.hive.ql.QTestUtil.executeClientInternal(QTestUtil.java:733) ~[hive-it-util-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.QTestUtil.executeClient(QTestUtil.java:703) ~[hive-it-util-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.cli.control.CoreCliDriver.runTest(CoreCliDriver.java:115) ~[hive-it-util-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.cli.control.CliAdapter.runTest(CliAdapter.java:157) ~[hive-it-util-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.cli.TestIcebergLlapLocalCliDriver.testCliDriver(TestIcebergLlapLocalCliDriver.java:60) ~[test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_301]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_301]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_301]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_301]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) ~[junit-4.13.2.jar:4.13.2]
	at org.apache.hadoop.hive.cli.control.CliAdapter$2$1.evaluate(CliAdapter.java:135) ~[hive-it-util-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.Suite.runChild(Suite.java:128) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.Suite.runChild(Suite.java:27) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) ~[junit-4.13.2.jar:4.13.2]
	at org.apache.hadoop.hive.cli.control.CliAdapter$1$1.evaluate(CliAdapter.java:95) ~[hive-it-util-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.junit.rules.RunRules.evaluate(RunRules.java:20) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) ~[junit-4.13.2.jar:4.13.2]
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
Caused by: java.lang.NullPointerException
	at org.apache.iceberg.mr.hive.HiveIcebergStorageHandler.hasAppendsOnly(HiveIcebergStorageHandler.java:1303) ~[hive-iceberg-handler-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.metadata.Hive.getMaterializationInvalidationInfo(Hive.java:2151) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.metadata.Hive.getValidMaterializedViews(Hive.java:2247) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	... 73 more
{code}"	HIVE	Resolved	3	7	6200	pull-request-available
13555828	Iceberg integration: enable copy on write update when split update is on	"Currently {{hive.split.update}} has to be set to {{false}} if a copy-on-write update should be executed when updating an Iceberg table.


[https://github.com/apache/hive/blob/0233dcc7f1f09198c093cb4b69bd2b2598c97303/iceberg/iceberg-handler/src/test/queries/positive/update_iceberg_copy_on_write_unpartitioned.q#L1]

[https://github.com/apache/hive/blob/0233dcc7f1f09198c093cb4b69bd2b2598c97303/ql/src/java/org/apache/hadoop/hive/ql/parse/UpdateDeleteSemanticAnalyzer.java#L78-L81]

 

Copy-on-write mode should be independent from split update because split update uses positional delete."	HIVE	Closed	3	4	6200	pull-request-available
13303470	SharedWorkOptimizer should check nullSortOrders when comparing ReduceSink operators	"SharedWorkOptimizer does not checks null sort order in ReduceSinkDesc when compares ReduceSink operators:
 [https://github.com/apache/hive/blob/ca9aba606c4d09b91ee28bf9ee1ae918db8cdfb9/ql/src/java/org/apache/hadoop/hive/ql/optimizer/SharedWorkOptimizer.java#L1444]
{code:java}
      ReduceSinkDesc op1Conf = ((ReduceSinkOperator) op1).getConf();
      ReduceSinkDesc op2Conf = ((ReduceSinkOperator) op2).getConf();

      if (StringUtils.equals(op1Conf.getKeyColString(), op2Conf.getKeyColString()) &&
        StringUtils.equals(op1Conf.getValueColsString(), op2Conf.getValueColsString()) &&
        StringUtils.equals(op1Conf.getParitionColsString(), op2Conf.getParitionColsString()) &&
        op1Conf.getTag() == op2Conf.getTag() &&
        StringUtils.equals(op1Conf.getOrder(), op2Conf.getOrder()) &&
        op1Conf.getTopN() == op2Conf.getTopN() &&
        canDeduplicateReduceTraits(op1Conf, op2Conf)) {
        return true;
      } else {
        return false;
      }
{code}
An expression like
{code:java}
        StringUtils.equals(op1Conf.getNullOrder(), op2Conf.getNullOrder()) &&
{code}
should be added.

 "	HIVE	Resolved	3	1	6200	pull-request-available
13529461	MetaException when executing CTAS query in Druid storage handler	"Any kind of CTAS query targeting the Druid storage handler fails with the following exception:
{noformat}
org.apache.hadoop.hive.ql.metadata.HiveException: MetaException(message:LOCATION may not be specified for Druid)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:1347) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:1352) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.ddl.table.create.CreateTableOperation.createTableNonReplaceMode(CreateTableOperation.java:158) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.ddl.table.create.CreateTableOperation.execute(CreateTableOperation.java:116) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.ddl.DDLTask.execute(DDLTask.java:84) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:214) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:105) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Executor.launchTask(Executor.java:354) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Executor.launchTasks(Executor.java:327) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Executor.runTasks(Executor.java:244) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Executor.execute(Executor.java:105) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:367) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:205) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:154) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:149) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:185) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:228) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:257) ~[hive-cli-4.0.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.hive.cli.CliDriver.processCmd1(CliDriver.java:201) ~[hive-cli-4.0.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:127) ~[hive-cli-4.0.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:425) ~[hive-cli-4.0.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:356) ~[hive-cli-4.0.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.hive.ql.dataset.QTestDatasetHandler.initDataset(QTestDatasetHandler.java:86) ~[hive-it-util-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.dataset.QTestDatasetHandler.beforeTest(QTestDatasetHandler.java:190) ~[hive-it-util-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.qoption.QTestOptionDispatcher.beforeTest(QTestOptionDispatcher.java:79) ~[hive-it-util-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.QTestUtil.cliInit(QTestUtil.java:607) ~[hive-it-util-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.cli.control.CoreCliDriver.runTest(CoreCliDriver.java:112) ~[hive-it-util-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.cli.control.CliAdapter.runTest(CliAdapter.java:157) ~[hive-it-util-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.cli.TestMiniDruidCliDriver.testCliDriver(TestMiniDruidCliDriver.java:60) ~[test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_261]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_261]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_261]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_261]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) ~[junit-4.13.2.jar:4.13.2]
	at org.apache.hadoop.hive.cli.control.CliAdapter$2$1.evaluate(CliAdapter.java:135) ~[hive-it-util-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.Suite.runChild(Suite.java:128) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.Suite.runChild(Suite.java:27) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) ~[junit-4.13.2.jar:4.13.2]
	at org.apache.hadoop.hive.cli.control.CliAdapter$1$1.evaluate(CliAdapter.java:95) ~[hive-it-util-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.junit.rules.RunRules.evaluate(RunRules.java:20) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) ~[junit-4.13.2.jar:4.13.2]
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
Caused by: org.apache.hadoop.hive.metastore.api.MetaException: LOCATION may not be specified for Druid
	at org.apache.hadoop.hive.druid.DruidStorageHandler.preCreateTable(DruidStorageHandler.java:219) ~[hive-druid-handler-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:1459) ~[hive-standalone-metastore-common-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:1435) ~[hive-standalone-metastore-common-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:1426) ~[hive-standalone-metastore-common-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_261]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_261]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_261]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_261]
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:218) ~[hive-standalone-metastore-common-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at com.sun.proxy.$Proxy133.createTable(Unknown Source) ~[?:?]
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:1336) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	... 67 more
{noformat}

One way of reproducing the problem is by removing the {{@Ignore}} annotation from {{TestMiniDruidCliDriver}} and running:

{noformat}
mvn test -Dtest=TestMiniDruidCliDriver -Dqfile=druidmini_expressions.q
{noformat}

The druidmini_expressions.q file has {{druid_table_alltypesorc}} dataset and the latter is initialized with the CTAS query outlined below:

{code:sql}
CREATE EXTERNAL TABLE druid_table_alltypesorc
STORED BY 'org.apache.hadoop.hive.druid.DruidStorageHandler'
TBLPROPERTIES (""druid.segment.granularity"" = ""HOUR"", ""druid.query.granularity"" = ""MINUTE"")
AS
SELECT cast (`ctimestamp1` as timestamp with local time zone) as `__time`,
  cstring1,
  cstring2,
  cdouble,
  cfloat,
  ctinyint,
  csmallint,
  cint,
  cbigint,
  cboolean1,
  cboolean2,
  cast(cint as string) as cintstring,
  cast(cfloat as string) as cfloatstring,
  cast(cdouble as string) as cdoublestring
  FROM alltypesorc1 where ctimestamp1 IS NOT NULL;
{code}

This is a regression caused by HIVE-26771 that is likely to affect other storage handlers as well.
"	HIVE	Closed	2	1	6200	pull-request-available
13375747	Number of reducers limited to fixed 1 when updating/deleting	"When updating/deleting bucketed tables an extra ReduceSink operator is created to enforce bucketing. After HIVE-22538 number of reducers limited to fixed 1 in these RS operators.

This can lead to performance degradation.

Prior HIVE-22538 multiple reducers was available such cases. The reason for limiting the number of reducers is to ensure RowId ascending order in delete delta files produced by the update/delete statements.

This is the plan of delete statement like:

{code}
DELETE FROM t1 WHERE a = 1;
{code}
{code}
TS[0]-FIL[8]-SEL[2]-RS[3]-SEL[4]-RS[5]-SEL[6]-FS[7]
{code}

RowId order is ensured by RS[3] and bucketing is enforced by RS[5]: number of reducers were limited to bucket number in the table or hive.exec.reducers.max. However RS[5] does not provide any ordering so above plan may generate unsorted deleted deltas which leads to corrupted data reads.

Prior HIVE-22538 these RS operators were merged by ReduceSinkDeduplication and the resulting RS kept the ordering and enabled multiple reducers. It could do because ReduceSinkDeduplication was prepared for ACID writes. This was removed by HIVE-22538 to get a more generic ReduceSinkDeduplication.
"	HIVE	Resolved	3	1	6200	pull-request-available
13478652	Implement MV maintenance with Iceberg sources using full rebuild	"{code}
set hive.support.concurrency=true;
set hive.txn.manager=org.apache.hadoop.hive.ql.lockmgr.DbTxnManager;

create external table tbl_ice(a int, b string, c int) stored by iceberg stored as orc tblproperties ('format-version'='2');

insert into tbl_ice values (1, 'one', 50), (2, 'two', 51), (3, 'three', 52), (4, 'four', 53), (5, 'five', 54);

create materialized view mat1 as
select b, c from tbl_ice where c > 52;

insert into tbl_ice values (111, 'one', 55), (333, 'two', 56);

explain cbo
alter materialized view mat1 rebuild;

alter materialized view mat1 rebuild;
{code}
MV full rebuild plan
{code}
CBO PLAN:
HiveProject(b=[$1], c=[$2])
  HiveFilter(condition=[>($2, 52)])
    HiveTableScan(table=[[default, tbl_ice]], table:alias=[tbl_ice])
{code}"	HIVE	Resolved	3	7	6200	pull-request-available
13366315	Adding Respect/Ignore nulls as a UDAF parameter is ambiguous	"Both function calls translated to the same UDAF call:
{code}
SELECT lead(a, 2, true) ...
SELECT lead(a, 2) IGNORE NULLS ...
{code}
IGNORE NULLS is passed as an extra constant boolean parameter to the UDAF
https://github.com/apache/hive/blob/eed78dfdcb6dfc2de400397a60de12e6f62b96e2/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/ASTConverter.java#L743

However the semantics of the two function calls has different semantics:
* *lead(a, 2, true)* - 'true' is the default value: ""The value of DEFAULT is returned as the result if there is no row corresponding to the OFFSET number of rows before R within P (for the lag function) or after R within P (for the lead function)""
* *lead(a, 2) IGNORE NULLS* - For each row in the current window find the 2nd not-NULL value starting directly after the current row. "	HIVE	Closed	3	1	6200	pull-request-available
13345276	Optimize MV: Materialized views should not rebuild when tables are not modified	"e.g
{noformat}
create materialized view c_c_address as 
select c_customer_sk from customer c, customer_address ca where c_current_addr_sk = ca.ca_address_id;

ALTER MATERIALIZED VIEW c_c_address REBUILD; <-- This shouldn't trigger rebuild, when source tables are not modified

 {noformat}"	HIVE	Resolved	3	7	6200	pull-request-available
13311865	Fix nulls first sorting behavior	"{code}
INSERT INTO t(a) VALUES (1), (null), (3), (2), (2), (2);

select a from t order by a desc;
{code}
instead of 
{code}
3, 2, 2, 2, 1, null
{code}
should return 
{code}
null, 3, 2 ,2 ,2, 1
{code}"	HIVE	Closed	3	1	6200	pull-request-available
13560157	Incremental rebuild goes wrong when inserts and deletes overlap between the source tables	"h1. Summary

The incremental rebuild plan and execution output are incorrect when one side of the table join has inserted/deleted join keys that the other side has deleted/inserted (note the order).

The argument is that tuples that have never been present simultaneously should not interact with one another, i.e., one's inserts should not join the other's deletes.
h1. Related Test Case

The bug was discovered during replication of the test case:

??hive/ql/src/test/queries/clientpositive/materialized_view_create_rewrite_5.q??
h1. Steps to Reproduce the Issue
 # Configurations:
{code:sql}
SET hive.vectorized.execution.enabled=false;
set hive.support.concurrency=true;
set hive.txn.manager=org.apache.hadoop.hive.ql.lockmgr.DbTxnManager;
set hive.strict.checks.cartesian.product=false;
set hive.materializedview.rewriting=true;{code}
 # 
{code:sql}
create table cmv_basetable_n6 (a int, b varchar(256), c decimal(10,2), d int) stored as orc TBLPROPERTIES ('transactional'='true'); {code}
 # 
{code:sql}
insert into cmv_basetable_n6 values
(1, 'alfred', 10.30, 2),
(1, 'charlie', 20.30, 2); {code}
 # 
{code:sql}
create table cmv_basetable_2_n3 (a int, b varchar(256), c decimal(10,2), d int) stored as orc TBLPROPERTIES ('transactional'='true'); {code}
 # 
{code:sql}
insert into cmv_basetable_2_n3 values
(1, 'bob', 30.30, 2),
(1, 'bonnie', 40.30, 2);{code}
 # 
{code:sql}
CREATE MATERIALIZED VIEW cmv_mat_view_n6 TBLPROPERTIES ('transactional'='true') AS
SELECT cmv_basetable_n6.a, cmv_basetable_2_n3.c
FROM cmv_basetable_n6 JOIN cmv_basetable_2_n3 ON (cmv_basetable_n6.a = cmv_basetable_2_n3.a)
WHERE cmv_basetable_2_n3.c > 10.0;{code}
 # 
{code:sql}
show tables; {code}
!截图.PNG!
 # Select tuples, including deletion and with VirtualColumn's, from the MV and source tables. We see that the MV is correctly built upon creation:
{code:sql}
SELECT ROW__IS__DELETED, ROW__ID, * FROM cmv_mat_view_n6('acid.fetch.deleted.rows'='true');{code}
!截图1.PNG!
 # 
{code:sql}
SELECT ROW__IS__DELETED, ROW__ID, * FROM cmv_basetable_n6('acid.fetch.deleted.rows'='true'); {code}
!截图2.PNG!
 # 
{code:sql}
SELECT ROW__IS__DELETED, ROW__ID, * FROM cmv_basetable_2_n3('acid.fetch.deleted.rows'='true'); {code}
!截图3.PNG!
 # Now make an insert to the LHS and a delete to the RHS source table:
{code:sql}
insert into cmv_basetable_n6 values
(1, 'kevin', 50.30, 2);

DELETE FROM cmv_basetable_2_n3 WHERE b = 'bonnie';{code}
 # Select again to see what happened:
{code:sql}
SELECT ROW__IS__DELETED, ROW__ID, * FROM cmv_basetable_n6('acid.fetch.deleted.rows'='true'); {code}
!截图4.PNG!
 # 
{code:sql}
SELECT ROW__IS__DELETED, ROW__ID, * FROM cmv_basetable_2_n3('acid.fetch.deleted.rows'='true'); {code}
!截图5.PNG!
 # Use {{EXPLAIN CBO}} to produce the incremental rebuild plan for the MV, which is incorrect already:
{code:sql}
EXPLAIN CBO
ALTER MATERIALIZED VIEW cmv_mat_view_n6 REBUILD; {code}
!截图6.PNG!
 # Rebuild MV and see (incorrect) results:
{code:sql}
ALTER MATERIALIZED VIEW cmv_mat_view_n6 REBUILD;

SELECT ROW__IS__DELETED, ROW__ID, * FROM cmv_mat_view_n6('acid.fetch.deleted.rows'='true');{code}
!截图7.PNG!
 # Run MV definition directly, which outputs incorrect results because the MV is enabled for MV-based query rewrite, i.e., the following query will output what's in the MV for the time being:
{code:sql}
SELECT cmv_basetable_n6.a, cmv_basetable_2_n3.c
FROM cmv_basetable_n6 JOIN cmv_basetable_2_n3 ON (cmv_basetable_n6.a = cmv_basetable_2_n3.a)
WHERE cmv_basetable_2_n3.c > 10.0; {code}
!截图8.PNG!
 # Disable MV-based query rewrite for the MV and re-run the definition, which should give the correct results:
{code:sql}
ALTER MATERIALIZED VIEW cmv_mat_view_n6 DISABLE REWRITE;

SELECT cmv_basetable_n6.a, cmv_basetable_2_n3.c
FROM cmv_basetable_n6 JOIN cmv_basetable_2_n3 ON (cmv_basetable_n6.a = cmv_basetable_2_n3.a)
WHERE cmv_basetable_2_n3.c > 10.0;{code}
!截图9.PNG!

h1. Note

This issue is also seen in update-incurred inserts/deletes."	HIVE	Closed	2	1	6200	bug, hive, hive-4.1.0-must, known_issue, materializedviews, pull-request-available
13370273	Incremental rebuild of MV having aggregate in presence of delete operation	"Extension of HIVE-24854: handle cases when the Materialized view definition has aggregation like
{code}
CREATE MATERIALIZED VIEW cmv_mat_view_n5 DISABLE REWRITE TBLPROPERTIES ('transactional'='true') AS
  SELECT cmv_basetable_n5.a, cmv_basetable_2_n2.c, sum(cmv_basetable_2_n2.d)
  FROM cmv_basetable_n5 JOIN cmv_basetable_2_n2 ON (cmv_basetable_n5.a = cmv_basetable_2_n2.a)
  WHERE cmv_basetable_2_n2.c > 10.0
  GROUP BY cmv_basetable_n5.a, cmv_basetable_2_n2.c;

{code}"	HIVE	Resolved	3	4	6200	pull-request-available
13550668	Handle casting NULL literal to complex type	"{{NULL}} literal values of a complex type column are treated as void typed literals.
{code:java}
create table explain_npe_map    ( c1 map<string, string> );
explain select c1 from explain_npe_map where c1 is null;
{code}
[https://github.com/apache/hive/blob/88bc8269a64d31eee372bf3602933c75283c686b/ql/src/test/results/clientpositive/llap/analyze_npe.q.out#L142]

The goal of this patch is to use the original complex type:
{code:java}
          Select Operator
            expressions: Const map<string,string> null (type: map<string,string>)
{code}

Void typed {{NULL}} literals makes CTAS statements are fail since the original complex type can not be inferred.
"	HIVE	Closed	3	4	6200	pull-request-available
13520225	Deadlock when enabling/disabling Materialized view stored by Iceberg	"{code}
set hive.support.concurrency=true;
set hive.txn.manager=org.apache.hadoop.hive.ql.lockmgr.DbTxnManager;

create table all100k(
        t int,
        si int,
        i int,
        b bigint,
        f float,
        d double,
        s string,
        dc decimal(38,18),
        bo boolean,
        v string,
        c string,
        ts timestamp,
        dt date)
    partitioned by spec (BUCKET(16, t))
    stored by iceberg
    stored as parquet;

create materialized view mv_rewrite stored by iceberg as select t, si from all100k where t>115;

explain select si,t from all100k where t>116 and t<120;

alter materialized view mv_rewrite disable rewrite;
{code}"	HIVE	Resolved	3	1	6200	pull-request-available
13539607	Upgrade Antlr in hplsql to 4.9.3	"HIVE-27362 replaced Antlr3 to Antlr4 in HMS. It uses the version 4.9.3 however HPL/SQL uses 4.5.
To goal is to synchronize these."	HIVE	Resolved	3	4	6200	pull-request-available
13211976	DEFAULT keyword handling in MERGE UPDATE clause issues	"once HIVE-21159 lands, enable {{HiveConf.MERGE_SPLIT_UPDATE}} and run these tests.

TestMiniLlapLocalCliDriver.testCliDriver[sqlmerge_stats]
 mvn test -Dtest=TestMiniLlapLocalCliDriver -Dqfile=insert_into_default_keyword.q

Merge is rewritten as a multi-insert. When Update clause has DEFAULT, it's not properly replaced with a value in the muli-insert - it's treated as a literal
{noformat}
INSERT INTO `default`.`acidTable`    -- update clause(insert part)
 SELECT `t`.`key`, `DEFAULT`, `t`.`value`
   WHERE `t`.`key` = `s`.`key` AND `s`.`key` > 3 AND NOT(`s`.`key` < 3)
{noformat}
See {{LOG.info(""Going to reparse <"" + originalQuery + ""> as \n<"" + rewrittenQueryStr.toString() + "">"");}} in hive.log

{{MergeSemanticAnalyzer.replaceDefaultKeywordForMerge()}} is only called in {{handleInsert}} but not {{handleUpdate()}}. Why does issue only show up with {{MERGE_SPLIT_UPDATE}}?

Once this is fixed, HiveConf.MERGE_SPLIT_UPDATE should be true by default"	HIVE	Resolved	3	7	6200	pull-request-available
13320379	SemanticException in query 30 while generating logical plan	"Invalid table alias or column reference 'c_last_review_date' is thrown when  running TPC-DS query 30 (cbo_query30.q, query30.q) on the metastore with the partitoned TPC-DS 30TB dataset. 

The respective stacktrace is attached to this case."	HIVE	Resolved	3	1	6200	hive-4.0.1-merged, hive-4.0.1-must, pull-request-available
13391340	Handle Sum0 when rebuilding materialized view incrementally	"When rewriting MV insert overwrite plan to incremental rebuild plan a Sum0 aggregate function is used when aggregating count function subresults coming from the existing MV data and the aggregated newly inserted/deleted records since the last rebuild
{code}
create materialized view mat1 stored as orc TBLPROPERTIES ('transactional'='true') as
select t1.a, count(*) from t1
{code}
Insert overwrite plan:
{code}
HiveAggregate(group=[{0}], agg#0=[$SUM0($1)])
  HiveUnion(all=[true])
    HiveAggregate(group=[{0}], agg#0=[count()])
      HiveProject($f0=[$0])
        HiveFilter(condition=[<(2, $5.writeid)])
          HiveTableScan(table=[[default, t1]], table:alias=[t1])
    HiveTableScan(table=[[default, mat1]], table:alias=[default.mat1])
{code}
AssertionError when rewriting the plan to incremental rebuild
{code}
java.lang.AssertionError: Found an aggregation that could not be recognized: $SUM0
	at org.apache.hadoop.hive.ql.optimizer.calcite.rules.views.HiveAggregateIncrementalRewritingRuleBase.createAggregateNode(HiveAggregateIncrementalRewritingRuleBase.java:183)
	at org.apache.hadoop.hive.ql.optimizer.calcite.rules.views.HiveAggregateInsertIncrementalRewritingRule.createAggregateNode(HiveAggregateInsertIncrementalRewritingRule.java:128)
	at org.apache.hadoop.hive.ql.optimizer.calcite.rules.views.HiveAggregateIncrementalRewritingRuleBase.onMatch(HiveAggregateIncrementalRewritingRuleBase.java:138)
	at org.apache.calcite.plan.AbstractRelOptPlanner.fireRule(AbstractRelOptPlanner.java:333)
	at org.apache.calcite.plan.hep.HepPlanner.applyRule(HepPlanner.java:542)
	at org.apache.calcite.plan.hep.HepPlanner.applyRules(HepPlanner.java:407)
	at org.apache.calcite.plan.hep.HepPlanner.executeInstruction(HepPlanner.java:243)
	at org.apache.calcite.plan.hep.HepInstruction$RuleInstance.execute(HepInstruction.java:127)
	at org.apache.calcite.plan.hep.HepPlanner.executeProgram(HepPlanner.java:202)
	at org.apache.calcite.plan.hep.HepPlanner.findBestExp(HepPlanner.java:189)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner$CalcitePlannerAction.executeProgram(CalcitePlanner.java:2440)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner$CalcitePlannerAction.executeProgram(CalcitePlanner.java:2406)
	at org.apache.hadoop.hive.ql.ddl.view.materialized.alter.rebuild.AlterMaterializedViewRebuildAnalyzer$MVRebuildCalcitePlannerAction.applyIncrementalRebuild(AlterMaterializedViewRebuildAnalyzer.java:407)
	at org.apache.hadoop.hive.ql.ddl.view.materialized.alter.rebuild.AlterMaterializedViewRebuildAnalyzer$MVRebuildCalcitePlannerAction.applyAggregateInsertIncremental(AlterMaterializedViewRebuildAnalyzer.java:334)
	at org.apache.hadoop.hive.ql.ddl.view.materialized.alter.rebuild.AlterMaterializedViewRebuildAnalyzer$MVRebuildCalcitePlannerAction.applyRecordIncrementalRebuildPlan(AlterMaterializedViewRebuildAnalyzer.java:309)
	at org.apache.hadoop.hive.ql.ddl.view.materialized.alter.rebuild.AlterMaterializedViewRebuildAnalyzer$MVRebuildCalcitePlannerAction.applyMaterializedViewRewriting(AlterMaterializedViewRebuildAnalyzer.java:267)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner$CalcitePlannerAction.apply(CalcitePlanner.java:1716)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner$CalcitePlannerAction.apply(CalcitePlanner.java:1588)
	at org.apache.calcite.tools.Frameworks.lambda$withPlanner$0(Frameworks.java:131)
	at org.apache.calcite.prepare.CalcitePrepareImpl.perform(CalcitePrepareImpl.java:914)
	at org.apache.calcite.tools.Frameworks.withPrepare(Frameworks.java:180)
	at org.apache.calcite.tools.Frameworks.withPlanner(Frameworks.java:126)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.logicalPlan(CalcitePlanner.java:1340)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.genOPTree(CalcitePlanner.java:559)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12512)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.analyzeInternal(CalcitePlanner.java:452)
	at org.apache.hadoop.hive.ql.ddl.view.materialized.alter.rebuild.AlterMaterializedViewRebuildAnalyzer.analyzeInternal(AlterMaterializedViewRebuildAnalyzer.java:128)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:317)
	at org.apache.hadoop.hive.ql.parse.ExplainSemanticAnalyzer.analyzeInternal(ExplainSemanticAnalyzer.java:175)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:317)
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223)
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:105)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:500)
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:453)
	at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:417)
	at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:411)
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.compileAndRespond(ReExecDriver.java:125)
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:229)
	at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:256)
	at org.apache.hadoop.hive.cli.CliDriver.processCmd1(CliDriver.java:201)
	at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:127)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:422)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:353)
	at org.apache.hadoop.hive.ql.QTestUtil.executeClientInternal(QTestUtil.java:744)
	at org.apache.hadoop.hive.ql.QTestUtil.executeClient(QTestUtil.java:714)
	at org.apache.hadoop.hive.cli.control.CoreCliDriver.runTest(CoreCliDriver.java:170)
	at org.apache.hadoop.hive.cli.control.CliAdapter.runTest(CliAdapter.java:157)
	at org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver(TestMiniLlapLocalCliDriver.java:62)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.apache.hadoop.hive.cli.control.CliAdapter$2$1.evaluate(CliAdapter.java:135)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.apache.hadoop.hive.cli.control.CliAdapter$1$1.evaluate(CliAdapter.java:95)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
{code}"	HIVE	Resolved	3	4	6200	pull-request-available
13353472	Support column aliases in Values clause	"Enable explicitly specify column aliases in the first row of Values clause. If not all the columns has alias specified generate one.
{code:java}
values(1, 2 b, 3 c),(4, 5, 6);
{code}
{code:java}
_col1   b   c
  1     2   3
  4     5   6
{code}
 This is not an standard SQL feature but some database engines like Impala supports it."	HIVE	Closed	3	4	6200	pull-request-available
13335430	Implement Query Text based MaterializedView rewrite	"Besides the way queries are currently rewritten to use materialized views in Hive this project provides an alternative:
Compare the query text with the materialized views query text stored. If we found a match the original query's logical plan can be replaced by a scan on the materialized view.
- Only materialized views which are enabled to rewrite can participate
- Use existing *HiveMaterializedViewsRegistry* through *Hive* object by adding a lookup method by query text.
- There might be more than one materialized views which have the same query text. In this case chose the first valid one.
- Validation can be done by calling *Hive.validateMaterializedViewsFromRegistry()*
- The scope of this first patch is rewriting queries which entire text can be matched only.
- Use the expanded query text (fully qualified column and table names) for comparing
"	HIVE	Resolved	3	4	6200	pull-request-available
13486084	Iceberg table is created when running explain ctas command	"{code}
create table source(a int, b string, c int);

explain
create table tbl_ice stored by iceberg stored as orc tblproperties ('format-version'='2') as
select a, b, c from source;

create table tbl_ice stored by iceberg stored as orc tblproperties ('format-version'='2') as
select a, b, c from source;
{code}
{code}
 org.apache.hadoop.hive.ql.parse.SemanticException: org.apache.hadoop.hive.ql.parse.SemanticException: Table already exists: default.tbl_ice
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeCreateTable(SemanticAnalyzer.java:13963)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genResolvedParseTree(SemanticAnalyzer.java:12528)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12693)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.analyzeInternal(CalcitePlanner.java:460)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:317)
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:224)
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:106)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:522)
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:474)
	at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:439)
	at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:433)
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.compileAndRespond(ReExecDriver.java:121)
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:227)
	at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:255)
	at org.apache.hadoop.hive.cli.CliDriver.processCmd1(CliDriver.java:200)
	at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:126)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:421)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:352)
	at org.apache.hadoop.hive.ql.QTestUtil.executeClientInternal(QTestUtil.java:727)
	at org.apache.hadoop.hive.ql.QTestUtil.executeClient(QTestUtil.java:697)
	at org.apache.hadoop.hive.cli.control.CoreCliDriver.runTest(CoreCliDriver.java:114)
	at org.apache.hadoop.hive.cli.control.CliAdapter.runTest(CliAdapter.java:157)
	at org.apache.hadoop.hive.cli.TestIcebergLlapLocalCliDriver.testCliDriver(TestIcebergLlapLocalCliDriver.java:60)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.apache.hadoop.hive.cli.control.CliAdapter$2$1.evaluate(CliAdapter.java:135)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.apache.hadoop.hive.cli.control.CliAdapter$1$1.evaluate(CliAdapter.java:95)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
Caused by: org.apache.hadoop.hive.ql.parse.SemanticException: Table already exists: default.tbl_ice
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeCreateTable(SemanticAnalyzer.java:13960)
	... 61 more
{code}
The EXPLAIN ... command creates the Iceberg table default.tbl_ice hence the ctas command executed after it fails with table already exists."	HIVE	Closed	3	1	6200	pull-request-available
13427144	Create view fails when definition contains a materialized view definition	"View definition contains the materialized view definition as subquery:
{code}
create materialized view mv1 as
select * from t1 where col0 > 2 union select * from t1 where col0 = 0;

explain cbo
create view v1 as
select sub.* from (select * from t1 where col0 > 2 union select * from t1 where col0 = 0) sub
where sub.col0 = 10 
{code}
{code}
See ./ql/target/tmp/log/hive.log or ./itests/qtest/target/tmp/log/hive.log, or check ./ql/target/surefire-reports or ./itests/qtest/target/surefire-reports/ for specific test cases logs.
 org.apache.hadoop.hive.ql.parse.SemanticException: View definition references materialized view default@mv1
	at org.apache.hadoop.hive.ql.ddl.view.create.CreateViewAnalyzer.validateCreateView(CreateViewAnalyzer.java:211)
	at org.apache.hadoop.hive.ql.ddl.view.create.CreateViewAnalyzer.analyzeInternal(CreateViewAnalyzer.java:99)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:317)
	at org.apache.hadoop.hive.ql.parse.ExplainSemanticAnalyzer.analyzeInternal(ExplainSemanticAnalyzer.java:180)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:317)
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:224)
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:106)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:501)
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:453)
	at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:417)
	at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:411)
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.compileAndRespond(ReExecDriver.java:121)
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:227)
	at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:256)
	at org.apache.hadoop.hive.cli.CliDriver.processCmd1(CliDriver.java:201)
	at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:127)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:422)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:353)
	at org.apache.hadoop.hive.ql.QTestUtil.executeClientInternal(QTestUtil.java:727)
	at org.apache.hadoop.hive.ql.QTestUtil.executeClient(QTestUtil.java:697)
	at org.apache.hadoop.hive.cli.control.CoreCliDriver.runTest(CoreCliDriver.java:114)
	at org.apache.hadoop.hive.cli.control.CliAdapter.runTest(CliAdapter.java:157)
	at org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver(TestMiniLlapLocalCliDriver.java:62)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.apache.hadoop.hive.cli.control.CliAdapter$2$1.evaluate(CliAdapter.java:135)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.apache.hadoop.hive.cli.control.CliAdapter$1$1.evaluate(CliAdapter.java:95)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
Caused by: org.apache.hadoop.hive.ql.parse.SemanticException: View definition references materialized view default@mv1
	at org.apache.hadoop.hive.ql.ddl.view.create.AbstractCreateViewAnalyzer.validateTablesUsed(AbstractCreateViewAnalyzer.java:100)
	at org.apache.hadoop.hive.ql.ddl.view.create.CreateViewAnalyzer.validateCreateView(CreateViewAnalyzer.java:192)
	... 61 more
{code}"	HIVE	Resolved	3	1	6200	pull-request-available
13557353	Incremental materialized view throws NPE whew Iceberg source table is empty	"Repro
https://github.com/apache/hive/blob/master/iceberg/iceberg-handler/src/test/queries/positive/mv_iceberg_orc.q

in hive.log
{code}
2023-11-09T05:17:05,625  WARN [e35c7637-b0ba-4e30-8448-5bdc0d0e4779 main] rebuild.AlterMaterializedViewRebuildAnalyzer: Exception loading materialized views
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException
        at org.apache.hadoop.hive.ql.metadata.Hive.getValidMaterializedViews(Hive.java:2321) ~[hive-exec-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.apache.hadoop.hive.ql.metadata.Hive.getMaterializedViewForRebuild(Hive.java:2227) ~[hive-exec-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.apache.hadoop.hive.ql.ddl.view.materialized.alter.rebuild.AlterMaterializedViewRebuildAnalyzer$MVRebuildCalcitePlannerAction.applyMaterializedViewRewriting(AlterMaterializedViewRebuildAnaly
zer.java:215) ~[hive-exec-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.apache.hadoop.hive.ql.parse.CalcitePlanner$CalcitePlannerAction.apply(CalcitePlanner.java:1700) ~[hive-exec-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.apache.hadoop.hive.ql.parse.CalcitePlanner$CalcitePlannerAction.apply(CalcitePlanner.java:1569) ~[hive-exec-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.apache.calcite.tools.Frameworks.lambda$withPlanner$0(Frameworks.java:131) ~[hive-exec-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.apache.calcite.prepare.CalcitePrepareImpl.perform(CalcitePrepareImpl.java:914) ~[hive-exec-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.apache.calcite.tools.Frameworks.withPrepare(Frameworks.java:180) ~[hive-exec-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.apache.calcite.tools.Frameworks.withPlanner(Frameworks.java:126) ~[hive-exec-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.apache.hadoop.hive.ql.parse.CalcitePlanner.logicalPlan(CalcitePlanner.java:1321) ~[hive-exec-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.apache.hadoop.hive.ql.parse.CalcitePlanner.genOPTree(CalcitePlanner.java:570) ~[hive-exec-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:13113) ~[hive-exec-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.apache.hadoop.hive.ql.parse.CalcitePlanner.analyzeInternal(CalcitePlanner.java:465) ~[hive-exec-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.apache.hadoop.hive.ql.ddl.view.materialized.alter.rebuild.AlterMaterializedViewRebuildAnalyzer.analyzeInternal(AlterMaterializedViewRebuildAnalyzer.java:135) ~[hive-exec-4.0.0-beta-2-SNAPSH
OT.jar:4.0.0-beta-2-SNAPSHOT]
at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:327) ~[hive-exec-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.apache.hadoop.hive.ql.parse.ExplainSemanticAnalyzer.analyzeInternal(ExplainSemanticAnalyzer.java:180) ~[hive-exec-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:327) ~[hive-exec-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:224) ~[hive-exec-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:107) ~[hive-exec-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:519) ~[hive-exec-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:471) ~[hive-exec-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:436) ~[hive-exec-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:430) ~[hive-exec-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.apache.hadoop.hive.ql.reexec.ReExecDriver.compileAndRespond(ReExecDriver.java:121) ~[hive-exec-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:227) ~[hive-exec-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:257) ~[hive-cli-4.0.0-beta-2-SNAPSHOT.jar:?]
        at org.apache.hadoop.hive.cli.CliDriver.processCmd1(CliDriver.java:201) ~[hive-cli-4.0.0-beta-2-SNAPSHOT.jar:?]
        at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:127) ~[hive-cli-4.0.0-beta-2-SNAPSHOT.jar:?]
        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:425) ~[hive-cli-4.0.0-beta-2-SNAPSHOT.jar:?]
        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:356) ~[hive-cli-4.0.0-beta-2-SNAPSHOT.jar:?]
        at org.apache.hadoop.hive.ql.QTestUtil.executeClientInternal(QTestUtil.java:733) ~[hive-it-util-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.apache.hadoop.hive.ql.QTestUtil.executeClient(QTestUtil.java:703) ~[hive-it-util-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.apache.hadoop.hive.cli.control.CoreCliDriver.runTest(CoreCliDriver.java:115) ~[hive-it-util-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.apache.hadoop.hive.cli.control.CliAdapter.runTest(CliAdapter.java:157) ~[hive-it-util-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.apache.hadoop.hive.cli.TestIcebergLlapLocalCliDriver.testCliDriver(TestIcebergLlapLocalCliDriver.java:60) ~[test-classes/:?]
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_301]
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_301]
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_301]
        at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_301]
        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) ~[junit-4.13.2.jar:4.13.2]
        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) ~[junit-4.13.2.jar:4.13.2]
        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) ~[junit-4.13.2.jar:4.13.2]
        at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) ~[junit-4.13.2.jar:4.13.2]
        at org.apache.hadoop.hive.cli.control.CliAdapter$2$1.evaluate(CliAdapter.java:135) ~[hive-it-util-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
        at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) ~[junit-4.13.2.jar:4.13.2]
        at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) ~[junit-4.13.2.jar:4.13.2]
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) ~[junit-4.13.2.jar:4.13.2]
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) ~[junit-4.13.2.jar:4.13.2]
        at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) ~[junit-4.13.2.jar:4.13.2]
        at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) ~[junit-4.13.2.jar:4.13.2]
        at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) ~[junit-4.13.2.jar:4.13.2]
        at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) ~[junit-4.13.2.jar:4.13.2]
        at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) ~[junit-4.13.2.jar:4.13.2]
        at org.junit.runners.ParentRunner.run(ParentRunner.java:413) ~[junit-4.13.2.jar:4.13.2]
        at org.junit.runners.Suite.runChild(Suite.java:128) ~[junit-4.13.2.jar:4.13.2]
        at org.junit.runners.Suite.runChild(Suite.java:27) ~[junit-4.13.2.jar:4.13.2]
        at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) ~[junit-4.13.2.jar:4.13.2]
        at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) ~[junit-4.13.2.jar:4.13.2]
        at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) ~[junit-4.13.2.jar:4.13.2]
        at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) ~[junit-4.13.2.jar:4.13.2]
        at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) ~[junit-4.13.2.jar:4.13.2]
        at org.apache.hadoop.hive.cli.control.CliAdapter$1$1.evaluate(CliAdapter.java:95) ~[hive-it-util-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.junit.rules.RunRules.evaluate(RunRules.java:20) ~[junit-4.13.2.jar:4.13.2]
        at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
        at org.junit.runners.ParentRunner.run(ParentRunner.java:413) ~[junit-4.13.2.jar:4.13.2]
        at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
        at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
        at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
        at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
        at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
        at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
        at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
        at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
Caused by: java.lang.NullPointerException
        at org.apache.hadoop.hive.ql.optimizer.calcite.rules.views.HiveAugmentSnapshotMaterializationRule.onMatch(HiveAugmentSnapshotMaterializationRule.java:128) ~[hive-exec-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.apache.calcite.plan.AbstractRelOptPlanner.fireRule(AbstractRelOptPlanner.java:333) ~[hive-exec-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.apache.calcite.plan.hep.HepPlanner.applyRule(HepPlanner.java:542) ~[hive-exec-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.apache.calcite.plan.hep.HepPlanner.applyRules(HepPlanner.java:407) ~[hive-exec-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.apache.calcite.plan.hep.HepPlanner.executeInstruction(HepPlanner.java:243) ~[hive-exec-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.apache.calcite.plan.hep.HepInstruction$RuleInstance.execute(HepInstruction.java:127) ~[hive-exec-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.apache.calcite.plan.hep.HepPlanner.executeProgram(HepPlanner.java:202) ~[hive-exec-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.apache.calcite.plan.hep.HepPlanner.findBestExp(HepPlanner.java:189) ~[hive-exec-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.apache.hadoop.hive.ql.optimizer.calcite.rules.views.HiveMaterializedViewUtils.applyRule(HiveMaterializedViewUtils.java:295) ~[hive-exec-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.apache.hadoop.hive.ql.optimizer.calcite.rules.views.HiveMaterializedViewUtils.augmentMaterializationWithTimeInformation(HiveMaterializedViewUtils.java:243) ~[hive-exec-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.apache.hadoop.hive.ql.metadata.Hive.getValidMaterializedViews(Hive.java:2313) ~[hive-exec-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        ... 73 more
{code}"	HIVE	Closed	3	7	6200	iceberg, materializedviews, pull-request-available
13537160	Incorrect incremental rebuild mode shown of materialized view with Iceberg sources	"{code}
CREATE TABLE shtb_test1(KEY INT, VALUE STRING) PARTITIONED BY(ds STRING)
stored by iceberg stored as orc tblproperties ('format-version'='2');

CREATE MATERIALIZED VIEW shtb_test1_view1 stored by iceberg stored as orc tblproperties ('format-version'='1') AS
SELECT * FROM shtb_test1 where KEY > 1000 and KEY < 2000;

SHOW MATERIALIZED VIEWS;
{code}
{code}
# MV Name           	Rewriting Enabled   	Mode                	Incremental rebuild 
shtb_test1_view1    	Yes                 	Manual refresh      	Available           
{code}

It should be 
{code}
# MV Name           	Rewriting Enabled   	Mode                	Incremental rebuild 
shtb_test1_view1    	Yes                 	Manual refresh      	Available in presence of insert operations only
{code}
because deleted rows can not be identified in case of Iceberg source tables."	HIVE	Resolved	3	7	6200	pull-request-available
13447668	No vectorization if query has upper case window function	"{code}
CREATE TABLE t1 (a int, b int);

EXPLAIN VECTORIZATION ONLY SELECT ROW_NUMBER() OVER(order by a) AS rn FROM t1;
{code}
{code}
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
      Vertices:
        Map 1 
            Execution mode: vectorized, llap
            LLAP IO: all inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                inputFormatFeatureSupport: [DECIMAL_64]
                featureSupportInUse: [DECIMAL_64]
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
        Reducer 2 
            Execution mode: llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez] IS true
                notVectorizedReason: PTF operator: ROW_NUMBER not in supported functions [avg, count, dense_rank, first_value, lag, last_value, lead, max, min, rank, row_number, sum]
                vectorized: false

  Stage: Stage-0
    Fetch Operator
{code}
{code}
                notVectorizedReason: PTF operator: ROW_NUMBER not in supported functions [avg, count, dense_rank, first_value, lag, last_value, lead, max, min, rank, row_number, sum]
{code}"	HIVE	Closed	3	1	6200	pull-request-available
13402689	Enable incremental rebuild of Materialized views with insert only source tables	"{code}
create table t1(a int, b int, c int) stored as parquet TBLPROPERTIES ('transactional'='true', 'transactional_properties'='insert_only');

create materialized view mat1 stored as orc TBLPROPERTIES ('transactional'='true') as
select a, b, c from t1 where a > 10;
{code}

Currently materialized view *mat1* can not be rebuilt incrementally because it has an insert only source table (t1). Such tables does not have ROW_ID.write_id which is required to identify newly inserted records since the last rebuild.
HIVE-25406 adds the ability to query write_id."	HIVE	Resolved	3	4	6200	pull-request-available
13318434	Simplify special_character_in_tabnames_1.q	"* move similar queries to unit tests into the parser module and keep only one in the q test.
* use *explain* instead of executing the queries if possible since we are focusing on parser testing"	HIVE	Closed	4	3	6200	pull-request-available
13360649	Materialized View rebuild loses materializationTime property value	"Materialized View rebuild like
{code}
alter materialized view mat1 rebuild;
{code}
updates the CreationMetadata of a org.apache.hadoop.hive.ql.metadata.Table object  of the materialized view but it does not copy the materializationTime property value from the original CreationMetadata object and updates the entry in the MaterializedViewCache:
{code}
    } else if (desc.isUpdateCreationMetadata()) {
        // We need to update the status of the creation signature
        Table mvTable = context.getDb().getTable(desc.getName());
        CreationMetadata cm = new CreationMetadata(MetaStoreUtils.getDefaultCatalog(context.getConf()),
            mvTable.getDbName(), mvTable.getTableName(),
            ImmutableSet.copyOf(mvTable.getCreationMetadata().getTablesUsed()));
        cm.setValidTxnList(context.getConf().get(ValidTxnWriteIdList.VALID_TABLES_WRITEIDS_KEY));
        context.getDb().updateCreationMetadata(mvTable.getDbName(), mvTable.getTableName(), cm);
        mvTable.setCreationMetadata(cm);
        HiveMaterializedViewsRegistry.get().createMaterializedView(context.getDb().getConf(), mvTable);
      }
{code}
Later when loading Materializetions using 
{code}
Hive.getValidMaterializedViews(List<Table> materializedViewTables ...) 
{code}
the materialization stored in the cache and in the metastore will be not the same because of the lost materializationTime.
Cache tried to be refreshed 
{code}
HiveMaterializedViewsRegistry.get().refreshMaterializedView(conf, null, materializedViewTable);
{code}
by passing null as oldMaterializedViewTable which leads to NullPointerException and CBO failure because the registry expect a non null oldMaterializedViewTable value:
It may drops the old MV in Metastore and also tries to update the cache."	HIVE	Resolved	3	1	6200	pull-request-available
13324798	Enable pre-materializing CTEs referenced in scalar subqueries	"HIVE-11752 introduces materializing CTE based on config
{code}
hive.optimize.cte.materialize.threshold
{code}
Goal of this jira is
* extending the implementation to support materializing CTE's referenced in scalar subqueries
* add a config to materialize CTEs with aggregate output only"	HIVE	Closed	3	4	6200	pull-request-available
13421912	DISTINCT with ORDER BY on ordinals fails with NPE	"{code}
explain cbo select distinct int_col x, bigint_col y from alltypes order by 1, 2;
{code}"	HIVE	Resolved	3	1	6200	pull-request-available
13423493	Unable to compile cpp metastore thrift client	"HIVE-25656 introduced struct {{SourceTable}} into the metastore Thrift API.

The following structs definition contains circular dependency:
{code:java}
struct SourceTable {
    1: required Table table,
   ...
}

struct CreationMetadata {
    ...
    7: optional set<SourceTable> sourceTables
}

struct Table {
  ...
  16: optional CreationMetadata creationMetadata,   // only for MVs, it stores table names used and txn list at MV creation
  ...
}
{code}"	HIVE	Resolved	3	1	6200	pull-request-available
13551867	Materialized view query rewrite fails if query has decimal derived aggregate	"{code}
create table t1 (a int, b decimal(3,2)) stored as orc TBLPROPERTIES ('transactional'='true');

create materialized view mv1 as
select a, sum(b), count(b) from t1 group by a;

explain cbo
select a, avg(b) from t1 group by a;
{code}
MV is not used
{code}
CBO PLAN:
HiveProject(a=[$0], _o__c1=[CAST(/($1, $2)):DECIMAL(7, 6)])
  HiveAggregate(group=[{0}], agg#0=[sum($1)], agg#1=[count($1)])
    HiveTableScan(table=[[default, t1]], table:alias=[t1])
{code}

If {{avg}} input is not decimal but for example {{int}} the query plan is rewritten to use the MV"	HIVE	Resolved	3	1	6200	cbo, materializedviews, pull-request-available
13505538	Use DDLTask to created Iceberg table when running ctas statement	"When Iceberg table is created via ctas statement the table is created in HiveIcebergSerDe and no DDL task is executed.
Negative effects of this workflow:
* Missing table properties: format-version, write.[delete|update|merge].mode
* Default privileges of the new table are not granted.
* The new Iceberg table can be seen by other transactions at compile time of ctas.
* Table creation and table properties are not shown in explain ctas output."	HIVE	Resolved	3	4	6200	pull-request-available
13367433	Remove outdated check for correlated exists subqueries with full aggregate	"Since HIVE-24929 QBSubQuery.subqueryRestrictionsCheck is no longer called. Check for exists subqueries with full aggregate moved to QBSubQueryParseInfo.hasFullAggregate() and QBSubQueryParseInfo.getOperator()
"	HIVE	Resolved	4	4	6200	pull-request-available
13342769	Filter out materialized views for rewriting if plan pattern is not allowed	"Some materialized views are not enabled for Calcite based rewriting. Rules for validating materialized views are implemented by HIVE-20748. 
Since text based materialized view query rewrite doesn't have such limitations some logic must be implemented to flag materialized view whether they are enabled to text based rewrite only or both."	HIVE	Resolved	3	4	6200	pull-request-available
13380530	Query with multiple count(distinct constant) fails	"{code}
select count(distinct 0), count(distinct null) from alltypes;
{code}
{code}
org.apache.hadoop.hive.ql.parse.SemanticException: Line 0:-1 Expression not in GROUP BY key 'TOK_NULL'
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genAllExprNodeDesc(SemanticAnalyzer.java:12941)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genExprNodeDesc(SemanticAnalyzer.java:12883)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genSelectPlan(SemanticAnalyzer.java:4695)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genSelectPlan(SemanticAnalyzer.java:4483)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPostGroupByBodyPlan(SemanticAnalyzer.java:10960)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBodyPlan(SemanticAnalyzer.java:10902)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:11808)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:11665)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:11692)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:11678)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.genOPTree(CalcitePlanner.java:618)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12505)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.analyzeInternal(CalcitePlanner.java:449)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:316)
	at org.apache.hadoop.hive.ql.parse.ExplainSemanticAnalyzer.analyzeInternal(ExplainSemanticAnalyzer.java:175)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:316)
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223)
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:105)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:492)
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:445)
	at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:409)
	at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:403)
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.compileAndRespond(ReExecDriver.java:125)
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:229)
	at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:256)
	at org.apache.hadoop.hive.cli.CliDriver.processCmd1(CliDriver.java:201)
	at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:127)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:422)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:353)
	at org.apache.hadoop.hive.ql.QTestUtil.executeClientInternal(QTestUtil.java:744)
	at org.apache.hadoop.hive.ql.QTestUtil.executeClient(QTestUtil.java:714)
	at org.apache.hadoop.hive.cli.control.CoreCliDriver.runTest(CoreCliDriver.java:170)
	at org.apache.hadoop.hive.cli.control.CliAdapter.runTest(CliAdapter.java:157)
	at org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver(TestMiniLlapLocalCliDriver.java:62)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.apache.hadoop.hive.cli.control.CliAdapter$2$1.evaluate(CliAdapter.java:135)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.apache.hadoop.hive.cli.control.CliAdapter$1$1.evaluate(CliAdapter.java:95)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
{code}

CBO Plan:
{code}
HiveAggregate(group=[{}], agg#0=[count($0)], agg#1=[count($1)])
  HiveProject($f0=[CASE(=($2, 1), 1, null:INTEGER)], $f1=[null:INTEGER])
    HiveAggregate(group=[{0, 1}], GROUPING__ID=[GROUPING__ID()])
      HiveProject($f0=[true], $f1=[true])
        HiveTableScan(table=[[default, alltypes]], table:alias=[alltypes])
{code}

Query is rewritten to use an aggregate with one grouping set but later at ASTConverter this aggregate is treated as a simple Group By without grouping sets. However the function GROUPING__ID can only be used when grouping sets are defined.
"	HIVE	Resolved	3	1	6200	pull-request-available
13362921	Incremental Materialized view refresh in presence of update/delete operations	"Current implementation of incremental Materialized can not be used if any of the Materialized view source tables has update or delete operation since the last rebuild. In such cases a full rebuild should be performed.

Steps to enable incremental rebuild:
1. Introduce a new virtual column to mark a row deleted
2. Execute the query in the view definition 
2.a. Add filter to each table scan in order to pull only the rows from each source table which has a higher writeId than the writeId of the last rebuild - this is already implemented by current incremental rebuild
2.b Add row is deleted virtual column to each table scan. In join nodes if any of the branches has a deleted row the result row is also deleted.

We should distinguish two type of view definition queries: with and without Aggregate.

3.a No aggregate path:
Rewrite the plan of the full rebuild to a multi insert statement with two insert branches. One branch to insert new rows into the materialized view table and the second one for insert deleted rows to the materialized view delete delta.

3.b Aggregate path: TBD

Prerequisite:
source tables haven't compacted since the last MV revuild
"	HIVE	Closed	3	4	6200	pull-request-available
13553779	Exception when join has 2 Group By operators in the same branch in the same reducer	"Sort- merge join with Group By + PTF operator leads  to Runtime exception 
{code:java}
Caused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row
	at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:313)
	at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:291)
	at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:293)
	... 15 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row
	at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource$GroupIterator.next(ReduceRecordSource.java:387)
	at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:303)
	... 17 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: Attempting to overwrite nextKeyWritables[1]
	at org.apache.hadoop.hive.ql.exec.CommonMergeJoinOperator.joinOneGroup(CommonMergeJoinOperator.java:392)
	at org.apache.hadoop.hive.ql.exec.CommonMergeJoinOperator.joinOneGroup(CommonMergeJoinOperator.java:372)
	at org.apache.hadoop.hive.ql.exec.CommonMergeJoinOperator.process(CommonMergeJoinOperator.java:316)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:94)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.FilterOperator.process(FilterOperator.java:127)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.PTFOperator$PTFInvocation.handleOutputRows(PTFOperator.java:337)
	at org.apache.hadoop.hive.ql.exec.PTFOperator$PTFInvocation.processRow(PTFOperator.java:325)
	at org.apache.hadoop.hive.ql.exec.PTFOperator.process(PTFOperator.java:139)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:94)
	at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource$GroupIterator.next(ReduceRecordSource.java:372)
	... 18 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: Attempting to overwrite nextKeyWritables[1]
	at org.apache.hadoop.hive.ql.exec.CommonMergeJoinOperator.fetchOneRow(CommonMergeJoinOperator.java:534)
	at org.apache.hadoop.hive.ql.exec.CommonMergeJoinOperator.fetchNextGroup(CommonMergeJoinOperator.java:488)
	at org.apache.hadoop.hive.ql.exec.CommonMergeJoinOperator.joinOneGroup(CommonMergeJoinOperator.java:390)
	... 31 more
Caused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: Attempting to overwrite nextKeyWritables[1]
	at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:313)
	at org.apache.hadoop.hive.ql.exec.CommonMergeJoinOperator.fetchOneRow(CommonMergeJoinOperator.java:522)
	... 33 more {code}
Issue can be reproduced with [^auto_sortmerge_join_17.q]"	HIVE	Resolved	3	1	6200	pull-request-available
13530459	Incremental rebuild of materialized view having aggregate and stored by iceberg	"Currently incremental rebuild of materialized view stored by iceberg which definition query contains aggregate operator is transformed to an insert overwrite statement which contains a union operator if the source tables contains insert operations only. One branch of the union scans the view the other produces the delta.

This can be improved further: transform the statement to a multi insert statement representing a merge statement to insert new aggregations and update existing."	HIVE	Resolved	3	4	6200	pull-request-available
13400410	Merge statement does not enforce check constraints	"{code}
set hive.support.concurrency=true;
set hive.txn.manager=org.apache.hadoop.hive.ql.lockmgr.DbTxnManager;

CREATE TABLE table_check_merge(
name string CHECK (length(name)<=20),
age int,
gpa double CHECK (gpa BETWEEN 0.0 AND 4.0)
) stored as orc TBLPROPERTIES ('transactional'='true');

CREATE TABLE table_source( name string, age int, gpa double);

insert into table_source(name, age, gpa) values ('student1', 16, null), (null, 20, 4.0);

insert into table_check_merge(name, age, gpa) values ('student1', 16, 2.0);

merge into table_check_merge using (select age from table_source)source
on source.age=table_check_merge.age
when matched then update set gpa=6;
{code}

Merge statement tries to update gpa to 6 which is not between 0.0 and 4.0.
However the update succeeds.
"	HIVE	Resolved	3	1	6200	pull-request-available
13537646	Unable to pushdown partition filter with unquoted date literal type to metastore	"After HIVE-26787 and HIVE-26778 filter expressions with unquoted date literals and timestamp literals without type name are not supported when calling metastore api {{getPartitionsByExpr}}
Example
{code}
(j = 1990-11-12 or j = 1990-11-11 or j = 1990-11-10)
{code}"	HIVE	Resolved	3	1	6200	pull-request-available
13340832	Trailing zeros of constant decimal numbers are removed	"In some case Hive removes trailing zeros of constant decimal numbers
{code}
select cast(1.1 as decimal(22, 2)) 
1.1
{code}
In this case *WritableConstantHiveDecimalObjectInspector* is used and this object inspector takes it's wrapped HiveDecimal scale instead of the scale specified in the wrapped typeinfo: 
{code}
this = {WritableConstantHiveDecimalObjectInspector@14415} 
 value = {HiveDecimalWritable@14426} ""1.1""
 typeInfo = {DecimalTypeInfo@14421} ""decimal(22,2)""{code}

However in case of an expression with an aggregate function *WritableHiveDecimalObjectInspector* is used
{code}
select cast(sum(1.1) as decimal(22, 2))
1.10
{code}
{code}
o = {HiveDecimalWritable@16633} ""1.1""
oi = {WritableHiveDecimalObjectInspector@16634} 
 typeInfo = {DecimalTypeInfo@16640} ""decimal(22,2)""
{code}

Casting the expressions to string
{code:java}
select cast(cast(1.1 as decimal(22, 2)) as string), cast(cast(sum(1.1) as decimal(22, 2)) as string)
1.1	1.10
{code}
"	HIVE	Resolved	3	1	6200	pull-request-available
13352022	Support CTE with column labels	"{code}
with cte1(a, b) as (select int_col x, bigint_col y from t1)
select a, b from cte1{code}
{code}
a	b
1	2
3	4
{code}

{code}
<query expression> ::=
  [ <with clause> ] <query expression body>
  [ <order by clause> ] [ <result offset clause> ] [ <fetch first clause> ]

<with clause> ::=
  WITH [ RECURSIVE ] <with list>

<with list> ::=
  <with list element> [ { <comma> <with list element> }... ]

<with list element> ::=
  <query name> [ <left paren> <with column list> <right paren> ]
  AS <table subquery> [ <search or cycle clause> ]

<with column list> ::=
  <column name list>
{code}"	HIVE	Closed	3	4	6200	pull-request-available
13319575	SharedWorkOptimizer: take the union of columns in mergeable TableScans	"{code}
POSTHOOK: query: explain
select case when (select count(*) 
                  from store_sales 
                  where ss_quantity between 1 and 20) > 409437
            then (select avg(ss_ext_list_price) 
                  from store_sales 
                  where ss_quantity between 1 and 20) 
            else (select avg(ss_net_paid_inc_tax)
                  from store_sales
                  where ss_quantity between 1 and 20) end bucket1 ,
       case when (select count(*)
                  from store_sales
                  where ss_quantity between 21 and 40) > 4595804
            then (select avg(ss_ext_list_price)
                  from store_sales
                  where ss_quantity between 21 and 40) 
            else (select avg(ss_net_paid_inc_tax)
                  from store_sales
                  where ss_quantity between 21 and 40) end bucket2,
       case when (select count(*)
                  from store_sales
                  where ss_quantity between 41 and 60) > 7887297
            then (select avg(ss_ext_list_price)
                  from store_sales
                  where ss_quantity between 41 and 60)
            else (select avg(ss_net_paid_inc_tax)
                  from store_sales
                  where ss_quantity between 41 and 60) end bucket3,
       case when (select count(*)
                  from store_sales
                  where ss_quantity between 61 and 80) > 10872978
            then (select avg(ss_ext_list_price)
                  from store_sales
                  where ss_quantity between 61 and 80)
            else (select avg(ss_net_paid_inc_tax)
                  from store_sales
                  where ss_quantity between 61 and 80) end bucket4,
       case when (select count(*)
                  from store_sales
                  where ss_quantity between 81 and 100) > 43571537
            then (select avg(ss_ext_list_price)
                  from store_sales
                  where ss_quantity between 81 and 100)
            else (select avg(ss_net_paid_inc_tax)
                  from store_sales
                  where ss_quantity between 81 and 100) end bucket5
from reason
where r_reason_sk = 1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@reason
POSTHOOK: Input: default@store_sales
POSTHOOK: Output: hdfs://### HDFS PATH ###
Plan optimized by CBO.

Vertex dependency in root stage
Reducer 10 <- Reducer 34 (CUSTOM_SIMPLE_EDGE), Reducer 9 (CUSTOM_SIMPLE_EDGE)
Reducer 11 <- Reducer 10 (CUSTOM_SIMPLE_EDGE), Reducer 18 (CUSTOM_SIMPLE_EDGE)
Reducer 12 <- Reducer 11 (CUSTOM_SIMPLE_EDGE), Reducer 24 (CUSTOM_SIMPLE_EDGE)
Reducer 13 <- Reducer 12 (CUSTOM_SIMPLE_EDGE), Reducer 30 (CUSTOM_SIMPLE_EDGE)
Reducer 14 <- Reducer 13 (CUSTOM_SIMPLE_EDGE), Reducer 19 (CUSTOM_SIMPLE_EDGE)
Reducer 15 <- Reducer 14 (CUSTOM_SIMPLE_EDGE), Reducer 25 (CUSTOM_SIMPLE_EDGE)
Reducer 16 <- Reducer 15 (CUSTOM_SIMPLE_EDGE), Reducer 31 (CUSTOM_SIMPLE_EDGE)
Reducer 18 <- Map 17 (CUSTOM_SIMPLE_EDGE)
Reducer 19 <- Map 17 (CUSTOM_SIMPLE_EDGE)
Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE), Reducer 20 (CUSTOM_SIMPLE_EDGE)
Reducer 20 <- Map 17 (CUSTOM_SIMPLE_EDGE)
Reducer 21 <- Map 17 (CUSTOM_SIMPLE_EDGE)
Reducer 22 <- Map 17 (CUSTOM_SIMPLE_EDGE)
Reducer 24 <- Map 23 (CUSTOM_SIMPLE_EDGE)
Reducer 25 <- Map 23 (CUSTOM_SIMPLE_EDGE)
Reducer 26 <- Map 23 (CUSTOM_SIMPLE_EDGE)
Reducer 27 <- Map 23 (CUSTOM_SIMPLE_EDGE)
Reducer 28 <- Map 23 (CUSTOM_SIMPLE_EDGE)
Reducer 3 <- Reducer 2 (CUSTOM_SIMPLE_EDGE), Reducer 26 (CUSTOM_SIMPLE_EDGE)
Reducer 30 <- Map 29 (CUSTOM_SIMPLE_EDGE)
Reducer 31 <- Map 29 (CUSTOM_SIMPLE_EDGE)
Reducer 32 <- Map 29 (CUSTOM_SIMPLE_EDGE)
Reducer 33 <- Map 29 (CUSTOM_SIMPLE_EDGE)
Reducer 34 <- Map 29 (CUSTOM_SIMPLE_EDGE)
Reducer 4 <- Reducer 3 (CUSTOM_SIMPLE_EDGE), Reducer 32 (CUSTOM_SIMPLE_EDGE)
Reducer 5 <- Reducer 21 (CUSTOM_SIMPLE_EDGE), Reducer 4 (CUSTOM_SIMPLE_EDGE)
Reducer 6 <- Reducer 27 (CUSTOM_SIMPLE_EDGE), Reducer 5 (CUSTOM_SIMPLE_EDGE)
Reducer 7 <- Reducer 33 (CUSTOM_SIMPLE_EDGE), Reducer 6 (CUSTOM_SIMPLE_EDGE)
Reducer 8 <- Reducer 22 (CUSTOM_SIMPLE_EDGE), Reducer 7 (CUSTOM_SIMPLE_EDGE)
Reducer 9 <- Reducer 28 (CUSTOM_SIMPLE_EDGE), Reducer 8 (CUSTOM_SIMPLE_EDGE)

Stage-0
  Fetch Operator
    limit:-1
    Stage-1
      Reducer 16
      File Output Operator [FS_154]
        Select Operator [SEL_153] (rows=2 width=560)
          Output:[""_col0"",""_col1"",""_col2"",""_col3"",""_col4""]
          Merge Join Operator [MERGEJOIN_185] (rows=2 width=1140)
            Conds:(Left Outer),Output:[""_col1"",""_col2"",""_col3"",""_col4"",""_col5"",""_col6"",""_col7"",""_col8"",""_col9"",""_col10"",""_col11"",""_col12"",""_col13"",""_col14"",""_col15""]
          <-Reducer 15 [CUSTOM_SIMPLE_EDGE]
            PARTITION_ONLY_SHUFFLE [RS_150]
              Merge Join Operator [MERGEJOIN_184] (rows=2 width=1028)
                Conds:(Left Outer),Output:[""_col1"",""_col2"",""_col3"",""_col4"",""_col5"",""_col6"",""_col7"",""_col8"",""_col9"",""_col10"",""_col11"",""_col12"",""_col13"",""_col14""]
              <-Reducer 14 [CUSTOM_SIMPLE_EDGE]
                PARTITION_ONLY_SHUFFLE [RS_147]
                  Merge Join Operator [MERGEJOIN_183] (rows=2 width=916)
                    Conds:(Left Outer),Output:[""_col1"",""_col2"",""_col3"",""_col4"",""_col5"",""_col6"",""_col7"",""_col8"",""_col9"",""_col10"",""_col11"",""_col12"",""_col13""]
                  <-Reducer 13 [CUSTOM_SIMPLE_EDGE]
                    PARTITION_ONLY_SHUFFLE [RS_144]
                      Merge Join Operator [MERGEJOIN_182] (rows=2 width=912)
                        Conds:(Left Outer),Output:[""_col1"",""_col2"",""_col3"",""_col4"",""_col5"",""_col6"",""_col7"",""_col8"",""_col9"",""_col10"",""_col11"",""_col12""]
                      <-Reducer 12 [CUSTOM_SIMPLE_EDGE]
                        PARTITION_ONLY_SHUFFLE [RS_141]
                          Merge Join Operator [MERGEJOIN_181] (rows=2 width=800)
                            Conds:(Left Outer),Output:[""_col1"",""_col2"",""_col3"",""_col4"",""_col5"",""_col6"",""_col7"",""_col8"",""_col9"",""_col10"",""_col11""]
                          <-Reducer 11 [CUSTOM_SIMPLE_EDGE]
                            PARTITION_ONLY_SHUFFLE [RS_138]
                              Merge Join Operator [MERGEJOIN_180] (rows=2 width=688)
                                Conds:(Left Outer),Output:[""_col1"",""_col2"",""_col3"",""_col4"",""_col5"",""_col6"",""_col7"",""_col8"",""_col9"",""_col10""]
                              <-Reducer 10 [CUSTOM_SIMPLE_EDGE]
                                PARTITION_ONLY_SHUFFLE [RS_135]
                                  Merge Join Operator [MERGEJOIN_179] (rows=2 width=684)
                                    Conds:(Left Outer),Output:[""_col1"",""_col2"",""_col3"",""_col4"",""_col5"",""_col6"",""_col7"",""_col8"",""_col9""]
                                  <-Reducer 34 [CUSTOM_SIMPLE_EDGE] vectorized
                                    PARTITION_ONLY_SHUFFLE [RS_275]
                                      Select Operator [SEL_274] (rows=1 width=112)
                                        Output:[""_col0""]
                                        Group By Operator [GBY_273] (rows=1 width=120)
                                          Output:[""_col0"",""_col1""],aggregations:[""sum(VALUE._col0)"",""count(VALUE._col1)""]
                                        <-Map 29 [CUSTOM_SIMPLE_EDGE] vectorized
                                          PARTITION_ONLY_SHUFFLE [RS_254]
                                            Group By Operator [GBY_249] (rows=1 width=120)
                                              Output:[""_col0"",""_col1""],aggregations:[""sum(ss_net_paid_inc_tax)"",""count(ss_net_paid_inc_tax)""]
                                              Select Operator [SEL_244] (rows=182855757 width=110)
                                                Output:[""ss_net_paid_inc_tax""]
                                                Filter Operator [FIL_239] (rows=182855757 width=110)
                                                  predicate:ss_quantity BETWEEN 41 AND 60
                                                  TableScan [TS_80] (rows=575995635 width=110)
                                                    default@store_sales,store_sales,Tbl:COMPLETE,Col:COMPLETE,Output:[""ss_quantity"",""ss_net_paid_inc_tax""]
                                  <-Reducer 9 [CUSTOM_SIMPLE_EDGE]
                                    PARTITION_ONLY_SHUFFLE [RS_132]
                                      Merge Join Operator [MERGEJOIN_178] (rows=2 width=572)
                                        Conds:(Left Outer),Output:[""_col1"",""_col2"",""_col3"",""_col4"",""_col5"",""_col6"",""_col7"",""_col8""]
                                      <-Reducer 28 [CUSTOM_SIMPLE_EDGE] vectorized
                                        PARTITION_ONLY_SHUFFLE [RS_272]
                                          Select Operator [SEL_271] (rows=1 width=112)
                                            Output:[""_col0""]
                                            Group By Operator [GBY_270] (rows=1 width=120)
                                              Output:[""_col0"",""_col1""],aggregations:[""sum(VALUE._col0)"",""count(VALUE._col1)""]
                                            <-Map 23 [CUSTOM_SIMPLE_EDGE] vectorized
                                              PARTITION_ONLY_SHUFFLE [RS_231]
                                                Group By Operator [GBY_226] (rows=1 width=120)
                                                  Output:[""_col0"",""_col1""],aggregations:[""sum(ss_ext_list_price)"",""count(ss_ext_list_price)""]
                                                  Select Operator [SEL_221] (rows=182855757 width=110)
                                                    Output:[""ss_ext_list_price""]
                                                    Filter Operator [FIL_216] (rows=182855757 width=110)
                                                      predicate:ss_quantity BETWEEN 41 AND 60
                                                      TableScan [TS_73] (rows=575995635 width=110)
                                                        default@store_sales,store_sales,Tbl:COMPLETE,Col:COMPLETE,Output:[""ss_quantity"",""ss_ext_list_price""]
                                      <-Reducer 8 [CUSTOM_SIMPLE_EDGE]
                                        PARTITION_ONLY_SHUFFLE [RS_129]
                                          Merge Join Operator [MERGEJOIN_177] (rows=2 width=460)
                                            Conds:(Left Outer),Output:[""_col1"",""_col2"",""_col3"",""_col4"",""_col5"",""_col6"",""_col7""]
                                          <-Reducer 22 [CUSTOM_SIMPLE_EDGE] vectorized
                                            PARTITION_ONLY_SHUFFLE [RS_269]
                                              Select Operator [SEL_268] (rows=1 width=4)
                                                Output:[""_col0""]
                                                Group By Operator [GBY_267] (rows=1 width=8)
                                                  Output:[""_col0""],aggregations:[""count(VALUE._col0)""]
                                                <-Map 17 [CUSTOM_SIMPLE_EDGE] vectorized
                                                  PARTITION_ONLY_SHUFFLE [RS_208]
                                                    Group By Operator [GBY_203] (rows=1 width=8)
                                                      Output:[""_col0""],aggregations:[""count()""]
                                                      Select Operator [SEL_198] (rows=182855757 width=3)
                                                        Filter Operator [FIL_193] (rows=182855757 width=3)
                                                          predicate:ss_quantity BETWEEN 41 AND 60
                                                          TableScan [TS_66] (rows=575995635 width=3)
                                                            default@store_sales,store_sales,Tbl:COMPLETE,Col:COMPLETE,Output:[""ss_quantity""]
                                          <-Reducer 7 [CUSTOM_SIMPLE_EDGE]
                                            PARTITION_ONLY_SHUFFLE [RS_126]
                                              Merge Join Operator [MERGEJOIN_176] (rows=2 width=456)
                                                Conds:(Left Outer),Output:[""_col1"",""_col2"",""_col3"",""_col4"",""_col5"",""_col6""]
                                              <-Reducer 33 [CUSTOM_SIMPLE_EDGE] vectorized
                                                PARTITION_ONLY_SHUFFLE [RS_266]
                                                  Select Operator [SEL_265] (rows=1 width=112)
                                                    Output:[""_col0""]
                                                    Group By Operator [GBY_264] (rows=1 width=120)
                                                      Output:[""_col0"",""_col1""],aggregations:[""sum(VALUE._col0)"",""count(VALUE._col1)""]
                                                    <-Map 29 [CUSTOM_SIMPLE_EDGE] vectorized
                                                      PARTITION_ONLY_SHUFFLE [RS_253]
                                                        Group By Operator [GBY_248] (rows=1 width=120)
                                                          Output:[""_col0"",""_col1""],aggregations:[""sum(ss_net_paid_inc_tax)"",""count(ss_net_paid_inc_tax)""]
                                                          Select Operator [SEL_243] (rows=182855757 width=110)
                                                            Output:[""ss_net_paid_inc_tax""]
                                                            Filter Operator [FIL_238] (rows=182855757 width=110)
                                                              predicate:ss_quantity BETWEEN 21 AND 40
                                                               Please refer to the previous TableScan [TS_80]
                                              <-Reducer 6 [CUSTOM_SIMPLE_EDGE]
                                                PARTITION_ONLY_SHUFFLE [RS_123]
                                                  Merge Join Operator [MERGEJOIN_175] (rows=2 width=344)
                                                    Conds:(Left Outer),Output:[""_col1"",""_col2"",""_col3"",""_col4"",""_col5""]
                                                  <-Reducer 27 [CUSTOM_SIMPLE_EDGE] vectorized
                                                    PARTITION_ONLY_SHUFFLE [RS_263]
                                                      Select Operator [SEL_262] (rows=1 width=112)
                                                        Output:[""_col0""]
                                                        Group By Operator [GBY_261] (rows=1 width=120)
                                                          Output:[""_col0"",""_col1""],aggregations:[""sum(VALUE._col0)"",""count(VALUE._col1)""]
                                                        <-Map 23 [CUSTOM_SIMPLE_EDGE] vectorized
                                                          PARTITION_ONLY_SHUFFLE [RS_230]
                                                            Group By Operator [GBY_225] (rows=1 width=120)
                                                              Output:[""_col0"",""_col1""],aggregations:[""sum(ss_ext_list_price)"",""count(ss_ext_list_price)""]
                                                              Select Operator [SEL_220] (rows=182855757 width=110)
                                                                Output:[""ss_ext_list_price""]
                                                                Filter Operator [FIL_215] (rows=182855757 width=110)
                                                                  predicate:ss_quantity BETWEEN 21 AND 40
                                                                   Please refer to the previous TableScan [TS_73]
                                                  <-Reducer 5 [CUSTOM_SIMPLE_EDGE]
                                                    PARTITION_ONLY_SHUFFLE [RS_120]
                                                      Merge Join Operator [MERGEJOIN_174] (rows=2 width=232)
                                                        Conds:(Left Outer),Output:[""_col1"",""_col2"",""_col3"",""_col4""]
                                                      <-Reducer 21 [CUSTOM_SIMPLE_EDGE] vectorized
                                                        PARTITION_ONLY_SHUFFLE [RS_260]
                                                          Select Operator [SEL_259] (rows=1 width=4)
                                                            Output:[""_col0""]
                                                            Group By Operator [GBY_258] (rows=1 width=8)
                                                              Output:[""_col0""],aggregations:[""count(VALUE._col0)""]
                                                            <-Map 17 [CUSTOM_SIMPLE_EDGE] vectorized
                                                              PARTITION_ONLY_SHUFFLE [RS_207]
                                                                Group By Operator [GBY_202] (rows=1 width=8)
                                                                  Output:[""_col0""],aggregations:[""count()""]
                                                                  Select Operator [SEL_197] (rows=182855757 width=3)
                                                                    Filter Operator [FIL_192] (rows=182855757 width=3)
                                                                      predicate:ss_quantity BETWEEN 21 AND 40
                                                                       Please refer to the previous TableScan [TS_66]
                                                      <-Reducer 4 [CUSTOM_SIMPLE_EDGE]
                                                        PARTITION_ONLY_SHUFFLE [RS_117]
                                                          Merge Join Operator [MERGEJOIN_173] (rows=2 width=228)
                                                            Conds:(Left Outer),Output:[""_col1"",""_col2"",""_col3""]
                                                          <-Reducer 3 [CUSTOM_SIMPLE_EDGE]
                                                            PARTITION_ONLY_SHUFFLE [RS_114]
                                                              Merge Join Operator [MERGEJOIN_172] (rows=2 width=116)
                                                                Conds:(Left Outer),Output:[""_col1"",""_col2""]
                                                              <-Reducer 2 [CUSTOM_SIMPLE_EDGE]
                                                                PARTITION_ONLY_SHUFFLE [RS_111]
                                                                  Merge Join Operator [MERGEJOIN_171] (rows=2 width=4)
                                                                    Conds:(Left Outer),Output:[""_col1""]
                                                                  <-Map 1 [CUSTOM_SIMPLE_EDGE] vectorized
                                                                    PARTITION_ONLY_SHUFFLE [RS_188]
                                                                      Select Operator [SEL_187] (rows=2 width=4)
                                                                        Filter Operator [FIL_186] (rows=2 width=4)
                                                                          predicate:(r_reason_sk = 1)
                                                                          TableScan [TS_0] (rows=72 width=4)
                                                                            default@reason,reason,Tbl:COMPLETE,Col:COMPLETE,Output:[""r_reason_sk""]
                                                                  <-Reducer 20 [CUSTOM_SIMPLE_EDGE] vectorized
                                                                    PARTITION_ONLY_SHUFFLE [RS_211]
                                                                      Select Operator [SEL_210] (rows=1 width=4)
                                                                        Output:[""_col0""]
                                                                        Group By Operator [GBY_209] (rows=1 width=8)
                                                                          Output:[""_col0""],aggregations:[""count(VALUE._col0)""]
                                                                        <-Map 17 [CUSTOM_SIMPLE_EDGE] vectorized
                                                                          PARTITION_ONLY_SHUFFLE [RS_206]
                                                                            Group By Operator [GBY_201] (rows=1 width=8)
                                                                              Output:[""_col0""],aggregations:[""count()""]
                                                                              Select Operator [SEL_196] (rows=182855757 width=3)
                                                                                Filter Operator [FIL_191] (rows=182855757 width=3)
                                                                                  predicate:ss_quantity BETWEEN 1 AND 20
                                                                                   Please refer to the previous TableScan [TS_66]
                                                              <-Reducer 26 [CUSTOM_SIMPLE_EDGE] vectorized
                                                                PARTITION_ONLY_SHUFFLE [RS_234]
                                                                  Select Operator [SEL_233] (rows=1 width=112)
                                                                    Output:[""_col0""]
                                                                    Group By Operator [GBY_232] (rows=1 width=120)
                                                                      Output:[""_col0"",""_col1""],aggregations:[""sum(VALUE._col0)"",""count(VALUE._col1)""]
                                                                    <-Map 23 [CUSTOM_SIMPLE_EDGE] vectorized
                                                                      PARTITION_ONLY_SHUFFLE [RS_229]
                                                                        Group By Operator [GBY_224] (rows=1 width=120)
                                                                          Output:[""_col0"",""_col1""],aggregations:[""sum(ss_ext_list_price)"",""count(ss_ext_list_price)""]
                                                                          Select Operator [SEL_219] (rows=182855757 width=110)
                                                                            Output:[""ss_ext_list_price""]
                                                                            Filter Operator [FIL_214] (rows=182855757 width=110)
                                                                              predicate:ss_quantity BETWEEN 1 AND 20
                                                                               Please refer to the previous TableScan [TS_73]
                                                          <-Reducer 32 [CUSTOM_SIMPLE_EDGE] vectorized
                                                            PARTITION_ONLY_SHUFFLE [RS_257]
                                                              Select Operator [SEL_256] (rows=1 width=112)
                                                                Output:[""_col0""]
                                                                Group By Operator [GBY_255] (rows=1 width=120)
                                                                  Output:[""_col0"",""_col1""],aggregations:[""sum(VALUE._col0)"",""count(VALUE._col1)""]
                                                                <-Map 29 [CUSTOM_SIMPLE_EDGE] vectorized
                                                                  PARTITION_ONLY_SHUFFLE [RS_252]
                                                                    Group By Operator [GBY_247] (rows=1 width=120)
                                                                      Output:[""_col0"",""_col1""],aggregations:[""sum(ss_net_paid_inc_tax)"",""count(ss_net_paid_inc_tax)""]
                                                                      Select Operator [SEL_242] (rows=182855757 width=110)
                                                                        Output:[""ss_net_paid_inc_tax""]
                                                                        Filter Operator [FIL_237] (rows=182855757 width=110)
                                                                          predicate:ss_quantity BETWEEN 1 AND 20
                                                                           Please refer to the previous TableScan [TS_80]
                              <-Reducer 18 [CUSTOM_SIMPLE_EDGE] vectorized
                                PARTITION_ONLY_SHUFFLE [RS_278]
                                  Select Operator [SEL_277] (rows=1 width=4)
                                    Output:[""_col0""]
                                    Group By Operator [GBY_276] (rows=1 width=8)
                                      Output:[""_col0""],aggregations:[""count(VALUE._col0)""]
                                    <-Map 17 [CUSTOM_SIMPLE_EDGE] vectorized
                                      PARTITION_ONLY_SHUFFLE [RS_204]
                                        Group By Operator [GBY_199] (rows=1 width=8)
                                          Output:[""_col0""],aggregations:[""count()""]
                                          Select Operator [SEL_194] (rows=182855757 width=3)
                                            Filter Operator [FIL_189] (rows=182855757 width=3)
                                              predicate:ss_quantity BETWEEN 61 AND 80
                                               Please refer to the previous TableScan [TS_66]
                          <-Reducer 24 [CUSTOM_SIMPLE_EDGE] vectorized
                            PARTITION_ONLY_SHUFFLE [RS_281]
                              Select Operator [SEL_280] (rows=1 width=112)
                                Output:[""_col0""]
                                Group By Operator [GBY_279] (rows=1 width=120)
                                  Output:[""_col0"",""_col1""],aggregations:[""sum(VALUE._col0)"",""count(VALUE._col1)""]
                                <-Map 23 [CUSTOM_SIMPLE_EDGE] vectorized
                                  PARTITION_ONLY_SHUFFLE [RS_227]
                                    Group By Operator [GBY_222] (rows=1 width=120)
                                      Output:[""_col0"",""_col1""],aggregations:[""sum(ss_ext_list_price)"",""count(ss_ext_list_price)""]
                                      Select Operator [SEL_217] (rows=182855757 width=110)
                                        Output:[""ss_ext_list_price""]
                                        Filter Operator [FIL_212] (rows=182855757 width=110)
                                          predicate:ss_quantity BETWEEN 61 AND 80
                                           Please refer to the previous TableScan [TS_73]
                      <-Reducer 30 [CUSTOM_SIMPLE_EDGE] vectorized
                        PARTITION_ONLY_SHUFFLE [RS_284]
                          Select Operator [SEL_283] (rows=1 width=112)
                            Output:[""_col0""]
                            Group By Operator [GBY_282] (rows=1 width=120)
                              Output:[""_col0"",""_col1""],aggregations:[""sum(VALUE._col0)"",""count(VALUE._col1)""]
                            <-Map 29 [CUSTOM_SIMPLE_EDGE] vectorized
                              PARTITION_ONLY_SHUFFLE [RS_250]
                                Group By Operator [GBY_245] (rows=1 width=120)
                                  Output:[""_col0"",""_col1""],aggregations:[""sum(ss_net_paid_inc_tax)"",""count(ss_net_paid_inc_tax)""]
                                  Select Operator [SEL_240] (rows=182855757 width=110)
                                    Output:[""ss_net_paid_inc_tax""]
                                    Filter Operator [FIL_235] (rows=182855757 width=110)
                                      predicate:ss_quantity BETWEEN 61 AND 80
                                       Please refer to the previous TableScan [TS_80]
                  <-Reducer 19 [CUSTOM_SIMPLE_EDGE] vectorized
                    PARTITION_ONLY_SHUFFLE [RS_287]
                      Select Operator [SEL_286] (rows=1 width=4)
                        Output:[""_col0""]
                        Group By Operator [GBY_285] (rows=1 width=8)
                          Output:[""_col0""],aggregations:[""count(VALUE._col0)""]
                        <-Map 17 [CUSTOM_SIMPLE_EDGE] vectorized
                          PARTITION_ONLY_SHUFFLE [RS_205]
                            Group By Operator [GBY_200] (rows=1 width=8)
                              Output:[""_col0""],aggregations:[""count()""]
                              Select Operator [SEL_195] (rows=182855757 width=3)
                                Filter Operator [FIL_190] (rows=182855757 width=3)
                                  predicate:ss_quantity BETWEEN 81 AND 100
                                   Please refer to the previous TableScan [TS_66]
              <-Reducer 25 [CUSTOM_SIMPLE_EDGE] vectorized
                PARTITION_ONLY_SHUFFLE [RS_290]
                  Select Operator [SEL_289] (rows=1 width=112)
                    Output:[""_col0""]
                    Group By Operator [GBY_288] (rows=1 width=120)
                      Output:[""_col0"",""_col1""],aggregations:[""sum(VALUE._col0)"",""count(VALUE._col1)""]
                    <-Map 23 [CUSTOM_SIMPLE_EDGE] vectorized
                      PARTITION_ONLY_SHUFFLE [RS_228]
                        Group By Operator [GBY_223] (rows=1 width=120)
                          Output:[""_col0"",""_col1""],aggregations:[""sum(ss_ext_list_price)"",""count(ss_ext_list_price)""]
                          Select Operator [SEL_218] (rows=182855757 width=110)
                            Output:[""ss_ext_list_price""]
                            Filter Operator [FIL_213] (rows=182855757 width=110)
                              predicate:ss_quantity BETWEEN 81 AND 100
                               Please refer to the previous TableScan [TS_73]
          <-Reducer 31 [CUSTOM_SIMPLE_EDGE] vectorized
            PARTITION_ONLY_SHUFFLE [RS_293]
              Select Operator [SEL_292] (rows=1 width=112)
                Output:[""_col0""]
                Group By Operator [GBY_291] (rows=1 width=120)
                  Output:[""_col0"",""_col1""],aggregations:[""sum(VALUE._col0)"",""count(VALUE._col1)""]
                <-Map 29 [CUSTOM_SIMPLE_EDGE] vectorized
                  PARTITION_ONLY_SHUFFLE [RS_251]
                    Group By Operator [GBY_246] (rows=1 width=120)
                      Output:[""_col0"",""_col1""],aggregations:[""sum(ss_net_paid_inc_tax)"",""count(ss_net_paid_inc_tax)""]
                      Select Operator [SEL_241] (rows=182855757 width=110)
                        Output:[""ss_net_paid_inc_tax""]
                        Filter Operator [FIL_236] (rows=182855757 width=110)
                          predicate:ss_quantity BETWEEN 81 AND 100
                           Please refer to the previous TableScan [TS_80]

{code}
{code}
TableScan [TS_80] (rows=575995635 width=110)
default@store_sales,store_sales,Tbl:COMPLETE,Col:COMPLETE,Output:[""ss_quantity"",""ss_net_paid_inc_tax""]
{code}
{code}
TableScan [TS_73] (rows=575995635 width=110)default@store_sales,store_sales,Tbl:COMPLETE,Col:COMPLETE,Output:[""ss_quantity"",""ss_ext_list_price""]
{code}
{code}
TableScan [TS_66] (rows=575995635 width=3)
default@store_sales,store_sales,Tbl:COMPLETE,Col:COMPLETE,Output:[""ss_quantity""]
{code}
Table *store_sales* read by three TableScans. The difference between then is the projected columns.
The goal of this patch is to merge those TableScan operators and project the columns from all three original TS."	HIVE	Closed	3	4	6200	pull-request-available
13470450	Invalid materialized view after rebuild if source table was compacted	"After HIVE-25656 MV state depends on the number of rows deleted/updated in the source tables of the view. However if one of the source tables are major compacted the delete delta files are no longer available and reproducing the rows should be deleted from the MV is no longer possible.

{code}
create table t1(a int, b varchar(128), c float) stored as orc TBLPROPERTIES ('transactional'='true');
insert into t1(a,b, c) values (1, 'one', 1.1), (2, 'two', 2.2), (NULL, NULL, NULL);
create materialized view mv1 stored as orc TBLPROPERTIES ('transactional'='true') as select a,b,c from t1 where a > 0 or a is null;
update t1 set b = 'Changed' where a = 1;
alter table t1 compact 'major';
alter materialized view t1 rebuild;
select * from mv1;
{code}
Select should result 
{code}
      ""1\tChanged\t1.1"",
      ""2\ttwo\t2.2"",
      ""NULL\tNULL\tNULL""
{code}
but was
{code}
      ""1\tone\t1.1"",      
      ""2\ttwo\t2.2"",
      ""NULL\tNULL\tNULL"",
      ""1\tChanged\t1.1""
{code}"	HIVE	Closed	3	1	6200	pull-request-available
13392531	Fetch writeId from insert-only transactional tables	"When generating plan for incremental materialized view rebuild a filter operator is inserted on top of each source table scans. The predicates contain a filter for writeId since we want to get all the rows inserted/deleted from the source tables since the last rebuild only.

WriteId is part of the ROW_ID virtual column and only available for fully-ACID ORC tables.

The goal of this jira is to populate a writeId when fetching from insert-only transactional tables.
{code:java}
create table t1(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true', 'transactional_properties'='insert_only');

...

SELECT t1.ROW__ID.writeId, a, b FROM t1;
{code}"	HIVE	Resolved	3	4	6200	pull-request-available
13565223	Shared work optimizer ignores schema merge setting in case of virtual column difference	"{code:java}
set hive.optimize.shared.work.merge.ts.schema=false;

create table t1(a int);

explain
WITH t AS (
  select BLOCK__OFFSET__INSIDE__FILE, INPUT__FILE__NAME, a from (
    select BLOCK__OFFSET__INSIDE__FILE, INPUT__FILE__NAME, a, row_number() OVER (partition by INPUT__FILE__NAME) rn from t1
    where a = 1
  ) q
  where rn=1
)
select BLOCK__OFFSET__INSIDE__FILE, INPUT__FILE__NAME, a from t1 where NOT (a = 1) AND INPUT__FILE__NAME IN (select INPUT__FILE__NAME from t)
union all
select * from t
{code}
Before SharedWorkOptimizer:
{code:java}
TS[0]-FIL[32]-SEL[2]-RS[14]-MERGEJOIN[42]-SEL[17]-UNION[27]-FS[29]
TS[3]-FIL[34]-RS[5]-SEL[6]-PTF[7]-FIL[33]-SEL[8]-GBY[13]-RS[15]-MERGEJOIN[42]
TS[18]-FIL[36]-RS[20]-SEL[21]-PTF[22]-FIL[35]-SEL[23]-UNION[27]
{code}
After SharedWorkOptimizer:
{code:java}
TS[0]-FIL[32]-SEL[2]-RS[14]-MERGEJOIN[42]-SEL[17]-UNION[27]-FS[29]
     -FIL[34]-RS[5]-SEL[6]-PTF[7]-FIL[33]-SEL[8]-GBY[13]-RS[15]-MERGEJOIN[42]
TS[18]-FIL[36]-RS[20]-SEL[21]-PTF[22]-FIL[35]-SEL[23]-UNION[27]
{code}
TS[3] and TS[18] are merged but their schema doesn't match and {{hive.optimize.shared.work.merge.ts.schema}} was turned off in the test
{code:java}
TS[3]: 0 = FILENAME
TS[18]: 0 = BLOCKOFFSET,  FILENAME
{code}"	HIVE	Closed	3	1	6200	pull-request-available
13475359	NPE when converting join to mapjoin and join column referenced more than once	"{code}
explain
select count(*)
from LU_CUSTOMER pa11
      join        ORDER_FACT        a15
      on         (pa11.CUSTOMER_ID = a15.CUSTOMER_ID)
      join        LU_CUSTOMER        a16
      on         (a15.CUSTOMER_ID = a16.CUSTOMER_ID and pa11.CUSTOMER_ID = a16.CUSTOMER_ID);
{code}
{{a16.CUSTOMER_ID}} is referenced more than once in the join condition.

Hive generates Reduce sink operators for the join's children and one of the RS row schema contains only one instance of the join keys (customer_id).
{code}
RS[13]                    
result = {HashMap@16092}  size = 2
 ""KEY.reducesinkkey0"" -> {ExprNodeColumnDesc@16083} ""Column[_col0]""
 ""KEY.reducesinkkey1"" -> {ExprNodeColumnDesc@16102} ""Column[_col0]""                    
 
 
result = {RowSchema@16104} ""(KEY.reducesinkkey0: int|{$hdt$_2}customer_id)""
 signature = {ArrayList@16110}  size = 1
  0 = {ColumnInfo@16087} ""KEY.reducesinkkey0: int""
{code}

{{KEY.reducesinkkey1}} is missing from the schema.

When converting the join to mapjoin the converter algorithm fails looking up both join key column instances.

https://github.com/apache/hive/blob/2aaba3c79e740ef27fc263b5a8ff33ad679c5a12/ql/src/java/org/apache/hadoop/hive/ql/plan/ExprNodeDescUtils.java#L538"	HIVE	Resolved	3	1	6200	pull-request-available
13565043	Materialized view with aggregate function incorrectly shows it allows incremental rebuild	"{code}
set hive.support.concurrency=true;
set hive.txn.manager=org.apache.hadoop.hive.ql.lockmgr.DbTxnManager;

create table store_sales (
  ss_sold_date_sk int,
  ss_ext_sales_price int,
  ss_customer_sk int
) stored as orc TBLPROPERTIES ('transactional'='true');

insert into store_sales (ss_sold_date_sk, ss_ext_sales_price, ss_customer_sk) values (2, 2, 2);

create materialized view mat1 stored as orc tblproperties ('format-version'='2') as
select ss_customer_sk
      ,min(ss_ext_sales_price)
      ,count(*)
 from store_sales
 group by ss_customer_sk;

delete from store_sales where ss_sold_date_sk = 1;

show materialized views;

explain cbo
alter materialized view mat1 rebuild;
{code}
Incremental rebuild is available
{code}
# MV Name           	Rewriting Enabled   	Mode                	Incremental rebuild 
mat1                	Yes                 	Manual refresh      	Available           
{code}
vs full rebuild plan
{code}
CBO PLAN:
HiveAggregate(group=[{2}], agg#0=[min($1)], agg#1=[count()])
  HiveTableScan(table=[[default, store_sales]], table:alias=[store_sales])
{code}
"	HIVE	Resolved	3	1	6200	hive-4.0.1-merged, pull-request-available
13579521	OOM/slow compilation when query contains SELECT clauses with nested expressions	"{code:sql}
CREATE TABLE t0 (`title` string);
SELECT x10 from
    (SELECT concat_ws('L10',x9, x9, x9, x9) as x10 from
        (SELECT concat_ws('L9',x8, x8, x8, x8) as x9 from
            (SELECT concat_ws('L8',x7, x7, x7, x7) as x8 from
                (SELECT concat_ws('L7',x6, x6, x6, x6) as x7 from
                    (SELECT concat_ws('L6',x5, x5, x5, x5) as x6 from
                        (SELECT concat_ws('L5',x4, x4, x4, x4) as x5 from
                            (SELECT concat_ws('L4',x3, x3, x3, x3) as x4 from
                                (SELECT concat_ws('L3',x2, x2, x2, x2) as x3 from
                                    (SELECT concat_ws('L2',x1, x1, x1, x1) as x2 from
                                        (SELECT concat_ws('L1',x0, x0, x0, x0) as x1 from
                                            (SELECT concat_ws('L0',title, title, title, title) as x0 from t0) t1) t2) t3) t4) t5) t6) t7) t8) t9) t10) t
WHERE x10 = 'Something';
{code}
The query above fails with OOM when run with the TestMiniLlapLocalCliDriver and the default max heap size configuration effective for tests (-Xmx2048m).

{noformat}
java.lang.OutOfMemoryError: Java heap space
	at java.util.Arrays.copyOf(Arrays.java:3332)
	at java.lang.AbstractStringBuilder.ensureCapacityInternal(AbstractStringBuilder.java:124)
	at java.lang.AbstractStringBuilder.append(AbstractStringBuilder.java:448)
	at java.lang.StringBuilder.append(StringBuilder.java:136)
	at org.apache.calcite.rex.RexCall.computeDigest(RexCall.java:152)
	at org.apache.calcite.rex.RexCall.toString(RexCall.java:165)
	at org.apache.calcite.rex.RexCall.appendOperands(RexCall.java:105)
	at org.apache.calcite.rex.RexCall.computeDigest(RexCall.java:151)
	at org.apache.calcite.rex.RexCall.toString(RexCall.java:165)
	at java.lang.String.valueOf(String.java:2994)
	at java.lang.StringBuilder.append(StringBuilder.java:131)
	at org.apache.calcite.rel.externalize.RelWriterImpl.explain_(RelWriterImpl.java:90)
	at org.apache.calcite.rel.externalize.RelWriterImpl.done(RelWriterImpl.java:144)
	at org.apache.calcite.rel.AbstractRelNode.explain(AbstractRelNode.java:246)
	at org.apache.calcite.rel.externalize.RelWriterImpl.explainInputs(RelWriterImpl.java:122)
	at org.apache.calcite.rel.externalize.RelWriterImpl.explain_(RelWriterImpl.java:116)
	at org.apache.calcite.rel.externalize.RelWriterImpl.done(RelWriterImpl.java:144)
	at org.apache.calcite.rel.AbstractRelNode.explain(AbstractRelNode.java:246)
	at org.apache.calcite.plan.RelOptUtil.toString(RelOptUtil.java:2308)
	at org.apache.calcite.plan.RelOptUtil.toString(RelOptUtil.java:2292)
	at org.apache.hadoop.hive.ql.optimizer.calcite.RuleEventLogger.ruleProductionSucceeded(RuleEventLogger.java:73)
	at org.apache.calcite.plan.MulticastRelOptListener.ruleProductionSucceeded(MulticastRelOptListener.java:68)
	at org.apache.calcite.plan.AbstractRelOptPlanner.notifyTransformation(AbstractRelOptPlanner.java:370)
	at org.apache.calcite.plan.hep.HepPlanner.applyTransformationResults(HepPlanner.java:702)
	at org.apache.calcite.plan.hep.HepPlanner.applyRule(HepPlanner.java:545)
	at org.apache.calcite.plan.hep.HepPlanner.applyRules(HepPlanner.java:407)
	at org.apache.calcite.plan.hep.HepPlanner.executeInstruction(HepPlanner.java:271)
	at org.apache.calcite.plan.hep.HepInstruction$RuleCollection.execute(HepInstruction.java:74)
	at org.apache.calcite.plan.hep.HepPlanner.executeProgram(HepPlanner.java:202)
	at org.apache.calcite.plan.hep.HepPlanner.findBestExp(HepPlanner.java:189)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner$CalcitePlannerAction.executeProgram(CalcitePlanner.java:2452)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner$CalcitePlannerAction.executeProgram(CalcitePlanner.java:2411)

{noformat}
"	HIVE	Resolved	3	1	6200	hive-4.0.1-merged, hive-4.0.1-must, pull-request-available
13222694	MERGE correctness issues with null safe equality	"The way Hive currently generates plan for MERGE statement can lead to wrong results with null safe equality.

To illustrate consider the following reproducer
{code:sql}
create table ttarget(s string, j int, flag string) stored as orc tblproperties(""transactional""=""true"");
truncate table ttarget;
insert into ttarget values('not_null', 1, 'dont udpate'), (null,2, 'update');

create table tsource (i int);
insert into tsource values(null),(2);
{code}

Let's say you have the following MERGE statement
{code:sql}
explain merge into ttarget using tsource on i<=>j
 when matched THEN
 	UPDATE set flag='updated'
 when not matched THEN
  	INSERT VALUES('new', 1999, 'true');
{code}

With this MERGE {{*ONLY ONE*}} row should match in target which should be updated. But currently due to the plan hive generate it will end up matching both rows.

This is because MERGE statement is rewritten into RIGHT OUTER JOIN + FILTER corresponding to all branches.

The part of the plan generated by hive for this statement consist of:
{noformat}
Map 2
            Map Operator Tree:
                TableScan
                  alias: tsource
                  Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE
                  Map Join Operator
                    condition map:
                         Right Outer Join 0 to 1
                    keys:
                      0 j (type: int)
                      1 i (type: int)
                    nullSafes: [true]
                    outputColumnNames: _col0, _col1, _col5, _col6
                    input vertices:
                      0 Map 1
                    Statistics: Num rows: 1 Data size: 206 Basic stats: COMPLETE Column stats: NONE
                    HybridGraceHashJoin: true
                    Filter Operator
                      predicate: (_col6 IS NOT DISTINCT FROM _col1) (type: boolean)
                      Statistics: Num rows: 1 Data size: 206 Basic stats: COMPLETE Column stats: NONE
                      Select Operator
                        expressions: _col5 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>), _col0 (type: string), _col1 (type: int)
                        outputColumnNames: _col0, _col1, _col2
                        Statistics: Num rows: 1 Data size: 206 Basic stats: COMPLETE Column stats: NONE
                        Reduce Output Operator
                          key expressions: _col0 (type: struct<writeid:bigint,bucketid:int,rowid:bigint>)
                          sort order: +
                          Map-reduce partition columns: UDFToInteger(_col0) (type: int)
                          Statistics: Num rows: 1 Data size: 206 Basic stats: COMPLETE Column stats: NONE
                          value expressions: _col1 (type: string), _col2 (type: int)
{noformat}

Result after JOIN will be :
{code:sql}
select s,j,i from ttarget right outer join tsource on i<=>j ;
NULL	NULL	NULL
NULL	NULL	2
{code}

On this resultset predicate {{(_col6 IS NOT DISTINCT FROM _col1)}} will be true for both resulting into both rows matching.
"	HIVE	Open	3	1	6200	pull-request-available
13479299	Case When Some result data is lost when there are common column conditions and partitioned column conditions 	"{code:java}https://issues.apache.org/jira/browse/HIVE-26505#
create table test0831 (id string) partitioned by (cp string);
insert into test0831 values ('a', '2022-08-23'),('c', '2022-08-23'),('d', '2022-08-23');
insert into test0831 values ('a', '2022-08-24'),('b', '2022-08-24');
select * from test0831;
+-------------+--------------+
| test0831.id | test0831.cp  |
+-------------+--------------+
| a         | 2022-08-23   |
| b        | 2022-08-23   |
| a        | 2022-08-23   |
| c        | 2022-08-24   |
| d        | 2022-08-24   |
+-------------+--------------+

select * from test0831 where (case when id='a' and cp='2022-08-23' then 1 else 0 end)=0;  
+--------------+--------------+
| test0830.id  | test0830.cp  |
+--------------+--------------+
| a        | 2022-08-24   |
| b        | 2022-08-24   |
+--------------+--------------+
{code}
 "	HIVE	Open	2	1	6200	check, hive-4.1.0-must, pull-request-available
13510452	Set column names in result schema when plan has Values root	"The query
{code}
select b1, count(a1) count1 from (select a1, b1 from t1) s where 1=0 group by b1;
{code}
should have a result with column names
{code}
b1	count1
{code}
but it is
{code}
$f0	$f1
{code}"	HIVE	Resolved	3	4	6200	pull-request-available
13243826	The list of table expression in the inclusion and exclusion list should be separated by '|' instead of comma.	Java regex expression does not support comma. If user wants multiple expression to be present in the include or exclude list, then the expressions can be provided separated by pipe ('|') character. The policy will look something like db_name.'(t1*)|(t3)'.'t100'	HIVE	Resolved	3	7	6781	DR, Replication, pull-request-available
13436825	Duplicate path/Jar in hive.aux.jars.path or hive.reloadable.aux.jars.path causing IllegalArgumentException	" hive.aux.jars.path and hive.reloadable.aux.jars.path  are used for providing auxiliary jars which are used doing query processing. These jars are copied to Tez temp path so that the Tez jobs have access to these jars while processing the job. There are a duplicate check to avoid copying the same jar multiple times. This check assumes the jar to be in local file system. But in real, the jars path can be anywhere. So this duplicate check fails, when the source path is not in local path.
{code:java}
ERROR : Failed to execute tez graph.
java.lang.IllegalArgumentException: Wrong FS: hdfs://localhost:53877/tmp/test_jar/identity_udf.jar, expected: file:///
    at org.apache.hadoop.fs.FileSystem.checkPath(FileSystem.java:781) ~[hadoop-common-3.1.0.jar:?]
    at org.apache.hadoop.fs.RawLocalFileSystem.pathToFile(RawLocalFileSystem.java:86) ~[hadoop-common-3.1.0.jar:?]
    at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:636) ~[hadoop-common-3.1.0.jar:?]
    at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:930) ~[hadoop-common-3.1.0.jar:?]
    at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:631) ~[hadoop-common-3.1.0.jar:?]
    at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:454) ~[hadoop-common-3.1.0.jar:?]
    at org.apache.hadoop.hive.ql.exec.tez.DagUtils.checkPreExisting(DagUtils.java:1392) ~[hive-exec-4.0.0-alpha-1.jar:4.0.0-alpha-1]
    at org.apache.hadoop.hive.ql.exec.tez.DagUtils.localizeResource(DagUtils.java:1411) ~[hive-exec-4.0.0-alpha-1.jar:4.0.0-alpha-1]
    at org.apache.hadoop.hive.ql.exec.tez.DagUtils.addTempResources(DagUtils.java:1295) ~[hive-exec-4.0.0-alpha-1.jar:4.0.0-alpha-1]
    at org.apache.hadoop.hive.ql.exec.tez.DagUtils.localizeTempFilesFromConf(DagUtils.java:1177) ~[hive-exec-4.0.0-alpha-1.jar:4.0.0-alpha-1]
    at org.apache.hadoop.hive.ql.exec.tez.TezSessionState.ensureLocalResources(TezSessionState.java:636) ~[hive-exec-4.0.0-alpha-1.jar:4.0.0-alpha-1]
    at org.apache.hadoop.hive.ql.exec.tez.TezSessionState.openInternal(TezSessionState.java:283) ~[hive-exec-4.0.0-alpha-1.jar:4.0.0-alpha-1]
    at org.apache.hadoop.hive.ql.exec.tez.TezSessionPoolSession.openInternal(TezSessionPoolSession.java:124) ~[hive-exec-4.0.0-alpha-1.jar:4.0.0-alpha-1]
    at org.apache.hadoop.hive.ql.exec.tez.TezSessionState.open(TezSessionState.java:241) ~[hive-exec-4.0.0-alpha-1.jar:4.0.0-alpha-1]
    at org.apache.hadoop.hive.ql.exec.tez.TezTask.ensureSessionHasResources(TezTask.java:448) ~[hive-exec-4.0.0-alpha-1.jar:4.0.0-alpha-1]
    at org.apache.hadoop.hive.ql.exec.tez.TezTask.execute(TezTask.java:215) [hive-exec-4.0.0-alpha-1.jar:4.0.0-alpha-1]
    at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:212) [hive-exec-4.0.0-alpha-1.jar:4.0.0-alpha-1]
    at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:105) [hive-exec-4.0.0-alpha-1.jar:4.0.0-alpha-1]
    at org.apache.hadoop.hive.ql.Executor.launchTask(Executor.java:361) [hive-exec-4.0.0-alpha-1.jar:4.0.0-alpha-1]
    at org.apache.hadoop.hive.ql.Executor.launchTasks(Executor.java:334) [hive-exec-4.0.0-alpha-1.jar:4.0.0-alpha-1]
    at org.apache.hadoop.hive.ql.Executor.runTasks(Executor.java:245) [hive-exec-4.0.0-alpha-1.jar:4.0.0-alpha-1]
    at org.apache.hadoop.hive.ql.Executor.execute(Executor.java:106) [hive-exec-4.0.0-alpha-1.jar:4.0.0-alpha-1]
    at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:348) [hive-exec-4.0.0-alpha-1.jar:4.0.0-alpha-1]
    at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:204) [hive-exec-4.0.0-alpha-1.jar:4.0.0-alpha-1]
    at org.apache.hadoop.hive.ql.Driver.run(Driver.java:153) [hive-exec-4.0.0-alpha-1.jar:4.0.0-alpha-1]
    at org.apache.hadoop.hive.ql.Driver.run(Driver.java:148) [hive-exec-4.0.0-alpha-1.jar:4.0.0-alpha-1]
    at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:185) [hive-exec-4.0.0-alpha-1.jar:4.0.0-alpha-1]
    at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:233) [hive-service-4.0.0-alpha-1.jar:4.0.0-alpha-1]
    at org.apache.hive.service.cli.operation.SQLOperation.access$500(SQLOperation.java:88) [hive-service-4.0.0-alpha-1.jar:4.0.0-alpha-1]
    at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:336) [hive-service-4.0.0-alpha-1.jar:4.0.0-alpha-1]
    at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_282]
    at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_282]
    at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682) [hadoop-common-3.1.0.jar:?]
    at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:356) [hive-service-4.0.0-alpha-1.jar:4.0.0-alpha-1]
    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_282]
    at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_282]
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_282]
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_282]
    at java.lang.Thread.run(Thread.java:748) [?:1.8.0_282] {code}
 "	HIVE	Resolved	3	1	6781	pull-request-available
13215437	Hive replication to a target with hive.strict.managed.tables enabled is failing when used HMS on postgres.	"Missing quotes in sql string is causing sql execution error for postgres.

 
{code:java}
metastore.RetryingHMSHandler (RetryingHMSHandler.java:invokeInternal(201)) - MetaException(message:Unable to update transaction database org.postgresql.util.PSQLException: ERROR: relat
ion ""database_params"" does not exist
Position: 25
at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2284)
at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2003)
at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:200)
at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:424)
at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:321)
at org.postgresql.jdbc.PgStatement.executeQuery(PgStatement.java:284)
at com.zaxxer.hikari.pool.ProxyStatement.executeQuery(ProxyStatement.java:108)
at com.zaxxer.hikari.pool.HikariProxyStatement.executeQuery(HikariProxyStatement.java)
at org.apache.hadoop.hive.metastore.txn.TxnHandler.updateReplId(TxnHandler.java:907)
at org.apache.hadoop.hive.metastore.txn.TxnHandler.commitTxn(TxnHandler.java:1023)
at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.commit_txn(HiveMetaStore.java:7703)
at sun.reflect.GeneratedMethodAccessor43.invoke(Unknown Source)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:498)
at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
at com.sun.proxy.$Proxy39.commit_txn(Unknown Source)
at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$commit_txn.getResult(ThriftHiveMetastore.java:18730)
at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$commit_txn.getResult(ThriftHiveMetastore.java:18714)
at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
at org.apache.hadoop.hive.metastore.security.HadoopThriftAuthBridge$Server$TUGIAssumingProcessor$1.run(HadoopThriftAuthBridge.java:636)
at org.apache.hadoop.hive.metastore.security.HadoopThriftAuthBridge$Server$TUGIAssumingProcessor$1.run(HadoopThriftAuthBridge.java:631)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:422)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
at org.apache.hadoop.hive.metastore.security.HadoopThriftAuthBridge$Server$TUGIAssumingProcessor.process(HadoopThriftAuthBridge.java:631)
at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
at java.lang.Thread.run(Thread.java:748)
){code}
 "	HIVE	Closed	3	1	6781	pull-request-available
13382372	Reduce overhead of adding notification log for update partition column statistics	The notification logs for partition column statistics can be optimised by adding them in batch. In the current implementation its done one by one causing multiple sql execution in the backend RDBMS. These SQL executions can be batched to reduce the execution time.	HIVE	Resolved	3	7	6781	perfomance, pull-request-available
13279714	After disable operation log property in hive, still HS2 saving the operation log	"There are few issues in this area.
 1. If logging is disabled using hive.server2.logging.operation.enabled, then operation logs for the queries should not be generated. But the registerLoggingContext method in LogUtils, registers the logging context  even if the operation log is disabled. This causes the logs to be added by logger. The registration of query context should be done only if operation logging is enabled.
{code:java}
 public static void registerLoggingContext(Configuration conf) {
-    MDC.put(SESSIONID_LOG_KEY, HiveConf.getVar(conf, HiveConf.ConfVars.HIVESESSIONID));
-    MDC.put(QUERYID_LOG_KEY, HiveConf.getVar(conf, HiveConf.ConfVars.HIVEQUERYID));
     if (HiveConf.getBoolVar(conf, HiveConf.ConfVars.HIVE_SERVER2_LOGGING_OPERATION_ENABLED)) {
+      MDC.put(SESSIONID_LOG_KEY, HiveConf.getVar(conf, HiveConf.ConfVars.HIVESESSIONID));
+      MDC.put(QUERYID_LOG_KEY, HiveConf.getVar(conf, HiveConf.ConfVars.HIVEQUERYID));
       MDC.put(OPERATIONLOG_LEVEL_KEY, HiveConf.getVar(conf, HiveConf.ConfVars.HIVE_SERVER2_LOGGING_OPERATION_LEVEL));{code}
 

2. In case of failed query, we close the operations and that deletes the logging context (appender and route) from logger for that query. But if any log is added after that, the query logs are getting added and new operation log file is getting generated for the query. This looks like issue with MCD clear. MCD clear is not removing the keys from the map. If remove is used instead of clear, its working fine."	HIVE	Closed	3	1	6781	pull-request-available
13157268	REPL LOAD creates staging directory in source dump directory instead of table data location	REPL LOAD creates staging directory in source dump directory instead of table data location. In case of replication from on-perm to cloud it can create problem. 	HIVE	Closed	3	1	6781	Hive, Repl, pull-request-available
13197377	TestJdbcDriver2#testSelectExecAsync2 fails with result set not present error	if async prepare is enabled, control will be returned to the client before driver could set of the query has a result set or not. But in current code, while generating the response for the query, it is not checked if the result set field is set or not. 	HIVE	Resolved	3	1	6781	pull-request-available
13417478	Analyse table does not fail for non existing partitions	"If all the column names are given in the analyse command , then the query fails. But if all the partition column values are not given then its not failing.

analyze table tbl partition *(fld1 = 2, fld2 = 3)* COMPUTE STATISTICS FOR COLUMNS – This will fail with SemanticException, if partition corresponds to fld1 = 2, fld2 = 3 does not exists. But analyze table tbl partition *(fld1 = 2)* COMPUTE STATISTICS FOR COLUMNS, this will not fail and it will compute stats for whole table.

 "	HIVE	Open	3	1	6781	pull-request-available
13393197	Null bit vector is not handled while getting the stats for Postgres backend	"While adding stats with null bit vector, a special string ""HL"" is added as Postgres does not support null value for byte columns. But while getting the stats, the conversion to null is not done. This is causing failure during deserialisation of bit vector field if the existing stats is used for merge.

 
{code:java}
 The input stream is not a HyperLogLog stream.  7276-1 instead of 727676 or 7077^M        at org.apache.hadoop.hive.common.ndv.hll.HyperLogLogUtils.checkMagicString(HyperLogLogUtils.java:349)^M at org.apache.hadoop.hive.common.ndv.hll.HyperLogLogUtils.deserializeHLL(HyperLogLogUtils.java:139)^M   at org.apache.hadoop.hive.common.ndv.hll.HyperLogLogUtils.deserializeHLL(HyperLogLogUtils.java:213)^M   at org.apache.hadoop.hive.common.ndv.hll.HyperLogLogUtils.deserializeHLL(HyperLogLogUtils.java:227)^M   at org.apache.hadoop.hive.common.ndv.NumDistinctValueEstimatorFactory.getNumDistinctValueEstimator(NumDistinctValueEstimatorFactory.java:53)^M  at org.apache.hadoop.hive.metastore.columnstats.cache.LongColumnStatsDataInspector.updateNdvEstimator(LongColumnStatsDataInspector.java:124)^M  at org.apache.hadoop.hive.metastore.columnstats.cache.LongColumnStatsDataInspector.getNdvEstimator(LongColumnStatsDataInspector.java:107)^M     at org.apache.hadoop.hive.metastore.columnstats.merge.LongColumnStatsMerger.merge(LongColumnStatsMerger.java:36)^M      at org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.mergeColStats(MetaStoreUtils.java:1174)^M      at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.updateTableColumnStatsWithMerge(HiveMetaStore.java:8934)^M at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.set_aggr_stats_for(HiveMetaStore.java:8800)^M      at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)^M        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)^M      at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)^M      at java.lang.reflect.Method.invoke(Method.java:498)^M   at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:160)^M    at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:121)^M    at com.sun.proxy.$Proxy35.set_aggr_stats_for(Unknown Source)^M  at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$set_aggr_stats_for.getResult(ThriftHiveMetastore.java:20489)^M    at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$set_aggr_stats_for.getResult(ThriftHiveMetastore.java:20473)^M    at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)^M at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)^M   at org.apache.hadoop.hive.metastore.security.HadoopThriftAuthBridge$Server$TUGIAssumingProcessor$1.run(HadoopThriftAuthBridge.java:643)^M       at org.apache.hadoop.hive.metastore.security.HadoopThriftAuthBridge$Server$TUGIAssumingProcessor$1.run(HadoopThriftAuthBridge.java:638)^M       at java.security.AccessController.doPrivileged(Native Method)^M at javax.security.auth.Subject.doAs(Subject.java:422)^M at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1898)^M       at org.apache.hadoop.hive.metastore.security.HadoopThriftAuthBridge$Server$TUGIAssumingProcessor.process(HadoopThriftAuthBridge.java:638)^M     at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)^M   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)^M    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)^M    at java.lang.Thread.run(Thread.java:748) {code}"	HIVE	Resolved	3	7	6781	pull-request-available
13329214	Map side SMB join is producing wrong result	"{code:java}
 CREATE TABLE tbl1_n5(key int, value string) CLUSTERED BY (key) SORTED BY (key) INTO 2 BUCKETS ;
 CREATE TABLE tbl2_n4(key int, value string) CLUSTERED BY (key) SORTED BY (key) INTO 2 BUCKETS;

 set hive.auto.convert.join=true;
 set hive.optimize.bucketmapjoin = true;
 set hive.optimize.bucketmapjoin.sortedmerge = true;
 set hive.input.format = org.apache.hadoop.hive.ql.io.BucketizedHiveInputFormat;
 set hive.auto.convert.sortmerge.join=true;
 set hive.auto.convert.sortmerge.join.to.mapjoin=false;
 set hive.auto.convert.join.noconditionaltask.size=1;
 set hive.optimize.semijoin.conversion = false;

 insert into tbl2_n4 values (2, 'val_2'), (0, 'val_0'), (0, 'val_0'), (0, 'val_0'), (4, 'val_4') ,(5, 'val_5') ,(5, 'val_5') , (5, 'val_5'), (8, 'val_8'), (9, 'val_9');

 insert into tbl1_n5 values (2, 'val_2'), (0, 'val_0'), (0, 'val_0'), (0, 'val_0'), (4, 'val_4') ,(5, 'val_5') ,(5, 'val_5') , (5, 'val_5'), (8, 'val_8'), (9, 'val_9');{code}
 

 
{code:java}
 Select * from (select b.key as key, count as value from tbl1_n5 b where key < 6 group by b.key) subq1 join (select a.key as key, a.value as value from tbl2_n4 a where key < 6) subq2 on subq1.key = subq2.key;{code}
 

The above select is producing 0,0,0,2,4,5,5,5,5,5,5 instead of 0,0,0,2,4,5,5,5. The input format for sorted tables should be set to BucketizedHiveInputFormat instead of HiveInputFormat. This is done only for MapWork. But if the root task in a MapJoinWork, it is not handled. This is causing the mapper to create splits more than the number of buckets and resulting into extra records.

 "	HIVE	Resolved	3	1	6781	pull-request-available
13187232	Hive returns 20011 error code for re-triable error	"In case of network issue .repl load is returning non retry-able error code. 

The scenario is 
1. While copying the file, repl load found that source is not reachable and went for copy retry.
2. While retying, getting file checksum failed due to network issue and thus its assumed that the source file is not present. So in the next retry copy is tried from cm path.
3. In the next retry, network is recovered and it in cm path no file was found. This will cause return of non retry-able error."	HIVE	Closed	3	1	6781	pull-request-available
13343919	Add support for combiner in hash mode group aggregation 	"In map side group aggregation, partial grouped aggregation is calculated to reduce the data written to disk by map task. In case of hash aggregation, where the input data is not sorted, hash table is used (with sorting also being performed before flushing). If the hash table size increases beyond configurable limit, data is flushed to disk and new hash table is generated. If the reduction by hash table is less than min hash aggregation reduction calculated during compile time, the map side aggregation is converted to streaming mode. So if the first few batch of records does not result into significant reduction, then the mode is switched to streaming mode. This may have impact on performance, if the subsequent batch of records have less number of distinct values. 

To improve performance both in Hash and Streaming mode, a combiner can be added to the map task after the keys are sorted. This will make sure that the aggregation is done if possible and reduce the data written to disk."	HIVE	Open	3	1	6781	pull-request-available
13194050	Hive does not copy source data when importing as non-hive user 	while loading data to a managed table from user given path, Hive uses move operation to copy data from user location to table location. In case move can not be used due to permission issue or mismatched encryption zone etc, hive uses copy and then deletes the files from source location to keep to behavior same. But in case the user does not have write access to the source location, delete will fail with file permission exception and load operation will fail. 	HIVE	Closed	3	1	6781	pull-request-available
13370243	Add support for complex types columns for Dynamic Partition pruning Optimisation	DynamicPartitionPruningOptimization fails for complex types.  	HIVE	Open	3	1	6781	pull-request-available
13432843	Insert with partition value containing colon and space is creating partition having wrong value	The path used for generating the dynamic partition value is obtained from uri. This is causing the serialised value to be used for partition name generation and wrong names are generated. The path value should be used, not the URI.	HIVE	Resolved	3	1	6781	pull-request-available
13382373	Reduce overhead of adding write notification log during batch loading of partition..	During batch loading of partition the write notification logs are added for each partition added. This is causing delay in execution as the call to HMS is done for each partition. This can be optimised by adding a new API in HMS to send a batch of partition and then this batch can be added together to the backend database. Once we have a batch of notification log, at HMS side, code can be optimised to add the logs using single call to backend RDBMS. 	HIVE	Closed	3	7	6781	performance
13170768	Incremental repl load DAG generation is causing OOM error.	Split the incremental load into multiple iterations. In each iteration create number of tasks equal to the configured value.	HIVE	Closed	3	3	6781	pull-request-available
13205867	Support statistics in cachedStore for transactional table	Currently statistics for transactional table is not stored in cached store for consistency issues. Need to add validation for valid write ids and generation of aggregate stats based on valid partitions. 	HIVE	Resolved	3	3	6781	pull-request-available
13340305	Leading and trailing spaces are not removed before decimal conversion	The decimal conversion is not removing the extra spaces in some scenarios. because of this the numbers are getting converted to null.	HIVE	Closed	3	1	6781	pull-request-available
13365022	Support ARRAY/STRUCT  types in equality SMB and Common merge join	Hive fails to execute joins on array type columns as the comparison functions are not able to handle array and struct type columns.   	HIVE	Closed	3	7	6781	pull-request-available
13340123	Wrong predicate is pushed down for view with constant value projection.	"For below query the predicate pushed down for one of the table scan is not proper.

 
{code:java}
set hive.explain.user=false;
set hive.cbo.enable=false;
set hive.optimize.ppd=true;DROP TABLE arc;

CREATE table arc(`dt_from` string, `dt_to` string);
CREATE table loc1(`dt_from` string, `dt_to` string);

CREATE
 VIEW view AS
     SELECT
        '9999' as DT_FROM,
        uuid() as DT_TO
     FROM
       loc1
 UNION ALL
     SELECT
        dt_from as DT_FROM,
        uuid() as DT_TO
     FROM
       arc;

EXPLAIN
    SELECT
      dt_from, dt_to
    FROM
      view
    WHERE
      '2020'  between dt_from and dt_to;


{code}
 

For table loc1,  DT_FROM is projected as '9999' so the predicate ""predicate: '2020' BETWEEN '9999' AND _col1 (type: boolean)"" is proper. But for table arc, the column is projected so the predicate should be ""predicate: '2020' BETWEEN _col0 (type: boolean) AND _col1 (type: boolean)"".

This is because the predicates are stored in a map for each expression. Here the expression is ""_col0"". When the predicate is pushed down the union, the same predicate is used for creating the filter expression. Later when constant replacement is done, the first filter is overwriting the second one.

So we should create a clone (as done at other places) before using the cached predicate for filter. This way the overwrite can be avoided.   

 "	HIVE	Resolved	3	1	6781	pull-request-available
13149458	Create/Replicate Allocate write-id event	"*EVENT_ALLOCATE_WRITE_ID*
*Source Warehouse:*
 * Create new event type EVENT_ALLOCATE_WRITE_ID with related message format etc.

 * Capture this event when allocate a table write ID from the sequence table by ACID operation.

 * Repl dump should read this event from EventNotificationTable and dump the message.

*Target Warehouse:*
 * Repl load should read the event from the dump and get the message.

 * Validate if source txn ID from the event is there in the source-target txn ID map. If not there, just noop the event.

 * If valid, then Allocate table write ID from sequence table

*Extend listener notify event API to add two new parameter , dbconn and sqlgenerator to add the events to notification_log table within the same transaction* "	HIVE	Closed	3	7	6781	ACID, DR, pull-request-available, replication
13213247	Hive replication can add duplicate data during migration to a target with hive.strict.managed.tables enabled	During bootstrap phase it may happen that the files copied to target are created by events which are not part of the bootstrap. This is because of the fact that, bootstrap first gets the last event id and then the file list. During this period if some event are added, then bootstrap will include files created by these events also.The same files will be copied again during the first incremental replication just after the bootstrap. In normal scenario, the duplicate copy does not cause any issue as hive allows the use of target database only after the first incremental. But in case of migration, the file at source and target are copied to different location (based on the write id at target) and thus this may lead to duplicate data at target. This can be avoided by having at check at load time for duplicate file. This check can be done only for the first incremental and the search can be done in the bootstrap directory (with write id 1). if the file is already present then just ignore the copy.	HIVE	Resolved	3	3	6781	pull-request-available
13381367	Analyse and optimise execution time for batch loading of partitions.	When load partition is done in batch, of more than 10k, the execution time is exceeding hours. This may be an issue for ETL type of work load. This task is to track the issues and fix it.	HIVE	Open	3	3	6781	performance
13218050	Hive external table replication failed with Permission denied issue.	"During external table replication the file copy is done in parallel to the meta data replication. If the file copy task creates the directory with do as set to true, it will create the directory with permission set to the user running the repl command. In that case the meta data task while creating the table may fail as hive user might not have access to the created directory.

The fix should be
 # While creating directory, if sql based authentication is enabled, then disable storage based authentication for hive user.
 # Currently the created directory has the login user access, it should retain the source clusters owner, group and permission.
 # For external table replication don't create the directory during create table and add partition.

 "	HIVE	Closed	3	1	6781	pull-request-available
13183581	Creation of staging directory and Move operation is taking time in S3	Operations like insert and add partition creates a staging directory to generate the files and then move the files created to actual location. In replication flow, the files are first copied to the staging directory and then moved (rename) to the actual table location. In case of S3, move is not an atomic operation. It internally does a copy and delete. So it can not guarantee the consistency required. So it is better to copy the files directly to the actual location. This will help in avoiding the staging directory creation (which takes 1-2 seconds in s3) and move (which takes time proportional to file size).	HIVE	Closed	3	7	6781	pull-request-available
13232923	REPL:: logs are missing in hiveStatement.getQueryLog output during parallel execution mode.	"getQueryLog only reads logs from Background thread scope. If parallel execution is set to true, a new thread is created for execution and all the logs added by the new thread are not added to the parent  Background thread scope. In replication scope, replStateLogTasks are started in parallel mode causing the logs to be skipped from getQueryLog scope. 

There is one more issue, with the conf is not passed while creating replStateLogTask during bootstrap load end. The same issue is there with event load during incremental load. The incremental load end log task is created with the proper config. "	HIVE	Closed	3	1	6781	pull-request-available
13233409	Hive import fails, post upgrade of source 3.0 cluster, to a target 4.0 cluster with strict managed table set to true.	"The scenario is 
 # Replication policy is set with hive  3.0 source cluster (strict managed table set to false) and hive 4.0 target cluster with strict managed table set  true.
 # User upgrades the 3.0 source cluster to 4.0 cluster using upgrade tool.
 # The upgrade converts all managed tables to acid tables.
 # In the next repl dump, user sets hive .repl .dump .include .acid .tables and hive .repl .bootstrap. acid. tables set true triggering bootstrap of newly converted ACID tables.
 # As the old tables are non-txn tables, dump is not filtering the events even tough bootstrap acid table is set to true. This is causing the repl load to fail as the write id is not set in the table object.
 # If we ignore the event replay, the bootstrap is failing with dump directory mismatch error.

The fix should be 
 # Ignore dumping the alter table event if bootstrap acid table is set true and the alter is converting a non-acid table to acid table.
 # In case of bootstrap during incremental load, ignore the dump directory property set in table object."	HIVE	Resolved	3	1	6781	pull-request-available
13390610	Optimize set_aggr_stats_for for mergeColStats path. 	"The optimisation used for normal path to use direct sql can also be used for mergeColStats

path. The stats to be updated can be accumulated in a temp list and that list can be used to update the stats in a batch."	HIVE	Resolved	3	7	6781	pull-request-available
13312017	Support Anti Join in Hive 	"Currently hive does not support Anti join. The query for anti join is converted to left outer join and null filter on right side join key is added to get the desired result. This is causing
 # Extra computation — The left outer join projects the redundant columns from right side. Along with that, filtering is done to remove the redundant rows. This is can be avoided in case of anti join as anti join will project only the required columns and rows from the left side table.
 # Extra shuffle — In case of anti join the duplicate records moved to join node can be avoided from the child node. This can reduce significant amount of data movement if the number of distinct rows( join keys) is significant.
 # Extra Memory Usage - In case of map based anti join , hash set is sufficient as just the key is required to check  if the records matches the join condition. In case of left join, we need the key and the non key columns also and thus a hash table will be required.

For a query like
{code:java}
 select wr_order_number FROM web_returns LEFT JOIN web_sales  ON wr_order_number = ws_order_number WHERE ws_order_number IS NULL;{code}
The number of distinct ws_order_number in web_sales table in a typical 10TB TPCDS set up is just 10% of total records. So when we convert this query to anti join, instead of 7 billion rows, only 600 million rows are moved to join node.

In the current patch, just one conversion is done. The pattern of project->filter->left-join is converted to project->anti-join. This will take care of sub queries with “not exists” clause. The queries with “not exists” are converted first to filter + left-join and then its converted to anti join. The queries with “not in” are not handled in the current patch.

From execution side, both merge join and map join with vectorized execution  is supported for anti join."	HIVE	Closed	3	1	6781	pull-request-available
13137728	create/replicate open transaction event	"*EVENT_OPEN_TXN:*
*Source Warehouse:*
 - Create new event type EVENT_OPEN_TXN with related message format etc.
 - When any transaction is opened either by auto-commit mode or multi-statement mode, need to capture this event.
 - Repl dump should read this event from EventNotificationTable and dump the message.

*Target Warehouse:*
 - Repl load should read the event from the dump and get the message.
 - Open a txn in target warehouse.
 - Create a map of source txn ID against target txn ID and persist the same in metastore. There should be one map per replication policy (DBName.* incase of DB level replication, DBName.TableName incase of table level replication)"	HIVE	Closed	3	7	6781	pull-request-available
13379435	Rehashing in map join fast hash table  causing corruption for large keys	In map join the hash table is created using the keys. To support rehashing, the keys are stored in write buffer. The hash table contains the offset of the keys along with the hash code. When rehashing is done, the offset is extracted from the hash table and then hash code is generated again. For large keys of size greater than 255, the key length is also stored along with the key. In case of fast hash table implementation the way key is extracted is not proper. There is a code bug and thats causing the wrong key to be extracted and causing wrong hash code generation. This is causing the corruption in the hash table.	HIVE	Closed	3	1	6781	pull-request-available
13342057	Use LazyBinarySerDe2 in PlanUtils::getReduceValueTableDesc	"!Screenshot 2020-11-23 at 10.52.49 AM.png|width=858,height=493!  

Lines of interest:

[https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java#L535] (non-vectorized path due to stats)

 

[https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/plan/PlanUtils.java#L581]

 

 

 

 

 "	HIVE	Closed	3	4	6781	pull-request-available
13171064	SQL Script changes for creating  txn write notification in 3.2.0 files 	"1. Change partition name size from 1024 to 767 . (mySQL 5.6 and before that supports max 767 length keys)

 2. Remove the create txn_write_notification_log table creation from 3.1.0 scripts and add a new scripts for 3.2.0

3. Remove the file 3.1.0-to-4.0.0 and instead add file for 3.2.0-to-4.0.0 and 3.1.0-to-3.2.0

4. Change in metastore init schema  xml file to take 4.0.0 instead of 3.1.0 as current version.
h1.  "	HIVE	Closed	3	7	6781	ACID, DR, pull-request-available, replication
13217723	Hive Replication not retaining the owner in the replicated table	Hive Replication not retaining the owner in the replicated table. The owner for the target table is set same as the user executing the load command. The user information should be read from the dump metadata and should be used while creating the table at target cluster.	HIVE	Resolved	3	1	6781	pull-request-available
13235281	Support replication from haddop-2 (hive 3.0 and beelow) on-prem cluster to hadoop-3 (hive 4 and above) cloud cluster	"In case of replication to cloud both dump and load are executed in the source cluster. This push based replication is done to avoid computation at target cloud cluster. In case in the source cluster, strict managed table is not set to true the tables will be non acid. So during replication to a cluster with strict managed table, migration logic same as upgrade tool has to be applied on the replicated data. This migration logic is implemented only in hive4.0. So it's required that a hive 4.0 instance started at the source cluster. If the source cluster has hadoop-2 installation, hive4 has to be built with hadoop-2 and necessary changes are required in the pom files and the shim files.

1. Change the pom.xml files to accept a profile for hadoop-2. If hadoop-2 profile is set, the hadoop version should be set accordingly to hadoop-2.

2. In shim creare a new file for hadoop-2. Based on the profile the respective file will be included in the build.

3. Changed artifactId hadoop-hdfs-client to hadoop-client as in hadoop-2 the jars are stored under hadoop-client folder.

 

 

Command to enable hadop-2 dependency  —  mvn clean install package -DskipTests  -Pdist -pl '!standalone-metastore, !llap-common, !llap-client, !llap-ext-client, !llap-tez, !llap-server, !hbase-handler, !service, !hplsql, !kryo-registrator' -Phadoop-2.7

 "	HIVE	Patch Available	3	3	6781	pull-request-available
13189099	Bootstrap is missing partitions in replicated DB when retry after kill query.	"The issue is

1. When bootstrap was going on, kill query was called to kill the repl load command.
2. During restart, one table with no partition set the scope to table as the ckpt property was not yet set for that table.
3. Due to this, all partitioned table after this didn't get their tasks related to partition appended in the root task if the ckpt property is already updated for those tables.

The fix is to reset the table scope to false if for that table there are no tasks added."	HIVE	Closed	3	1	6781	pull-request-available
13200424	Support bootstrap and incremental replication to a target with hive.strict.managed.tables enabled.	"*Requirements:*
Hive2 supports replication of managed tables. But in Hive3 with hive.strict.managed.tables=true, some of these managed tables are converted to ACID or MM tables. Also, some of them are converted to external tables based on below rules. 
- Avro format with external schema, Storage handlers, List bucketed tabled are converted to external tables.
- Location not owned by ""hive"" user are converted to external table.
- Hive owned ORC format are converted to full ACID transactional table.
- Hive owned Non-ORC format are converted to MM transactional table.

REPL LOAD should apply these rules during bootstrap and incremental phases and convert the tables accordingly."	HIVE	Resolved	3	7	6781	DR
13258454	Hive replication fails with table already exist error when replicating from old version of hive.	"HIve replication from old version where HIVE-22046 is not patched will not have engine column set in the table column stats. This causes ""ERROR: null value in column ""ENGINE"" violates not-null constraint"" error during create table while updating the column stats. As the column stats are updated after the create table txn is committed, the next retry by HMS client throws table already exist error. Need to update the ENGINE column to default value while importing the table if the column value is not set. The column stat and create table in same txn can be done as part of separate Jira."	HIVE	Resolved	3	1	6781	pull-request-available
13184229	One of the task , either move or add partition can be avoided in repl load flow	In replication load, both add partition and insert operations are handled through import. Import creates 3 major tasks. Copy, add partition and move. Copy does the copy of data from source location to staging directory. Then add partition (which runs in parallel to copy) creates the partition in meta store. Its a no op in case of insert and by the time this ddl task is executed for insert partition would be already present. The third operation is move. Which actually moves the file from staging directory to actual location. And then in case of insert it adds the insert event to notification table. It does this for add partition operation which is redundant as the event for add partition would have been written already by ddl task. With the optimization to copy directly to actual table location in S3, move task can be avoided for add partition operation replay and replay of insert need not create the add partition (ddl) task.	HIVE	Closed	3	7	6781	pull-request-available
13240140	REPL - With table list - Handle rename events during replace policy	"If some rename events are found to be dumped and replayed while replace policy is getting executed, it needs to take care of the policy inclusion in both the policy for each table name.

 1. Create a list of tables to be bootstrapped. 

  2. During handling of alter table, if the alter type is rename 

      1. If the old table name is present in the list of table to be bootstrapped, remove it.

       2. If the new table name, matches the new policy, add it to the list of tables to be bootstrapped.

       3. If the old table does not match the old policy drop it, even if the table is not present at target.

  3. During handling of drop table

       1. if the table is in the list of tables to be bootstrapped, then remove it and ignore the event.

  4. During other event handling 

       1. if the table is there in the list of tables to be bootstrapped, then ignore the event.

       2. If the new policy does not match the table name, then ignore the event.

 

Rename handling during replace policy
 # Old name not matching old policy – The old table will not be there at the target cluster. The table will not be returned by get-all-table.
 ## Old name is not matching new policy
 ### New name not matching old policy
 #### New name not matching new policy
 ***** Ignore the event, no need to do anything.
 #### New name matching new policy
 ***** The table will be returned by get-all-table. Replace policy handler will bootstrap this table as its matching new policy and not matching old policy.
 ***** All the future events will be ignored as part of check added by replace policy handling.
 ***** All the event with old table name will anyways be ignored as the old name is not matching the new policy.
 ### New name matching old policy
 #### New name not matching new policy
 ***** As the new name is not matching the new policy, the table need not be replicated.
 ***** As the old name is not matching the new policy, the rename events will be ignored.
 ***** So nothing to be done for this scenario.
 #### New name matching new policy
 ***** As the new name is matching both old and new policy, replace handler will not bootstrap the table.
 ***** Add the table to the list of tables to be bootstrapped.
 ***** Ignore all the events with new name.
 ***** If there is a drop event for the table (with new name), then remove the table from the the list of table to be bootstrapped.
 ***** In case of rename event (double rename)
 ****** If the new name satisfies the table pattern, then add the new name to the list of tables to be bootstrapped and remove the old name from the list of tables to be bootstrapped.
 ****** If the new name does not satisfies then just removed the table name from the list of tables to be bootstrapped.
 ## Old name is matching new policy – As per replace policy handler, which checks based on old table, the table should be bootstrapped and event should be ignored. But rename handler should decide based on new name.The old table name will not be returned by get-all-table, so replace handler will not d anything for the old table.
 ### New name not matching old policy
 #### New name not matching new policy
 ***** As the old table is not there at target and new name is not matching new policy. Ignore the event.
 ***** No need to add the table to the list of tables to be bootstrapped.
 ***** All the subsequent events will be ignored as the new name is not matching the new policy.
 #### New name matching new policy
 ***** As the new name is not matching old policy but matching new policy, the table will be bootstrapped by replace policy handler. So rename event need not add this table to list of table to be bootstrapped.
 ***** All the future events will be ignored by replace policy handler.
 ***** For rename event (double rename)
 ****** If there is a rename, the table (with intermittent new name) will not be present and thus replace handler will not bootstrap the table.
 ****** So if the new name (the latest one) is matching the new policy, then add it to the list of table to be bootstrapped.
 ****** And If the new name (the latest one)  is not matching the new policy, then just ignore the event as the  intermittent new name would not have added to the list of table to be bootstrapped.
 ### New name matching old policy
 #### New name not matching new policy
 ***** Dump the event. The table will be dropped by repl load at the target.
 #### New name matching new policy
 ***** Replace handler will not bootstrap this table as the new name is matching both policies.
 ***** As old name is not matching the old policy, the table will not be there at target. The rename event should add the new name to the list of table to be bootstrapped.
 ***** Subsequent events with new table name should be ignored.
 ***** Drop events should not be ignored as if the table is present during bootstrapped, then its a new table and thus should be dropped.
 ***** In case of rename event (double rename)
 ****** If the new name satisfies the table pattern, then add the new name to the list of tables to be bootstrapped and remove the old name from the list of tables to be bootstrapped.
 ****** If the new name does not satisfies then just removed the table name from the list of tables to be bootstrapped.
 # Old name is matching old policy – The old table will be there at the target cluster. The table will not be returned by get-all-table. Repl load should delete the old table as it is not matching the new policy.
 ## Old name is not matching new policy
 ### New name not matching old policy
 #### New name not matching new policy
 ***** Nothing to be done. Ignore the event.
 #### New name matching new policy
 ***** As the new name is not matching old policy but matching new policy, the table will be bootstrapped by replace policy handler. So rename event need not add this table to list of table to be bootstrapped.
 ***** All the future events will be ignored by replace policy handler.
 ***** For rename event (double rename)
 ****** If there is a rename, the table (with intermittent new name) will not be present and thus replace handler will not bootstrap the table.
 ****** So if the new name (the latest one) is matching the new policy, then add it to the list of table to be bootstrapped.
 ****** And If the new name (the latest one)  is not matching the new policy, then just ignore the event as the  intermittent new name would not have added to the list of table to be bootstrapped.
 ### New name matching old policy
 #### New name not matching new policy
 ***** Table with new name will be dropped by repl load
 ***** Along with other event, ignore the rename event also.
 #### New name matching new policy
 ***** As the new name is matching both old and new policy, replace handler will not bootstrap the table.
 ***** Add the table to the list of tables to be bootstrapped.
 ***** Ignore all the events with new name.
 ***** If there is a drop event for the table (with new name), then remove the table from the the list of table to be bootstrapped.
 ***** In case of rename event (double rename)
 ****** If the new name satisfies the table pattern, then add the new name to the list of tables to be bootstrapped and remove the old name from the list of tables to be bootstrapped.
 ****** If the new name does not satisfies then just removed the table name from the list of tables to be bootstrapped.
 ## Old name is matching new policy
 ### New name not matching old policy
 #### New name not matching new policy
 ***** The old table needs to be dropped at target. Ignore this event, as the old table is not matching the new policy, it will be dropped by repl load.
 #### New name matching new policy
 ***** Allow the event to dump and replayed at target.
 ***** Allow further events to be handled as usual.
 ***** In case of rename event (double rename)
 ****** If the latest new name is matching the new policy, then keep it as is it. Let rename event replayed at target.
 ****** If the latest new name is not matching the new policy, then change the rename event to drop event.
 ### New name matching old policy
 #### New name not matching new policy
 ##### Nothing to be done.
 #### New name matching new policy
 ##### Add the table name to the list of tables to be bootstrapped."	HIVE	Resolved	3	7	6781	DR, Replication, pull-request-available
13320771	Use task counter enum to get the approximate counter value	The value for APPROXIMATE_INPUT_RECORDS should be obtained using the enum name instead of static string. Once Tez release is done with the specific information we should change it to org.apache.tez.common.counters.TaskCounter.APPROXIMATE_INPUT_RECORDS.	HIVE	In Progress	3	1	6781	pull-request-available
13350575	Drop catalog failing with deadlock error for Oracle backend dbms.	"When we do a drop catalog we drop the catalog from the CTLGS table. The DBS table has a foreign key reference on CTLGS for CTLG_NAME. This is causing the DBS table to be locked exclusively and causing deadlocks. This can be avoided by creating an index in the DBS table on CTLG_NAME.
{code:java}
CREATE INDEX CTLG_NAME_DBS ON DBS(CTLG_NAME); {code}
{code:java}
 Oracle Database maximizes the concurrency control of parent keys in relation to dependent foreign keys.Locking behaviour depends on whether foreign key columns are indexed. If foreign keys are not indexed, then the child table will probably be locked more frequently, deadlocks will occur, and concurrency will be decreased. For this reason foreign keys should almost always be indexed. The only exception is when the matching unique or primary key is never updated or deleted.{code}
 "	HIVE	Resolved	3	1	6781	pull-request-available
13408162	Select returns deleted records in Hive ACID table	Hive stores the stripe stats in the ORC files. During select, these stats are used to create the SARG. The SARG is used to reduce the records read from the delete-delta files. Currently, in case where the number of stripes are more than 1, the SARG generated is not proper as it uses the first stripe index for both min and max key interval. The max key interval should be obtained from last stripe index. This cause some valid deleted records to be skipped. And those records are return to the user. We need the last stripe here instead of the first one, is the fact the keys are ordered in the file.	HIVE	Resolved	3	1	6781	pull-request-available
13234518	REPL DUMP should detect and bootstrap any rename table events where old table was excluded but renamed table is included.	"REPL DUMP fetches the events from NOTIFICATION_LOG table based on regular expression + inclusion/exclusion list. So, in case of rename table event, the event will be ignored if old table doesn't match the pattern but the new table should be bootstrapped. REPL DUMP should have a mechanism to detect such tables and automatically bootstrap with incremental replication.Also, if renamed table is excluded from replication policy, then need to drop the old table at target as well. 

There are 4 scenarios that needs to be handled.
 # Both new name and old name satisfies the table name pattern filter.
 ## No need to do anything. The incremental event for rename should take care of the replication.
 # Both the names does not satisfy the table name pattern filter.
 ## Both the names are not in the scope of the policy and thus nothing needs to be done.
 # New name satisfies the pattern but the old name does not.
 ## The table will not be present at the target.
 ## Rename event handler for dump should detect this case and add the new table name to the list of table for bootstrap.
 ## All the events related to the table (new name) should be ignored.
 ## If there is a drop event for the table (with new name), then remove the table from the list of tables to be bootstrapped.
 ## In case of rename (double rename)
 ### If the new name satisfies the table pattern, then add the new name to the list of tables to be bootstrapped and remove the old name from the list of tables to be bootstrapped.
 ### If the new name does not satisfies then just removed the table name from the list of tables to be bootstrapped.
 # New name does not satisfies the pattern but the old name satisfies.
 ## Change the rename event to a drop event."	HIVE	Resolved	3	7	6781	DR, Replication, pull-request-available
13344802	Optimize vector row serde by avoiding type check at run time 	Serialization/Deserialization of vectorized batch done at VectorSerializeRow and VectorDeserializeRow does a type checking for each column of each row. This becomes very costly when there are billions of rows to read/write. This can be optimized if the type check is done during init time and specific reader/writer classes are created. This classes can be used directly stored in filed structure to avoid run time type check.	HIVE	Resolved	3	1	6781	pull-request-available
13415713	Hive DB creation is failing when MANAGEDLOCATION is specified with existing location	"As part of HIVE-23387 check is added to restrict user from creating database with managed table location, if the location is already present. This was not the case. As this is causing backward compatibility issue, the check needs to be removed.

 
{code:java}
if (madeManagedDir) {
  LOG.info(""Created database path in managed directory "" + dbMgdPath);
} else {
  throw new MetaException(
      ""Unable to create database managed directory "" + dbMgdPath + "", failed to create database "" + db.getName());
}  {code}
 "	HIVE	Resolved	3	1	6781	pull-request-available
13165835	Repl Load to return recoverable vs non-recoverable error codes	"To enable bootstrap of large databases, application has to have the ability to keep retrying the bootstrap load till it encounters a fatal error. The ability to identify if an error is fatal or not will be decided by hive and communication of the same will happen to application via error codes.

So there should be different error codes for recoverable vs non-recoverable failures which should be propagated to application as part of running the repl load command."	HIVE	Closed	3	3	6781	pull-request-available
13470969	Stats generation fails during CTAS for external partitioned table.	"As part of HIVE-25990 manifest file was generated to list out the files to be moved. The files are moved in move task by referring to the manifest file. For partitioned table flow, the move is not done. This prevents the dynamic partition creation as the target path will be empty. As stats task needs the partition information, this causes the stat task to fail.

 
{code:java}
class=""metastore.RetryingHMSHandler"" level=""ERROR"" thread=""pool-10-thread-144""] MetaException(message:Unable to update Column stats for  ext_par due to: The IN list is empty!)
 org.apache.hadoop.hive.metastore.DirectSqlUpdateStat.updatePartitionColumnStatistics(DirectSqlUpdateStat.java:634)
 org.apache.hadoop.hive.metastore.MetaStoreDirectSql.updatePartitionColumnStatisticsBatch(MetaStoreDirectSql.java:2803)
 org.apache.hadoop.hive.metastore.ObjectStore.updatePartitionColumnStatisticsInBatch(ObjectStore.java:10001)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43 java.lang.reflect.Method.invoke(Method.java:498)
 org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
com.sun.proxy.$Proxy33.updatePartitionColumnStatisticsInBatch(Unknown Source)
 org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.updatePartitionColStatsForOneBatch(HiveMetaStore.java:7124)
 org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.updatePartitionColStatsInBatch(HiveMetaStore.java:7109) {code}"	HIVE	Resolved	3	1	6781	pull-request-available
13184231	File operation at target side during S3 replication slowing down the replication	"1. Check is there during create partition for existence of partition location (in add partitions core method in metastore.java). It’s not required as we would have created the directory and copied the required files to it.
2. Creating qualified directory name (convertAddSpecToMetaPartition method in hive.java)– File system is access to check if the path provided is fully qualified or not. Not sure why it’s taking 1-2 seconds."	HIVE	Open	3	7	6781	pull-request-available
13319146	Support conversion of not-exists to Anti join directly	"The current anti join conversion does not support direct conversion of not-exists to anti join. The not exists sub query is converted first to left out join and then its converted to anti join. This may cause some of the optimization rule to be skipped.

 "	HIVE	Open	3	1	6781	pull-request-available
13138722	Replicate Commit Txn operation (without writes)	"Add new EVENT_COMMIT_TXN to log the metadata/data of all tables/partitions modified within the txn.

*Source warehouse:*
 - Create EVENT_COMMIT_TXN event type with corresponding message format etc.

*Target warehouse:*
 - Repl load should read this event from the dump.
 - Validate the source txn ID from the event using the Source-Target Txn ID map maintained in target metastore. Also, need to check if corresponding target txn ID is valid.
 - If valid, then apply the event and commit the corresponding target transaction.
 - This new event should be idempotent such that if it is applied twice, then second time it should be loop.

 *{color:#d04437}{color}* "	HIVE	Closed	3	7	6781	pull-request-available
13243191	Add the list of table selected by dump in the dump folder.	The list of tables selected by a dump should be kept in the dump folder as a _tables file. This will help user to find out the tables replicated and the list can be used by user for ranger and atlas policy replication.	HIVE	Resolved	3	7	6781	pull-request-available
13139616	REPL STATUS should support 'with' clause	"We have support for ""WITH"" clause in ""REPL LOAD"" command, but we don't have that for ""REPL STATUS"" command.
 With the cloud replication model , HiveServer2 is only running in the source on-prem cluster.
 ""REPL LOAD""'s with clause is currently used to pass the remote cloud clusters metastore uri, using ""hive.metastore.uri"" parameter.

Once ""REPL LOAD"" is run, ""REPL STATUS"" needs to be run to determine where the next incremental replication should start from. Since ""REPL STATUS"" is also going to run on source cluster, we need to add support for the ""WITH"" clause for it.

We should also change the privilege required for ""REPL STATUS"" command to what is required by ""REPL LOAD"" command as now arbitrary configs can be set for ""REPL STATUS"" using the WITH clause."	HIVE	Closed	3	3	6781	pull-request-available
13238104	HMS schema Upgrade Script is failing with NPE	"schema upgrade tool is failing with NPE while executing ""SELECT 'Upgrading MetaStore schema from 1.2.0 to 2.0.0' AS ' '"". The header row (metadata) is coming with rows having value null. This is causing null pointer access in function TableOutputFormat::getOutputString when row.values[i] is accessed. Instead of "" AS ' ' "", if some other value  like ""AS dummy"" is given, it's working fine. The issue is coming with mysql version 5.7 and above.

 

 

 "	HIVE	Closed	3	3	6781	pull-request-available
13393157	Optimise Hive::addWriteNotificationLog: Reduce FS call per notification	"AddWriteNotification is slow due to FS interactions (i.e to get the set of insert file information). This can be avoided as FileStatus can be passed instead of Path from parent methods.

[https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java#L3572] 

[https://github.com/apache/hive/blob/96b39cd5190f0cfadb677e3f3b7ead1d663921b2/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java#L3620]

 

 "	HIVE	Resolved	3	7	6781	pull-request-available
13402227	Enable batch update of column stats only for MySql and Postgres 	The batch updation of partition column stats using direct sql is tested only for MySql and Postgres.	HIVE	Open	3	7	6781	pull-request-available
13234783	Support extraction of replication spec from notification event. 	"The notification event structure currently does not have the partition spec. Events which can span across multiple databases and tables, the database and table info can not be obtained from the event structure. To know the event is added for which partition, the event message has to be deserialized and the partition information can be obtained from it. 
 * Each event handler has to expose a static API.
 * The API should take the event as input and return the list of db name, table name and partition spec from it.
 * If database name, table name or partition name is present in the event structure, then return it. If all these info are present then no need to deserialize the message. Later if these info are added to the event structure then it will be useful. 
 * Deserialize the message and create the list of name and return through a partition info class object.
 * If the table is not partitioned or is table level event, then set the partition info as null. Same for table info incase of db level events."	HIVE	Patch Available	3	7	6781	pull-request-available
13177304	Long running repl load (incr/bootstrap) causing OOM error	The task created in the previous iterations of the load are not delinked and thus causing heap memory usage issue. need to delink the tasks to avoid OOM error.	HIVE	Closed	3	3	6781	DR, replication
13140400	Create/Replicate Open, Commit (without writes) and Abort Txn events	"*EVENT_OPEN_TXN:*
 *Source Warehouse:*
 - Create new event type EVENT_OPEN_TXN with related message format etc.
 - When any transaction is opened either by auto-commit mode or multi-statement mode, need to capture this event.
 - Repl dump should read this event from EventNotificationTable and dump the message.

*Target Warehouse:*
 - Repl load should read the event from the dump and get the message.
 - Open a txn in target warehouse.
 - Create a map of source txn ID against target txn ID and persist the same in metastore. There should be one map per replication policy (DBName.* incase of DB level replication, DBName.TableName incase of table level replication)

 

*EVENT_COMMIT_TXN (Without writes)*

Add new EVENT_COMMIT_TXN to log the metadata/data of all tables/partitions modified within the txn.

*Source warehouse:*
 - Create EVENT_COMMIT_TXN event type with corresponding message format etc.

*Target warehouse:*
 - Repl load should read this event from the dump.
 - Validate the source txn ID from the event using the Source-Target Txn ID map maintained in target metastore. Also, need to check if corresponding target txn ID is valid.
 - If valid, then apply the event and commit the corresponding target transaction.
 - This new event should be idempotent such that if it is applied twice, then second time it should be loop.

 

*EVENT_ABORT_TXN*
 Source Warehouse:
 - Create new event type EVENT_ABORT_TXN with related message format etc.
 - Capture this event when abort the txn.
 - Repl dump should read this event from EventNotificationTable and dump the message.

*Target Warehouse:*
 - Repl load should read the event from the dump and get the message.
 - Validate if source txn ID from the event is there in the source-target txn ID map. If not there, just noop the event.
 - If valid, then Abort the corresponding target txn and remove the entry from source-target txn ID map.

All these new events should be idempotent such that if it is applied twice, then second time it should be noop."	HIVE	Closed	3	7	6781	ACID, DR, pull-request-available, replication
13383001	Update column stat throws NPE if direct sql is disabled	In case direct sql is disabled, the MetaStoreDirectSql object is not initialised and thats causing NPE. 	HIVE	Resolved	3	7	6781	pull-request-available
13161970	Repl copy retrying with cm path even if the failure is due to network issue	"* During repl load
 ** for filesystem based copying of file if the copy fails due to a connection error to source Name Node, we should recreate the filesystem object.
 ** the retry logic for local file copy should be triggered using the original source file path ( and not the CM root path ) since failure can be due to network issues between DFSClient and NN.

 * When listing files in tables / partition to include them in _files, we should add retry logic when failure occurs. FileSystem object here also should be recreated since the existing one might be in inconsistent state."	HIVE	Closed	3	3	6781	pull-request-available
13183431	REPL DUMP is leaking metastore connections	"With remote metastore, REPL DUMP  leaking connections. Each repl dump task is leaking one connection due to the usage of stale hive object. 

{code}
18/09/04 16:01:46 INFO ReplState: REPL::EVENT_DUMP: {""dbName"":""*"",""eventId"":""566"",""eventType"":""EVENT_COMMIT_TXN"",""eventsDumpProgress"":""1/0"",""dumpTime"":1536076906}
18/09/04 16:01:46 INFO events.AbstractEventHandler: Processing#567 OPEN_TXN message : {""txnIds"":null,""timestamp"":1536076905,""fromTxnId"":269,""toTxnId"":269,""server"":""thrift://metastore-service.warehouse-1536062326-s74h.svc.cluster.local:9083"",""servicePrincipal"":""""}
18/09/04 16:01:46 INFO ReplState: REPL::EVENT_DUMP: {""dbName"":""*"",""eventId"":""567"",""eventType"":""EVENT_OPEN_TXN"",""eventsDumpProgress"":""2/0"",""dumpTime"":1536076906}
18/09/04 16:01:46 INFO metastore.HiveMetaStoreClient: Trying to connect to metastore with URI thrift://metastore-service.warehouse-1536062326-s74h.svc.cluster.local:9083
18/09/04 16:01:46 INFO metastore.HiveMetaStoreClient: Opened a connection to metastore, current connections: 471
18/09/04 16:01:46 INFO metastore.HiveMetaStoreClient: Connected to metastore.
18/09/04 16:01:46 INFO metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=hive (auth:SIMPLE) retries=24 delay=5 lifetime=0
18/09/04 16:01:46 INFO ReplState: REPL::END: {""dbName"":""*"",""dumpType"":""INCREMENTAL"",""actualNumEvents"":2,""dumpEndTime"":1536076906,""dumpDir"":""/user/hive/repl/e45bde27-74dc-45cd-9823-400a8fc1aea3"",""lastReplId"":""567""}
18/09/04 16:01:46 INFO repl.ReplDumpTask: Done dumping events, preparing to return /user/hive/repl/e45bde27-74dc-45cd-9823-400a8fc1aea3,567
18/09/04 16:01:46 INFO ql.Driver: Completed executing command(queryId=hive_20180904160145_30f9570a-44e0-4f3b-b961-1906d3972fc4); Time taken: 0.585 seconds
OK
18/09/04 16:01:46 INFO ql.Driver: OK
18/09/04 16:01:46 INFO lockmgr.DbTxnManager: Stopped heartbeat for query: hive_20180904160145_30f9570a-44e0-4f3b-b961-1906d3972fc4
18/09/04 16:01:46 INFO metastore.HiveMetaStoreClient: Trying to connect to metastore with URI thrift://metastore-service.warehouse-1536062326-s74h.svc.cluster.local:9083
18/09/04 16:01:46 INFO metastore.HiveMetaStoreClient: Opened a connection to metastore, current connections: 472
18/09/04 16:01:46 INFO metastore.HiveMetaStoreClient: Connected to metastore.
{code}"	HIVE	Closed	3	1	6781	pull-request-available
13339652	AST tree processing is suboptimal for tree with large number of nodes	In hive the children information is stored as list of objects. During processing of the children of a node, the list of object is converted to list of Nodes. This can cause large compilation time if the number of children is large(300,000). The list of children can be cached in the AST node to avoid this re-computation. The caching part is already fixed as part of HIVE-24031, the allocation of array is fixed in this Jira.	HIVE	Resolved	3	1	6781	pull-request-available
13167730	Replication dump has a NPE when table is empty	if table directory or partition directory is missing ..dump is throwing NPE instead of file missing exception.	HIVE	Closed	3	3	6781	pull-request-available
13353429	Reduce overhead of partition column stat updation during batch loading of partitions.	"When large number of partitions (>20K) are processed, ColStatsProcessor runs into DB issues. 

{{ db.setPartitionColumnStatistics(request);}} gets stuck for hours together and in some cases postgres stops processing. 

It would be good to introduce small batches for stats gathering in ColStatsProcessor instead of bulk update.

Ref: 
https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/stats/ColStatsProcessor.java#L181

https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/stats/ColStatsProcessor.java#L199

"	HIVE	Resolved	3	7	6781	performance, pull-request-available
13335985	NPE when parsing druid logs using Hive	"As per current Sys-logger parser, its always expecting a valid proc id. But as per RFC3164 and RFC5424, the proc id can be skipped.So hive should handled it by using NILVALUE/empty string in case the proc id is null.

 
{code:java}
Caused by: java.lang.NullPointerException: null
at java.lang.String.<init>(String.java:566)
at org.apache.hadoop.hive.ql.log.syslog.SyslogParser.createEvent(SyslogParser.java:361)
at org.apache.hadoop.hive.ql.log.syslog.SyslogParser.readEvent(SyslogParser.java:326)
at org.apache.hadoop.hive.ql.log.syslog.SyslogSerDe.deserialize(SyslogSerDe.java:95) {code}"	HIVE	Resolved	3	1	6781	pull-request-available
13234552	Repl load command config is not passed to the txn manager	"*Cause:*
REPL LOAD replicates Txn State (writeIds of tables) to the target HMS (backend RDBMS). But, in this case, it is still connected to source HMS due to configs passed in WITH clause were not stored in HiveTxnManager. 
We pass the config object to the ReplTxnTask objects but HiveTxnManager was created by Driver using session config object.

*Fix:*
We need to pass it to HiveTxnManager too by creating a txn manager for repl txn operations with the config passed by user."	HIVE	Patch Available	3	1	6781	pull-request-available
13234784	Support partition filter (where clause) in REPL dump command (Bootstrap Dump)	"*Bootstrap for managed table*

User should be allowed to execute REPL DUMP with where clause. The where clause should support filtering out partition from dump. Format of the where clause should be similar to *""REPL DUMP dbname from 10 where 't0' where key < 10,'t1'* where key = 3, '(t2*)|'t3' where key > 3"".* For initial version, very basic filter condition will be supported and later the complexity will be increased as and when required.
 * From the AST generated for the where clause, extract the table information.
 * Generate AST for each table.
 * List the partition for each table using the AST generated for each table using the   same metastore API used by select query.
 * During bootstrap load use the partition list to dump the partitions.
 * During incremental dump, use the list to filter out the event.

In case of bootstrap load, all the tables of the database will be scanned and
 * If table is not partitioned, then it will be dumped.
 * If key provided in the filter condition for the table is not a partition column, then dump will fail.
 * If table is not mentioned in the where clause, then all partitions of the table will be dumped.
 * All the partitioned of the table satisfying the where clause will be dumped.

*Incremental for managed table (Not part of this patch)*

In case of Incremental Dump, the events from the notification log will be scanned and once the partition spec is extracted from the event, the partition spec will be filtered against the condition.
 * If table is not partitioned then the event will be added to the dump.
 * If key mentioned is not a partition column, then dump will fail.
 * If the table is not mentioned in the filter then event will be added to the dump.
 * If the event is multi partitioned, then the event will be added to the dump. (Filtering out redundant partitions from message will be done as part of separate task).
 * If the partition spec matches the filter, then the event will be added to the dump*.*

 "	HIVE	Patch Available	3	7	6781	pull-request-available
13391475	Modify buildColumnStatsDesc to send configured number of stats for updation	The number of stats sent for updation should be controlled to avoid thrift error in case the size exceeds the limit.	HIVE	Resolved	3	7	6781	pull-request-available
13205070	REPL LOAD command executing copy in serial mode even if parallel execution is enabled using WITH clause	"For repl load command use can specify the execution mode as part of ""with"" clause. But the config for executing task in parallel or serial is not read from the command specific config. It is read from the hive server config. So even if user specifies to run the tasks in parallel during repl load command, the tasks are getting executed serially."	HIVE	Resolved	3	1	6781	pull-request-available
13324560	Execution exception in sort-merge semijoin	"Working on HIVE-24041, we trigger an additional SJ conversion that leads to this exception at execution time:

{code}
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: Attempting to overwrite nextKeyWritables[1]
	at org.apache.hadoop.hive.ql.exec.GroupByOperator.closeOp(GroupByOperator.java:1063)
	at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:685)
	at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:707)
	at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:707)
	at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:707)
	at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:707)
	at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.close(MapRecordProcessor.java:462)
	... 16 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: Attempting to overwrite nextKeyWritables[1]
	at org.apache.hadoop.hive.ql.exec.GroupByOperator.flush(GroupByOperator.java:1037)
	at org.apache.hadoop.hive.ql.exec.GroupByOperator.closeOp(GroupByOperator.java:1060)
	... 22 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Attempting to overwrite nextKeyWritables[1]
	at org.apache.hadoop.hive.ql.exec.CommonMergeJoinOperator.processKey(CommonMergeJoinOperator.java:564)
	at org.apache.hadoop.hive.ql.exec.CommonMergeJoinOperator.process(CommonMergeJoinOperator.java:243)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:887)
	at org.apache.hadoop.hive.ql.exec.TezDummyStoreOperator.process(TezDummyStoreOperator.java:49)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:887)
	at org.apache.hadoop.hive.ql.exec.GroupByOperator.forward(GroupByOperator.java:1003)
	at org.apache.hadoop.hive.ql.exec.GroupByOperator.flush(GroupByOperator.java:1020)
	... 23 more
{code}

To reproduce, just set {{hive.auto.convert.sortmerge.join}} to {{true}} in the last query in {{auto_sortmerge_join_10.q}} after HIVE-24041 has been merged."	HIVE	Resolved	3	1	6781	pull-request-available
13137299	CachedStore: Use metastore notification log events to update cache	Currently, a background thread updates the entire cache which is pretty inefficient. We capture the updates to metadata in NOTIFICATION_LOG table which is getting used in the Replication work. We should have the background thread apply these notifications to incrementally update the cache.	HIVE	Resolved	3	7	6781	pull-request-available
13437126	Show columns shows extra values if column comments contains specific Chinese character 	"The issue is happening because the UTF code for one of the Chinese character contains the binary value of '\r' (CR). Because of this, the Hadoop line reader (used by fetch task in Hive) is assuming the value after that character as new value and this extra value with junk is getting displayed. The issue is with 0x540D 名 ... The last value is ""D"" ..that is 13. While reading the result, Hadoop line reader interpreting it as CR ( '\r'). Thus an extra value with Junk is coming as output. For show column, we do not need the comments. So while writing to the file, only column names should be included.

[https://github.com/apache/hadoop/blob/0fbd96a2449ec49f840d93e1c7d290c5218ef4ea/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/LineReader.java#L238]

 
{code:java}
create table tbl_test  (fld0 string COMMENT  '期 ' , fld string COMMENT '期末日期', fld1 string COMMENT '班次名称', fld2  string COMMENT '排班人数');

show columns from tbl_test;
+--------+
| field  |
+--------+
| fld    |
| fld0   |
| fld1   |
| �      |
| fld2   |
+--------+
5 rows selected (171.809 seconds)
 {code}"	HIVE	Resolved	3	1	6781	pull-request-available
13158516	Enable CM root based on db parameter, identifying a db as source of replication.	"* add a parameter at db level to identify if its a source of replication. user should set this.

 * Enable CM root only for databases that are a source of a replication policy, for other db's skip the CM root functionality.

 * prevent database drop if the parameter indicating its source of a replication, is set.

 * as an upgrade to this version, user should set the property on all existing database policies, in affect.

 * the parameter should be of the form . –  repl.source.for : List < policy ids >"	HIVE	Closed	3	3	6781	pull-request-available
13187173	Hive incremental replication fails with events missing error if database is kept idle for more than an hour	Start a source cluster with 2 database. Replicate the databases to target after doing some operations. Keep taking incremental dump for both database and keep replicating them to target cluster. Keep one the database idle for more than 24 hrs. After 24 hrs, the incremental dump of idle database fails with event missing error.	HIVE	Closed	3	1	6781	pull-request-available
13165872	Allow metadata-only dump for database which are not source of replication	If the dump is meta data only then allow dump even if the db is not source of replication	HIVE	Closed	3	3	6781	pull-request-available
13162471	Add ability to dump non-native tables in replication metadata dump	"if hive.repl.dump.metadata.only is set to true, allow dumping non native tables also. 

Data dump for non-native tables should never be allowed."	HIVE	Closed	3	3	6781	Repl, pull-request-available
13243239	The list of table expression in the inclusion and exclusion list should be separated by '|' instead of comma.	Java regex expression does not support comma. If user wants multiple expression to be present in the include or exclude list, then the expressions can be provided separated by pipe ('|') character. The policy will look something like db_name.'(t1*)|(t3)'.'t100'	HIVE	Resolved	3	7	6781	pull-request-available
13263558	Reduce db lookups during dynamic partition loading	{{HiveAlterHandler::alterPartitions}} could lookup all partition details via single call instead of multiple lookups.	HIVE	Resolved	3	4	6781	performance
13320426	Improve plan regression tests using TPCDS30TB metastore dump and custom configs	"The existing regression tests (HIVE-12586) based on TPC-DS have certain shortcomings:

The table statistics do not reflect cardinalities from a specific TPC-DS scale factor (SF). Some tables are from a 30TB dataset, others from 200GB dataset, and others from a 3GB dataset. This mix leads to plans that may never appear when using an actual TPC-DS dataset. 

The existing statistics do not contain information about partitions something that can have a big impact on the resulting plans.

The existing regression tests rely on more or less on the default configuration (hive-site.xml). In real-life scenarios though some of the configurations differ and may impact the choices of the optimizer.

This issue aims to address the above shortcomings by using a curated TPCDS30TB metastore dump along with some custom hive configurations. "	HIVE	Closed	3	4	11212	pull-request-available
13407106	Stack trace is difficult to find when qtest fails during setup/teardown	"When a qtest fails while executing one of the setup/teardown methods of a CLI driver ([CliAdapter|https://github.com/apache/hive/blob/3e37ba473545a691f5f32c08fc4b62b49257cab4/itests/util/src/main/java/org/apache/hadoop/hive/cli/control/CliAdapter.java#L36] and its subclasses):

{code:java}
  public abstract void beforeClass() throws Exception;
  public abstract void setUp();
  public abstract void tearDown();
  public abstract void shutdown() throws Exception;
{code}

the original stack trace leading to the failure cannot be found easily. 

Maven console shows a stack trace which doesn't correspond to the actual exception causing the problem but another one which in most cases does not contain the original cause. 

The original stack trace is not displayed in the maven console and it is not in the {{target/tmp/logs/hive.log}} either. At the moment it goes to {{target/surefire-reports/...-output.txt}}. 

The developer needs to search in 2-3 places and navigate back and forth to the code in order to find what went wrong.

Ideally the stack trace from the original exception should be printed directly in maven console. "	HIVE	Closed	4	4	11212	pull-request-available
13584609	Discard old builds in Jenkins to avoid disk space exhaustion	"Currently Jenkins retains the builds from all active branches/PRs. 

{code:bash}
for b in `find var/jenkins_home/jobs -name ""builds""`; do echo -n $b"" "" ; ls -l $b | wc -l; done | sort -k2 -rn > builds.txt
{code}

Some PRs (e.g., [PR-5216|https://ci.hive.apache.org/job/hive-precommit/view/change-requests/job/PR-5216/]) with an excessive number of builds (i.e., 66) can easily consume many GBs of data (PR-5216 uses 13GB for the builds). The first build for PR-5216 was saved on April 26, 2024 and it is now more than 2 months old.

For master, we currently have all builds since January 2023 (previous builds where manually removed as part of HIVE-28013). The builds for master occupy currently 50GB of space.

Due to the above the disk space (persistent volume) cannot be reclaimed and currently it is almost full (91% /var/jenkins_home).

{noformat}
kubectl exec jenkins-6858ddb664-l4xfg -- bash -c ""df""
Filesystem     1K-blocks      Used Available Use% Mounted on
overlay         98831908   4675004  94140520   5% /
tmpfs              65536         0     65536   0% /dev
tmpfs            6645236         0   6645236   0% /sys/fs/cgroup
/dev/sdb       308521792 278996208  29509200  91% /var/jenkins_home
/dev/sda1       98831908   4675004  94140520   5% /etc/hosts
shm                65536         0     65536   0% /dev/shm
tmpfs           10801128        12  10801116   1% /run/secrets/kubernetes.io/serviceaccount
tmpfs            6645236         0   6645236   0% /proc/acpi
tmpfs            6645236         0   6645236   0% /proc/scsi
tmpfs            6645236         0   6645236   0% /sys/firmware
{noformat}

Without a discard policy in place we are going to hit again HIVE-28013 or other disk related issues pretty soon."	HIVE	Resolved	3	3	11212	pull-request-available
13447915	Drop unused requests from TestHiveMetaStoreClientApiArgumentsChecker	Some tests in TestHiveMetaStoreClientApiArgumentsChecker are creating a request but not really using them so it is basically dead code that can be removed.	HIVE	Closed	5	7	11212	pull-request-available
13523947	Website deployment GitHub action should not trigger on pull requests	"The Website deployment GitHub action configured here:

[https://github.com/apache/hive-site/blob/a3132faf0f4a555434076cb8ad690ae2c2c8c371/.github/workflows/gh-pages.yml]

should not trigger on pull requests.

The issue can be seen here:

https://github.com/apache/hive-site/actions/runs/4127993132/jobs/7131893178

where the action was launched for https://github.com/apache/hive-site/pull/1"	HIVE	Closed	3	1	11212	pull-request-available
13407631	Drop support of multiple qfiles in QTestUtil, output and result processors	"The current implementation of [QTestUtil|https://github.com/apache/hive/blob/afeb0f8413b1fd777611e890e53925119a5e39f1/itests/util/src/main/java/org/apache/hadoop/hive/ql/QTestUtil.java], [QOutProcessor|https://github.com/apache/hive/blob/master/itests/util/src/main/java/org/apache/hadoop/hive/ql/QOutProcessor.java], and [QTestResultProcessor|https://github.com/apache/hive/blob/afeb0f8413b1fd777611e890e53925119a5e39f1/itests/util/src/main/java/org/apache/hadoop/hive/ql/QTestResultProcessor.java], has some methods and fields (maps) for managing multiple input files. However, *all* clients of this API, such as [CoreCliDriver|https://github.com/apache/hive/blob/afeb0f8413b1fd777611e890e53925119a5e39f1/itests/util/src/main/java/org/apache/hadoop/hive/cli/control/CoreCliDriver.java], use these classes by processing one file per run.

+Example+
{code:java}
public void runTest(String testName, String fname, String fpath) {
    ...
    qt.addFile(fpath);
    qt.cliInit(new File(fpath));
    ...
    try {
      qt.executeClient(fname);
    } catch (CommandProcessorException e) {
      qt.failedQuery(e.getCause(), e.getResponseCode(), fname, QTestUtil.DEBUG_HINT);
    }
    ...
}
{code}
Notice that {{qt.addFile}} will keep accumulating input files to memory (filename + content) while {{qt.executeClient}} (and other similar APIs) always operate on the last file added. Apart from wasting memory, the APIs for multiple files are harder to understand, and extend.

The goal of this JIRA is to simplify the aforementioned APIs by removing unused/redundant parts associated to multiple files to improve code readability, and reduce memory consumption.

+Historical note+
 Before HIVE-25625 the functionality of multiple input files was used by the {{TestCompareCliDriver}} but it was still useless for all the other clients. With the removal of {{TestCompareCliDriver}} in HIVE-25625 keeping multiple files is completely redundant."	HIVE	Closed	3	3	11212	pull-request-available
13533421	Simplify correlated queries with empty inputs	"The correlated query below will not produce any result no matter the content of the table.
{code:sql}
create table t1 (id int, val varchar(10)) stored as orc TBLPROPERTIES ('transactional'='true');
create table t2 (id int, val varchar(10)) stored as orc TBLPROPERTIES ('transactional'='true');

EXPLAIN CBO SELECT id FROM t1 WHERE NULL IN (SELECT NULL FROM t2 where t1.id = t2.id);
{code}
The CBO is able to derive that part of the query is empty and ends up with the following plan.
{noformat}
CBO PLAN:
HiveProject(id=[$0])
  LogicalCorrelate(correlation=[$cor0], joinType=[semi], requiredColumns=[{}])
    HiveTableScan(table=[[default, t1]], table:alias=[t1])
    HiveValues(tuples=[[]])
{noformat}
The presence of LogicalCorrelate is first redundant but also problematic since many parts of the optimizer assume that queries are decorrelated and do not know how to handle the LogicalCorrelate.

In the presence of views the same query can lead to the following exception during compilation.
{code:sql}
CREATE MATERIALIZED VIEW v1 AS SELECT id FROM t2;
EXPLAIN CBO SELECT id FROM t1 WHERE NULL IN (SELECT NULL FROM t2 where t1.id = t2.id);
{code}
{noformat}
org.apache.calcite.plan.RelOptPlanner$CannotPlanException: There are not enough rules to produce a node with desired properties: convention=HIVE, sort=[], dist=any. All the inputs have relevant nodes, however the cost is still infinite.
Root: rel#185:RelSubset#3.HIVE.[].any
Original rel:
HiveProject(id=[$0]): rowcount = 4.0, cumulative cost = {20.0 rows, 13.0 cpu, 0.0 io}, id = 178
  LogicalCorrelate(correlation=[$cor0], joinType=[semi], requiredColumns=[{}]): rowcount = 4.0, cumulative cost = {16.0 rows, 9.0 cpu, 0.0 io}, id = 176
    HiveTableScan(table=[[default, t1]], table:alias=[t1]): rowcount = 4.0, cumulative cost = {4.0 rows, 5.0 cpu, 0.0 io}, id = 111
    HiveValues(tuples=[[]]): rowcount = 1.0, cumulative cost = {1.0 rows, 1.0 cpu, 0.0 io}, id = 139

Sets:
Set#0, type: RecordType(INTEGER id, VARCHAR(10) val, BIGINT BLOCK__OFFSET__INSIDE__FILE, VARCHAR(2147483647) INPUT__FILE__NAME, RecordType(BIGINT writeid, INTEGER bucketid, BIGINT rowid) ROW__ID, BOOLEAN ROW__IS__DELETED)
	rel#180:RelSubset#0.HIVE.[].any, best=rel#111
		rel#111:HiveTableScan.HIVE.[].any(table=[default, t1],htColumns=[0, 1, 2, 3, 4, 5],insideView=false,plKey=default.t1;,table:alias=t1,tableScanTrait=null), rowcount=4.0, cumulative cost={4.0 rows, 5.0 cpu, 0.0 io}
Set#1, type: RecordType(NULL _o__c0)
	rel#181:RelSubset#1.HIVE.[].any, best=rel#139
		rel#139:HiveValues.HIVE.[].any(type=RecordType(NULL _o__c0),tuples=[]), rowcount=1.0, cumulative cost={1.0 rows, 1.0 cpu, 0.0 io}
Set#2, type: RecordType(INTEGER id, VARCHAR(10) val, BIGINT BLOCK__OFFSET__INSIDE__FILE, VARCHAR(2147483647) INPUT__FILE__NAME, RecordType(BIGINT writeid, INTEGER bucketid, BIGINT rowid) ROW__ID, BOOLEAN ROW__IS__DELETED)
	rel#183:RelSubset#2.NONE.[].any, best=null
		rel#182:LogicalCorrelate.NONE.[].any(left=RelSubset#180,right=RelSubset#181,correlation=$cor0,joinType=semi,requiredColumns={}), rowcount=4.0, cumulative cost={inf}
Set#3, type: RecordType(INTEGER id)
	rel#185:RelSubset#3.HIVE.[].any, best=null
		rel#184:HiveProject.HIVE.[].any(input=RelSubset#183,inputs=0,synthetic=false), rowcount=4.0, cumulative cost={inf}

Graphviz:
digraph G {
	root [style=filled,label=""Root""];
	subgraph cluster0{
		label=""Set 0 RecordType(INTEGER id, VARCHAR(10) val, BIGINT BLOCK__OFFSET__INSIDE__FILE, VARCHAR(2147483647) INPUT__FILE__NAME, RecordType(BIGINT writeid, INTEGER bucketid, BIGINT rowid) ROW__ID, BOOLEAN ROW__IS__DELETED)"";
		rel111 [label=""rel#111:HiveTableScan\ntable=[default, t1],htColumns=[0, 1, 2, 3, 4, 5],insideView=false,plKey=default.t1;,table:alias=t1,tableScanTrait=null\nrows=4.0, cost={4.0 rows, 5.0 cpu, 0.0 io}"",color=blue,shape=box]
		subset180 [label=""rel#180:RelSubset#0.HIVE.[].any""]
	}
	subgraph cluster1{
		label=""Set 1 RecordType(NULL _o__c0)"";
		rel139 [label=""rel#139:HiveValues\ntype=RecordType(NULL _o__c0),tuples=[]\nrows=1.0, cost={1.0 rows, 1.0 cpu, 0.0 io}"",color=blue,shape=box]
		subset181 [label=""rel#181:RelSubset#1.HIVE.[].any""]
	}
	subgraph cluster2{
		label=""Set 2 RecordType(INTEGER id, VARCHAR(10) val, BIGINT BLOCK__OFFSET__INSIDE__FILE, VARCHAR(2147483647) INPUT__FILE__NAME, RecordType(BIGINT writeid, INTEGER bucketid, BIGINT rowid) ROW__ID, BOOLEAN ROW__IS__DELETED)"";
		rel182 [label=""rel#182:LogicalCorrelate\nleft=RelSubset#180,right=RelSubset#181,correlation=$cor0,joinType=semi,requiredColumns={}\nrows=4.0, cost={inf}"",shape=box]
		subset183 [label=""rel#183:RelSubset#2.NONE.[].any""]
	}
	subgraph cluster3{
		label=""Set 3 RecordType(INTEGER id)"";
		rel184 [label=""rel#184:HiveProject\ninput=RelSubset#183,inputs=0,synthetic=false\nrows=4.0, cost={inf}"",shape=box]
		subset185 [label=""rel#185:RelSubset#3.HIVE.[].any""]
	}
	root -> subset185;
	subset180 -> rel111[color=blue];
	subset181 -> rel139[color=blue];
	subset183 -> rel182; rel182 -> subset180[label=""0""]; rel182 -> subset181[label=""1""];
	subset185 -> rel184; rel184 -> subset183;
}
	at org.apache.calcite.plan.volcano.RelSubset$CheapestPlanReplacer.visit(RelSubset.java:742) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.calcite.plan.volcano.RelSubset.buildCheapestPlan(RelSubset.java:365) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.calcite.plan.volcano.VolcanoPlanner.findBestExp(VolcanoPlanner.java:520) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner$CalcitePlannerAction.applyMaterializedViewRewriting(CalcitePlanner.java:2058) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner$CalcitePlannerAction.apply(CalcitePlanner.java:1722) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner$CalcitePlannerAction.apply(CalcitePlanner.java:1591) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.calcite.tools.Frameworks.lambda$withPlanner$0(Frameworks.java:131) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.calcite.prepare.CalcitePrepareImpl.perform(CalcitePrepareImpl.java:914) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.calcite.tools.Frameworks.withPrepare(Frameworks.java:180) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.calcite.tools.Frameworks.withPlanner(Frameworks.java:126) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.logicalPlan(CalcitePlanner.java:1343) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.genOPTree(CalcitePlanner.java:570) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12820) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.analyzeInternal(CalcitePlanner.java:465) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:326) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.ExplainSemanticAnalyzer.analyzeInternal(ExplainSemanticAnalyzer.java:180) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:326) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:224) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:107) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:519) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:471) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:436) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:430) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.compileAndRespond(ReExecDriver.java:121) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:227) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:257) ~[hive-cli-4.0.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.hive.cli.CliDriver.processCmd1(CliDriver.java:201) ~[hive-cli-4.0.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:127) ~[hive-cli-4.0.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:425) ~[hive-cli-4.0.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:356) ~[hive-cli-4.0.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.hive.ql.QTestUtil.executeClientInternal(QTestUtil.java:733) ~[hive-it-util-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.QTestUtil.executeClient(QTestUtil.java:703) ~[hive-it-util-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.cli.control.CoreCliDriver.runTest(CoreCliDriver.java:115) ~[hive-it-util-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.cli.control.CliAdapter.runTest(CliAdapter.java:157) ~[hive-it-util-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver(TestMiniLlapLocalCliDriver.java:62) ~[test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_261]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_261]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_261]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_261]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) ~[junit-4.13.2.jar:4.13.2]
	at org.apache.hadoop.hive.cli.control.CliAdapter$2$1.evaluate(CliAdapter.java:135) ~[hive-it-util-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.Suite.runChild(Suite.java:128) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.Suite.runChild(Suite.java:27) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) ~[junit-4.13.2.jar:4.13.2]
	at org.apache.hadoop.hive.cli.control.CliAdapter$1$1.evaluate(CliAdapter.java:95) ~[hive-it-util-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.junit.rules.RunRules.evaluate(RunRules.java:20) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) ~[junit-4.13.2.jar:4.13.2]
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
{noformat}
The goal of this ticket is to get rid of the redundant correlation to avoid compilation failures but also for unlocking further simplifications and improving plan readability.

The plan can be simplified further based on the following observations.

If the right side of the correlate is empty then the whole correlate is empty when joinType is SEMI/INNER. Moreover if correlate type is LEFT then we can also drop the correlate and use t1 padded with nulls for the right side. Lastly, if the type is ANTI then result is the entire t1 so the correlate can also be dropped. RIGHT and FULL correlations are invalid and should never appear in the plan.

If the left side of the correlate is empty the result is empty and the correlation can be dropped for every legal joinType (INNER/SEMI/ANTI/LEFT)."	HIVE	Closed	3	1	11212	pull-request-available
13578874	AssertionError when using HiveTableScan with a HepPlanner cluster	"The {{HiveTableScan}} operator throws an [AssertionError|https://github.com/apache/hive/blob/7950967eae9640fcc0aa22f4b6c7906b34281eac/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/reloperators/HiveTableScan.java#L153] if the operator does not have the {{HiveRelNode.CONVENTION}} set.

The {{HepPlanner}} does not use any [RelTraitDef|https://github.com/apache/calcite/blob/f854ef5ee480e0ff893b18d27ec67dc381ee2244/core/src/main/java/org/apache/calcite/plan/AbstractRelOptPlanner.java#L276] so the default [empty traitset for the respective cluster|https://github.com/apache/calcite/blob/f854ef5ee480e0ff893b18d27ec67dc381ee2244/core/src/main/java/org/apache/calcite/plan/RelOptCluster.java#L99] is gonna be always empty.

In principle we should not be able to use the {{HiveTableScan}} operator with {{HepPlanner}}. However, the optimizer heavily uses the {{HepPlanner}} (in fact more than the {{VolcanoPlanner}} and it is reasonable to wonder how is this possible given that this assertion is in place. The assertion is circumvented by creating a cluster from a [VolcanoPlanner|https://github.com/apache/hive/blob/7950967eae9640fcc0aa22f4b6c7906b34281eac/ql/src/java/org/apache/hadoop/hive/ql/parse/CalcitePlanner.java#L1620] and then using it in the [HepPlanner|https://github.com/apache/hive/blob/7950967eae9640fcc0aa22f4b6c7906b34281eac/ql/src/java/org/apache/hadoop/hive/ql/parse/CalcitePlanner.java#L2422]. 
This cluster usage is a bit contrived but does not necessarily need to change at this stage.

Nevertheless, since the {{HiveTableScan}} operator is suitable to run with the {{HepPlanner}} the assertion can be relaxed (or removed altogether) to better reflect the actual usage of the operator, and allow passing a ""true"" HepPlanner cluster inside the operator."	HIVE	Resolved	3	4	11212	pull-request-available
13445631	Decouple sort filter predicates optimization from digest normalization in CBO	"HIVE-21857 introduced an optimization for ordering predicates inside a filter based on a cost function. After HIVE-23456, this optimization can run only if the the digest normalization (introduced in CALCITE-2450) in CBO is disabled (via {{calcite.enable.rexnode.digest.normalize}}).

The goal of this issue is to decouple the sort predicate optimization from digest normalization. After the changes here the optimization shouldn't be affected by the value of {{calcite.enable.rexnode.digest.normalize}} property."	HIVE	Closed	3	4	11212	pull-request-available
13325508	NPE due to null key columns in ReduceSink after deduplication	"In some cases the {{ReduceSinkDeDuplication}} optimization creates ReduceSink operators where the key columns are null. This can lead to NPE in various places in the code. 

The following stracktraces show some places where a NPE appears. Note that the stacktraces do not correspond to the same query.

+NPE  during planning+
{noformat}
java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.plan.ExprNodeDesc$ExprNodeDescEqualityWrapper.equals(ExprNodeDesc.java:141)
	at java.util.AbstractList.equals(AbstractList.java:523)
	at org.apache.hadoop.hive.ql.optimizer.SetReducerParallelism.process(SetReducerParallelism.java:101)
	at org.apache.hadoop.hive.ql.lib.DefaultRuleDispatcher.dispatch(DefaultRuleDispatcher.java:90)
	at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.dispatchAndReturn(DefaultGraphWalker.java:105)
	at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.dispatch(DefaultGraphWalker.java:89)
	at org.apache.hadoop.hive.ql.lib.ForwardWalker.walk(ForwardWalker.java:74)
	at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.startWalking(DefaultGraphWalker.java:120)
	at org.apache.hadoop.hive.ql.parse.TezCompiler.runStatsDependentOptimizations(TezCompiler.java:492)
	at org.apache.hadoop.hive.ql.parse.TezCompiler.optimizeOperatorPlan(TezCompiler.java:226)
	at org.apache.hadoop.hive.ql.parse.TaskCompiler.compile(TaskCompiler.java:161)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12643)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.analyzeInternal(CalcitePlanner.java:443)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:301)
	at org.apache.hadoop.hive.ql.parse.ExplainSemanticAnalyzer.analyzeInternal(ExplainSemanticAnalyzer.java:171)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:301)
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:220)
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:104)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:173)
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:414)
	at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:363)
	at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:357)
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.compileAndRespond(ReExecDriver.java:129)
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:231)
	at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:258)
	at org.apache.hadoop.hive.cli.CliDriver.processCmd1(CliDriver.java:203)
	at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:129)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:424)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:355)
	at org.apache.hadoop.hive.ql.QTestUtil.executeClientInternal(QTestUtil.java:740)
	at org.apache.hadoop.hive.ql.QTestUtil.executeClient(QTestUtil.java:710)
	at org.apache.hadoop.hive.cli.control.CoreCliDriver.runTest(CoreCliDriver.java:170)
	at org.apache.hadoop.hive.cli.control.CliAdapter.runTest(CliAdapter.java:157)
	at org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver(TestMiniLlapLocalCliDriver.java:62)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.apache.hadoop.hive.cli.control.CliAdapter$2$1.evaluate(CliAdapter.java:135)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.apache.hadoop.hive.cli.control.CliAdapter$1$1.evaluate(CliAdapter.java:95)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
{noformat}

+NPE at runtime+
{noformat}
org.apache.hadoop.hive.ql.metadata.HiveException: Vertex failed, vertexName=Map 1, vertexId=vertex_1598975134540_0001_2_00, diagnostics=[Task failed, taskId=task_1598975134540_0001_2_00_000000, diagnostics=[TaskAttempt 0 failed, info=[Error: Error while running task ( failure ) : attempt_1598975134540_0001_2_00_000000_0:java.lang.RuntimeException: java.lang.RuntimeException: Map operator initialization failed
	at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:296)
	at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:250)
	at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:374)
	at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:73)
	at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:61)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:61)
	at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:37)
	at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)
	at org.apache.hadoop.hive.llap.daemon.impl.StatsRecordingThreadPool$WrappedCallable.call(StatsRecordingThreadPool.java:118)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.RuntimeException: Map operator initialization failed
	at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.init(MapRecordProcessor.java:351)
	at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:266)
	... 15 more
Caused by: java.lang.RuntimeException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.exec.ReduceSinkOperator.initializeOp(ReduceSinkOperator.java:242)
	at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:359)
	at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:548)
	at org.apache.hadoop.hive.ql.exec.Operator.initializeChildren(Operator.java:502)
	at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:368)
	at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:548)
	at org.apache.hadoop.hive.ql.exec.Operator.initializeChildren(Operator.java:502)
	at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:368)
	at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:548)
	at org.apache.hadoop.hive.ql.exec.Operator.initializeChildren(Operator.java:502)
	at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:368)
	at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:548)
	at org.apache.hadoop.hive.ql.exec.Operator.initializeChildren(Operator.java:502)
	at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:368)
	at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:548)
	at org.apache.hadoop.hive.ql.exec.Operator.initializeChildren(Operator.java:502)
	at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:368)
	at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:548)
	at org.apache.hadoop.hive.ql.exec.Operator.initializeChildren(Operator.java:502)
	at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:368)
	at org.apache.hadoop.hive.ql.exec.MapOperator.initializeMapOperator(MapOperator.java:506)
	at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.init(MapRecordProcessor.java:314)
	... 16 more
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.exec.ReduceSinkOperator.initializeOp(ReduceSinkOperator.java:160)
	... 37 more
], TaskAttempt 1 failed, info=[Error: Error while running task ( failure ) : attempt_1598975134540_0001_2_00_000000_1:java.lang.RuntimeException: java.lang.RuntimeException: Map operator initialization failed
	at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:296)
	at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:250)
	at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:374)
	at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:73)
	at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:61)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:61)
	at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:37)
	at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)
	at org.apache.hadoop.hive.llap.daemon.impl.StatsRecordingThreadPool$WrappedCallable.call(StatsRecordingThreadPool.java:118)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.RuntimeException: Map operator initialization failed
	at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.init(MapRecordProcessor.java:351)
	at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:266)
	... 15 more
Caused by: java.lang.RuntimeException: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.exec.ReduceSinkOperator.initializeOp(ReduceSinkOperator.java:242)
	at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:359)
	at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:548)
	at org.apache.hadoop.hive.ql.exec.Operator.initializeChildren(Operator.java:502)
	at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:368)
	at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:548)
	at org.apache.hadoop.hive.ql.exec.Operator.initializeChildren(Operator.java:502)
	at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:368)
	at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:548)
	at org.apache.hadoop.hive.ql.exec.Operator.initializeChildren(Operator.java:502)
	at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:368)
	at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:548)
	at org.apache.hadoop.hive.ql.exec.Operator.initializeChildren(Operator.java:502)
	at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:368)
	at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:548)
	at org.apache.hadoop.hive.ql.exec.Operator.initializeChildren(Operator.java:502)
	at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:368)
	at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:548)
	at org.apache.hadoop.hive.ql.exec.Operator.initializeChildren(Operator.java:502)
	at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:368)
	at org.apache.hadoop.hive.ql.exec.MapOperator.initializeMapOperator(MapOperator.java:506)
	at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.init(MapRecordProcessor.java:314)
	... 16 more
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.exec.ReduceSinkOperator.initializeOp(ReduceSinkOperator.java:160)
	... 37 more
]], Vertex did not succeed due to OWN_TASK_FAILURE, failedTasks:1 killedTasks:0, Vertex vertex_1598975134540_0001_2_00 [Map 1] killed/failed due to:OWN_TASK_FAILURE]Vertex killed, vertexName=Reducer 2, vertexId=vertex_1598975134540_0001_2_01, diagnostics=[Vertex received Kill while in RUNNING state., Vertex did not succeed due to OTHER_VERTEX_FAILURE, failedTasks:0 killedTasks:1, Vertex vertex_1598975134540_0001_2_01 [Reducer 2] killed/failed due to:OTHER_VERTEX_FAILURE]DAG did not succeed due to VERTEX_FAILURE. failedVertices:1 killedVertices:1
	at org.apache.hadoop.hive.ql.exec.tez.TezTask.execute(TezTask.java:244)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:213)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:105)
	at org.apache.hadoop.hive.ql.Executor.launchTask(Executor.java:361)
	at org.apache.hadoop.hive.ql.Executor.launchTasks(Executor.java:334)
	at org.apache.hadoop.hive.ql.Executor.runTasks(Executor.java:245)
	at org.apache.hadoop.hive.ql.Executor.execute(Executor.java:108)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:498)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:307)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:302)
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:166)
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:232)
	at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:258)
	at org.apache.hadoop.hive.cli.CliDriver.processCmd1(CliDriver.java:203)
	at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:129)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:424)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:355)
	at org.apache.hadoop.hive.ql.QTestUtil.executeClientInternal(QTestUtil.java:740)
	at org.apache.hadoop.hive.ql.QTestUtil.executeClient(QTestUtil.java:710)
	at org.apache.hadoop.hive.cli.control.CoreCliDriver.runTest(CoreCliDriver.java:170)
	at org.apache.hadoop.hive.cli.control.CliAdapter.runTest(CliAdapter.java:157)
	at org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver(TestMiniLlapLocalCliDriver.java:62)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.apache.hadoop.hive.cli.control.CliAdapter$2$1.evaluate(CliAdapter.java:135)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.apache.hadoop.hive.cli.control.CliAdapter$1$1.evaluate(CliAdapter.java:95)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
{noformat}

"	HIVE	Closed	3	1	11212	pull-request-available
13432890	Change integration tests under DBInstallBase to CheckIn tests	"After HIVE-18588, some tests including those under [DBInstallBase|https://github.com/apache/hive/blob/1139c4b14db82a9e2316196819b35cfb713f34b5/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/dbinstall/DbInstallBase.java] class have been marked as integration tests mainly to keep the test duration low.

Nowadays, Hive developers rarely run all tests locally so separating between integration tests and unit tests does not provide a clear benefit. The separation adds maintenance cost and makes their execution more difficult scaring people away.

The goal of this issue is to change the tests under {{DBInstallBase}} from ""integration"" tests back to regular unit tests and run them as part of the standard maven test phase without any fancy arguments."	HIVE	Closed	3	4	11212	pull-request-available
13488652	INT64 Parquet timestamps cannot be mapped to most Hive numeric types	"When attempting to read a Parquet file with column of primitive type INT64 and logical type [TIMESTAMP|https://github.com/apache/parquet-format/blob/54e53e5d7794d383529dd30746378f19a12afd58/LogicalTypes.md?plain=1#L337] an error is raised when the Hive type is different from TIMESTAMP and BIGINT.

Consider a Parquet file (e.g., ts_file.parquet) with the following schema:
{code:json}
{
  ""name"": ""eventtime"",
  ""type"": [""null"", {
    ""type"": ""long"",
    ""logicalType"": ""timestamp-millis""
  }],
  ""default"": null
}
{code}
 
Mapping the column to a Hive numeric type among TINYINT, SMALLINT, INT, FLOAT, DOUBLE, DECIMAL, and trying to run a SELECT will give back an error.

The following snippet can be used to reproduce the problem.
{code:sql}
CREATE TABLE ts_table (eventtime INT) STORED AS PARQUET;
LOAD DATA LOCAL INPATH 'ts_file.parquet' into table ts_table;
SELECT * FROM ts_table;
{code}
This is a regression caused by HIVE-21215. Although, HIVE-21215 allows to read INT64 types as Hive TIMESTAMP, which was not possible before, at the same time it broke the mapping to every other Hive numeric type. The problem was addressed selectively for BIGINT type very recently (HIVE-26612).

The primary goal of this ticket is to restore backward compatibility since these use-cases were working before HIVE-21215."	HIVE	Closed	4	1	11212	backwards-compatibility, pull-request-available
13472089	HMS memory leak when compaction cleaner fails to remove obsolete files	"While investigating an issue where HMS becomes unresponsive we noticed a lot of failed attempts from the compaction Cleaner thread to remove obsolete directories with exceptions similar to the one below.
{noformat}
2022-06-16 05:48:24,819 ERROR org.apache.hadoop.hive.ql.txn.compactor.Cleaner: [Cleaner-executor-thread-0]: Caught exception when cleaning, unable to complete cleaning of id:4410976,dbname:my_database,tableName:my_table,partName:day=20220502,state:,type:MAJOR,enqueueTime:0,start:0,properties:null,runAs:some_user,tooManyAborts:false,hasOldAbort:false,highestWriteId:187502,errorMessage:null java.io.IOException: Not enough history available for (187502,x).  Oldest available base: hdfs://nameservice1/warehouse/tablespace/managed/hive/my_database.db/my_table/day=20220502/base_0188687_v4297872
	at org.apache.hadoop.hive.ql.io.AcidUtils.getAcidState(AcidUtils.java:1432)
	at org.apache.hadoop.hive.ql.txn.compactor.Cleaner.removeFiles(Cleaner.java:261)
	at org.apache.hadoop.hive.ql.txn.compactor.Cleaner.access$000(Cleaner.java:71)
	at org.apache.hadoop.hive.ql.txn.compactor.Cleaner$1.run(Cleaner.java:203)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1898)
	at org.apache.hadoop.hive.ql.txn.compactor.Cleaner.clean(Cleaner.java:200)
	at org.apache.hadoop.hive.ql.txn.compactor.Cleaner.lambda$run$0(Cleaner.java:105)
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorUtil$ThrowingRunnable.lambda$unchecked$0(CompactorUtil.java:54)
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1640)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
{noformat}
In addition the logs contained a large number of long JVM pauses as shown below and the HMS (RSZ) memory kept increasing at rate of 90MB per hour.
{noformat}
2022-06-16 16:17:17,805 WARN  org.apache.hadoop.hive.metastore.metrics.JvmPauseMonitor: [org.apache.hadoop.hive.metastore.metrics.JvmPauseMonitor$Monitor@5b022296]: Detected pause in JVM or host machine (eg GC): pause of approximately 34346ms
2022-06-16 16:17:21,497 INFO  org.apache.hadoop.hive.metastore.metrics.JvmPauseMonitor: [org.apache.hadoop.hive.metastore.metrics.JvmPauseMonitor$Monitor@5b022296]: Detected pause in JVM or host machine (eg GC): pause of approximately 1690ms
2022-06-16 16:17:57,696 WARN  org.apache.hadoop.hive.metastore.metrics.JvmPauseMonitor: [org.apache.hadoop.hive.metastore.metrics.JvmPauseMonitor$Monitor@5b022296]: Detected pause in JVM or host machine (eg GC): pause of approximately 34697ms
2022-06-16 16:18:01,326 INFO  org.apache.hadoop.hive.metastore.metrics.JvmPauseMonitor: [org.apache.hadoop.hive.metastore.metrics.JvmPauseMonitor$Monitor@5b022296]: Detected pause in JVM or host machine (eg GC): pause of approximately 1628ms
2022-06-16 16:18:37,280 WARN  org.apache.hadoop.hive.metastore.metrics.JvmPauseMonitor: [org.apache.hadoop.hive.metastore.metrics.JvmPauseMonitor$Monitor@5b022296]: Detected pause in JVM or host machine (eg GC): pause of approximately 34453ms
2022-06-16 16:18:40,927 INFO  org.apache.hadoop.hive.metastore.metrics.JvmPauseMonitor: [org.apache.hadoop.hive.metastore.metrics.JvmPauseMonitor$Monitor@5b022296]: Detected pause in JVM or host machine (eg GC): pause of approximately 1646ms
2022-06-16 16:19:16,929 WARN  org.apache.hadoop.hive.metastore.metrics.JvmPauseMonitor: [org.apache.hadoop.hive.metastore.metrics.JvmPauseMonitor$Monitor@5b022296]: Detected pause in JVM or host machine (eg GC): pause of approximately 33997ms
2022-06-16 16:19:20,572 INFO  org.apache.hadoop.hive.metastore.metrics.JvmPauseMonitor: [org.apache.hadoop.hive.metastore.metrics.JvmPauseMonitor$Monitor@5b022296]: Detected pause in JVM or host machine (eg GC): pause of approximately 1637ms
2022-06-16 16:20:01,643 WARN  org.apache.hadoop.hive.metastore.metrics.JvmPauseMonitor: [org.apache.hadoop.hive.metastore.metrics.JvmPauseMonitor$Monitor@5b022296]: Detected pause in JVM or host machine (eg GC): pause of approximately 39329ms
2022-06-16 16:20:05,572 INFO  org.apache.hadoop.hive.metastore.metrics.JvmPauseMonitor: [org.apache.hadoop.hive.metastore.metrics.JvmPauseMonitor$Monitor@5b022296]: Detected pause in JVM or host machine (eg GC): pause of approximately 1927ms
{noformat}
We took a heapdump of the HMS around the time that it becomes unresponsive and we have seen many Configuration objects (~40K) occupying more than 90% of the current heap (~9GB).
{noformat}
Class Name                                   |     Objects |  Shallow Heap |    Retained Heap
----------------------------------------------------------------------------------------------
org.apache.hadoop.conf.Configuration         |      39,452 |     1,893,696 | >= 8,560,573,960
java.util.concurrent.ConcurrentHashMap       |     155,863 |     9,975,232 | >= 4,696,003,968
java.util.concurrent.ConcurrentHashMap$Node[]|     139,348 | 1,312,967,944 | >= 4,686,230,296
java.util.Properties                         |      87,119 |     4,181,712 | >= 4,193,638,904
java.util.Hashtable$Entry[]                  |      87,840 |   987,968,472 | >= 4,189,518,928
java.util.concurrent.ConcurrentHashMap$Node  |  99,097,078 | 3,171,106,496 | >= 3,375,319,552
java.util.Hashtable$Entry                    | 100,047,081 | 3,201,506,592 | >= 3,201,551,936
org.postgresql.jdbc.PgConnection             |       6,488 |       830,464 |   >= 551,442,952
----------------------------------------------------------------------------------------------

{noformat}
It turns out that these Configuration objects are all referenced by CACHE entries in org.apache.hadoop.fs.FileSystem$Cache.
{noformat}
Class Name                                                                             | Shallow Heap | Retained Heap
----------------------------------------------------------------------------------------------------------------------
org.apache.hadoop.fs.FileSystem$Cache @ 0x45403fe70                                    |           32 |   108,671,824
|- <class> class org.apache.hadoop.fs.FileSystem$Cache @ 0x45410c3e0                   |            8 |           544
'- map java.util.HashMap @ 0x453ffb598                                                 |           48 |    92,777,232
   |- <class> class java.util.HashMap @ 0x4520382c8 System Class                       |           40 |           168
   |- entrySet java.util.HashMap$EntrySet @ 0x454077848                                |           16 |            16
   '- table java.util.HashMap$Node[32768] @ 0x463585b68                                |      131,088 |    92,777,168
      |- class java.util.HashMap$Node[] @ 0x4520b7790                                  |            0 |             0
      '- [1786] java.util.HashMap$Node @ 0x451998ce0                                   |           32 |         9,968
         |- <class> class java.util.HashMap$Node @ 0x4520b7728 System Class            |            8 |            32
         '- value org.apache.hadoop.hdfs.DistributedFileSystem @ 0x452990178           |           56 |         4,976
            |- <class> class org.apache.hadoop.hdfs.DistributedFileSystem @ 0x45402e290|            8 |         4,664
            |- uri java.net.URI @ 0x451a05cd0  hdfs://nameservice1                     |           80 |           432
            |- dfs org.apache.hadoop.hdfs.DFSClient @ 0x451f5d9b8                      |          128 |         3,824
            '- conf org.apache.hadoop.hive.conf.HiveConf @ 0x453a34b38                 |           80 |       250,160
----------------------------------------------------------------------------------------------------------------------
{noformat}
As long as they are in the CACHE they cannot be garbage collected so this leads to a memory leak.

The memory leak seems to come from the fact the compaction Cleaner attempts to [remove|https://github.com/apache/hive/blob/69e6a5a4151100849d2b03b6b14b1605c3abc3f1/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java#L266] the obsolete files and fails. The exception does not allow the [filesystem cleanup|https://github.com/apache/hive/blob/69e6a5a4151100849d2b03b6b14b1605c3abc3f1/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java#L270] to take place so we are leaving filesystem entries in the CACHE and subsequently configuration objects.

Although, the HMS unresponsiveness in this use-case may not be due to lack of memory the leak needs to be addressed to avoid hitting OOM."	HIVE	Closed	3	1	11212	pull-request-available
13485903	Remove HiveRelBuilder.aggregateCall override and refactor callers to use existing public methods	"The HiveRelBuilder overrides [aggregateCall|https://github.com/apache/hive/blob/8c3567ea8e423b202cde370f4d3fb401bcc23e46/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/HiveRelBuilder.java#L246] from its superclass simply to expose and use it in HiveRewriteToDataSketchesRules. 

However, there is no real need to override this method since we can achieve the same outcome by using existing methods in RelBuilder which are easier to use and understand. Furthermore it is safer to depend on public APIs since are more stable in general."	HIVE	Closed	3	3	11212	pull-request-available
13432897	Error: ORA-00904 when initializing metastore schema in Oracle	"The Metastore schema tool fails to create the database schema when the underlying backend is Oracle. 

The initialization scripts fails while creating the ""REPLICATION_METRICS"" table:

{noformat}
338/362      --Create table replication metrics
339/362      CREATE TABLE ""REPLICATION_METRICS"" ( 
  ""RM_SCHEDULED_EXECUTION_ID"" number PRIMARY KEY, 
  ""RM_POLICY"" varchar2(256) NOT NULL, 
  ""RM_DUMP_EXECUTION_ID"" number NOT NULL, 
  ""RM_METADATA"" varchar2(4000), 
  ""RM_PROGRESS"" varchar2(4000), 
  ""RM_START_TIME"" integer NOT NULL, 
  ""MESSAGE_FORMAT"" VARCHAR(16) DEFAULT 'json-0.2', 
);
Error: ORA-00904: : invalid identifier (state=42000,code=904)
{noformat}

The problem can be reproduced by running the {{ITestOracle}}.

{noformat}
mvn -pl standalone-metastore/metastore-server verify -DskipITests=false -Dit.test=ITestOracle -Dtest=nosuch
{noformat}


"	HIVE	Closed	1	1	11212	pull-request-available
13255087	Query with multiple lateral views hangs during compilation	"Steps To Repro:
{code:java}
-- create table 

CREATE EXTERNAL TABLE `jsontable`( 
`json_string` string) 
ROW FORMAT SERDE 
'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe' 
STORED AS INPUTFORMAT 
'org.apache.hadoop.mapred.TextInputFormat' 
OUTPUTFORMAT 
'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat' ;

-- Run explain of the query
explain SELECT
*
FROM jsontable
lateral view explode(split(regexp_replace(get_json_object(jsontable.json_string, '$.jsonfield.addr.city'), ""\\[|\\]|\"""", """"),',')) t1 as c1
lateral view explode(split(regexp_replace(get_json_object(jsontable.json_string, '$.jsonfield.addr.country'), ""\\[|\\]|\"""", """"),',')) t2 as c2
lateral view explode(split(regexp_replace(get_json_object(jsontable.json_string, '$.jsonfield.addr'), ""\\[|\\]|\"""", """"),',')) t3 as c3
lateral view explode(split(regexp_replace(get_json_object(jsontable.json_string, '$.jsonfield.addr.postalCode'), ""\\[|\\]|\"""", """"),',')) t4 as c4
lateral view explode(split(regexp_replace(get_json_object(jsontable.json_string, '$.jsonfield.addr.state'), ""\\[|\\]|\"""", """"),',')) t5 as c5
lateral view explode(split(regexp_replace(get_json_object(jsontable.json_string, '$.jsonfield.addr.streetAddressLine'), ""\\[|\\]|\"""", """"),',')) t6 as c6
lateral view explode(split(regexp_replace(get_json_object(jsontable.json_string, '$.jsonfield.dummyfield'), ""\\[|\\]|\"""", """"),',')) t7 as c7
lateral view explode(split(regexp_replace(get_json_object(jsontable.json_string, '$.jsonfield.dummyfield'), ""\\[|\\]|\"""", """"),',')) t8 as c8
lateral view explode(split(regexp_replace(get_json_object(jsontable.json_string, '$.jsonfield.dummyfield.name.suffix'), ""\\[|\\]|\"""", """"),',')) t9 as c9
lateral view explode(split(regexp_replace(get_json_object(jsontable.json_string, '$.jsonfield.id.extension'), ""\\[|\\]|\"""", """"),',')) t10 as c10
lateral view explode(split(regexp_replace(get_json_object(jsontable.json_string, '$.jsonfield.id'), ""\\[|\\]|\"""", """"),',')) t11 as c11
lateral view explode(split(regexp_replace(get_json_object(jsontable.json_string, '$.jsonfield.id.root'), ""\\[|\\]|\"""", """"),',')) t12 as c12
lateral view explode(split(regexp_replace(get_json_object(jsontable.json_string, '$.jsonfield.telecom.'), ""\\[|\\]|\"""", """"),',')) t13 as c13
lateral view explode(split(regexp_replace(get_json_object(jsontable.json_string, '$.jsonfield.dummyfield1.use'), ""\\[|\\]|\"""", """"),',')) t14 as c14
lateral view explode(split(regexp_replace(get_json_object(jsontable.json_string, '$.jsonfield.dummyfield1.value'), ""\\[|\\]|\"""", """"),',')) t15 as c15
lateral view explode(split(regexp_replace(get_json_object(jsontable.json_string, '$.jsonfield1.dummyfield1.code'), ""\\[|\\]|\"""", """"),',')) t16 as c16
lateral view explode(split(regexp_replace(get_json_object(jsontable.json_string, '$.jsonfield1.dummyfield1.value'), ""\\[|\\]|\"""", """"),',')) t17 as c17
lateral view explode(split(regexp_replace(get_json_object(jsontable.json_string, '$.jsonfield2.city'), ""\\[|\\]|\"""", """"),',')) t18 as c18
lateral view explode(split(regexp_replace(get_json_object(jsontable.json_string, '$.jsonfield2.city'), ""\\[|\\]|\"""", """"),',')) t19 as c19
lateral view explode(split(regexp_replace(get_json_object(jsontable.json_string, '$.jsonfield2.country'), ""\\[|\\]|\"""", """"),',')) t20 as c20
lateral view explode(split(regexp_replace(get_json_object(jsontable.json_string, '$.jsonfield2.country'), ""\\[|\\]|\"""", """"),',')) t21 as c21
lateral view explode(split(regexp_replace(get_json_object(jsontable.json_string, '$.jsonfield'), ""\\[|\\]|\"""", """"),',')) t22 as c22
lateral view explode(split(regexp_replace(get_json_object(jsontable.json_string, '$.jsonfield2.postalCode'), ""\\[|\\]|\"""", """"),',')) t23 as c23
lateral view explode(split(regexp_replace(get_json_object(jsontable.json_string, '$.jsonfield2.postalCode'), ""\\[|\\]|\"""", """"),',')) t24 as c24
lateral view explode(split(regexp_replace(get_json_object(jsontable.json_string, '$.jsonfield2.state'), ""\\[|\\]|\"""", """"),',')) t25 as c25
lateral view explode(split(regexp_replace(get_json_object(jsontable.json_string, '$.jsonfield2.state'), ""\\[|\\]|\"""", """"),',')) t26 as c26
lateral view explode(split(regexp_replace(get_json_object(jsontable.json_string, '$.jsonfield2'), ""\\[|\\]|\"""", """"),',')) t27 as c27
lateral view explode(split(regexp_replace(get_json_object(jsontable.json_string, '$.jsonfield2.streetAddressLine'), ""\\[|\\]|\"""", """"),',')) t28 as c28
lateral view explode(split(regexp_replace(get_json_object(jsontable.json_string, '$.jsonfield2.use'), ""\\[|\\]|\"""", """"),',')) t29 as c29
lateral view explode(split(regexp_replace(get_json_object(jsontable.json_string, '$.jsonfield3'), ""\\[|\\]|\"""", """"),',')) t30 as c30
lateral view explode(split(regexp_replace(get_json_object(jsontable.json_string, '$.jsonfield3'), ""\\[|\\]|\"""", """"),',')) t31 as c31
lateral view explode(split(regexp_replace(get_json_object(jsontable.json_string, '$.jsonfield4'), ""\\[|\\]|\"""", """"),',')) t32 as c32
;

-- it will hung forever
{code}
– HS2 jstacks
{code:java}
// 

""8ed37c3a-be03-4f74-9afd-419d05609b9c HiveServer2-Handler-Pool: Thread-85"" #85 prio=5 os_prio=0 tid=0x00007f3bd873f800 nid=0x90b94 runnable [0x00007f3baa6e2000]""8ed37c3a-be03-4f74-9afd-419d05609b9c HiveServer2-Handler-Pool: Thread-85"" #85 prio=5 os_prio=0 tid=0x00007f3bd873f800 nid=0x90b94 runnable [0x00007f3baa6e2000]   java.lang.Thread.State: RUNNABLE at java.util.regex.Pattern$Curly.match0(Pattern.java:4272) at java.util.regex.Pattern$Curly.match(Pattern.java:4234) at java.util.regex.Pattern$Slice.match(Pattern.java:3972) at java.util.regex.Pattern$GroupHead.match(Pattern.java:4658) at java.util.regex.Matcher.match(Matcher.java:1270) at java.util.regex.Matcher.matches(Matcher.java:604) at org.apache.hadoop.hive.ql.lib.RuleRegExp.costPatternWithWildCardChar(RuleRegExp.java:236) at org.apache.hadoop.hive.ql.lib.RuleRegExp.cost(RuleRegExp.java:279) at org.apache.hadoop.hive.ql.lib.DefaultRuleDispatcher.dispatch(DefaultRuleDispatcher.java:72) at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.dispatchAndReturn(DefaultGraphWalker.java:105) at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.dispatch(DefaultGraphWalker.java:89) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:43) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.PreOrderOnceWalker.walk(PreOrderOnceWalker.java:54) at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.startWalking(DefaultGraphWalker.java:120) at org.apache.hadoop.hive.ql.ppd.SyntheticJoinPredicate.transform(SyntheticJoinPredicate.java:106) at org.apache.hadoop.hive.ql.optimizer.Optimizer.optimize(Optimizer.java:250) at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12423) at org.apache.hadoop.hive.ql.parse.CalcitePlanner.analyzeInternal(CalcitePlanner.java:360) at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:289) at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:664) at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1869) at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:1816) at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:1811) at org.apache.hadoop.hive.ql.reexec.ReExecDriver.compileAndRespond(ReExecDriver.java:126) at org.apache.hive.service.cli.operation.SQLOperation.prepare(SQLOperation.java:197) at org.apache.hive.service.cli.operation.SQLOperation.runInternal(SQLOperation.java:262) at org.apache.hive.service.cli.operation.Operation.run(Operation.java:247) at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementInternal(HiveSessionImpl.java:575) at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementAsync(HiveSessionImpl.java:561) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.hive.service.cli.session.HiveSessionProxy.invoke(HiveSessionProxy.java:78) at org.apache.hive.service.cli.session.HiveSessionProxy.access$000(HiveSessionProxy.java:36) at org.apache.hive.service.cli.session.HiveSessionProxy$1.run(HiveSessionProxy.java:63) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:422) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) at org.apache.hive.service.cli.session.HiveSessionProxy.invoke(HiveSessionProxy.java:59) at com.sun.proxy.$Proxy45.executeStatementAsync(Unknown Source) at org.apache.hive.service.cli.CLIService.executeStatementAsync(CLIService.java:315) at org.apache.hive.service.cli.thrift.ThriftCLIService.ExecuteStatement(ThriftCLIService.java:566) at org.apache.hive.service.rpc.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1557) at org.apache.hive.service.rpc.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1542) at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39) at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39) at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:56) at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:745)
{code}
 

attached 10 jstacks taken at the interval of 30 seconds.

 "	HIVE	Closed	2	1	11212	pull-request-available
13426097	ClassCastException when pushing boolean column predicate in HBaseStorageHandler	"The following queries fail with a {{ClassCastException}} when the optimizer tries to push the predicates in the underlying HBase table.

{code:sql}
CREATE TABLE hbase_table(row_key string, c1 boolean, c2 boolean)
STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'
WITH SERDEPROPERTIES (
""hbase.columns.mapping"" = "":key,cf:c1,cf:c2""
);

-- Q1
select * from hbase_table where c1 and c2;
-- Q2
select * from hbase_table where c1=true and c2=true;
{code}

{code:java}
ClassCastException org.apache.hadoop.hive.ql.plan.ExprNodeColumnDesc cannot be cast to org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc
java.lang.ClassCastException: org.apache.hadoop.hive.ql.plan.ExprNodeColumnDesc cannot be cast to org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc
        at org.apache.hadoop.hive.ql.index.IndexPredicateAnalyzer$1.process(IndexPredicateAnalyzer.java:163)
        at org.apache.hadoop.hive.ql.lib.DefaultRuleDispatcher.dispatch(DefaultRuleDispatcher.java:90)
        at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.dispatchAndReturn(DefaultGraphWalker.java:105)
        at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.dispatch(DefaultGraphWalker.java:89)
        at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.walk(DefaultGraphWalker.java:178)
        at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.startWalking(DefaultGraphWalker.java:120)
        at org.apache.hadoop.hive.ql.index.IndexPredicateAnalyzer.analyzePredicate(IndexPredicateAnalyzer.java:174)
        at org.apache.hadoop.hive.hbase.HBaseStorageHandler.decomposePredicate(HBaseStorageHandler.java:415) 
{code}

mvn test -Dtest=TestHBaseCliDriver -Dqfile=test.q -Dtest.output.overwrite -DskipSparkTests -pl itests/qtest -Pitests

The failure in Q2 is probably related to HIVE-13815 since the expression (c1 = true and c2 = true) is simplified to (c1 and c2) leading to the exception above but the problem was probably there even before as Q1 is failing as well with the same stacktrace.
"	HIVE	Closed	3	1	11212	pull-request-available
13556518	Tests under hive-unit module are not running	"All the tests under hive-unit module are not running currently in master neither locally nor in Jenkins CI.

{noformat}
mvn test -pl itests/hive-unit -Pitests
{noformat}

{noformat}
[INFO] — maven-surefire-plugin:3.0.0-M4:test (default-test) @ hive-it-unit —
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  10.444 s
[INFO] Finished at: 2023-11-02T12:21:51+01:00
[INFO] ------------------------------------------------------------------------
{noformat}

The problem is caused by HIVE-27757 as it can be seen by comparing the test reports in master:
* http://ci.hive.apache.org/job/hive-precommit/job/master/1907/testReport/
* http://ci.hive.apache.org/job/hive-precommit/job/master/1906/testReport/

Observe that when HIVE-27757 was merged the total number of tests dropped from 49,200 (1906) to 47,663 (1907) reducing the total number of tests by 1537. Comparing the two test reports together it becomes clear that all the tests under hive-unit module are now missing.

The problem seems to be caused by the new junit-jupiter-engine dependency that was added in hive-unit module."	HIVE	Closed	3	1	11212	pull-request-available
13567897	Refactor ParseDriver to remove duplicate code	"The [ParseDriver class|https://github.com/apache/hive/blob/56e7aae05016603e6064eb55e9bbe49bfab934f0/parser/src/java/org/apache/hadoop/hive/ql/parse/ParseDriver.java#L41] has lots of duplicated code since roughly every method in there is a copy of the previous one. 

The goal is to refactor this class to reduce duplicate code and improve readability and maintenance."	HIVE	Open	3	3	11212	pull-request-available
13447911	Add unit tests for Hive#getPartitionsByNames using batching	[Hive#getPartitionsByNames|https://github.com/apache/hive/blob/6626b5564ee206db5a656d2f611ed71f10a0ffc1/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java#L4155] supports decomposing requests in batches but there are no unit tests checking for the ValidWriteIdList when batching is used.	HIVE	Closed	3	7	11212	pull-request-available
13361243	Replace HiveSubQueryFinder with RexUtil.SubQueryFinder	HiveSubQueryFinder has been copied from RexUtil::SubQueryFinder due to CALCITE-1726. Currently, Hive is in calcite-1.21.0 and this bug is resolved so the duplicated code can be removed.	HIVE	Closed	3	4	11212	pull-request-available
13486626	Replace HiveFilterMergeRule with Calcite's built-in implementation	"The rule was copied from Calcite to address HIVE-23389 as a temporary workaround till the next Calcite upgrade. 

Now that Hive is on calcite 1.25.0 (HIVE-23456) the in-house copy can be removed."	HIVE	Closed	3	4	11212	pull-request-available
13449443	Remove unused junit runners from test-utils module	"The two classes under https://github.com/apache/hive/tree/master/testutils/src/java/org/apache/hive/testutils/junit/runners namely:
* [ConcurrentTestRunner|https://github.com/apache/hive/blob/fe0f1a648b14cdf27edcf7a5d323cbd060104ebf/testutils/src/java/org/apache/hive/testutils/junit/runners/ConcurrentTestRunner.java]
* [ConcurrentScheduler|https://github.com/apache/hive/blob/fe0f1a648b14cdf27edcf7a5d323cbd060104ebf/testutils/src/java/org/apache/hive/testutils/junit/runners/model/ConcurrentScheduler.java]

have been introduced a long time ago by HIVE-2935 to somewhat parallelize execution for {{TestBeeLineDriver}}.

However, since HIVE-14444 (resolved 6 years ago) they are not used by anyone and unlikely to be used again in the future since there are much more modern alternatives."	HIVE	Closed	5	3	11212	pull-request-available
13405232	Setup JDBC databases in tests via QT options	"The goal of this jira is to add a new QT option for setting up JDBC DBMS and using it in qtests which need a JDBC endpoint up and running. It can be used in tests with external JDBC tables, connectors, etc.

A sample file using the proposed option ({{qt:database}}) is shown below.
{code:sql}
--!qt:database:postgres:init_sript_1234.sql:cleanup_script_1234.sql

CREATE EXTERNAL TABLE country (name varchar(80))
STORED BY 'org.apache.hive.storage.jdbc.JdbcStorageHandler'
TBLPROPERTIES (
""hive.sql.database.type"" = ""POSTGRES"",
""hive.sql.jdbc.driver"" = ""org.postgresql.Driver"",
""hive.sql.jdbc.url"" = ""jdbc:postgresql://localhost:5432/qtestDB"",
""hive.sql.dbcp.username"" = ""qtestuser"",
""hive.sql.dbcp.password"" = ""qtestpassword"",
""hive.sql.table"" = ""country"");
EXPLAIN CBO SELECT COUNT(*) from country;
SELECT COUNT(*) from country;
{code}
This builds upon HIVE-25423 but proposes to use JDBC datasources without the need for a using a specific CLI driver. Furthermore, the proposed QT option syntax allows using customised init/cleanup scripts for the JDBC datasource per test."	HIVE	Closed	3	4	11212	pull-request-available
13451350	TestWebHCatE2e causes surefire fork to exit and fails	"Any attempt to run TestWebHCatE2e in current master ([https://github.com/apache/hive/commit/948f9fb56a00e981cd653146de44ae82307b4f2f]) causes the surefire fork to exit and the test fails.
{noformat}
cd hcatalog/webhcat/svr && mvn test -Dtest=TestWebHCatE2e

[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:3.0.0-M4:test (default-test) on project hive-webhcat: There are test failures.
[ERROR] 
[ERROR] Please refer to /home/stamatis/Projects/Apache/hive/hcatalog/webhcat/svr/target/surefire-reports for the individual test results.
[ERROR] Please refer to dump files (if any exist) [date].dump, [date]-jvmRun[N].dump and [date].dumpstream.
[ERROR] ExecutionException The forked VM terminated without properly saying goodbye. VM crash or System.exit called?
[ERROR] Command was /bin/sh -c cd /home/stamatis/Projects/Apache/hive/hcatalog/webhcat/svr && /opt/jdks/jdk1.8.0_261/jre/bin/java -Xmx2048m -jar /home/stamatis/Projects/Apache/hive/hcatalog/webhcat/svr/target/surefire/surefirebooter4564605288390864592.jar /home/stamatis/Projects/Apache/hive/hcatalog/webhcat/svr/target/surefire 2022-06-20T16-29-05_858-jvmRun1 surefire4795088574293215609tmp surefire_01535173811171404671tmp
[ERROR] Error occurred in starting fork, check output in log
[ERROR] Process Exit Code: 1
[ERROR] org.apache.maven.surefire.booter.SurefireBooterForkException: ExecutionException The forked VM terminated without properly saying goodbye. VM crash or System.exit called?
[ERROR] Command was /bin/sh -c cd /home/stamatis/Projects/Apache/hive/hcatalog/webhcat/svr && /opt/jdks/jdk1.8.0_261/jre/bin/java -Xmx2048m -jar /home/stamatis/Projects/Apache/hive/hcatalog/webhcat/svr/target/surefire/surefirebooter4564605288390864592.jar /home/stamatis/Projects/Apache/hive/hcatalog/webhcat/svr/target/surefire 2022-06-20T16-29-05_858-jvmRun1 surefire4795088574293215609tmp surefire_01535173811171404671tmp
[ERROR] Error occurred in starting fork, check output in log
[ERROR] Process Exit Code: 1
[ERROR] 	at org.apache.maven.plugin.surefire.booterclient.ForkStarter.awaitResultsDone(ForkStarter.java:513)
[ERROR] 	at org.apache.maven.plugin.surefire.booterclient.ForkStarter.runSuitesForkPerTestSet(ForkStarter.java:460)
[ERROR] 	at org.apache.maven.plugin.surefire.booterclient.ForkStarter.run(ForkStarter.java:301)
[ERROR] 	at org.apache.maven.plugin.surefire.booterclient.ForkStarter.run(ForkStarter.java:249)
[ERROR] 	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1217)
[ERROR] 	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1063)
[ERROR] 	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:889)
[ERROR] 	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
[ERROR] 	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:210)
[ERROR] 	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:156)
[ERROR] 	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:148)
[ERROR] 	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:117)
[ERROR] 	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
[ERROR] 	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
[ERROR] 	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:128)
[ERROR] 	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:305)
[ERROR] 	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
[ERROR] 	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
[ERROR] 	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:957)
[ERROR] 	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:289)
[ERROR] 	at org.apache.maven.cli.MavenCli.main(MavenCli.java:193)
[ERROR] 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[ERROR] 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
[ERROR] 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
[ERROR] 	at java.lang.reflect.Method.invoke(Method.java:498)
[ERROR] 	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
[ERROR] 	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
[ERROR] 	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
[ERROR] 	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
[ERROR] Caused by: org.apache.maven.surefire.booter.SurefireBooterForkException: The forked VM terminated without properly saying goodbye. VM crash or System.exit called?
[ERROR] Command was /bin/sh -c cd /home/stamatis/Projects/Apache/hive/hcatalog/webhcat/svr && /opt/jdks/jdk1.8.0_261/jre/bin/java -Xmx2048m -jar /home/stamatis/Projects/Apache/hive/hcatalog/webhcat/svr/target/surefire/surefirebooter4564605288390864592.jar /home/stamatis/Projects/Apache/hive/hcatalog/webhcat/svr/target/surefire 2022-06-20T16-29-05_858-jvmRun1 surefire4795088574293215609tmp surefire_01535173811171404671tmp
[ERROR] Error occurred in starting fork, check output in log
[ERROR] Process Exit Code: 1
[ERROR] 	at org.apache.maven.plugin.surefire.booterclient.ForkStarter.fork(ForkStarter.java:690)
[ERROR] 	at org.apache.maven.plugin.surefire.booterclient.ForkStarter.access$600(ForkStarter.java:118)
[ERROR] 	at org.apache.maven.plugin.surefire.booterclient.ForkStarter$2.call(ForkStarter.java:447)
[ERROR] 	at org.apache.maven.plugin.surefire.booterclient.ForkStarter$2.call(ForkStarter.java:423)
[ERROR] 	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
[ERROR] 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
[ERROR] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
[ERROR] 	at java.lang.Thread.run(Thread.java:748)
{noformat}
The failure also appears in [CI |http://ci.hive.apache.org/blue/organizations/jenkins/hive-precommit/detail/master/1281/pipeline/445#step-454-log-368].

CI appears to be green cause the error is masked by [maven.test.failure.ignore|https://maven.apache.org/surefire/maven-surefire-plugin/test-mojo.html#testfailureignore] property due to SUREFIRE-1426."	HIVE	Resolved	3	1	11212	pull-request-available
13313701	Metastore's update service wrongly strips partition column stats from the cache	"Metastore's update service wrongly strips partition column stats from the cache in an attempt to update them. The issue may go unnoticed since missing stats do not lead to query failures. 

However, they can alter significantly the query plan affecting performance. Moreover, they lead to flakiness since some times the stats are present and sometimes are not leading to a query that has a different plan overtime. 

Normally missing elements from the cache shouldn't be a correctness problem since we can always fallback to the raw stats. Unfortunately, there are many interconnections with other parts of the code (e.g., code to obtain aggregate statistics) where this contract breaks.   "	HIVE	Closed	2	1	11212	pull-request-available
13350541	Run tests using specific log4j2 configuration conveniently	"In order to reproduce a problem (e.g., HIVE-24569) or validate that a log4j2 configuration is working as expected it is necessary to run a test and explicitly specify which configuration should be used. Moreover, after the end of the test in question it is desirable to restore the old logging configuration that was used before launching the test to avoid affecting the overall logging output.

The goal of this issue is to introduce a convenient & declarative way of running tests with log4j2 configurations based on Jupiter extensions and annotations. The test could like below:

{code:java}
  @Test
  @Log4jConfig(""test-log4j2.properties"")
  void testUseExplicitConfig() {
    // Do something and assert
  }
{code}

"	HIVE	Closed	3	4	11212	pull-request-available
13328276	Memory leak in HS2 DbTxnManager when compiling SHOW LOCKS statement	"The problem can be reproduced by executing repeatedly a SHOW LOCK statement and monitoring the heap memory of HS2. For a small heap (e.g., 2g) it only takes a few minutes before the server crashes with OutOfMemory error such as the one shown below.

{noformat}
java.lang.OutOfMemoryError: GC overhead limit exceeded
        at java.util.Arrays.copyOf(Arrays.java:3332)
        at java.lang.AbstractStringBuilder.ensureCapacityInternal(AbstractStringBuilder.java:124)
        at java.lang.AbstractStringBuilder.append(AbstractStringBuilder.java:448)
        at java.lang.StringBuilder.append(StringBuilder.java:136)
        at org.apache.maven.surefire.booter.ForkedChannelEncoder.encodeMessage(ForkedChannelEncoder.j
        at org.apache.maven.surefire.booter.ForkedChannelEncoder.setOutErr(ForkedChannelEncoder.java:
        at org.apache.maven.surefire.booter.ForkedChannelEncoder.stdErr(ForkedChannelEncoder.java:166
        at org.apache.maven.surefire.booter.ForkingRunListener.writeTestOutput(ForkingRunListener.jav
        at org.apache.maven.surefire.report.ConsoleOutputCapture$ForwardingPrintStream.write(ConsoleO
        at org.apache.logging.log4j.core.util.CloseShieldOutputStream.write(CloseShieldOutputStream.j
        at org.apache.logging.log4j.core.appender.OutputStreamManager.writeToDestination(OutputStream
        at org.apache.logging.log4j.core.appender.OutputStreamManager.flushBuffer(OutputStreamManager
        at org.apache.logging.log4j.core.appender.OutputStreamManager.flush(OutputStreamManager.java:
        at org.apache.logging.log4j.core.appender.AbstractOutputStreamAppender.directEncodeEvent(Abst
        at org.apache.logging.log4j.core.appender.AbstractOutputStreamAppender.tryAppend(AbstractOutp
        at org.apache.logging.log4j.core.appender.AbstractOutputStreamAppender.append(AbstractOutputS
        at org.apache.logging.log4j.core.config.AppenderControl.tryCallAppender(AppenderControl.java:
        at org.apache.logging.log4j.core.config.AppenderControl.callAppender0(AppenderControl.java:12
        at org.apache.logging.log4j.core.config.AppenderControl.callAppenderPreventRecursion(Appender
        at org.apache.logging.log4j.core.config.AppenderControl.callAppender(AppenderControl.java:84)
        at org.apache.logging.log4j.core.config.LoggerConfig.callAppenders(LoggerConfig.java:543)
        at org.apache.logging.log4j.core.config.LoggerConfig.processLogEvent(LoggerConfig.java:502)
        at org.apache.logging.log4j.core.config.LoggerConfig.log(LoggerConfig.java:485)
        at org.apache.logging.log4j.core.config.LoggerConfig.log(LoggerConfig.java:460)
        at org.apache.logging.log4j.core.config.AwaitCompletionReliabilityStrategy.log(AwaitCompletio
        at org.apache.logging.log4j.core.Logger.log(Logger.java:162)
        at org.apache.logging.log4j.spi.AbstractLogger.tryLogMessage(AbstractLogger.java:2190)
        at org.apache.logging.log4j.spi.AbstractLogger.logMessageTrackRecursion(AbstractLogger.java:2
        at org.apache.logging.log4j.spi.AbstractLogger.logMessageSafely(AbstractLogger.java:2127)
        at org.apache.logging.log4j.spi.AbstractLogger.logMessage(AbstractLogger.java:2008)
        at org.apache.logging.log4j.spi.AbstractLogger.logIfEnabled(AbstractLogger.java:1867)
        at org.apache.logging.slf4j.Log4jLogger.info(Log4jLogger.java:179)
{noformat}

The heap dump shows (summary.png) that most of the memory is consumed by {{Hashtable$Entry}} and {{ConcurrentHashMap$Node}} objects coming from Hive configurations referenced by {{DbTxnManager}}. 

The latter are not eligible for garbage collection since at [construction|https://github.com/apache/hive/blob/975c832b6d069559c5b406a4aa8def3180fe4e75/ql/src/java/org/apache/hadoop/hive/ql/lockmgr/DbTxnManager.java#L212] time they are passed implicitly in a callback  stored inside ShutdownHookManager.  

When the {{DbTxnManager}} is closed properly the leak is not present since the callback is [removed|https://github.com/apache/hive/blob/975c832b6d069559c5b406a4aa8def3180fe4e75/ql/src/java/org/apache/hadoop/hive/ql/lockmgr/DbTxnManager.java#L882] from ShutdownHookManager. 

{{SHOW LOCKS}} statements create ([ShowDbLocksAnalyzer|https://github.com/apache/hive/blob/975c832b6d069559c5b406a4aa8def3180fe4e75/ql/src/java/org/apache/hadoop/hive/ql/ddl/table/lock/show/ShowDbLocksAnalyzer.java#L52], [ShowLocksAnalyzer|https://github.com/apache/hive/blob/975c832b6d069559c5b406a4aa8def3180fe4e75/ql/src/java/org/apache/hadoop/hive/ql/ddl/table/lock/show/ShowLocksAnalyzer.java#L72]) a new {{TxnManager}} and they never close it leading to the memory leak.
"	HIVE	Closed	3	1	11212	pull-request-available
13537674	Exception while getting kafka delegation tokens in Kerberos/SSL enabled clusters	"When Hiveserver2 is in a secure cluster (e.g., Kerberos) and Kafka brokers have Kerberos and SSL enabled (SASL_SSL) queries will fail while trying to obtain a delegation token.

To reproduce the problem create a cluster with Kerberos and SSL enabled and do the following:

{code:sql}
CREATE EXTERNAL TABLE person
(`msg` string)
STORED BY 'org.apache.hadoop.hive.kafka.KafkaStorageHandler'
TBLPROPERTIES
('kafka.topic' = 'person_topic', 'kafka.bootstrap.servers'='127.0.0.1:9093',
'kafka.consumer.sasl.kerberos.service.name'='kafka',
'kafka.consumer.security.protocol'='SASL_SSL',
'kafka.serde.class'='org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe' );

SELECT COUNT(1) FROM person;
{code}

In an internal Hive fork the exception is the following:

{noformat}
2023-05-18 14:15:47,058 ERROR org.apache.hadoop.hive.ql.exec.tez.TezTask: [HiveServer2-Background-Pool: Thread-1430715]: Failed to execute tez graph.
java.lang.RuntimeException: Exception while getting kafka delegation tokens
        at org.apache.hadoop.hive.ql.exec.tez.DagUtils.getKafkaDelegationTokenForBrokers(DagUtils.java:386) ~[hive-exec-3.1.3000.7.1.7.1000-141.jar:3.1.3000.7.1.7.1000-141]
        at org.apache.hadoop.hive.ql.exec.tez.DagUtils.collectKafkaDelegationTokenForTableDesc(DagUtils.java:349) ~[hive-exec-3.1.3000.7.1.7.1000-141.jar:3.1.3000.7.1.7.1000-141]
        at org.apache.hadoop.hive.ql.exec.tez.DagUtils.getKafkaCredentials(DagUtils.java:316) ~[hive-exec-3.1.3000.7.1.7.1000-141.jar:3.1.3000.7.1.7.1000-141]
        at org.apache.hadoop.hive.ql.exec.tez.DagUtils.addCredentials(DagUtils.java:290) ~[hive-exec-3.1.3000.7.1.7.1000-141.jar:3.1.3000.7.1.7.1000-141]
        at org.apache.hadoop.hive.ql.exec.tez.TezTask.build(TezTask.java:522) ~[hive-exec-3.1.3000.7.1.7.1000-141.jar:3.1.3000.7.1.7.1000-141]
        at org.apache.hadoop.hive.ql.exec.tez.TezTask.execute(TezTask.java:229) [hive-exec-3.1.3000.7.1.7.1000-141.jar:3.1.3000.7.1.7.1000-141]
        at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:213) [hive-exec-3.1.3000.7.1.7.1000-141.jar:3.1.3000.7.1.7.1000-141]
        at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:105) [hive-exec-3.1.3000.7.1.7.1000-141.jar:3.1.3000.7.1.7.1000-141]
        at org.apache.hadoop.hive.ql.Executor.launchTask(Executor.java:357) [hive-exec-3.1.3000.7.1.7.1000-141.jar:3.1.3000.7.1.7.1000-141]
        at org.apache.hadoop.hive.ql.Executor.launchTasks(Executor.java:330) [hive-exec-3.1.3000.7.1.7.1000-141.jar:3.1.3000.7.1.7.1000-141]
        at org.apache.hadoop.hive.ql.Executor.runTasks(Executor.java:246) [hive-exec-3.1.3000.7.1.7.1000-141.jar:3.1.3000.7.1.7.1000-141]
        at org.apache.hadoop.hive.ql.Executor.execute(Executor.java:109) [hive-exec-3.1.3000.7.1.7.1000-141.jar:3.1.3000.7.1.7.1000-141]
        at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:749) [hive-exec-3.1.3000.7.1.7.1000-141.jar:3.1.3000.7.1.7.1000-141]
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:504) [hive-exec-3.1.3000.7.1.7.1000-141.jar:3.1.3000.7.1.7.1000-141]
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:498) [hive-exec-3.1.3000.7.1.7.1000-141.jar:3.1.3000.7.1.7.1000-141]
        at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:166) [hive-exec-3.1.3000.7.1.7.1000-141.jar:3.1.3000.7.1.7.1000-141]
        at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:226) [hive-service-3.1.3000.7.1.7.1000-141.jar:3.1.3000.7.1.7.1000-141]
        at org.apache.hive.service.cli.operation.SQLOperation.access$700(SQLOperation.java:88) [hive-service-3.1.3000.7.1.7.1000-141.jar:3.1.3000.7.1.7.1000-141]
        at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:327) [hive-service-3.1.3000.7.1.7.1000-141.jar:3.1.3000.7.1.7.1000-141]
        at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_232]
        at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_232]
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1898) [hadoop-common-3.1.1.7.1.7.1000-141.jar:?]
        at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:345) [hive-service-3.1.3000.7.1.7.1000-141.jar:3.1.3000.7.1.7.1000-141]
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_232]
        at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_232]
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_232]
        at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_232]
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_232]
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_232]
        at java.lang.Thread.run(Thread.java:748) [?:1.8.0_232]
Caused by: java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.TimeoutException: Call(callName=createDelegationToken, deadlineMs=1684390547054) timed out at 1684390547055 after 1 attempt(s)
        at org.apache.kafka.common.internals.KafkaFutureImpl.wrapAndThrow(KafkaFutureImpl.java:45) ~[kafka-clients-2.5.0.7.1.7.1000-141.jar:?]
        at org.apache.kafka.common.internals.KafkaFutureImpl.access$000(KafkaFutureImpl.java:32) ~[kafka-clients-2.5.0.7.1.7.1000-141.jar:?]
        at org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:89) ~[kafka-clients-2.5.0.7.1.7.1000-141.jar:?]
        at org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:260) ~[kafka-clients-2.5.0.7.1.7.1000-141.jar:?]
        at org.apache.hadoop.hive.ql.exec.tez.DagUtils.getKafkaDelegationTokenForBrokers(DagUtils.java:384) ~[hive-exec-3.1.3000.7.1.7.1000-141.jar:3.1.3000.7.1.7.1000-141]
        ... 29 more
Caused by: org.apache.kafka.common.errors.TimeoutException: Call(callName=createDelegationToken, deadlineMs=1684390547054) timed out at 1684390547055 after 1 attempt(s)
Caused by: org.apache.kafka.common.errors.TimeoutException: Timed out waiting for a node assignment.
{noformat}


I could also reproduce it with a unit test in current master and there the exception looks like below:
{noformat}
java.lang.RuntimeException: Exception while getting kafka delegation tokens
	at org.apache.hadoop.hive.ql.exec.tez.DagUtils.getKafkaDelegationTokenForBrokers(DagUtils.java:387)
	at org.apache.hadoop.hive.ql.exec.tez.DagUtils.collectKafkaDelegationTokenForTableDesc(DagUtils.java:350)
	at org.apache.hadoop.hive.ql.exec.tez.DagUtils.getKafkaCredentials(DagUtils.java:326)
	at org.apache.hadoop.hive.ql.exec.tez.DagUtils.addCredentials(DagUtils.java:291)
	at org.apache.hadoop.hive.ql.exec.tez.TestDagUtilsKafkaCredentials$1.run(TestDagUtilsKafkaCredentials.java:151)
	at org.apache.hadoop.hive.ql.exec.tez.TestDagUtilsKafkaCredentials$1.run(TestDagUtilsKafkaCredentials.java:148)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.hive.ql.exec.tez.TestDagUtilsKafkaCredentials.testAddCredentialsForKafka(TestDagUtilsKafkaCredentials.java:148)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
Caused by: java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.TimeoutException: Timed out waiting for a node assignment. Call: createDelegationToken
	at java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:357)
	at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1908)
	at org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165)
	at org.apache.hadoop.hive.ql.exec.tez.DagUtils.getKafkaDelegationTokenForBrokers(DagUtils.java:385)
	... 39 more
Caused by: org.apache.kafka.common.errors.TimeoutException: Timed out waiting for a node assignment. Call: createDelegationToken
{noformat}
"	HIVE	Closed	3	1	11212	pull-request-available
13449282	Remove Log4jConfig junit extension in favor LoggerContextSource	"The Log4JConfig JUnit extension was introduced by HIVE-24588 in order to facilitate running tests with a specific log4j2 configuration.

However, there is a very similar and seemingly more powerful JUnit extension in the official LOG4J2 release/repo, i.e., [LoggerContextSource|https://github.com/apache/logging-log4j2/blob/eedc3cdb6be6744071f8ae6dcfb37b26b1fc0940/log4j-core/src/test/java/org/apache/logging/log4j/junit/LoggerContextSource.java]. 

The goal of this JIRA is to remove code related to Log4jConfig from Hive repo and replace its usages with LoggerContextSource. By doing this we reduce the maintenance overhead for the Hive community and reduce the dependencies to log4j-core."	HIVE	Closed	4	3	11212	pull-request-available
13351115	Add JUnit annotation for running tests only if ports are available	"Some unit tests tend to rely on some specific ports assuming that they are available. Moreover, in some cases it is necessary to create explicitly a socket bound to some specific port. 

The goal of this Jira is to add a JUnit annotation that will run a test only if the requested ports are available (skip it otherwise).

 "	HIVE	Resolved	3	4	11212	pull-request-available
13597089	Skip ColumnAccessInfo collection when not needed to speed-up compilation	"Avoid paying the perf-overhead of collecting {{ColumnAccessInfo}} via the {{HiveRelFieldTrimmer}} when it is not necessary. 

Currently, we only use the {{ColumnAccessInfo}} when we need to perform column based authorization or when it is requested explicitly by the user via the hive.stats.collect.scancols property.

The field trimmer is an expensive operation and can become pretty slow for certain use-cases/queries so skipping some calls when it is not necessary is in general beneficial and can notably improve  the compilation time for some queries."	HIVE	Open	3	4	11212	pull-request-available
13410855	Many (~16K) skipped tests in TestGenericUDFInitializeOnCompareUDF	"TestGenericUDFInitializeOnCompareUDF is a parameterized test leading to 24K possible test combinations. From those only 7K are actually run and the rest (~16K) are skipped. 

{noformat}
mvn test -Dtest=TestGenericUDFInitializeOnCompareUDF
...
[WARNING] Tests run: 24300, Failures: 0, Errors: 0, Skipped: 16452, Time elapsed: 7.098 s - in org.apache.hadoop.hive.ql.udf.generic.TestGenericUDFInitializeOnCompareUDF
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 7848, Failures: 0, Errors: 0, Skipped: 0
{noformat}

This generates a lot of noise in Jenkins CI, where many tests appear as skipped, and it may make people believe it is a problem (side effect of their changes).  Moreover, we know in advance which tests are skipped and why so instead of generating invalid parameter combinations we could simply remove those combinations altogether.
"	HIVE	Closed	3	3	11212	pull-request-available
13404061	Configurable datetime formatter for unix_timestamp, from_unixtime	"HIVE-25403, HIVE-25458 switched the internal implementation of datetime formatter for unix_timestamp and from_unixtime from {{java.text.SimpleDateFormat}} to {{java.time.format.DateTimeFormatter}} in order fix some bugs and inconsistencies when the aforementioned functions are combined with other UDFs that have already migrated to use the new modern java.time package.

The two Java formatters present differences in their behavior leading to different query results. The supported patterns, between the two formatters, are also different something that makes existing queries crash at runtime (after upgrade). Adapting to the new behavior of DateTimeFormatter is a challenging and time-consuming task for end users especially due to the widespread use of the afforementioned unixtime functions.

Although DateTimeFormatter is a clear improvement over SimpleDateFormat some users still want to retain the old behavior for compatibility reasons thus introducing a property is necessary for facilitating migration.

The goal of this ticket is to introduce a new property namely {{hive.datetime.formatter}} to control the formatter used by unix_timestamp and from_unixtime. By default the new {{DateTimeFormatter}} is used while the use of {{SimpleDateFormat}} is discouraged. Eventually, {{SimpleDateFormat}} will cease to exist."	HIVE	Closed	3	4	11212	pull-request-available
13448363	Remove useless try catch in DataWritableReadSupport#getWriterDateProleptic	"{code:java}
    try {
      if (value != null) {
        return Boolean.valueOf(value);
      }
    } catch (DateTimeException e) {
      throw new RuntimeException(""Can't parse writer proleptic property stored in file metadata"", e);
    }
{code}
The Boolean.valueOf never throws so try catch block is completely useless."	HIVE	Closed	5	3	11212	pull-request-available
13573662	Add ASF license header in non-java files	"According to the a [ASF policy|https://www.apache.org/legal/src-headers.html] all source files should contain an ASF header. Currently there are a lot of source files that do not contain the ASF header. The files can be broken into the following categories:

*Must have:*
 * Python files (.py)
 * Bash/Shell script files (.sh)
 * Javascript files (.js)

*Should have:*
 * Maven files (pom.xml)
 * GitHub workflows and Docker files (.yml)

*Good to have:*
 * Hive/Tez/Yarn and other configuration files (.xml)
 * Log4J property files (.properties)
 * Markdown files (.md)

*Could have but OK if they don't:*
 * Data files for tests (data/files/**)
 * Generated code files (src/gen)
 * QTest input/output files (.q, .q.out)
 * IntelliJ files (.idea)
 * Other txt and data files

The changes here aim to address the first three categories (must, should, good) and add the missing header when possible."	HIVE	Resolved	3	3	11212	hive-4.0.1-merged, hive-4.0.1-must
13435539	Add README with build instructions to the src tarball 	"We need to add the README to the src tarball.

This should contain info about how to build the project from source"	HIVE	Closed	3	3	11212	pull-request-available
13594902	Basic UNIONTYPE support in CBO	"{code:sql}
CREATE TABLE utable (cu UNIONTYPE<INTEGER, STRING>);
SELECT cu FROM utable;
{code}
Currently any query that contains a UNIONTYPE cannot be handled by the CBO. 

{noformat}
2024-10-10T02:05:47,369 ERROR [c8b49b58-c8e0-437a-8f15-301cfaf3fb89 main] parse.CalcitePlanner: CBO failed, skipping CBO. 
org.apache.hadoop.hive.ql.optimizer.calcite.CalciteSemanticException: Union type is not supported
        at org.apache.hadoop.hive.ql.optimizer.calcite.translator.TypeConverter.convert(TypeConverter.java:281) ~[hive-exec-4.1.0-SNAPSHOT.jar:4.1.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.optimizer.calcite.translator.TypeConverter.convert(TypeConverter.java:165) ~[hive-exec-4.1.0-SNAPSHOT.jar:4.1.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.optimizer.calcite.translator.TypeConverter.getType(TypeConverter.java:136) ~[hive-exec-4.1.0-SNAPSHOT.jar:4.1.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.parse.CalcitePlanner$CalcitePlannerAction.genTableLogicalPlan(CalcitePlanner.java:3127) ~[hive-exec-4.1.0-SNAPSHOT.jar:4.1.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.parse.CalcitePlanner$CalcitePlannerAction.genLogicalPlan(CalcitePlanner.java:5043) ~[hive-exec-4.1.0-SNAPSHOT.jar:4.1.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.parse.CalcitePlanner$CalcitePlannerAction.apply(CalcitePlanner.java:1630) ~[hive-exec-4.1.0-SNAPSHOT.jar:4.1.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.parse.CalcitePlanner$CalcitePlannerAction.apply(CalcitePlanner.java:1573) ~[hive-exec-4.1.0-SNAPSHOT.jar:4.1.0-SNAPSHOT]
        at org.apache.calcite.tools.Frameworks.lambda$withPlanner$0(Frameworks.java:131) ~[hive-exec-4.1.0-SNAPSHOT.jar:4.1.0-SNAPSHOT]
        at org.apache.calcite.prepare.CalcitePrepareImpl.perform(CalcitePrepareImpl.java:914) ~[hive-exec-4.1.0-SNAPSHOT.jar:4.1.0-SNAPSHOT]
        at org.apache.calcite.tools.Frameworks.withPrepare(Frameworks.java:180) ~[hive-exec-4.1.0-SNAPSHOT.jar:4.1.0-SNAPSHOT]
        at org.apache.calcite.tools.Frameworks.withPlanner(Frameworks.java:126) ~[hive-exec-4.1.0-SNAPSHOT.jar:4.1.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.parse.CalcitePlanner.logicalPlan(CalcitePlanner.java:1325) ~[hive-exec-4.1.0-SNAPSHOT.jar:4.1.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.parse.CalcitePlanner.genOPTree(CalcitePlanner.java:573) ~[hive-exec-4.1.0-SNAPSHOT.jar:4.1.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:13164) ~[hive-exec-4.1.0-SNAPSHOT.jar:4.1.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.parse.CalcitePlanner.analyzeInternal(CalcitePlanner.java:466) ~[hive-exec-4.1.0-SNAPSHOT.jar:4.1.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:332) ~[hive-exec-4.1.0-SNAPSHOT.jar:4.1.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.parse.ExplainSemanticAnalyzer.analyzeInternal(ExplainSemanticAnalyzer.java:180) ~[hive-exec-4.1.0-SNAPSHOT.jar:4.1.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:332) ~[hive-exec-4.1.0-SNAPSHOT.jar:4.1.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:224) ~[hive-exec-4.1.0-SNAPSHOT.jar:4.1.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:109) ~[hive-exec-4.1.0-SNAPSHOT.jar:4.1.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:499) ~[hive-exec-4.1.0-SNAPSHOT.jar:4.1.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:451) ~[hive-exec-4.1.0-SNAPSHOT.jar:4.1.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:415) ~[hive-exec-4.1.0-SNAPSHOT.jar:4.1.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:409) ~[hive-exec-4.1.0-SNAPSHOT.jar:4.1.0-SNAPSHOT]
{noformat}

When the hive.cbo.fallback.strategy is conservative the query will silently by-pass CBO with the exception above and run exclusively via the non-cbo optimizer.

The goal of this ticket is to support UNIONTYPE in the CBO path to take advantage of the powerful optimizations that are performed in the CBO layer and avoid relying on the fallback mechanism.

At the time of writing, the [support of UNIONTYPE|https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Types#LanguageManualTypes-UnionTypesunionUnionTypes] is still at a very primitive stage. This ticket does not aim to cover new use-cases but just to ensure that existing queries that involve UNIONTYPE can exploit the CBO.
"	HIVE	Resolved	3	7	11212	pull-request-available
13589112	Infer constant types from columns before strict type validation	"HIVE-2249 introduced some [specialized type inference logic|https://github.com/apache/hive/blob/5cbffb532a586226500abc498d6505722d62234d/ql/src/java/org/apache/hadoop/hive/ql/parse/type/TypeCheckProcFactory.java#L972] that kicks in when there are comparisons between columns and numeric constant expressions.

Consider for instance a comparison between a BIGINT column and a STRING constant.
{code:sql}
SELECT * FROM table WHERE c_bigint = '9223372036854775807'
{code}
The type derivation logic will attempt to convert the STRING constant to BIGINT and evaluate the expression by comparing long values.

Currently (commit 5cbffb532a586226500abc498d6505722d62234d), the query above throws the following ERROR/WARNING:
{noformat}
Comparing bigint and string may result in loss of information.
{noformat}
This is due to strict type checking (controlled via hive.strict.checks.type.safety property) that is now applied before the constant type inference logic described above.

In this case, the ERROR/WARNING is a bit misleading since there is no real risk for losing precision/information since the STRING constant fits into a BIGINT (Java long) and the whole comparison can be evaluated without precision loss.

For quite some time, strict type checking was performed *after* constant type inference (and not *before*) but the behavior was changed unintentionally by HIVE-23100.

The goal of this change is to perform constant type inference before strict type validation (behavior before HIVE-23100) to restore backward compatibility and remove some unnecessary warnings/errors during compilation."	HIVE	Open	3	4	11212	backwards-compatibility, pull-request-available
13549213	Error resolving join keys during conversion to dynamic partition hashjoin	"In certain cases the compilation of queries fail during the conversion to a dynamic partition hash join with the stacktrace similar to the one shown below.

{noformat}
2023-08-31T10:22:21,738 WARN  [HiveServer2-Handler-Pool: Thread-100]: thrift.ThriftCLIService (()) - Error executing statement: 
org.apache.hive.service.cli.HiveSQLException: Error while compiling statement: FAILED: SemanticException Error resolving join keys
	at org.apache.hive.service.cli.operation.Operation.toSQLException(Operation.java:335) ~[hive-service-100.jar:?]
	at org.apache.hive.service.cli.operation.SQLOperation.prepare(SQLOperation.java:199) ~[hive-service-100.jar:?]
	at org.apache.hive.service.cli.operation.SQLOperation.runInternal(SQLOperation.java:260) ~[hive-service-100.jar:?]
	at org.apache.hive.service.cli.operation.Operation.run(Operation.java:247) ~[hive-service-100.jar:?]
	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementInternal(HiveSessionImpl.java:541) ~[hive-service-100.jar:?]
	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementAsync(HiveSessionImpl.java:527) ~[hive-service-100.jar:?]
	at org.apache.hive.service.cli.CLIService.executeStatementAsync(CLIService.java:312) ~[hive-service-100.jar:?]
	at org.apache.hive.service.cli.thrift.ThriftCLIService.ExecuteStatement(ThriftCLIService.java:562) ~[hive-service-100.jar:?]
	at org.apache.hive.service.rpc.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1557) ~[hive-exec-100.jar:?]
	at org.apache.hive.service.rpc.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1542) ~[hive-exec-100.jar:?]
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39) ~[hive-exec-100.jar:?]
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39) ~[hive-exec-100.jar:?]
	at org.apache.hadoop.hive.metastore.security.HadoopThriftAuthBridge$Server$TUGIAssumingProcessor.process(HadoopThriftAuthBridge.java:647) ~[hive-exec-100.jar:?]
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286) ~[hive-exec-100.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_312]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_312]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_312]
Caused by: org.apache.hadoop.hive.ql.parse.SemanticException: Error resolving join keys
	at org.apache.hadoop.hive.ql.optimizer.MapJoinProcessor.getMapJoinDesc(MapJoinProcessor.java:1105) ~[hive-exec-100.jar:?]
	at org.apache.hadoop.hive.ql.optimizer.MapJoinProcessor.convertJoinOpMapJoinOp(MapJoinProcessor.java:372) ~[hive-exec-100.jar:?]
	at org.apache.hadoop.hive.ql.optimizer.ConvertJoinMapJoin.convertJoinMapJoin(ConvertJoinMapJoin.java:1056) ~[hive-exec-100.jar:?]
	at org.apache.hadoop.hive.ql.optimizer.ConvertJoinMapJoin.convertJoinDynamicPartitionedHashJoin(ConvertJoinMapJoin.java:1280) ~[hive-exec-100.jar:?]
	at org.apache.hadoop.hive.ql.optimizer.ConvertJoinMapJoin.fallbackToReduceSideJoin(ConvertJoinMapJoin.java:1312) ~[hive-exec-100.jar:?]
	at org.apache.hadoop.hive.ql.optimizer.ConvertJoinMapJoin.checkAndConvertSMBJoin(ConvertJoinMapJoin.java:371) ~[hive-exec-100.jar:?]
	at org.apache.hadoop.hive.ql.optimizer.ConvertJoinMapJoin.process(ConvertJoinMapJoin.java:151) ~[hive-exec-100.jar:?]
	at org.apache.hadoop.hive.ql.lib.DefaultRuleDispatcher.dispatch(DefaultRuleDispatcher.java:90) ~[hive-exec-100.jar:?]
	at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.dispatchAndReturn(DefaultGraphWalker.java:105) ~[hive-exec-100.jar:?]
	at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.dispatch(DefaultGraphWalker.java:89) ~[hive-exec-100.jar:?]
	at org.apache.hadoop.hive.ql.lib.ForwardWalker.walk(ForwardWalker.java:74) ~[hive-exec-100.jar:?]
	at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.startWalking(DefaultGraphWalker.java:120) ~[hive-exec-100.jar:?]
	at org.apache.hadoop.hive.ql.parse.TezCompiler.runStatsDependentOptimizations(TezCompiler.java:447) ~[hive-exec-100.jar:?]
	at org.apache.hadoop.hive.ql.parse.TezCompiler.optimizeOperatorPlan(TezCompiler.java:160) ~[hive-exec-100.jar:?]
	at org.apache.hadoop.hive.ql.parse.TaskCompiler.compile(TaskCompiler.java:144) ~[hive-exec-100.jar:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12320) ~[hive-exec-100.jar:?]
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.analyzeInternal(CalcitePlanner.java:330) ~[hive-exec-100.jar:?]
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:285) ~[hive-exec-100.jar:?]
	at org.apache.hadoop.hive.ql.parse.ExplainSemanticAnalyzer.analyzeInternal(ExplainSemanticAnalyzer.java:164) ~[hive-exec-100.jar:?]
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:285) ~[hive-exec-100.jar:?]
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:659) ~[hive-exec-100.jar:?]
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1826) ~[hive-exec-100.jar:?]
	at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:1773) ~[hive-exec-100.jar:?]
	at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:1768) ~[hive-exec-100.jar:?]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.compileAndRespond(ReExecDriver.java:126) ~[hive-exec-100.jar:?]
	at org.apache.hive.service.cli.operation.SQLOperation.prepare(SQLOperation.java:197) ~[hive-service-100.jar:?]
	... 15 more
2023-08-31T10:22:33,838 INFO  [org.apache.ranger.audit.queue.AuditBatchQueue0]: provider.BaseAuditHandler (())
{noformat}

The problem was originally reported for a query with a LEFT SEMI JOIN and the scenario is outlined below.
{code:sql}
create database test_condition;
use test_condition;

create external table to_szyy_user_right_issue_log_df(flow_no_ string, activity_code_ string, right_id_ string, user_id_ string,issue_flag_ string) partitioned by (ds string)
STORED AS parquet TBLPROPERTIES('parquet.compress'='SNAPPY');


create external table to_t0111_s62t1_cst_prft_df(dccp_stcd string,dccp_ordr_ar_id string) partitioned by (ds string)
STORED AS parquet TBLPROPERTIES('parquet.compress'='SNAPPY');


alter table to_szyy_user_right_issue_log_df add partition(ds='2023-08-24');
alter table to_t0111_s62t1_cst_prft_df add partition(ds='2023-08-24');


alter table to_szyy_user_right_issue_log_df partition(ds='2023-08-24') update statistics set('numRows'='8146725','rawDataSize'='46331126445');
alter table to_t0111_s62t1_cst_prft_df partition(ds='2023-08-24') update statistics set('numRows'='15680439','rawDataSize'='56180088521');

set hive.auto.convert.join.noconditionaltask.size=8153960755
set hive.auto.convert.join=true;
set hive.optimize.dynamic.partition.hashjoin=true;
set hive.stats.fetch.column.stats=false;
set hive.cbo.enable=true;


explain
select flow_no_, activity_code_, right_id_, user_id_
from test_condition.to_szyy_user_right_issue_log_df rlog
left semi join test_condition.to_t0111_s62t1_cst_prft_df prft on prft.ds = '2023-08-24' and  rlog.flow_no_ = prft.dccp_ordr_ar_id
group by flow_no_, activity_code_, right_id_, user_id_;
{code}

The {{SemanticException}} reported above is thrown by the [dynamic partition hashjoin transformation logic|https://github.com/apache/hive/blob/9b4ea7affa4902fc2849f1a88b68103940fc9866/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ConvertJoinMapJoin.java#L1590] of so a workaround consists in disabling the respective optimization via the {{hive.optimize.dynamic.partition.hashjoin}} property."	HIVE	Closed	3	1	11212	pull-request-available
13419001	Exclude Category-X JDBC drivers from binary distribution	"The binary distribution contains all the required elements to be able to run Hive in a cluster. It can be obtained by building from source using the following command:
{code:java}
mvn clean package -DskipTests -Pdist{code}
The binary distribution is also published during a release along with the source code.
 
In current master, commit 8572c1201e1d483eb03c7e413f4ff7f9b6f4a3d2, the binary distribution includes the following JDBC drivers:
 * derby-10.14.1.0.jar
 * postgresql-42.2.14.jar
 * ojdbc8-21.3.0.0.jar
 * mssql-jdbc-6.2.1.jre8.jar
 * mysql-connector-java-8.0.27.jar

JDBC drivers are needed:
 * by schemaTool to initialize the database backend for the Metastore
 * by metastore to communicate with underlying database
so if we want Hive to work out of the box we have to provide at least one.

The Oracle (ojdbc8) and MySQL (mysql-connector-java) drivers must be removed cause their license is not compatible with Apache License 2 (see [category x|https://www.apache.org/legal/resolved.html#category-x]).

Previous Hive releases (e.g., 3.1.2) are not affected since they only contain:
 * derby-10.14.1.0.jar
 * postgresql-9.4.1208.jre7.jar

The additional drivers that appear in the binary distribution are a side effect of HIVE-25701."	HIVE	Closed	3	3	11212	pull-request-available
13583652	Avoid redundant HiveConf creation in MiniHS2.Builder	"Every creation of a MiniHS2.Builder object triggers the creation  of a [HiveConf object|https://github.com/apache/hive/blob/1c9969a003b09abc851ae7e19631ad208d3b6066/itests/util/src/main/java/org/apache/hive/jdbc/miniHS2/MiniHS2.java#L100]. In many cases this new configuration object is thrown away and replaced by another conf object via the [withConf method|https://github.com/apache/hive/blob/1c9969a003b09abc851ae7e19631ad208d3b6066/itests/util/src/main/java/org/apache/hive/jdbc/miniHS2/MiniHS2.java#L159].

Creating a HiveConf object is computationally heavy so for performance reasons its best to avoid it if possible."	HIVE	Resolved	3	4	11212	pull-request-available
13450211	Use maven-surefire-plugin version consistently in standalone-metastore modules	"Due to some problems in the pom.xml files inside the standalone-metastore modules we end up using different maven-surefire-plugin versions.

Most of the modules use 3.0.0-M4, which is the expected one, while 
the {{hive-standalone-metastore-common}} uses the older 2.22.0 version.

+Actual+ 
{noformat}
[INFO] --- maven-surefire-plugin:2.22.0:test (default-test) @ hive-standalone-metastore-common ---
[INFO] --- maven-surefire-plugin:3.0.0-M4:test (default-test) @ hive-metastore ---
[INFO] --- maven-surefire-plugin:3.0.0-M4:test (default-test) @ hive-standalone-metastore-server ---
[INFO] --- maven-surefire-plugin:3.0.0-M4:test (default-test) @ metastore-tools-common ---
[INFO] --- maven-surefire-plugin:3.0.0-M4:test (default-test) @ hive-metastore-benchmarks ---
{noformat}

The goal of this JIRA is to ensure we use the same version consistently in all modules.

+Expected+
{noformat}
[INFO] --- maven-surefire-plugin:3.0.0-M4:test (default-test) @ hive-standalone-metastore-common ---
[INFO] --- maven-surefire-plugin:3.0.0-M4:test (default-test) @ hive-metastore ---
[INFO] --- maven-surefire-plugin:3.0.0-M4:test (default-test) @ hive-standalone-metastore-server ---
[INFO] --- maven-surefire-plugin:3.0.0-M4:test (default-test) @ metastore-tools-common ---
[INFO] --- maven-surefire-plugin:3.0.0-M4:test (default-test) @ hive-metastore-benchmarks ---
{noformat}
"	HIVE	Closed	3	3	11212	pull-request-available
13427717	Compactor job queue cannot be set per table via compactor.mapred.job.queue.name	"Before HIVE-20723 it was possible to schedule the compaction for each table on specific job queues by putting {{compactor.mapred.job.queue.name}} in the table properties. 

{code:sql}
CREATE TABLE person (name STRING, age INT) STORED AS ORC TBLPROPERTIES(
'transactional'='true',
'compactor.mapred.job.queue.name'='root.user2);

ALTER TABLE person COMPACT 'major' WITH OVERWRITE TBLPROPERTIES('compactor.mapred.job.queue.name'='root.user2')
{code}

This is no longer possible (after HIVE-20723) and in order to achieve the same effect someone needs to use the {{compactor.hive.compactor.job.queue}}.

{code:sql}
CREATE TABLE person (name STRING, age INT) STORED AS ORC TBLPROPERTIES(
'transactional'='true',
'compactor.hive.compactor.job.queue'='root.user2);

ALTER TABLE person COMPACT 'major' WITH OVERWRITE TBLPROPERTIES('compactor.hive.compactor.job.queue'='root.user2')
{code}
"	HIVE	Closed	3	1	11212	pull-request-available
13531731	Speedup build by skipping SBOM generation by default	"A full build of Hive locally in my environment takes ~15 minutes.
{noformat}
mvn clean install -DskipTests -Pitests
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  14:15 min
{noformat}

Profiling the build shows that we are spending roughly 30% of CPU in org.cyclonedx.maven plugin which is used to generate SBOM artifacts (HIVE-26912). 

The SBOM generation does not need run in every single build and probably needs to be active only during the release build. To speed-up every-day builds I propose to activate the cyclonedx plugin only in the dist (release) profile.

After this change, the default build drops from 14 minutes to 8.
{noformat}
mvn clean install -DskipTests -Pitests
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  08:19 min
{noformat}"	HIVE	Closed	3	4	11212	pull-request-available
13572710	Remove unnecessary shading of test jars in Kafka module to speedup build	"When the [shadeTestJar|https://github.com/apache/hive/blob/884981d1788c6966e895e2959ed954a22eb5c5eb/kafka-handler/pom.xml#L179] option is enabled it tries to fetch the test jars from all dependencies and include them in the shaded artifact.

For every dependency, and every available repository, there is a download attempt that fails most of the time (since most dependencies do not publish the test artifacts).
{noformat}
Downloading from confluent: https://packages.confluent.io/maven/com/sun/jersey/contribs/jersey-guice/1.19.4/jersey-guice-1.19.4-tests.jar
Downloading from central: https://repo.maven.apache.org/maven2/com/sun/jersey/contribs/jersey-guice/1.19.4/jersey-guice-1.19.4-tests.jar
Downloading from repository-release: https://repository.apache.org/content/repositories/releases/com/sun/jersey/contribs/jersey-guice/1.19.4/jersey-guice-1.19.4-tests.jar
Downloading from shibboleth: https://build.shibboleth.net/nexus/content/groups/public/com/sun/jersey/contribs/jersey-guice/1.19.4/jersey-guice-1.19.4-tests.jar
[WARNING] Could not get tests for com.sun.jersey.contribs:jersey-guice:jar:1.19.4:compile
{noformat}
All these download attempts increase build time noticeably, especially on slow internet connections.

Shading the test jars in Kafka module is not necessary since we are not using the resulting jars (kafka-handler-4.1.0-SNAPSHOT-tests.jar) anywhere inside the project (no occurrence of kafka-handler along with tests)."	HIVE	Resolved	3	3	11212	pull-request-available
13458567	TestOperatorCmp/TestReOptimization fail silently due to incompatible configuration	"Running TestOperatorCmp, TestReOptimization currently in master (https://github.com/apache/hive/commit/10e5381cb6a4215c0b25fe0cda0a26a084ba6a89) shows BUILD SUCCESS although the tests are actually failing when executing the {{@BeforeClass}} logic. 

Since the error appears inside {{@BeforeClass}} the failure remains unnoticed and the only  indication that something is wrong is given by the INFO line below:

{noformat}
[INFO] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
{noformat}

+Steps to reproduce:+
{code:bash}
mvn test -Dtest=TestOperatorCmp
mvn test -Dtest=TestReOptimization
{code}
 
{noformat}
[INFO] --- maven-surefire-plugin:3.0.0-M4:test (default-test) @ hive-exec ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.hive.ql.plan.mapping.TestOperatorCmp
[INFO] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.732 s - in org.apache.hadoop.hive.ql.plan.mapping.TestOperatorCmp
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  18.962 s
[INFO] Finished at: 2022-06-22T12:49:54+02:00
[INFO] ------------------------------------------------------------------------

{noformat}"	HIVE	Closed	3	1	11212	pull-request-available
13360132	Build failure while resolving javax.el dependency	"The Hive build (mvn clean install -DskipTests) fails while trying to resolve a transitive dependency to org.glassfish:javax.el:jar:3.0.1-b06-SNAPSHOT. 

{noformat}
[INFO] Reactor Summary:
[INFO] 
[INFO] Hive Storage API 2.7.3-SNAPSHOT .................... SUCCESS [  2.906 s]
[INFO] Hive 4.0.0-SNAPSHOT ................................ SUCCESS [  1.086 s]
[INFO] Hive Classifications 4.0.0-SNAPSHOT ................ SUCCESS [  0.182 s]
[INFO] Hive Shims Common 4.0.0-SNAPSHOT ................... SUCCESS [  1.121 s]
[INFO] Hive Shims 0.23 4.0.0-SNAPSHOT ..................... SUCCESS [  1.670 s]
[INFO] Hive Shims Scheduler 4.0.0-SNAPSHOT ................ SUCCESS [  0.832 s]
[INFO] Hive Shims 4.0.0-SNAPSHOT .......................... SUCCESS [  0.576 s]
[INFO] Hive Standalone Metastore 4.0.0-SNAPSHOT ........... SUCCESS [  1.134 s]
[INFO] Hive Standalone Metastore Common Code 4.0.0-SNAPSHOT SUCCESS [  9.868 s]
[INFO] Hive Common 4.0.0-SNAPSHOT ......................... SUCCESS [  2.969 s]
[INFO] Hive Service RPC 4.0.0-SNAPSHOT .................... SUCCESS [  1.206 s]
[INFO] Hive Serde 4.0.0-SNAPSHOT .......................... SUCCESS [  3.132 s]
[INFO] Hive Metastore 4.0.0-SNAPSHOT ...................... SUCCESS [  1.351 s]
[INFO] Hive Vector-Code-Gen Utilities 4.0.0-SNAPSHOT ...... SUCCESS [  0.164 s]
[INFO] Hive Parser 4.0.0-SNAPSHOT ......................... SUCCESS [  5.819 s]
[INFO] Hive UDF 4.0.0-SNAPSHOT ............................ SUCCESS [  0.955 s]
[INFO] Hive Llap Common 4.0.0-SNAPSHOT .................... SUCCESS [  2.381 s]
[INFO] Hive Llap Client 4.0.0-SNAPSHOT .................... SUCCESS [  1.734 s]
[INFO] Hive Llap Tez 4.0.0-SNAPSHOT ....................... SUCCESS [  1.765 s]
[INFO] Hive Spark Remote Client 4.0.0-SNAPSHOT ............ SUCCESS [  2.134 s]
[INFO] Hive Metastore Server 4.0.0-SNAPSHOT ............... SUCCESS [  9.440 s]
[INFO] Hive Query Language 4.0.0-SNAPSHOT ................. SUCCESS [ 34.747 s]
[INFO] Hive TestUtils 4.0.0-SNAPSHOT ...................... SUCCESS [  0.294 s]
[INFO] Hive Llap Server 4.0.0-SNAPSHOT .................... SUCCESS [  8.443 s]
[INFO] Hive HPL/SQL 4.0.0-SNAPSHOT ........................ SUCCESS [  4.635 s]
[INFO] Hive Service 4.0.0-SNAPSHOT ........................ SUCCESS [  4.901 s]
[INFO] Hive Accumulo Handler 4.0.0-SNAPSHOT ............... SUCCESS [  3.679 s]
[INFO] Hive JDBC 4.0.0-SNAPSHOT ........................... SUCCESS [ 12.405 s]
[INFO] Hive Beeline 4.0.0-SNAPSHOT ........................ SUCCESS [  3.108 s]
[INFO] Hive CLI 4.0.0-SNAPSHOT ............................ SUCCESS [  2.544 s]
[INFO] Hive Contrib 4.0.0-SNAPSHOT ........................ SUCCESS [  1.625 s]
[INFO] Hive Druid Handler 4.0.0-SNAPSHOT .................. SUCCESS [ 14.406 s]
[INFO] Hive HBase Handler 4.0.0-SNAPSHOT .................. SUCCESS [  3.308 s]
[INFO] Hive JDBC Handler 4.0.0-SNAPSHOT ................... SUCCESS [  1.938 s]
[INFO] Hive HCatalog 4.0.0-SNAPSHOT ....................... SUCCESS [  0.385 s]
[INFO] Hive HCatalog Core 4.0.0-SNAPSHOT .................. SUCCESS [  3.754 s]
[INFO] Hive HCatalog Pig Adapter 4.0.0-SNAPSHOT ........... SUCCESS [  2.907 s]
[INFO] Hive HCatalog Server Extensions 4.0.0-SNAPSHOT ..... SUCCESS [  2.595 s]
[INFO] Hive HCatalog Webhcat Java Client 4.0.0-SNAPSHOT ... SUCCESS [  2.947 s]
[INFO] Hive HCatalog Webhcat 4.0.0-SNAPSHOT ............... SUCCESS [  6.764 s]
[INFO] Hive Streaming 4.0.0-SNAPSHOT ...................... SUCCESS [  3.268 s]
[INFO] Hive Llap External Client 4.0.0-SNAPSHOT ........... SUCCESS [  2.512 s]
[INFO] Hive Shims Aggregator 4.0.0-SNAPSHOT ............... SUCCESS [  0.061 s]
[INFO] Hive Kryo Registrator 4.0.0-SNAPSHOT ............... SUCCESS [  2.050 s]
[INFO] Hive Kudu Handler 4.0.0-SNAPSHOT ................... SUCCESS [  4.839 s]
[INFO] Hive Kafka Storage Handler 4.0.0-SNAPSHOT .......... SUCCESS [  3.706 s]
[INFO] Hive Packaging 4.0.0-SNAPSHOT ...................... SUCCESS [  2.587 s]
[INFO] Hive Metastore Tools 4.0.0-SNAPSHOT ................ SUCCESS [  0.008 s]
[INFO] Hive Metastore Tools common libraries 4.0.0-SNAPSHOT FAILURE [  1.897 s]
[INFO] Hive metastore benchmarks 4.0.0-SNAPSHOT ........... SKIPPED
[INFO] Hive Upgrade Acid 4.0.0-SNAPSHOT ................... SKIPPED
[INFO] Hive Pre Upgrade Acid 4.0.0-SNAPSHOT ............... SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  03:09 min
[INFO] Finished at: 2021-02-22T15:58:27+01:00
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal on project metastore-tools-common: Could not resolve dependencies for project org.apache.hive:metastore-tools-common:jar:4.0.0-SNAPSHOT: Failed to collect dependencies at org.apache.hive.hcatalog:hive-hcatalog-server-extensions:jar:4.0.0-SNAPSHOT -> org.apache.hive.hcatalog:hive-hcatalog-core:jar:4.0.0-SNAPSHOT -> org.apache.hive:hive-cli:jar:4.0.0-SNAPSHOT -> org.apache.hive:hive-service:jar:4.0.0-SNAPSHOT -> org.apache.hive:hive-llap-server:jar:4.0.0-SNAPSHOT -> org.apache.hbase:hbase-mapreduce:jar:2.0.0-alpha4 -> org.apache.hbase:hbase-server:jar:2.0.0-alpha4 -> org.glassfish.web:javax.servlet.jsp:jar:2.3.2 -> org.glassfish:javax.el:jar:3.0.1-b06-SNAPSHOT: Failed to read artifact descriptor for org.glassfish:javax.el:jar:3.0.1-b06-SNAPSHOT: Could not transfer artifact org.glassfish:javax.el:pom:3.0.1-b06-SNAPSHOT from/to jvnet-nexus-snapshots (https://maven.java.net/content/repositories/snapshots): Transfer failed for https://maven.java.net/content/repositories/snapshots/org/glassfish/javax.el/3.0.1-b06-SNAPSHOT/javax.el-3.0.1-b06-SNAPSHOT.pom: PKIX path validation failed: java.security.cert.CertPathValidatorException: validity check failed: NotAfter: Fri Feb 19 13:00:00 CET 2021 -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/DependencyResolutionException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <args> -rf :metastore-tools-common
{noformat}

The error occurs only when there are multiple repositories in the local maven settings file (~/.m2/settings.xml).
"	HIVE	Closed	3	1	11212	pull-request-available
13507473	All tests in hive-unit module are skipped silently	"In current master (7207a62def246b3290f1ece529e65b79012a3578) the tests in hive-unit module are not running.

{noformat}
$ cd itests/hive-unit && mvn test
[INFO] --- maven-surefire-plugin:3.0.0-M4:test (default-test) @ hive-it-unit ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
{noformat}
"	HIVE	Closed	3	1	11212	pull-request-available
13485889	Cut dependencies between HiveXxPullUpConstantsRule and HiveReduceExpressionsRule	"HiveSortPullUpConstantsRule and HiveUnionPullUpConstantsRule are calling [predicateConstants|https://github.com/apache/hive/blob/8c3567ea8e423b202cde370f4d3fb401bcc23e46/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/rules/HiveSortPullUpConstantsRule.java#L128
] method from HiveReduceExpressionsRule. 

The method in HiveReduceExpressionsRule is deprecated and creates unnecessary dependencies among the rules. It can be replaced by a direct call to RexUtil.predicateConstants; the two methods are functionally equivalent."	HIVE	Closed	3	3	11212	pull-request-available
13435535	Remove core directory from src	This is not used. For the only file there we have an exact copy in {{org.apache.hive.hcatalog}}	HIVE	Closed	3	3	11212	pull-request-available
13325726	TestMiniLlapLocalCliDriver[dynamic_semijoin_reduction_on_aggcol] is flaky	http://ci.hive.apache.org/job/hive-flaky-check/96/	HIVE	Open	3	1	11212	flaky-test
13541574	Remove obsolete reference to category-X JSON license from NOTICE	The JSON.org dependencies were removed as part of HIVE-15144. The respective mention in the NOTICE file is obsolete , misleading, and probably violates ASF policy.	HIVE	Closed	1	1	11212	pull-request-available
13429987	Missing messages in HS2 operation logs	"After HIVE-22753 & HIVE-24590, with some unlucky timing of events, operation log messages can get lost and never appear in the appropriate files.

The changes in HIVE-22753 will prevent a {{HushableRandomAccessFileAppender}} from being created if the latter refers to a file that has been closed in the last second. Preventing the creation of the appender also means that the message which triggered the creation will be lost forever. In fact any message (for the same query) that comes in the interval of 1 second will be lost forever.

Before HIVE-24590 the appender/file was closed only once (explicitly by HS2) and thus the problem may be very hard to notice in practice. However, with the arrival of HIVE-24590 appenders may close much more frequently (and not via HS2) making the issue reproducible rather easily. It suffices to set _hive.server2.operation.log.purgePolicy.timeToLive_ property very low and check the operation logs.

The problem was discovered by investigating some intermittent failures in operation logging tests (e.g.,  TestOperationLoggingAPIWithTez)."	HIVE	Closed	3	1	11212	pull-request-available
13506568	Remove explicit protobuf-java dependency from blobstore and minikdc modules	"The modules do not directly need protobuf dependency so it is misleading to declare it explicitly.

Moreover, these modules use a different protobuf version (3.3.0) than the rest of the project (3.21.4) which can lead to compatibility problems, inconsistent behavior in tests, and undesired transitive propagation to other modules."	HIVE	Closed	3	3	11212	pull-request-available
13382795	Backward incompatible timestamp serialization in Avro for certain timezones	"HIVE-12192, HIVE-20007 changed the way that timestamp computations are performed and to some extend how timestamps are serialized and deserialized in files (Parquet, Avro).

In versions that include HIVE-12192 or HIVE-20007 the serialization in Avro files is not backwards compatible. In other words writing timestamps with a version of Hive that includes HIVE-12192/HIVE-20007 and reading them with another (not including the previous issues) may lead to different results depending on the default timezone of the system.

Consider the following scenario where the default system timezone is set to US/Pacific.

At apache/master commit eedcd82bc2d61861a27205f925ba0ffab9b6bca8
{code:sql}
CREATE EXTERNAL TABLE employee(eid INT,birth timestamp) STORED AS AVRO
 LOCATION '/tmp/hiveexttbl/employee';
INSERT INTO employee VALUES (1, '1880-01-01 00:00:00');
INSERT INTO employee VALUES (2, '1884-01-01 00:00:00');
INSERT INTO employee VALUES (3, '1990-01-01 00:00:00');
SELECT * FROM employee;
{code}
|1|1880-01-01 00:00:00|
|2|1884-01-01 00:00:00|
|3|1990-01-01 00:00:00|

At apache/branch-2.3 commit 324f9faf12d4b91a9359391810cb3312c004d356
{code:sql}
CREATE EXTERNAL TABLE employee(eid INT,birth timestamp) STORED AS AVRO
 LOCATION '/tmp/hiveexttbl/employee';
SELECT * FROM employee;
{code}
|1|1879-12-31 23:52:58|
|2|1884-01-01 00:00:00|
|3|1990-01-01 00:00:00|

The timestamp for {{eid=1}} in branch-2.3 is different from the one in master."	HIVE	Closed	3	1	11212	compatibility, pull-request-available, timestamp
13573715	Incorrect Copyright years in META-INF/NOTICE files	"The generated META-INF/NOTICE file which resides inside each jar produced by Hive has incorrect copyright years.

Inside all jars the NOTICE file has the following incorrect content:
{noformat}
Copyright 2020 The Apache Software Foundation
{noformat}
The Copyright statement should include the timespan from the inception of the project to now.
{noformat}
Copyright 2008-2024 The Apache Software Foundation
{noformat}
The problem can be easily seen by inspecting the jar content after building the module or checking the previously published jars in Maven central.
{noformat}
mvn clean install -DskipTests -pl common/
jar xf common/target/hive-common-4.1.0-SNAPSHOT.jar META-INF
cat META-INF/NOTICE 

Hive Common
Copyright 2020 The Apache Software Foundation

This product includes software developed at
The Apache Software Foundation (http://www.apache.org/).
{noformat}"	HIVE	Resolved	3	1	11212	hive-4.0.1-merged, hive-4.0.1-must, pull-request-available
13577570	Remove redundant sources maven profile	The sources maven profile was introduced in HIVE-5717 among others to package source code into a .jar and publish it to maven. However, after adding Apache pom as parent in HIVE-6608 the sources profile is now redundant; it is subsumed by the [apache-release profile|https://github.com/apache/maven-apache-parent/blob/c124276ad15e2eb05fde5029e8e2e6187bf05053/pom.xml#L428].	HIVE	In Progress	3	3	11212	pull-request-available
13474526	Duplicate hive-standalone-metastore-server dependency in QFile module	"The hive-standalone-metastore-server dependency is defined two times in the QFile module ([pom.xml|https://github.com/apache/hive/blob/9909edee8dad841e15fc36df81a2316bcb381bc3/itests/qtest/pom.xml#L67]) leading to the following warning.
{noformat}
[INFO] Scanning for projects...
[WARNING] 
[WARNING] Some problems were encountered while building the effective model for org.apache.hive:hive-it-qfile:jar:4.0.0-alpha-2-SNAPSHOT
[WARNING] 'dependencies.dependency.(groupId:artifactId:type:classifier)' must be unique: org.apache.hive:hive-standalone-metastore-server:jar:tests -> duplicate declaration of version (?) @ line 67, column 17
[WARNING] 
[WARNING] It is highly recommended to fix these problems because they threaten the stability of your build.
[WARNING] 
[WARNING] For this reason, future Maven versions might no longer support building such malformed projects.
[WARNING] 
[INFO] 
[INFO] -------------------< org.apache.hive:hive-it-qfile >--------------------
[INFO] Building Hive Integration - QFile Tests 4.0.0-alpha-2-SNAPSHOT
[INFO] --------------------------------[ jar ]---------------------------------
{noformat}
"	HIVE	Closed	3	1	11212	pull-request-available
13594286	Drop HCatalog download page from the website	"The HCatalog download page (https://hive.apache.org/general/hcatalogdownloads/) is mostly there for historical reasons. It was probably useful back in 2013 to inform users about the merge of HCatalog in Hive but for the past 10 years we have been releasing HCatalog as part of Hive so anyone who is using that module does not need to visit that obsolete page. 

Moreover, the presence of the HCatalog download page adds an additional level of indirection for users that want to download recent Hive releases."	HIVE	Resolved	3	3	11212	pull-request-available
13304409	IntelliJ compile errors in StaticPermanentFunctionChecker and TestVectorGroupByOperator	"The following errors appear when compiling the code using IntelliJ:

TestVectorGroupByOperator: Error:(89, 32) java: package com.sun.tools.javac.util does not exist

StaticPermanentFunctionChecker: Error:(31, 19) java: package com.sun.jdi does not exist"	HIVE	Closed	3	1	11212	pull-request-available
13350636	Operation Logging still leaks the log4j Appenders	"I'm using Hive 3.1.2 with options below.
 * hive.server2.logging.operation.enabled=true
 * hive.server2.logging.operation.level=VERBOSE
 * hive.async.log.enabled=false

I already know the ticket, https://issues.apache.org/jira/browse/HIVE-17128 but HS2 still leaks log4j RandomAccessFileManager.

!Screen Shot 2021-01-06 at 18.42.05.png|width=756,height=197!

I checked the operation log file which is not closed/deleted properly.

!Screen Shot 2021-01-06 at 18.42.24.png|width=603,height=272!

Then there's the log,
{code:java}
client.TezClient: Shutting down Tez Session, sessionName= ....{code}
!Screen Shot 2021-01-06 at 18.42.55.png|width=1372,height=26!"	HIVE	Closed	3	1	11212	pull-request-available
13550867	Intermittent OOM when running TestMiniTezCliDriver	"Running all the tests under TestMiniTezCliDriver very frequently (but still intermittently) leads to OutOfMemory errors.
{noformat}
cd itests/qtest && mvn test -Dtest=TestMiniTezCliDriver
{noformat}

I set {{-XX:+HeapDumpOnOutOfMemoryError}} and the respective heapdumps are attached to this ticket.

The OOM is thrown from the application master and a quick inspection of the dumps shows that it comes mainly from the accumulation of Configuration objects (~1MB each) by various classes.

The max heap size for application master is pretty low (~100MB) so it is quite easy to reach. The heap size is explicitly very low for testing purposes but maybe we should re-evaluate the current configurations for the tests."	HIVE	Closed	3	1	11212	pull-request-available
13386492	Replace parquet-hadoop-bundle dependency with the actual parquet modules	"The parquet-hadoop-bundle is not a real dependency but a mere packaging
of three parquet modules to create an uber jar. The Parquet community
created this artificial module on demand by HIVE-5783 but the
benefits if any are unclear.

On the contrary using the uber dependency has some drawbacks:
* Parquet souce code cannot be attached easily in IDEs which makes debugging sessions cumbersome.
* Finding concrete dependencies with Parquet is not possible just by inspecting the pom files.
* Extra maintenance cost for the Parquet community adding additional verification steps during a release.

The goal of this JIRA is to replace the uber dependency with concrete dependencies to the respective modules:
* parquet-common
* parquet-column
* parquet-hadoop"	HIVE	Open	3	4	11212	pull-request-available
13541590	Restore original license in PriorityBlockingDeque	"The org.apache.hadoop.hive.llap.daemon.impl.PriorityBlockingDeque was copied from https://code.google.com/archive/p/infomancers-collections/ as part of HIVE-10662. 

However, the file was modified with most notable modification the the license entry that was removed and replaced by the ASF header.

This class being a 3-party work should adhere to the following guidelines:
https://www.apache.org/legal/src-headers.html#3party

To comply with the guidelines above at the bare minimum we should remove the AL2 header and restore the original copyright in the file."	HIVE	Resolved	3	3	11212	pull-request-available
13548255	Preparing for 4.0.0-beta-2 development	"The main goal of this ticket is to increment the version and add the necessary metastore upgrade scripts so we don't lose track of what changed after the beta-1 release.

If later we decide to use another name (other than beta-2) that would be completely fine (and hopefully a simple rename would do). The most important thing in this change is to have the scripts in place so we don't mess up when we push changes to the metastore schema."	HIVE	Closed	3	3	11212	pull-request-available
13213208	Support semijoin reduction on multiple column join	"Currently for a query involving join on multiple columns creates  separate semi join edges for each key which in turn create a bloom filter for each of them, like below,

EXPLAIN select count(*) from srcpart_date_n7 join srcpart_small_n3 on (srcpart_date_n7.key = srcpart_small_n3.key1 and srcpart_date_n7.value = srcpart_small_n3.value1)
{code:java}
Map 1 <- Reducer 5 (BROADCAST_EDGE)
        Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 4 (SIMPLE_EDGE)
        Reducer 3 <- Reducer 2 (CUSTOM_SIMPLE_EDGE)
        Reducer 5 <- Map 4 (CUSTOM_SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: srcpart_date_n7
                  filterExpr: (key is not null and value is not null and (key BETWEEN DynamicValue(RS_7_srcpart_small_n3_key1_min) AND DynamicValue(RS_7_srcpart_small_n3_key1_max) and in_bloom_filter(key, DynamicValue(RS_7_srcpart_small_n3_key1_bloom_filter)))) (type: boolean)
                  Statistics: Num rows: 2000 Data size: 356000 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: ((key BETWEEN DynamicValue(RS_7_srcpart_small_n3_key1_min) AND DynamicValue(RS_7_srcpart_small_n3_key1_max) and in_bloom_filter(key, DynamicValue(RS_7_srcpart_small_n3_key1_bloom_filter))) and key is not null and value is not null) (type: boolean)
                    Statistics: Num rows: 2000 Data size: 356000 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: key (type: string), value (type: string)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 2000 Data size: 356000 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col0 (type: string), _col1 (type: string)
                        sort order: ++
                        Map-reduce partition columns: _col0 (type: string), _col1 (type: string)
                        Statistics: Num rows: 2000 Data size: 356000 Basic stats: COMPLETE Column stats: COMPLETE
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Map 4 
            Map Operator Tree:
                TableScan
                  alias: srcpart_small_n3
                  filterExpr: (key1 is not null and value1 is not null) (type: boolean)
                  Statistics: Num rows: 20 Data size: 3560 Basic stats: PARTIAL Column stats: PARTIAL
                  Filter Operator
                    predicate: (key1 is not null and value1 is not null) (type: boolean)
                    Statistics: Num rows: 20 Data size: 3560 Basic stats: PARTIAL Column stats: PARTIAL
                    Select Operator
                      expressions: key1 (type: string), value1 (type: string)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 20 Data size: 3560 Basic stats: PARTIAL Column stats: PARTIAL
                      Reduce Output Operator
                        key expressions: _col0 (type: string), _col1 (type: string)
                        sort order: ++
                        Map-reduce partition columns: _col0 (type: string), _col1 (type: string)
                        Statistics: Num rows: 20 Data size: 3560 Basic stats: PARTIAL Column stats: PARTIAL
                      Select Operator
                        expressions: _col0 (type: string)
                        outputColumnNames: _col0
                        Statistics: Num rows: 20 Data size: 3560 Basic stats: PARTIAL Column stats: PARTIAL
                        Group By Operator
                          aggregations: min(_col0), max(_col0), bloom_filter(_col0, expectedEntries=20)
                          mode: hash
                          outputColumnNames: _col0, _col1, _col2
                          Statistics: Num rows: 1 Data size: 730 Basic stats: PARTIAL Column stats: PARTIAL
                          Reduce Output Operator
                            sort order: 
                            Statistics: Num rows: 1 Data size: 730 Basic stats: PARTIAL Column stats: PARTIAL
                            value expressions: _col0 (type: string), _col1 (type: string), _col2 (type: binary)
            Execution mode: vectorized, llap
            LLAP IO: all inputs
        Reducer 2 
            Execution mode: llap
            Reduce Operator Tree:
              Merge Join Operator
                condition map:
                     Inner Join 0 to 1
                keys:
                  0 _col0 (type: string), _col1 (type: string)
                  1 _col0 (type: string), _col1 (type: string)
                Statistics: Num rows: 2200 Data size: 391600 Basic stats: PARTIAL Column stats: NONE
                Group By Operator
                  aggregations: count()
                  mode: hash
                  outputColumnNames: _col0
                  Statistics: Num rows: 1 Data size: 8 Basic stats: PARTIAL Column stats: NONE
                  Reduce Output Operator
                    sort order: 
                    Statistics: Num rows: 1 Data size: 8 Basic stats: PARTIAL Column stats: NONE
                    value expressions: _col0 (type: bigint)
        Reducer 3 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: count(VALUE._col0)
                mode: mergepartial
                outputColumnNames: _col0
                Statistics: Num rows: 1 Data size: 8 Basic stats: PARTIAL Column stats: NONE
                File Output Operator
                  compressed: false
                  Statistics: Num rows: 1 Data size: 8 Basic stats: PARTIAL Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
        Reducer 5 
            Execution mode: vectorized, llap
            Reduce Operator Tree:
              Group By Operator
                aggregations: min(VALUE._col0), max(VALUE._col1), bloom_filter(VALUE._col2, expectedEntries=20)
                mode: final
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1 Data size: 730 Basic stats: PARTIAL Column stats: PARTIAL
                Reduce Output Operator
                  sort order: 
                  Statistics: Num rows: 1 Data size: 730 Basic stats: PARTIAL Column stats: PARTIAL
                  value expressions: _col0 (type: string), _col1 (type: string), _col2 (type: binary)
{code}
Instead it should create one branch for a join with one bloom filter.

 

The implementation for bloom filter requires getting a hash out of all the key columns and converting it to a long and feeding it to bloom filter as input. This requires a new UDF which does this. It will be called at both bloom filter generation and lookup phases.

The min and max will stay independent as they are today for each columns.
A vectorized implementation of such UDF is also required."	HIVE	Closed	3	1	11212	pull-request-available
13561016	NPE in VectorMapJoinCommonOperator.setUpHashTable when running query with join on date	"The error can be reproduced on [current master|https://github.com/apache/hive/commit/fd6ced288dbf9ce7f3c3a2ca948d78f3b88f170f] using the following steps.
{code:sql}
set hive.auto.convert.join=true;

CREATE TABLE person (fname string, birthDate date);
INSERT INTO person VALUES ('Victor', '2023-11-27'), ('Alexandre', '2023-11-28');

SELECT * FROM person p1 INNER JOIN person p2 ON p1.birthDate=p2.birthDate;
{code}
The stacktrace is shown below.
{noformat}
2023-12-07T07:06:39,744 ERROR [TezTR-592758_1_2_1_0_0] tez.TezProcessor: Failed initializeAndRunProcessor
java.lang.RuntimeException: Map operator initialization failed
        at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.init(MapRecordProcessor.java:351) ~[hive-exec-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:292) ~[hive-exec-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:276) ~[hive-exec-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:381) ~[tez-runtime-internals-0.10.2.jar:0.10.2]
        at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:82) ~[tez-runtime-internals-0.10.2.jar:0.10.2]
        at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:69) ~[tez-runtime-internals-0.10.2.jar:0.10.2]
        at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_261]
        at javax.security.auth.Subject.doAs(Subject.java:422) ~[?:1.8.0_261]
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899) ~[hadoop-common-3.3.6.jar:?]
        at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:69) ~[tez-runtime-internals-0.10.2.jar:0.10.2]
        at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:39) ~[tez-runtime-internals-0.10.2.jar:0.10.2]
        at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36) ~[tez-common-0.10.2.jar:0.10.2]
        at org.apache.hadoop.hive.llap.daemon.impl.StatsRecordingThreadPool$WrappedCallable.call(StatsRecordingThreadPool.java:118) ~[hive-llap-server-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_261]
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_261]
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_261]
        at java.lang.Thread.run(Thread.java:748) ~[?:1.8.0_261]
Caused by: java.lang.NullPointerException
        at org.apache.hadoop.hive.ql.exec.vector.mapjoin.VectorMapJoinCommonOperator.setUpHashTable(VectorMapJoinCommonOperator.java:673) ~[hive-exec-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.apache.hadoop.hive.ql.exec.vector.mapjoin.VectorMapJoinCommonOperator.completeInitializationOp(VectorMapJoinCommonOperator.java:634) ~[hive-exec-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.apache.hadoop.hive.ql.exec.Operator.completeInitialization(Operator.java:450) ~[hive-exec-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:382) ~[hive-exec-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:549) ~[hive-exec-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.apache.hadoop.hive.ql.exec.Operator.initializeChildren(Operator.java:503) ~[hive-exec-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:369) ~[hive-exec-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.init(MapRecordProcessor.java:332) ~[hive-exec-4.0.0-beta-2-SNAPSHOT.jar:4.0.0-beta-2-SNAPSHOT]
        ... 16 more
{noformat}

This is probably caused by HIVE-23852 which added the DATE type as a possible key for the HashTable."	HIVE	Closed	3	1	11212	pull-request-available
13367249	Remove Read/WriteEntity parameters from TaskCompiler#optimizeOperatorPlan	"The {{ReadEntity}}, and {{WriteEntity}} parameters in {{TaskCompiler#optimizeOperatorPlan}} are passed in this method and various subsequent ones but they are never actually used so they can be removed.

This is a small refactoring to improve code readabiltiy."	HIVE	Closed	3	4	11212	pull-request-available
13404966	CREATE EXTERNAL TABLE fails for JDBC tables stored in non-default schema	"Consider the following use case where tables reside in some user-defined schema in some JDBC compliant database:

+Postgres+
{code:sql}
create schema world;

create table if not exists world.country (name varchar(80) not null);

insert into world.country (name) values ('India');
insert into world.country (name) values ('Russia');
insert into world.country (name) values ('USA');
{code}

The following DDL statement in Hive fails:

+Hive+
{code:sql}
CREATE EXTERNAL TABLE country (name varchar(80))
STORED BY 'org.apache.hive.storage.jdbc.JdbcStorageHandler'
TBLPROPERTIES (
""hive.sql.database.type"" = ""POSTGRES"",
""hive.sql.jdbc.driver"" = ""org.postgresql.Driver"",
""hive.sql.jdbc.url"" = ""jdbc:postgresql://localhost:5432/test"",
""hive.sql.dbcp.username"" = ""user"",
""hive.sql.dbcp.password"" = ""pwd"",
""hive.sql.schema"" = ""world"",
""hive.sql.table"" = ""country"");
{code}

The exception is the following:

{noformat}
org.postgresql.util.PSQLException: ERROR: relation ""country"" does not exist
  Position: 15
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2532) ~[postgresql-42.2.14.jar:42.2.14]
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2267) ~[postgresql-42.2.14.jar:42.2.14]
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:312) ~[postgresql-42.2.14.jar:42.2.14]
	at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:448) ~[postgresql-42.2.14.jar:42.2.14]
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:369) ~[postgresql-42.2.14.jar:42.2.14]
	at org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:153) ~[postgresql-42.2.14.jar:42.2.14]
	at org.postgresql.jdbc.PgPreparedStatement.executeQuery(PgPreparedStatement.java:103) ~[postgresql-42.2.14.jar:42.2.14]
	at org.apache.commons.dbcp2.DelegatingPreparedStatement.executeQuery(DelegatingPreparedStatement.java:122) ~[commons-dbcp2-2.7.0.jar:2.7.0]
	at org.apache.commons.dbcp2.DelegatingPreparedStatement.executeQuery(DelegatingPreparedStatement.java:122) ~[commons-dbcp2-2.7.0.jar:2.7.0]
	at org.apache.hive.storage.jdbc.dao.GenericJdbcDatabaseAccessor.getColumnNames(GenericJdbcDatabaseAccessor.java:83) [hive-jdbc-handler-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hive.storage.jdbc.JdbcSerDe.initialize(JdbcSerDe.java:98) [hive-jdbc-handler-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreUtils.getDeserializer(HiveMetaStoreUtils.java:95) [hive-metastore-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreUtils.getDeserializer(HiveMetaStoreUtils.java:78) [hive-metastore-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.metadata.Table.getDeserializerFromMetaStore(Table.java:342) [hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.metadata.Table.getDeserializer(Table.java:324) [hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.metadata.Table.getColsInternal(Table.java:734) [hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.metadata.Table.getCols(Table.java:717) [hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.ddl.table.create.CreateTableDesc.toTable(CreateTableDesc.java:933) [hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.ddl.table.create.CreateTableOperation.execute(CreateTableOperation.java:59) [hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.ddl.DDLTask.execute(DDLTask.java:84) [hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:212) [hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:105) [hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Executor.launchTask(Executor.java:361) [hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Executor.launchTasks(Executor.java:334) [hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Executor.runTasks(Executor.java:245) [hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Executor.execute(Executor.java:108) [hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:348) [hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
{noformat}
"	HIVE	Closed	3	1	11212	pull-request-available
13330354	Disable flaky TestStreaming	"Seems like the HeartBeater threads did not get cleaned up and deadlocks itself with the transactional table cleanups

[http://ci.hive.apache.org/job/hive-flaky-check/119/]

It seems random which test cases are failing in the class, like in this PR:
 [http://ci.hive.apache.org/blue/organizations/jenkins/hive-precommit/detail/PR-1539/1/tests]"	HIVE	Closed	3	1	11212	pull-request-available
13176638	INSERT OVERWRITE TABLE db.table PARTITION (...) IF NOT EXISTS throws InvalidTableException	"The following scenario reproduces the problem:

{code:sql}
CREATE DATABASE db2;
CREATE TABLE db2.destinTable (one STRING, two STRING) PARTITIONED BY (ds STRING);
INSERT OVERWRITE TABLE db2.destinTable PARTITION (ds='2011-11-11') IF NOT EXISTS SELECT 100, 200;
{code}

The last query ({{INSERT OVERWRITE ...}}) fails with the following stack trace:

{noformat}
2021-09-28T04:25:47,330 ERROR [e3399094-860f-4381-bfd3-d2acfa8a885d main] ql.Driver: FAILED: SemanticException org.apache.hadoop.hive.ql.metadata.InvalidTableException: Table not found db2
org.apache.hadoop.hive.ql.parse.SemanticException: org.apache.hadoop.hive.ql.metadata.InvalidTableException: Table not found db2
        at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.doPhase1(SemanticAnalyzer.java:1918)
        at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.doPhase1(SemanticAnalyzer.java:1959)
        at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genResolvedParseTree(SemanticAnalyzer.java:12393)
        at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12506)
        at org.apache.hadoop.hive.ql.parse.CalcitePlanner.analyzeInternal(CalcitePlanner.java:454)
        at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:317)
        at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223)
        at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:105)
        at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:500)
        at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:453)
        at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:417)
        at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:411)
        at org.apache.hadoop.hive.ql.reexec.ReExecDriver.compileAndRespond(ReExecDriver.java:125)
        at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:229)
        at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:256)
        at org.apache.hadoop.hive.cli.CliDriver.processCmd1(CliDriver.java:201)
        at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:127)
        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:422)
        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:353)
        at org.apache.hadoop.hive.ql.QTestUtil.executeClientInternal(QTestUtil.java:804)
        at org.apache.hadoop.hive.ql.QTestUtil.executeClient(QTestUtil.java:774)
        at org.apache.hadoop.hive.cli.control.CoreCliDriver.runTest(CoreCliDriver.java:175)
        at org.apache.hadoop.hive.cli.control.CliAdapter.runTest(CliAdapter.java:157)
        at org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver(TestMiniLlapLocalCliDriver.java:62)
{noformat}

The problem does not reproduce when the {{IF NOT EXISTS}} clause is not present in the query."	HIVE	Closed	3	1	11212	pull-request-available
13345956	Prevent comparisons between characters and decimals types when strict checks enabled	"When we compare decimal and character types implicit conversions take place that can lead to unexpected and surprising results. 

{code:sql}
create table t_str (str_col string);
insert into t_str values ('1208925742523269458163819');select * from t_str where str_col=1208925742523269479013976;
{code}

The SELECT query brings up one row while the filtering value is not the same with the one present in the string column of the table. The problem is that both types are converted to doubles and due to loss of precision the values are deemed equal.

Even if we change the implicit conversion to use another type (HIVE-24528) there are always some cases that may lead to unexpected results. 

The goal of this issue is to prevent comparisons between decimal and character types when hive.strict.checks.type.safety is enabled and throw an error. 
 "	HIVE	Closed	3	3	11212	pull-request-available
13345745	Wrong implicit type conversion when comparing decimals and strings	"In many cases when comparing decimals and strings (literals/columns) the comparison is done using doubles which can create some quite unexpected results in the answers of queries.

{code:sql}
create table t_str (str_col string);
insert into t_str values ('1208925742523269458163819');
select * from t_str where str_col=1208925742523269479013976;
{code}

The SELECT query brings up one row while the filtering value is not the same with the one present in the string column of the table. The problem is that both types are converted to doubles and due to loss of precision the values are deemed equal.

The same happens during the join of a decimal with a string type.
{code:sql}
create table t_dec (dec_col decimal(25,0));
insert into t_dec values (1208925742523269479013976);
select * from t_dec inner join t_str on dec_col=str_col;
{code}
The join result contains one row although the values are not equal.

Implicit type conversions are working differently in every DBMS and for some of them (e.g., mysql) the above behavior is normal or not allowed at all (e.g. Postgres). 

In the past, Hive used to compare decimal with string columns by converting to decimals but this behavior changed in 2.3.0 (with HIVE-13380). It seems that this behavior change was not intentional since following jiras (e.g., HIVE-18434) imply that comparison of decimals with strings should be done using decimals. Since decimal is an exact numeric it appears a more appropriate type for comparing decimals and strings.

The goal of this issue is to change the implicit conversion of decimals with strings to doubles and use decimals instead.

"	HIVE	Open	3	1	11212	pull-request-available
13410253	Uncaught exception in QTestDatabaseHandler#afterTest causes unrelated test failures	"When for some reason we fail to cleanup a database after running a test using the {{qt:database}} option an exception is raised and propagates up the stack. Not catching it in [QTestDatabaseHandler#afterTest|https://github.com/apache/hive/blob/0616bcaa2436ccbf388b635bfea160b47849553c/itests/util/src/main/java/org/apache/hadoop/hive/ql/qoption/QTestDatabaseHandler.java#L124] disrupts subsequent cleanup actions, which are not executed, and leads to failures in subsequent tests which are not related.
 
Moreover, the exception leaves {{QTestDatabaseHandler}} in an invalid state since the internal map holding the running databases is not updated."	HIVE	Closed	3	1	11212	pull-request-available
13407343	Drop TestCompareCliDriver and related code from tests	"The driver has been introduced back in 2015 (HIVE-6010) aiming to run queries with vectorization on/off and comparing the results. However it didn't receive much attention since then and currently only two queries are run with this driver.

The majority of tests aiming to ensure vectorization works correctly use the {{TestMiniLlapLocalCliDriver}} and run a query twice switching on/off the necessary properties.

Summing up having the [TestCompareCliDriver|https://github.com/apache/hive/blob/d521f149fade25f74e7ca28fa399103684a80580/itests/qtest/src/test/java/org/apache/hadoop/hive/cli/TestCompareCliDriver.java] in the repo leads to extra code maintenance cost without significant benefit."	HIVE	Closed	3	3	11212	pull-request-available
13541584	"NOTICE files use incorrect wording ""developed by"" instead of ""developed at"""	"The NOTICE files currently use the incorrect wording ""developed by The Apache Software Foundation"".

As it can be shown in the following links (and also from other JIRA tickets) the correct wording is ""developed at"". 

https://www.apache.org/legal/src-headers.html#notice
https://www.apache.org/legal/release-policy.html#notice-required"	HIVE	Closed	1	1	11212	pull-request-available
13408702	Remove ElapsedTimeLoggingWrapper from tests	"The  [ElapsedTimeLoggingWrapper|https://github.com/apache/hive/blob/f749ef2af27638914984c183bcfa213920f5cdd9/itests/util/src/main/java/org/apache/hadoop/hive/util/ElapsedTimeLoggingWrapper.java] introduced in HIVE-14625 is used by the [CoreCliDriver|#L68] to execute, measure, and display the time spend on some operations during the execution of {{@Before/@After}} methods. 

The benefit of logging the elapsed time for these methods is unclear. The time is usually rather short, especially compared to the actual time a query takes to run,  so it is not an information which can be of much use.

The enforced coding pattern for measuring and logging the time leads to boilerplate and makes the code harder to read and understand. 

{code:java}
qt = new ElapsedTimeLoggingWrapper<QTestUtil>() {
      @Override
      public QTestUtil invokeInternal() throws Exception {
        return new QTestUtil(
            QTestArguments.QTestArgumentsBuilder.instance()
              .withOutDir(cliConfig.getResultsDir())
              .withLogDir(cliConfig.getLogDir())
              .withClusterType(miniMR)
              .withConfDir(hiveConfDir)
              .withInitScript(initScript)
              .withCleanupScript(cleanupScript)
              .withLlapIo(true)
              .withFsType(cliConfig.getFsType())
              .build());
      }
    }.invoke(""QtestUtil instance created"", LOG, true);
{code}

Moreover, the wrapper is not used consistently across drivers making results less uniform.

The goal of this issue is to remove {{ElapsedTimeLoggingWrapper}} and its usages to improve code readability and maintenance.
"	HIVE	Closed	4	3	11212	pull-request-available
13581913	Disable hive.optimize.join.disjunctive.transitive.predicates.pushdown by default	"HIVE-25758 introduced hive.optimize.join.disjunctive.transitive.predicates.pushdown  to conditionally limit some features of the HiveJoinPushTransitivePredicatesRule which are rather unsafe and can lead to Hiveserver2 crashes (OOM, hangs, etc.). 

The property was initially set to true to retain the old behavior and prevent changes in performance for those queries that work fine as is. However, when the property is true there are various known cases/queries that can bring down HS2 completely. When this happens debugging, finding the root cause, and turning off the property may require lots of effort from developers and users.

In this ticket, we propose to disable the property by default and thus limit the optimizations performed by the rule (at least till a complete solution is found for the known problematic cases).

This change favors HS2 stability at the expense of slight performance degradation in certain queries."	HIVE	Resolved	3	3	11212	hive-4.0.1-merged, hive-4.0.1-must, pull-request-available
13552223	Generalize TestSchemaToolForMetastore to run on every supported DBMS	"[TestSchemaToolForMetastore|https://github.com/apache/hive/blob/57f096c9a73eb92806f2a7cc97f87fabf5d546fe/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/tools/schematool/TestSchemaToolForMetastore.java] contains a bunch of tests for the {{SchemaTool}} over a Derby database.

Derby is one out of the six (Postgres, Oracle, Microsoft SQL Server, MySQL, MariaDB, Derby) supported metastore DBMS backends.

The goal of this ticket is to generalize the class and run the tests on every supported DBMS to increase code coverage."	HIVE	Closed	3	6	11212	pull-request-available
