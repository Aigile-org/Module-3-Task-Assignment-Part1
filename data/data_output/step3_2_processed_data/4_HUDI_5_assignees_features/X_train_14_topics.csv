id	project_name	processed_title	processed_description	processed_labels	priority_id	type_id	status_name	topic_id	top_terms
13540263	HUDI	spark cdc delete record filegroup display fail	delete record filegroup cdc query fail assert	['pull-request-available']	3	1	Closed	12	['record', 'read', 'use', 'base', 'create', 'datum', 'query', 'time', 'set', 'currently']
13557235	HUDI	create config choose want read position base merge	right control separate read config	['pull-request-available']	1	2	Closed	12	['record', 'read', 'use', 'base', 'create', 'datum', 'query', 'time', 'set', 'currently']
13475674	HUDI	cloudwatch reporter create hudi spark bundle hudi aws bundle classpath	spark shell hudi hudi aws kryoserializer hoodiecatalog hoodiesparksessionextension nosuchmethoderror apache hudi com codahale metric apache hudi aws cloudwatch scala	['pull-request-available']	1	1	Closed	12	['record', 'read', 'use', 'base', 'create', 'datum', 'query', 'time', 'set', 'currently']
13438473	HUDI	enable default read path make hivesync fail	code java main info ittestbase container run command spark submit hivesynctool hoodie docker hoodie hadoop target hoodie hive sync default path hive warehouse file format parquet hive hive url jdbc main info ittestbase dockerjava jaxrs info ittestbase oncomplete call main info ittestbase exit code command main error ittestbase stdout main error ittestbase stderr warn nativecodeloader unable load native hadoop library platform builtin java class applicable exception thread main noclassdeffounderror org apache hadoop hbase util byte method method cause classnotfoundexception byte main info ittestbase code	['pull-request-available']	1	1	Closed	8	['metadata', 'path', 'commit', 'datum', 'run', 'add', 'base', 'create', 'enable', 'test']
13535693	HUDI	cdc payload field delete work	delete operation custom payload look release apache hudi find custom payload implementation like aws dms payload debezium payload properly migrate new api introduce cause delete operation fail test catch currently assume delete record mark custom cdc payload use field mark delete impact overwritewithlatest overwritenondefaultswithlatestavropayload affect custom payload awsdmsavropayload debezium payload delete break enforce delete issue custome payload cow delete non existant break way mor delete break way writer flink spark sql defaulthoodierecordpayload delete marker support affect	['pull-request-available']	1	1	Closed	12	['record', 'read', 'use', 'base', 'create', 'datum', 'query', 'time', 'set', 'currently']
13421651	HUDI	allow original partition column value retrieve timestampbasedkeygen	spark default omit partition value datum file instead encode partition path partitioned table timestampbasedkeygenerator original timestamp base column make impossible retrieve original value read spark persist data file code java import datasourcewriteoptions import hoodiewriteconfig import keygeneratoroption import multipartkeysvalueextractor val age mor timestampbasedkeygenerator yyyy yyyy savemode append hudi query datum hudi query datum hudi cow timestampbasedkeygenerator yyyy yyyy savemode append hudi query datum hudi work hudi code	['hudi-on-call', 'pull-request-available', 'sev:critical']	2	1	Open	9	['partition', 'log', 'metadata', 'time', 'read', 'commit', 'path', 'datum', 'issue', 'new']
13440523	HUDI	fix partition path construction metadata table validator	metadata table validator throw exception non partitioned table partition path construction code java hoodieexception unable hoodie metadata table validation ethan work script method cause illegalargumentexception create path string code	['pull-request-available']	1	3	Closed	8	['metadata', 'path', 'commit', 'datum', 'run', 'add', 'base', 'create', 'enable', 'test']
13575231	HUDI	read log block header schema instant time	tableschemaresolver read schema log file header current way instantiate log reader lazily read content cause block content read unnecessary cause oom spark driver cluster clustering rewrite file group contain log file require derive schema file group current logic code java public static messagetype path path throw ioexception try reader reader new null hoodiedatablock lastblock null hoodielogblock block block instanceof hoodiedatablock lastblock hoodiedatablock block return lastblock null new null code	['pull-request-available']	1	1	Closed	9	['partition', 'log', 'metadata', 'time', 'read', 'commit', 'path', 'datum', 'issue', 'new']
13306030	HUDI	partition columns miss file upserte metadata bootstrap	issue happen source datum partition hive style partitioning default behavior spark write datum partitioning partition column schema store file instead retrieve fly file path partition folder form metadata bootstrap store metadata column hudi table folder bootstrap schema computing directly read schema source datum file partition column schema complete manifest issue ultimately upsert bootstrappe file fully bootstrappe upsert time schema evolve upsert dataframe need partition column perform upsert ultimately upserted row correct partition column value store record simply copy metadata bootstrap file miss partition column observe different behavior bootstrappe non bootstrappe table moment create issue hive able determine partition column becuase metadata store create problem engine like spark partition column null upserted file read proposal fix following issue perform bootstrap figure partition schema store bootstrap schema commit metadata file provide follow benefit completeness perspective good behavioral change bootstrappe non bootstrappe table spark bootstrap relation incremental query relation need figure late schema simply accurate schema commit metadata file instead have determine partition column present schema obtain metadata file figure partition schema everytime merge expensive upsert file metadata bootstrappe partition column value correctly determine copy upserted file avoid missing null value consistent behavior non bootstrappe table hive handle consider engine like spark automatically handle significantly complicated able provide partition value read spark able determine everytime partition value null fill table fully bootstrappe point future bootstrap commit clean spark querying happen parquet datasource instead new bootstrappe datasource parquet datasource return null value find miss partition value case control parquet datasource simply read file	['pull-request-available']	1	1	Closed	9	['partition', 'log', 'metadata', 'time', 'read', 'commit', 'path', 'datum', 'issue', 'new']
13431528	HUDI	investigate read issue hudi spark bundle dataset	code java scala uuid partitionpath tablename warn deprecation detail enable set replay warn config dfspropertiesconfiguration find set dir warn config dfspropertiesconfiguration property file hudi conf hudi find ignore load prop file warn hudi hoodie table exist delete exist datum overwrite new datum warn metadata hoodiebackedtablemetadata metadata table find path metadata warn scheduler tasksetmanager lost task stage tid executor nosuchmethoderror lang error scheduler tasksetmanager task stage fail time abort job hoodieupsertexception fail upsert commit time elide code	['pull-request-available']	1	1	Closed	9	['partition', 'log', 'metadata', 'time', 'read', 'commit', 'path', 'datum', 'issue', 'new']
13422270	HUDI	unit test require hive service setup fail	happen test hudi utility module testhoodiedeltastreamer testhiveincrementalpuller error noclassdeffounderror org apache logging core appender core hudi utility test scope	['pull-request-available']	1	1	Closed	6	['test', 'metadata', 'partition', 'path', 'commit', 'cause', 'record', 'query', 'run', 'update']
13489167	HUDI	optimize deltasync	call source rdd twice deltasync try optimize reuse	['pull-request-available']	2	4	Patch Available	6	['test', 'metadata', 'partition', 'path', 'commit', 'cause', 'record', 'query', 'run', 'update']
13328900	HUDI	support metadata table spark datasource	expose spark datasource provide follow interface code java columnar interface filename available payload partition path decode fly list partition match key col stat col stat code	['pull-request-available']	1	3	Closed	5	['write', 'config', 'partition', 'support', 'add', 'path', 'need', 'use', 'record', 'metadata']
13556532	HUDI	support query sync partition metadata catalog	reduce load hms glue catalog register non partitioned table	['pull-request-available']	3	3	Closed	6	['test', 'metadata', 'partition', 'path', 'commit', 'cause', 'record', 'query', 'run', 'update']
13579013	HUDI	upgrade spark patch version include fix relate datum correctness	show data correctness issue spark upgrade spark upgrade issue affect	['pull-request-available']	3	4	Closed	1	['metadata', 'issue', 'case', 'partition', 'base', 'path', 'datum', 'read', 'use', 'create']
13547056	HUDI	fix partition validation consider commit metadata table validator	complete rollback datum table timeline interfere partition validation metadata table validator commit consider validation following example timeline mdt code java instant action state rollback info request inflight complete time time time action state request inflight complete time time time deltacommit complete deltacommit complete deltacommit inflight roll rollback inflight roll rollback complete deltacommit request deltacommit request rollback complete roll deltacommit complete rollback complete code partition metadata code java partition metadata sat aug utc code validator throw exception code java hoodievalidationexception compare partitions fail allpartitionpathsfromfs allpartitionpathsmeta method code	['pull-request-available']	1	1	Open	9	['partition', 'log', 'metadata', 'time', 'read', 'commit', 'path', 'datum', 'issue', 'new']
13383657	HUDI	fix extra commit metadata row writer path	regular path write client user pass extra commit metadata help commit key prefix config row writer path address	['pull-request-available']	3	1	Resolved	8	['metadata', 'path', 'commit', 'datum', 'run', 'add', 'base', 'create', 'enable', 'test']
13524718	HUDI	fail new commit inflight restore timeline	restore fail mid way user allow start new commit let add guard rail	['pull-request-available']	2	4	Closed	3	['new', 'record', 'read', 'partition', 'commit', 'base', 'metadata', 'type', 'add', 'use']
13550813	HUDI	fix internalschema schemaid column drop	case drop column spark sql schema incorrectly set max column instead commit timestamp	['pull-request-available']	3	3	Closed	1	['metadata', 'issue', 'case', 'partition', 'base', 'path', 'datum', 'read', 'use', 'create']
13448657	HUDI	add tooling delete non complete instant timeline	instant timeline old version hudi run issue fix apache hudi like provider user old version tool assist delete instant incase complete	['pull-request-available']	3	4	Closed	4	['commit', 'run', 'update', 'time', 'need', 'base', 'cause', 'partition', 'issue', 'write']
13590660	HUDI	use serializableconfiguration spark broadcast	place broadcast storageconf spark cause npe	['pull-request-available']	1	1	Closed	10	['cause', 'time', 'read', 'type', 'update', 'commit', 'log', 'use', 'config', 'support']
13441931	HUDI	sure hudi relations fetch strictly require column	able considerably optimize data throughput mor table xxx previously mor table read table row column simple query optimize fetch require column table type cow mor optimize cow table require column mor table require primary key pre combine key column actual merge update record delta log file perform avoid read col	['pull-request-available']	1	1	Closed	10	['cause', 'time', 'read', 'type', 'update', 'commit', 'log', 'use', 'config', 'support']
13543790	HUDI	hoodiemergehelper merge bootstrap file twice	merge helper use bootstrap file reader merge skeleton base file merge unnecessarily	['pull-request-available']	3	1	Closed	12	['record', 'read', 'use', 'base', 'create', 'datum', 'query', 'time', 'set', 'currently']
13510679	HUDI	clean partially fail restore	table attempt restore operation fail mid way restore lie attempt new instant time allot attempt scratch thwart compaction progression mdt need ensure give savepoint use restore instant	['pull-request-available']	1	1	Closed	10	['cause', 'time', 'read', 'type', 'update', 'commit', 'log', 'use', 'config', 'support']
13470202	HUDI	bulk insert url encode partition path properly	currently partition path slash hudi lay partition table incorrectly screen shot	['pull-request-available']	1	1	Closed	9	['partition', 'log', 'metadata', 'time', 'read', 'commit', 'path', 'datum', 'issue', 'new']
13507336	HUDI	multiple meta sync meta sync failure impact meta sync	example hms glue hms sync fail sync glue	['pull-request-available']	2	4	Closed	6	['test', 'metadata', 'partition', 'path', 'commit', 'cause', 'record', 'query', 'run', 'update']
13553989	HUDI	sparksql query perfermance cost hudi	version create table string string bigint day string comment 日期分区 hour int comment 小时分区 hudi options false false false tblpropertie primarykey type mor bucket partitioned insert select day hour insert select day hour insert select day hour select right stage task number table file cause driver oom fullgc long time	['pull-request-available']	3	1	Open	10	['cause', 'time', 'read', 'type', 'update', 'commit', 'log', 'use', 'config', 'support']
13520122	HUDI	fix kryo class registration spark	profile datum serialize hudi change considerably previously pass avro payload hold internal hoodierecord implementation class explicitly register kryo serialize class fully qualified fqn time object serialize carry lot unnecessary apache hudi work apache hudi add hoodiesparkkryoregistrar register commonly serialize hudi class rebase merging feature branch change partially revert need restore	['pull-request-available']	1	1	Closed	4	['commit', 'run', 'update', 'time', 'need', 'base', 'cause', 'partition', 'issue', 'write']
13481671	HUDI	fix tooling deprecated partition	hudi cli support fix deprecated partition assume stre datatype partitioning col fix assumption	['pull-request-available']	1	1	Closed	5	['write', 'config', 'partition', 'support', 'add', 'path', 'need', 'use', 'record', 'metadata']
13555928	HUDI	add support non partitioned dataset rli	need support rli non partitioned dataset initialization rli exist table new table	['pull-request-available']	3	4	Closed	5	['write', 'config', 'partition', 'support', 'add', 'path', 'need', 'use', 'record', 'metadata']
13480370	HUDI	fix scalatest respect config	recently address issue configuration properly respect hudi test xxx issue config pick scalatest test	['pull-request-available']	2	1	Closed	6	['test', 'metadata', 'partition', 'path', 'commit', 'cause', 'record', 'query', 'run', 'update']
13310250	HUDI	bulk insert convert rdd	bulk bulk insert operation infact dataset rdd conversion hoodiesparksqlwriter hoodieclient deal javardd try improve performance avoid rdd conversion start bulk insert end end work decide wanna operation perf analysis high level idea dataset pass way spark sql writer storage writer convert hoodierecord point time need use apache spark blob master sql core src main scala org apache spark sql execution datasource parquet write parquet internalrows gist wanna dataset sort partition path record key repartition parallelism config mappartition mappartition iterate rows encode internalrows write parquet write support link want check strategy actually improve perf quick hack mappartition func hoodiesparksqlwriter number look like check operation number get exist hoodie bulk insert rdd conversion javardd write directly parquet spark code give modify hoodie code operation record parallelism input size orig sec output size parquet sec output size modified hudi code direct parquet write sec output size essentially exist code bulk insert parquet modified hudi code operation close direct parquet write spark show strategy work parquet write spark key	['pull-request-available']	1	4	Closed	5	['write', 'config', 'partition', 'support', 'add', 'path', 'need', 'use', 'record', 'metadata']
13510330	HUDI	adjust coalesce behavior sort mode bulk insert	sort mode bulk insert coalesce input record row base shuffle parallelism bulk insert reduce parallelism affect write latency cluster worker fully utilize reduce parallelism	['pull-request-available']	1	4	Closed	0	['type', 'support', 'base', 'record', 'time', 'read', 'enable', 'new', 'use', 'log']
13437271	HUDI	automatically enable inprocesslockprovider lazy rollback spark datasoruce write compaction config set mor	add fix hudi automatically detect async table service enable lock provider configure automatically enable inprocesslockprovider occ lazy rollback pre requisite enable metadata table fix work cow clustering mor tricky explicit check condition auto enable table type mor compaction async enable inprocesslockprovider bcoz cow compaction mor compaction enable question inline async work user explicitly set compaction config code java uuid partitionpath tablename code clearly detect inline enable inprocesslockprovi auto detection work deltastreamer code path clearly detect compaction inline async inline deltastreamer explicitly set true tricky spark datasource user skip compaction config altogether auto detect inline ahead enable inprocesslockprovider addition occ lazy rollback behavior change simple single writer come code java uuid partitionpath tablename code reason code default value false deduce compaction async user explicitly set find way fix production pipeline likely write compaction config set compaction config set write lets try maintain behavior	['pull-request-available']	1	1	Closed	13	['set', 'query', 'enable', 'config', 'read', 'write', 'add', 'test', 'path', 'run']
13525107	HUDI	fix async indexer metadata writer avoid eager rollback cleaning	async indexer metadata writer configure use lazy fail write cleaning policy logic potentially roll delta commit regular metadata writer heartbeat disabled regular mdt write fail write cleaning go rollback commit regardless need fix async indexer metadata writer touch delta commit mdt cause follow test flaky code java error test run failure error skip time elapse failure testhoodiedeltastreamer error time elapse error executionexception runtimeexception hoodieexception method cause runtimeexception hoodieexception cause hoodieexception hoodieexception cause executionexception hoodieexception cause hoodieexception cause illegalargumentexception code	['pull-request-available']	2	1	Closed	10	['cause', 'time', 'read', 'type', 'update', 'commit', 'log', 'use', 'config', 'support']
13582603	HUDI	use typedproperties store spillable map config reader	take param reader store typedproperties pass	['pull-request-available']	3	4	Closed	5	['write', 'config', 'partition', 'support', 'add', 'path', 'need', 'use', 'record', 'metadata']
13538616	HUDI	sql insert default bulk insert	insert mainly append workflow well box experience default bulk insert case ctas merge usually update	['pull-request-available']	3	4	Closed	1	['metadata', 'issue', 'case', 'partition', 'base', 'path', 'datum', 'read', 'use', 'create']
13524275	HUDI	allow lazy rollback async indexer commit	fix async indexer fail eager rollback metadata table temporary solution little invovled clean fix apply eager rollback regular delta commit deduce delta commit hoodieindexer employ lazy clean heartbeat	['pull-request-available']	1	1	Closed	4	['commit', 'run', 'update', 'time', 'need', 'base', 'cause', 'partition', 'issue', 'write']
13515672	HUDI	optimize timeline loading hudi sync client	hudi archive timeline load metastore sync process sync time give archived timeline cache inside meta client start instant time give cause performance issue read timeout cloud storage rate limiting request load archived timeline storage archived timeline huge hundred log file archive folder	['pull-request-available']	1	4	Closed	10	['cause', 'time', 'read', 'type', 'update', 'commit', 'log', 'use', 'config', 'support']
13557219	HUDI	support read log file file group reader base spark parquet file format	hoodiefilegroupreaderbasedparquetfileformat read log file slice support fix code java todo use filegroupreader throw new support read log file code	['pull-request-available']	1	4	Closed	0	['type', 'support', 'base', 'record', 'time', 'read', 'enable', 'new', 'use', 'log']
13421199	HUDI	rebase hive fileinputformat abstracthoodietablefileindex	multiple control flow require accurate mapping start leverage abstracthoodietablefileindex snapshot query mode incremental query mode task focus rebase snapshot mode	['pull-request-available']	1	4	Closed	13	['set', 'query', 'enable', 'config', 'read', 'write', 'add', 'test', 'path', 'run']
13413244	HUDI	sure usage component thread safe	dateformat base class inherently thread safe need sure concurrency control threadlocals lock access bite	['pull-request-available']	3	1	Closed	0	['type', 'support', 'base', 'record', 'time', 'read', 'enable', 'new', 'use', 'log']
13588895	HUDI	rid separate reader instance cdc reader	use exist spark reader instead create separate cdc reader	['pull-request-available']	3	4	Closed	12	['record', 'read', 'use', 'base', 'create', 'datum', 'query', 'time', 'set', 'currently']
13425982	HUDI	investigate fix hive query validation integ test suite	hive query validation work integ test suite framework investigate fix	['user-support-issues']	2	3	Closed	6	['test', 'metadata', 'partition', 'path', 'commit', 'cause', 'record', 'query', 'run', 'update']
13571781	HUDI	schemaprovider deduce deltastreamer scenario	couple case schema cause stream failure bad table state	['pull-request-available']	3	1	Closed	10	['cause', 'time', 'read', 'type', 'update', 'commit', 'log', 'use', 'config', 'support']
13596563	HUDI	datum skip work rli record key composite	datum skip rli work column primary key work primary key multiple column code reproduce import column datum insert uuid rider city true insert data rider rider read query scan file use code uuid city true insert data key read work expect	['pull-request-available']	1	1	Patch Available	12	['record', 'read', 'use', 'base', 'create', 'datum', 'query', 'time', 'set', 'currently']
13411818	HUDI	illegalargexception timeline server serve getlastestbasefile multi writer	concurrent write try ingest hudi occasionally run illegalargumentexception exception see actual write succeed happen understanding let table late commit try commit try try non overlapping expect succeed start switch writer trigger go fine succeed timeline got instantiate late snapshot receive getlatestbasefile request late commit throw exception similar issue happend code java scala type zookeeperbasedlockprovider tablename warn commit time warn embeddedtimelineservice start embed timeline server stage error requesthandler get runtime exception servicing request partition illegalargumentexception know instant client server follow timeline warn exceptionmapper uncaught exception illegalargumentexception know instant client server follow timeline error prioritybasedfilesystemview get error run preferred function try secondary hoodieremoteexception server error cause httpresponseexception server error error requesthandler get runtime exception servicing request partition illegalargumentexception know instant client server follow timeline warn exceptionmapper uncaught exception illegalargumentexception know instant client server follow timeline error prioritybasedfilesystemview get error run preferred function try secondary hoodieremoteexception server error cause httpresponseexception server error error requesthandler get runtime exception servicing request partition illegalargumentexception know instant client server follow timeline warn exceptionmapper uncaught exception illegalargumentexception know instant client server follow timeline error prioritybasedfilesystemview get error run preferred function try secondary hoodieremoteexception server error cause httpresponseexception server error error requesthandler get runtime exception servicing request partition illegalargumentexception know instant client server follow timeline warn exceptionmapper uncaught exception illegalargumentexception know instant client server follow timeline error prioritybasedfilesystemview get error run preferred function try secondary hoodieremoteexception server error cause httpresponseexception server error stage code screen shot screen shot screen shot screen shot	['pull-request-available']	2	3	Closed	4	['commit', 'run', 'update', 'time', 'need', 'base', 'cause', 'partition', 'issue', 'write']
13483551	HUDI	cleaner clean file touch cluster	integration long running test cleaner clustering sep test start fail reason cluster kick find data file cluster look like cleaner clean	['pull-request-available']	1	1	Closed	6	['test', 'metadata', 'partition', 'path', 'commit', 'cause', 'record', 'query', 'run', 'update']
13411277	HUDI	validate metadata config reader	validate metadata config reader ensure default false metadata enable enable ensure metadata table file listing	['pull-request-available']	1	3	Resolved	8	['metadata', 'path', 'commit', 'datum', 'run', 'add', 'base', 'create', 'enable', 'test']
13430370	HUDI	mor compaction archive setting prevent metadata table compaction	mor table setting specify number delta commit compaction take place similarly setting control archiving instant set deltacommit accumulate folder compaction kick prevent metadata table compaction	['pull-request-available']	1	1	Closed	8	['metadata', 'path', 'commit', 'datum', 'run', 'add', 'base', 'create', 'enable', 'test']
13221944	HUDI	csv source support hudi delta streamer	deltastreamer support pull csv datum source hdfs log files kafka ticket provide support csv source	['pull-request-available']	3	4	Resolved	0	['type', 'support', 'base', 'record', 'time', 'read', 'enable', 'new', 'use', 'log']
13522854	HUDI	fix hoodieprunefilesourcepartition miss list non partitioned table	result table having incorrectly interpret spark byte cbo analysis	['pull-request-available']	1	1	Closed	6	['test', 'metadata', 'partition', 'path', 'commit', 'cause', 'record', 'query', 'run', 'update']
13524905	HUDI	early conflict detection update date	config class naming new implementation detail	['pull-request-available']	3	4	Closed	13	['set', 'query', 'enable', 'config', 'read', 'write', 'add', 'test', 'path', 'run']
13594733	HUDI	improve functional index test	testfunctionalindex currently cover follow index initialization drop cow mor index enable disable cow index non partitioned table hive sync mor upsert initialization cow mor need ensure cover follow case insert record validate update validate update reflect repeat update validate stat mor trigger compaction validate trigger cluster validate stat mor let trigger cluster compaction compaction ensure stat available replaced file group insert record update delete subset record impact min max value validate lets add test async compaction validate log file add new phantom file slice stat intact let test non partitioned table lets trigger rollback validate insert update partially fail validate stat pertiane insert reflect trigger rollback validate retry update stat reflect stat update record let add long running test commit aggressive clean archival sanity enable kind index exist sanity test good let test write operation insert upsert delete add test non partitioned dataset unmerged log record reading flow	['pull-request-available']	1	3	In Progress	6	['test', 'metadata', 'partition', 'path', 'commit', 'cause', 'record', 'query', 'run', 'update']
13429410	HUDI	refactor spark relations avoid code duplication	currently great deal duplication cow mor implementation spark relations lead necessity replicate fix multiple time case	['pull-request-available']	1	1	Closed	1	['metadata', 'issue', 'case', 'partition', 'base', 'path', 'datum', 'read', 'use', 'create']
13577755	HUDI	initialize index parallel instead compute type type		['hudi-1.0.0-beta2']	2	3	Open	11	['type', 'record', 'support', 'set', 'create', 'write', 'issue', 'base', 'test', 'partition']
13484030	HUDI	shade jol bundle	bundle shade hudi aws bundle hudi datahub sync bundle hudi gcp bundle hudi timeline server bundle hudi utility slim bundle	['pull-request-available']	1	1	Closed	6	['test', 'metadata', 'partition', 'path', 'commit', 'cause', 'record', 'query', 'run', 'update']
13258679	HUDI	translate documentation performance page	translate page chinese	['pull-request-available']	3	7	Closed	6	['test', 'metadata', 'partition', 'path', 'commit', 'cause', 'record', 'query', 'run', 'update']
13549760	HUDI	multiple base file format file group	ability mix different type base file single table single file group image json vector	['pull-request-available']	3	3	Closed	0	['type', 'support', 'base', 'record', 'time', 'read', 'enable', 'new', 'use', 'log']
13539310	HUDI	add doc spark support	doc update	['pull-request-available']	3	4	Closed	2	['test', 'run', 'add', 'cause', 'support', 'use', 'time', 'base', 'commit', 'query']
13588647	HUDI	add host storage info pass hive reader	hive reader use map right kinda messy break assumption reader context instead pass storage info	['pull-request-available']	3	2	Closed	2	['test', 'run', 'add', 'cause', 'support', 'use', 'time', 'base', 'commit', 'query']
13522991	HUDI	spark sql list hudi table sql operation	currently dml operation spark sql hudi invoke prior spark essentially follow invalidating relation cache force time relation resolve create new fileindex list file etc trigger cascade invalidation caching cache datum cachemanager spark additionally table previously temporary view entail table list trigger costly operation revert precede behavior spark	['pull-request-available']	1	1	Open	12	['record', 'read', 'use', 'base', 'create', 'datum', 'query', 'time', 'set', 'currently']
13572467	HUDI	fix hoodiemetadatapayload merge logic repeat delete	repeat duplicate delete partition file list file partition mdt current hoodiemetadatapayload merge logic drop deletion cause file delete file system suppose delete mdt file listing leave mdt following logic code java private map previousrecord map combinedfileinfo new hashmap add file list previous record null second merge file list new record filesystemmetadata null filesystemmetadata fileinfo fileinfo oldfileinfo newfileinfo null new false code concrete example bug cause ingestion fail datum file file group replace cluster data file file system mdt file listing clean plan generate delete datum file clean plan execute time fail commit spark job shutdown ingestion continue succeed clean plan generate contain data file file group delete clean plan successfully execute incur deletion file list metadata payload add log file mdt code java hoodiemetadatapayload key partition files code second clean plan successfully execute incur deletion file list metadata payload contain data file delete add subsequent log file file slice mdt code java hoodiemetadatapayload key partition files code replacecommit correspond clustering archive cleaner delete replace file group read mdt mdt compaction happen merging metadata payload identical delete lead deletion data file delete partition file list mdt expect behavior data file deletion field code java hoodiemetadatapayload key partition files code time upsert indexing delete data file serve file system view base mdt data file find file system cause ingestion fail	['pull-request-available']	1	1	Closed	9	['partition', 'log', 'metadata', 'time', 'read', 'commit', 'path', 'datum', 'issue', 'new']
13449886	HUDI	fix memory hoodiedata implementation operate lazily	currently hoodielistdata hoodiemappairdata operate eagerly payload mean transformation immediately apply follow performance drawback execute transformation regardless sequence require potentially waste bit compute cause oom sequence potentially large available memory caller rely assumption perform stream processing instead rebase hold internally provide semantic close spark rdd container	['pull-request-available']	1	1	Closed	10	['cause', 'time', 'read', 'type', 'update', 'commit', 'log', 'use', 'config', 'support']
13442034	HUDI	classnotfoundexception hudi spark bundle write table hbase index	run spark job encounter classnotfoundexception spark version scala version code java noclassdeffounderror org apache hudi org apache hadoop hbase protobuf generate code include hbase protocol packaging hudi spark bundle solve error code java classnotfoundexception gsonbuilder code include hbase shaded gson packaging hudi spark bundle solve error code java classnotfoundexception class find code configuration code java implementation status listener multicast message code set hbase configureation classnotfoundexception resolve exception code java retriesexhaustedexception fail exception connectionclosedexception address fail local exception connectionclosedexception connection close cause connectionclosedexception address fail local exception connectionclosedexception connection close cause connectionclosedexception connection close remove relocation relate hbase packaging hudi spark bundle job succeed check debug log idea reason connectionclosedexception occur use relocation	['pull-request-available']	2	1	Closed	10	['cause', 'time', 'read', 'type', 'update', 'commit', 'log', 'use', 'config', 'support']
13559416	HUDI	fix operation type bulk insert row writer hudi streamer	code java operationtype null code operationtype null commit metadata bulk insert operation row writer enable hudi streamer true	['pull-request-available']	1	1	Closed	7	['commit', 'metadata', 'cause', 'issue', 'enable', 'query', 'test', 'update', 'set', 'read']
13484458	HUDI	bundle combination testing cover	cover spark bundle utility bundle utility slim bundle	['pull-request-available']	3	6	Closed	6	['test', 'metadata', 'partition', 'path', 'commit', 'cause', 'record', 'query', 'run', 'update']
13476605	HUDI	support ingest apache pulsar deltastreamer	currently ingest pulsar native pulsar spark connector ingest spark subsequently use hudi spark integration write great match support pulsar deltastreamer source	['pull-request-available']	1	2	Closed	5	['write', 'config', 'partition', 'support', 'add', 'path', 'need', 'use', 'record', 'metadata']
13429357	HUDI	fix partition code path logrecordscanner	partition require metadata table read enable virtual key metadata chase code path logrecordscanner usage ensure partition set builder check apache hudi patch example fix	['pull-request-available']	1	3	Closed	9	['partition', 'log', 'metadata', 'time', 'read', 'commit', 'path', 'datum', 'issue', 'new']
13420201	HUDI	fix partitions command result drop partition	add partition drop partition partition query result expected result	['pull-request-available', 'user-support-issues']	1	1	Closed	6	['test', 'metadata', 'partition', 'path', 'commit', 'cause', 'record', 'query', 'run', 'update']
13550763	HUDI	update sql pages	update	['pull-request-available']	3	4	Closed	4	['commit', 'run', 'update', 'time', 'need', 'base', 'cause', 'partition', 'issue', 'write']
13425761	HUDI	ignore non existant temp marker dir commit downgrade table version	downgrade commit marker directory exception throw silently ignore code interest twotoonedowngradehandler code java private void string commitinstanttime hoodietable table hoodieenginecontext context int parallelism throw ioexception string markerdir filesystem filesystem option markertypeoption markerdir switch case read marker write timeline server map markersmap markerdir filesystem context parallelism directwritemarker directwritemarker new commitinstanttime recreate marker direct format delete marker type file markerdir delete timeline server base marker markerdir filesystem parallelism break default throw new marker type support rollback case partial failure downgrade chance marker type file delete timeline server base marker file leave delete markerdir filesystem parallelism code block code java private void context string markerdir filesystem filesystem int parallelism throw ioexception delete timeline base marker file predicate prefixfilter filestatus filesystem new parallelism prefixfilter pairofsubpathandconf false code fix block snippet deletetimelinebasedmarkerfile marker dir commit exist	['pull-request-available']	3	3	Closed	3	['new', 'record', 'read', 'partition', 'commit', 'base', 'metadata', 'type', 'add', 'use']
13583571	HUDI	add hudi cli bundle scala	build hudi cli bundle succeed scala work spark scala	['pull-request-available']	3	2	Closed	2	['test', 'run', 'add', 'cause', 'support', 'use', 'time', 'base', 'commit', 'query']
13432084	HUDI	task fail serialize concurrentmodificationexception	occasionally test observe fail concurrentmodificationexception iterate map serialize spark closure serialization particular case test procedure table testcallprocedure fail code java test procedure table failed completionexception sparkexception task serializable cause sparkexception task serializable cause concurrentmodificationexception source code	['pull-request-available']	1	1	Closed	6	['test', 'metadata', 'partition', 'path', 'commit', 'cause', 'record', 'query', 'run', 'update']
13575634	HUDI	spark write hudi table contain array type create flink	flink create hudi table contain array field element default array field nullable spark sql read datum hive table hudi table field verification exception occur code java info unresolvedexception invalid datatype unresolved object tree info info info info info info info info info info info info info code	['pull-request-available']	2	1	Closed	11	['type', 'record', 'support', 'set', 'create', 'write', 'issue', 'base', 'test', 'partition']
13446364	HUDI	rfc new table api proposal query engine integration	document api	['pull-request-available']	1	3	Patch Available	13	['set', 'query', 'enable', 'config', 'read', 'write', 'add', 'test', 'path', 'run']
13480572	HUDI	fix hudi bundle require classpath	address erroneously rebase hudi api module impression api module advertise turn case actual bridge implementation require provide classpath require dependency version spark method classnotfoundexception logmanager code	['pull-request-available']	1	1	Closed	1	['metadata', 'issue', 'case', 'partition', 'base', 'path', 'datum', 'read', 'use', 'create']
13448009	HUDI	tableschemaresolver fetch parse hoodiecommitmetadata multiple time extract schema	recently discover tableschemaresolver lot throw away work initialization basic schema reading perform spark datasource screenshot pose problem large table hoodiecommitmetadata non trivial size mbs minimize throw away work tableschemaresolver try use read parse commit metadata possible	['pull-request-available']	1	1	Closed	10	['cause', 'time', 'read', 'type', 'update', 'commit', 'log', 'use', 'config', 'support']
13510673	HUDI	cache file slice mdt reader	cache log file reader cache late file slice partition level call getlatestfileslice cause new file system view instantiate time list file partition listing avoid cache file system view inside hoodiebackedtablemetadata	['pull-request-available']	1	4	Closed	9	['partition', 'log', 'metadata', 'time', 'read', 'commit', 'path', 'datum', 'issue', 'new']
13424542	HUDI	investigate integ test failure spark yamls	have issue integ test test failure spark datum source yamls want fix	['pull-request-available']	3	3	Closed	6	['test', 'metadata', 'partition', 'path', 'commit', 'cause', 'record', 'query', 'run', 'update']
13478227	HUDI	primary key datum model	hudi require user specify primary key field away requirement epic track work support use case require primary key base datum modelling	['pull-request-available']	3	15	Closed	1	['metadata', 'issue', 'case', 'partition', 'base', 'path', 'datum', 'read', 'use', 'create']
13437360	HUDI	fix bloomindex incorrectly colstats lookup record location	currently bloomindex try rely solely column stats lookup record location incorrect state complete give moment instead use basis good effort assume record file find colstats list directly search code exact code location relate	['pull-request-available']	1	1	Closed	12	['record', 'read', 'use', 'base', 'create', 'datum', 'query', 'time', 'set', 'currently']
13469038	HUDI	update doc build hudi docker demo	test argument require mvn build hudi docker demo work	['pull-request-available']	3	4	Closed	6	['test', 'metadata', 'partition', 'path', 'commit', 'cause', 'record', 'query', 'run', 'update']
13479761	HUDI	option skip delta commit	option introduce avoid consume duplicate datum delta commit compaction mor table option cause delta commit case support timeline delta commit compaction commit let scan streaming read happen time late instant seperately scan true latest merge fileslice log file contain skip	['pull-request-available']	2	1	Closed	10	['cause', 'time', 'read', 'type', 'update', 'commit', 'log', 'use', 'config', 'support']
13426030	HUDI	hudi restore cow table	guy environment aws emr hudi problem cow table wich ingest deltastremer batch style minute kafka certain time deltastremer stop work message like diagnostic user class throw exception hoodierollbackexception find commit time rollback great commit hudi property value basepath datalake metapath datalake filesystem archive parquet usually replace commit pretty sure commit timeline message tell try rollback follow step hudi cli connect datalake success savepoint create success savepoint rollback failed savepoint create success savepoint rollback failed long story short run situation like able solve know method use case work progress prod issue like question right step command solve issue like able restart deltastremer table dimension datum happy share table curiuous need helpful let talk private mail slack sharing stop run actually clustering use clustering config deltastremer true true hope help tackle becase able solve manually confident prod thank advance darvi slack hudi istvan darvas	['pull-request-available']	2	1	Closed	4	['commit', 'run', 'update', 'time', 'need', 'base', 'cause', 'partition', 'issue', 'write']
13418925	HUDI	unify hive fileinputformat implementation	currently substantial overlap hoodieparquetinputformat hoodiehfileinputformat practically identical	['pull-request-available']	1	4	Closed	12	['record', 'read', 'use', 'base', 'create', 'datum', 'query', 'time', 'set', 'currently']
13413893	HUDI	fix handle cluster update reject exception deltastreamer	commit deltastreamer clash pende clustering detlastreamer shut expect user restart need fix behavior retry clustering complete eventually deltastreamer gets go	['pull-request-available']	1	1	Closed	4	['commit', 'run', 'update', 'time', 'need', 'base', 'cause', 'partition', 'issue', 'write']
13421094	HUDI	hoodieconfig getboolean method return null instead default value	config default value return instead null	['pull-request-available']	1	1	Closed	13	['set', 'query', 'enable', 'config', 'read', 'write', 'add', 'test', 'path', 'run']
13415343	HUDI	evaluate rebase hudi default compression gzip zstd	currently have gzip default prioritize compression storage cost expense compute write compute burn bulk insert local benchmark amazon reviews dataset gzip compute read query latencies query scan large dataset likely bind gzip snappy zstd spark switch default compression algorithm snappy apache spark edit actually evaluate put core data small fast data compression instead snappy compression ratio comparable gzip bring well performance	['pull-request-available']	2	4	Open	13	['set', 'query', 'enable', 'config', 'read', 'write', 'add', 'test', 'path', 'run']
13551697	HUDI	read optimize query use rli	read optimize query mor table rli present produce correct result rli lookup ability distinguish record base table record log file reproduce issue create mor table add record table delete record identify example table delete log file run read optimize query select mytable record base table knowledge record delete run read optimize query select mytable query return record record present base file rli enable query evaluate rli return record appear inconsistent result return step spark shell script reproduce issue attach code java scala script create table rli import quickstartutil import javaconversion import savemode import datasourcereadoption import datasourcewriteoption import hoodiewriteconfig import hoodierecord val tablename val basepath amrish table morereadoptimize val datagen new datagenerator generate insert val insert val uuid partitionpath tablename true true true true select query val readopt map true true true val tripssnapshotdf spark read myrli order count delete record hard delete val dataset myrli val delete val deletedf delete uuid partitionpath tablename count driver rider uuid myrli false read optimzie query val readopt map true false true val tripssnapshotdf spark read myrli order myrli count code	['pull-request-available']	1	1	Closed	12	['record', 'read', 'use', 'base', 'create', 'datum', 'query', 'time', 'set', 'currently']
13513483	HUDI	sure predicate appropriately push hoodiefileindex lazy list	introduction lazy listing capability expose issue spark design predicate push generic fileindex implementation execution phase pose follow issue hoodiefileindex list table listfile method invoke listing actually perform actual execution filesourcescanexac node list perform actual execution table statistic initialize bogus value byte cost base optimizations cbo take incorrect decision base	['pull-request-available']	1	1	Closed	1	['metadata', 'issue', 'case', 'partition', 'base', 'path', 'datum', 'read', 'use', 'create']
13578657	HUDI	fix usage new configuration production code	new configuration non test code place	['pull-request-available']	3	4	Closed	3	['new', 'record', 'read', 'partition', 'commit', 'base', 'metadata', 'type', 'add', 'use']
13440234	HUDI	fallback hadoopfsrelation non sophisticated cow use case	figure good way forward fallback hadoopfsrelation sure spark optimization applicable hudi cow read optimize table	['pull-request-available']	1	1	Closed	1	['metadata', 'issue', 'case', 'partition', 'base', 'path', 'datum', 'read', 'use', 'create']
13439914	HUDI	investigate hudi raw parquet table discrepancy	benchmarke query raw parquet table hudi table run test hudi table query path read raw parquet table read hudi table surprisingly diverge file read raw parquet hudi	['pull-request-available']	1	3	Closed	13	['set', 'query', 'enable', 'config', 'read', 'write', 'add', 'test', 'path', 'run']
13418299	HUDI	sure compression codec configuration respect board	currently place assume gzip compression codec incorrect give configurable user actually prefer use different compression codec example apache hudi	['new-to-hudi']	3	1	Open	12	['record', 'read', 'use', 'base', 'create', 'datum', 'query', 'time', 'set', 'currently']
13418379	HUDI	savepoint rollback leave trail rollback meta file	savepoint rollback trigger restore operation successfully complete meta file timeline code java nsb wheel dec nsb wheel dec nsb wheel dec nsb wheel dec nsb wheel dec nsb wheel dec code	['sev:critical']	3	1	Closed	6	['test', 'metadata', 'partition', 'path', 'commit', 'cause', 'record', 'query', 'run', 'update']
13412414	HUDI	order layout optimization strategy fail data skipping enable	testing ordering test environment discover follow issue query fail table enable cluster order layout data skipping enable unable read success file automatically create spark translation original query predicate index table predicate translate incorrectly like etc join merging index commit incorrectly check null column instead nth column pick result merge	['pull-request-available']	1	3	Closed	7	['commit', 'metadata', 'cause', 'issue', 'enable', 'query', 'test', 'update', 'set', 'read']
13477121	HUDI	enhance retrie fail write write conflict multi writer scenario	lets writer hudi fail succeed user restart min let overlap writer write succeed write conflict pipeline fail user need restart pipeline retry ingest batch ask add retrie hudi failure anyways case user restart pipeline case	['pull-request-available']	1	4	Closed	5	['write', 'config', 'partition', 'support', 'add', 'path', 'need', 'use', 'record', 'metadata']
13591874	HUDI	rid disable vectorize reader sql config spark reader implementation	modify sql conf effect necessary	['pull-request-available']	1	1	Closed	13	['set', 'query', 'enable', 'config', 'read', 'write', 'add', 'test', 'path', 'run']
13582449	HUDI	ensure property copy modify schema	property copy modify schema remove field	['pull-request-available']	3	1	Closed	6	['test', 'metadata', 'partition', 'path', 'commit', 'cause', 'record', 'query', 'run', 'update']
13524902	HUDI	add support kafka offset source	add support kafka offset avrokafkasource jsonkafkasource	['pull-request-available']	3	4	Open	2	['test', 'run', 'add', 'cause', 'support', 'use', 'time', 'base', 'commit', 'query']
13420926	HUDI	extract common hudi table file index implementation	extract common hudi table file index implementation spark hoodiefileindex leverage common file indexing functionality spark hive	['pull-request-available']	1	4	Closed	6	['test', 'metadata', 'partition', 'path', 'commit', 'cause', 'record', 'query', 'run', 'update']
13430555	HUDI	clustering fail update col stat disable metadata table		['hudi-on-call', 'pull-request-available']	1	1	Closed	7	['commit', 'metadata', 'cause', 'issue', 'enable', 'query', 'test', 'update', 'set', 'read']
13357670	HUDI	corrupt avro schema extract parquet file	run hudi deltastreamer complex stream schema deeply nest level hierarchy avro schema loc version hudi write dataset snapthot recently start attempt upgrade late hovewer late hudi read provide dataset exception code java get exception parse argument get exception parse argument find recursive reference avro schema process spark type record array field type null string default null type type null string default null exist type null boolean default null stack trace incompatibleschemaexception find recursive reference avro schema process spark type record array field type null string default null type type null string default null exist type null boolean default null method code write simple test open parquet file load schema attempt convert avro fail error appear avro schema look like noformat type null type record menuentitypath field type null type array item type record pathnode namespace field type null type string string default null type type null type enum menuentitytype namespace share symbol unknown default null default null default null default null noformat convert noformat null type record field type null type array item type record array field type null string default null type type null string default null exist type null boolean default null default null exist type null boolean default null noformat couple question similar issue good way forward edit convert dataset pure parquet presto intermediary create table select result fail similar error different place noformat find recursive reference avro schema process spark type record bag field type null type record field look like parquet writer replace array synthetic record give spark reader work open parquet file directly noformat dataset dataset noformat	['core-flow-ds', 'pull-request-available', 'sev:critical']	1	1	Closed	11	['type', 'record', 'support', 'set', 'create', 'write', 'issue', 'base', 'test', 'partition']
13583560	HUDI	remove support spark	hudi bridge release remove hudi support old spark version include spark dev work include remove build profile github action long relevant clean unused code spark integration upgrade default dependency version consistent spark updates	['pull-request-available']	1	4	Closed	0	['type', 'support', 'base', 'record', 'time', 'read', 'enable', 'new', 'use', 'log']
13410160	HUDI	umbrella new trino connector hudi	jira track task relate build new hudi connector trino	['hudi-umbrellas']	2	15	In Progress	3	['new', 'record', 'read', 'partition', 'commit', 'base', 'metadata', 'type', 'add', 'use']
13398387	HUDI	fix spark quick start guide minor issue	fix spark quick start guide minor issue	['pull-request-available']	3	4	Resolved	1	['metadata', 'issue', 'case', 'partition', 'base', 'path', 'datum', 'read', 'use', 'create']
13404801	HUDI	umbrella seamless meta sync	hudi hive sync common use case enable query hudi table query engine support hive connector presto trino currently hudi support sync hive asynchronously synchronously deltastreamer goal umbrella jira imrpove current sync mechanism support additionally need improve documentation different config sync mode	['hive', 'hive3', 'hudi-umbrellas']	3	15	Open	5	['write', 'config', 'partition', 'support', 'add', 'path', 'need', 'use', 'record', 'metadata']
13542850	HUDI	java compile time support	certify hudi java runtime support	['pull-request-available']	3	1	Closed	0	['type', 'support', 'base', 'record', 'time', 'read', 'enable', 'new', 'use', 'log']
13577757	HUDI	mdt partition type relate logic hoodiebackedtablemetadatawriter metadatapartitiontype		['hudi-1.0.0-beta2']	2	3	Open	11	['type', 'record', 'support', 'set', 'create', 'write', 'issue', 'base', 'test', 'partition']
13303109	HUDI	parquet schema conflict optional binary group	deal struct type like code json type struct field categoryresults type type array elementtype type struct field categoryid type string nullable true metadata containsnull true nullable true metadata code second ingest batch throw exception code error executor task launch worker task commit basecommitactionexecutor error upserting buckettype update partition hoodieexception hoodieexception executionexception hoodieexception operation fail cause hoodieexception executionexception hoodieexception operation fail cause executionexception hoodieexception operation fail cause hoodieexception operation fail cause classcastexception optional binary categoryid group code parquet schema fail struct code optional group categoryresults list repeat group array optional binary categoryid code leaf record multiple field issue go assume issue relate parquet avro follow array struct definition handle fine withtout exception code optional group productresult list repeat group array optional binary productid optional boolean productimage optional binary productshortdescription code	['hudi-on-call', 'sev:critical', 'user-support-issues']	2	1	Closed	11	['type', 'record', 'support', 'set', 'create', 'write', 'issue', 'base', 'test', 'partition']
13434455	HUDI	clean column stats index introduce spatial curves clustering	bespoke implementation introduce spatial curves require anymore	['pull-request-available']	1	1	Closed	6	['test', 'metadata', 'partition', 'path', 'commit', 'cause', 'record', 'query', 'run', 'update']
13353100	HUDI	hudi spark datasource fail noclassdeffounderror org apache hudi client common hoodieenginecontext	try quick start guide late master code java insert scala uuid partitionpath tablename noclassdeffounderror org apache hudi client common hoodieenginecontext elide cause classnotfoundexception hoodieenginecontext code command spark submit code java spark shell spark kryoserializer code step repro follow quick start guide command spark submit	['pull-request-available', 'release-blocker']	3	1	Resolved	10	['cause', 'time', 'read', 'type', 'update', 'commit', 'log', 'use', 'config', 'support']
13444277	HUDI	evaluate spark sql performance	internal benchmark detect regression spark sql relative spark datasource integration need investigate subsequently address	['pull-request-available']	1	3	Closed	4	['commit', 'run', 'update', 'time', 'need', 'base', 'cause', 'partition', 'issue', 'write']
13269361	HUDI	clean retention base time period account high deviation ingestion run	cleaner commit base number commit retain ingestion time vary run factor provide bind maximum running time query provide consistent retention period well use retention config base time	['core-flow-ds', 'new-to-hudi', 'pull-request-available', 'sev:high']	3	3	Closed	4	['commit', 'run', 'update', 'time', 'need', 'base', 'cause', 'partition', 'issue', 'write']
13392455	HUDI	sql change index type fail	try set different index type fail set simple spark sql create table hudi location test bucket option type cow primarykey randomid precombinefield partition type select error sparksqldriver fail create table hudi location test bucket option type cow primarykey randomid precombinefield partition type select illegalargumentexception enum constant hoodieindex indextype simple describe scala	['release-blocker']	1	3	Resolved	11	['type', 'record', 'support', 'set', 'create', 'write', 'issue', 'base', 'test', 'partition']
13478712	HUDI	fix thread safety remotetablefilesystemview	retry mechanism add remotetablefilesystemview look like code thread safe impact regular flow retrie enable	['pull-request-available']	3	6	Closed	13	['set', 'query', 'enable', 'config', 'read', 'write', 'add', 'test', 'path', 'run']
13520008	HUDI	support record key generation partition path generation row writer	add support record key generation partition path generation separate record key generation partition path generation separate interface jira aim add similar support row writer path spark	['pull-request-available']	2	1	Reopened	5	['write', 'config', 'partition', 'support', 'add', 'path', 'need', 'use', 'record', 'metadata']
13403590	HUDI	fix usage different key generator metadata enable	sync metadata apache hudi metadata enable default spark datasource test fail timestamp base key gen custom key gen metadata table record getting pick code java code disabled metadata test testsparkpartitonbywithtimestampbasedkeygenerator testsparkpartitonbywithcustomkeygenerator look doc late sql data source generic ignore certain path look like	['oct18_2021', 'pull-request-available', 'sev:critical']	3	3	Resolved	8	['metadata', 'path', 'commit', 'datum', 'run', 'add', 'base', 'create', 'enable', 'test']
13521552	HUDI	add version new config add	new config miss add need add documentation	['pull-request-available']	1	4	Closed	5	['write', 'config', 'partition', 'support', 'add', 'path', 'need', 'use', 'record', 'metadata']
13442338	HUDI	provide bundle jar option test pipeline	integ test bundle slim run test actual bundle	['pull-request-available']	3	3	Closed	2	['test', 'run', 'add', 'cause', 'support', 'use', 'time', 'base', 'commit', 'query']
13596499	HUDI	push partition filter functional index	partition prune key encoding col stat query late file slice fix need apply functional index	['pull-request-available']	1	3	In Progress	5	['write', 'config', 'partition', 'support', 'add', 'path', 'need', 'use', 'record', 'metadata']
13435649	HUDI	upsert metadata table fail schema change	scenario deltastreamer continuous mode cow table single writer async cluster cleaning file partition enable metadata table table write metadata schema change add columnname new writer new schema upsert metadata table fail schema compatibility check code java warn cleanactionexecutor fail perform previous clean operation instant hoodieupsertexception fail upsert schema compatibility check cause hoodieexception fail schema compatibility check writerschema record save metadata metadata file information partition file file bloom filter filter type timestamp metadata create filter binary byte filter entry valid delete index bloom filter data file user file column column statistic column statistic value range base user datum table schema convert appropriate value range base user datum table schema convert appropriate count count null storage size uncompressed storage size range entry valid delete index column statistic datum file user table schema record save metadata metadata file information partition file file bloom filter filter type timestamp metadata create filter binary byte filter entry valid delete index bloom filter data file user file column column statistic value range base user datum table schema convert appropriate value range base user datum table schema convert appropriate count count null storage size uncompressed storage size range entry valid delete index column statistic datum file user base path ethan work script metadata code	['pull-request-available']	1	1	Closed	8	['metadata', 'path', 'commit', 'datum', 'run', 'add', 'base', 'create', 'enable', 'test']
13514350	HUDI	sure trino instantiates hive inputformat partition file list	unblock implement stop gap fall filesystemview base listing appropriate long term solution need sure fix properly avoid instantiate inputformats trino properly use fileindex	['pull-request-available']	2	1	Closed	3	['new', 'record', 'read', 'partition', 'commit', 'base', 'metadata', 'type', 'add', 'use']
13557101	HUDI	fix partial merge logic base project schema	query table multiple round partial update generate multiple log file partial merge logic fail wrong result schema handling merge logic	['pull-request-available']	1	1	Closed	12	['record', 'read', 'use', 'base', 'create', 'datum', 'query', 'time', 'set', 'currently']
13516536	HUDI	sure ctas use bulk insert	apache hudi propagate configuration properly createhooditableasselectcommand insertintohoodietablecommand result ctas essentially insert instead bulk insert	['pull-request-available']	1	1	Closed	12	['record', 'read', 'use', 'base', 'create', 'datum', 'query', 'time', 'set', 'currently']
13557524	HUDI	disable new file reader metadata table	hfile base file implement metadata table use hoodie relation	['pull-request-available']	3	4	Open	3	['new', 'record', 'read', 'partition', 'commit', 'base', 'metadata', 'type', 'add', 'use']
13562519	HUDI	ensure closableiterator propagate way filescanrdd	test ooming cause resource free new filegroup reader code inspection find close call hoodiefilegroupreaderiterator	['pull-request-available']	2	1	Closed	2	['test', 'run', 'add', 'cause', 'support', 'use', 'time', 'base', 'commit', 'query']
13573875	HUDI	fix mdt validator account additional partition mdt	chance mdt list additional partition compare base list reason load active timeline metaclient poll base list complete commit poll mdt list partition commit complete mdt serve let account validation tool	['pull-request-available']	3	1	Closed	9	['partition', 'log', 'metadata', 'time', 'read', 'commit', 'path', 'datum', 'issue', 'new']
13474421	HUDI	restore bundle profile	run mvn clean install generate hudi bundle instead hudi bundle bundle change user depend consistent naming	['pull-request-available']	1	1	Closed	4	['commit', 'run', 'update', 'time', 'need', 'base', 'cause', 'partition', 'issue', 'write']
13428434	HUDI	fix sync clustering config property	hoodie clustering config describe config property look differ key configs need unify single source file prevent mismatch work set config true enable async cluster	['pull-request-available']	2	1	Closed	13	['set', 'query', 'enable', 'config', 'read', 'write', 'add', 'test', 'path', 'run']
13481771	HUDI	fix csi support inset operator	currently column stats index support operator support optimize inset version report user	['pull-request-available']	3	1	Closed	0	['type', 'support', 'base', 'record', 'time', 'read', 'enable', 'new', 'use', 'log']
13470685	HUDI	support row writing stream dataset dataframe	structured streaming setup hudi table write stream source hoodiestreamingsink call operation type set internally call simple write work stream dataset dataframe code java analysisexception write call stream dataset dataframe code bulk insert go row write path need fix hoodiestreamingsink support bulk insert row writing	['pull-request-available', 'streaming']	3	3	Closed	5	['write', 'config', 'partition', 'support', 'add', 'path', 'need', 'use', 'record', 'metadata']
13489160	HUDI	non serializable path enginecontext metadata table initialization	issue report use glue env reproduce emr code java error occur call sparkexception job abort stage failure fail serialize task attempt retry exception serialization notserializableexception path serialization stack object serializable class path value someprefix element array index array class object size field class array type class object object class someprefix writeobject datum class parallelcollectionpartition object class parallelcollectionpartition field class resulttask partition type interface partition object class resulttask scala method code	['pull-request-available']	3	1	Closed	1	['metadata', 'issue', 'case', 'partition', 'base', 'path', 'datum', 'read', 'use', 'create']
13529097	HUDI	infer clean policy base clean config	set automatically use corresponding clean policy	['pull-request-available']	3	2	Closed	12	['record', 'read', 'use', 'base', 'create', 'datum', 'query', 'time', 'set', 'currently']
13440699	HUDI	add guide page data skip	maybe	['pull-request-available']	2	3	Closed	2	['test', 'run', 'add', 'cause', 'support', 'use', 'time', 'base', 'commit', 'query']
13479382	HUDI	partitionsforfullcleane cleanplanner filesystembasedlisting	look like file system base listing partitionsforfullcleane invoke patch land synchronous fix later fix lazy use metadata table enable	['pull-request-available']	3	1	In Progress	1	['metadata', 'issue', 'case', 'partition', 'base', 'path', 'datum', 'read', 'use', 'create']
13528049	HUDI	fix validation partition list metadata table validator	hoodiemetadatatablevalidator compare partition list mdt file system code java ignore partition create uncommitted ingestion allpartitionpathsfromfs hoodiepartitionmetadata hoodiepartitionmetadata new option instantoption string instanttime return return false list allpartitionpathsmeta basepath true string message compare partitions fail allpartitionpathsfromfs allpartitionpathsfromfs allpartitionpathsmeta allpartitionpathsmeta throw new code decide partition file system consider comparison look commit time create partition code java string instanttime return return false code following scenario validation job fire false alarm complain partition list return file system metadata table check commit create partition partition metadata write fail write data file time add new datum partition roll case partition metadata create commit time hudi rewrite partition metadata	['pull-request-available']	1	1	Closed	9	['partition', 'log', 'metadata', 'time', 'read', 'commit', 'path', 'datum', 'issue', 'new']
13334872	HUDI	add delete support test suite framework	add delete support test suite framework	['pull-request-available']	3	4	Closed	2	['test', 'run', 'add', 'cause', 'support', 'use', 'time', 'base', 'commit', 'query']
13411168	HUDI	use early instant default compaction clustering job	currently hoodiecompactor compaction hoodieclusteringjob clustering require command line argument instant time async execution improve usability job default job search early instant corresponding action execution save step search instant time user	['pull-request-available']	1	4	Closed	12	['record', 'read', 'use', 'base', 'create', 'datum', 'query', 'time', 'set', 'currently']
13420928	HUDI	include file belong complete commit bootstrappe metadata table	metadata table bootstrap filter complete commit file file base filter file ongoing commit bootstrap	['pull-request-available', 'sev:critical']	1	3	Closed	8	['metadata', 'path', 'commit', 'datum', 'run', 'add', 'base', 'create', 'enable', 'test']
13401711	HUDI	kvcomparator hfile metadata table tie hbase version shading	guarantee compatibility hfile reading writing different version hbase instance hbase version modify comparator class store hfile metadata keyvalue kvcomparator long exist create issue read hfiles create early version hudi comparator class mark deprecate cellcomparatorimpl create issue shade hbase dependencie hudi namespace refactor hoodiekvcomparator bootstrap index apply use hfile hudi need logic backward compatibility read metadata write early version hudi maybe enforce user perform upgrade step write metadata base file	['pull-request-available']	1	4	Resolved	1	['metadata', 'issue', 'case', 'partition', 'base', 'path', 'datum', 'read', 'use', 'create']
13475795	HUDI	fail create timeline server marker hoodieremoteexception		['pull-request-available']	3	1	Open	12	['record', 'read', 'use', 'base', 'create', 'datum', 'query', 'time', 'set', 'currently']
13415706	HUDI	address high small object churn bulk insert layout optimization	base finding follow need address reduce pressure improve performance remove unnecessary arraylist resizing hilbert curve mapping avoid unnecessary boxing hilbert curve mapping parquet avoid allocate compareto method invoke method write parquet columnwriterbase avoid bytestoavro avrotobyte ser loop use overwritewithlatestavropayload replace rewriteavropayload avoid allocating substring cache fetch avoid allocate large deque currently allocate default internal arraydeque	['pull-request-available']	1	3	Resolved	5	['write', 'config', 'partition', 'support', 'add', 'path', 'need', 'use', 'record', 'metadata']
13386479	HUDI	umbrella support space fill curve hudi	supoort space curve optimize cluster hudi file improve query performance	['hudi-umbrellas']	1	15	Closed	13	['set', 'query', 'enable', 'config', 'read', 'write', 'add', 'test', 'path', 'run']
13357971	HUDI	issue hive metastore disable jdbc	ref	['pull-request-available', 'sev:critical', 'user-support-issues']	3	3	Closed	1	['metadata', 'issue', 'case', 'partition', 'base', 'path', 'datum', 'read', 'use', 'create']
13532048	HUDI	avoid load tableschemaresolver need read bootstrap table	read bootstrap table unnecessary cyle spend instantiate table schema resolver setup schema evolution context	['pull-request-available']	3	3	Open	3	['new', 'record', 'read', 'partition', 'commit', 'base', 'metadata', 'type', 'add', 'use']
13420306	HUDI	break test failure	break test failure stacktace code java error hivealterhandler fail alter table error retryinghmshandler follow column type incompatible exist column respective position method source method main error hmsddlexecutor fail update table follow column type incompatible exist column respective position method source method source method warn hiveconf hiveconf exist warn hiveconf hiveconf exist hoodieexception get runtime exception hive sync method cause hoodiehivesyncexception fail update table cause follow column type incompatible exist column respective position method source method source code	['pull-request-available']	3	3	Closed	10	['cause', 'time', 'read', 'type', 'update', 'commit', 'log', 'use', 'config', 'support']
13587583	HUDI	partition query transform value incorrectly prune valid partition	timestamp keygen partition column timestamp use keygen create partition base day record timestamp parititon value partition column differ hour minute etc cause problem partition pruning lets query select table partition file structure partition interpret partition prune search space	['pull-request-available']	2	1	In Progress	6	['test', 'metadata', 'partition', 'path', 'commit', 'cause', 'record', 'query', 'run', 'update']
13582722	HUDI	ensure commit instant table version readable	ensure commit instant readable reader need migrate hoodieinstant parse logic backwards compatible manner port need write test validate contain portion hoodieinstant change method rename	['pull-request-available']	3	4	Closed	4	['commit', 'run', 'update', 'time', 'need', 'base', 'cause', 'partition', 'issue', 'write']
13436007	HUDI	mor mergeonread fitleringiterator stackoverflow error	run integration test hudi regular cadence recently see stackoverflow error mor table spark long run yaml code java info validatedatasetnode validate datum target hudi path error executor exception task stage tid stackoverflowerror repeat time job fail eventually likely root cause iterator encounter delete record hasnext skip current create function stack repeat time stack size less corresponding jvm test fail reality million delete record need find way fix experiment java option temporarily increase stack size jvm code snippet hoodiemorrdd especially line record delete skip snippet code java override def hasnext boolean val currowrecord val curkey val updatedrecordopt merge need load current row require projected schema recordtoload requiredschemafieldordinal true val mergedavrorecordopt record delete skip note occurrence merge know schema record return record delta log bear table schema record base file read project optimization use performant projectavrounsafe instead fallback projectavro val projectedavrorecord requiredavroschema recordbuild recordtoload true code	['pull-request-available']	1	1	Closed	12	['record', 'read', 'use', 'base', 'create', 'datum', 'query', 'time', 'set', 'currently']
13475287	HUDI	hive sync bundle cause class loader issue	weird classpath issue find test deltastreamer hudi utility slim bundle hudi hive sync hudi spark error write code java cause nosuchmethoderror lang apache avro apache avro generic genericrecord code spark bundle hive sync bundle issue hive sync bundle issue hive sync bundle mess classpath sure report hudi common api find cause shade avro behavior observe aw bundle make sense superset hive sync bundle	['pull-request-available']	1	1	Closed	7	['commit', 'metadata', 'cause', 'issue', 'enable', 'query', 'test', 'update', 'set', 'read']
13412299	HUDI	upgrade hbase dependency hudi	bootstrap metadata depend hbase server hfile reader writer currently hudi hbase version upgrade significant change especially change relate comparator need fully certify upgrade determine affect user reader writer different version	['pull-request-available']	1	4	Closed	5	['write', 'config', 'partition', 'support', 'add', 'path', 'need', 'use', 'record', 'metadata']
13437339	HUDI	allow offline compaction mor table spark streaming	currently way avoid compaction take lot resource run inline async mor table spark streaming delta streamer way assign resource ingestion async compaction spark streaming option introduce flag turn automatic compaction allow user run compaction separate process decouple concern allow user size cluster ingestion deal compaction separate blocking need look document good practice run offline compaction	['easyfix', 'pull-request-available']	2	4	Closed	4	['commit', 'run', 'update', 'time', 'need', 'base', 'cause', 'partition', 'issue', 'write']
13430581	HUDI	leverage column stat index hoodiefileindex	implement leverage spark hoodiefileindex purpose enable dataskipping lieu bespoke column stat index implementation	['pull-request-available']	1	4	Closed	13	['set', 'query', 'enable', 'config', 'read', 'write', 'add', 'test', 'path', 'run']
13533768	HUDI	fix multiple stream writer streaming sink	multiple stream writer order commit chance checkpoint management miss thing cause dup need fix properly	['pull-request-available']	3	1	Closed	4	['commit', 'run', 'update', 'time', 'need', 'base', 'cause', 'partition', 'issue', 'write']
13577885	HUDI	support query hint inject index query plan	docs late sql ref syntax qry select user way suggest sql use specific approach generate execution plan simply create index functional index secondary index necessarily ensure usage query planning hierarchy index use hoodiefileindex want way user provide explicitly use specific index instantance index join use plan	['hudi-1.0.0-beta2']	3	3	Open	12	['record', 'read', 'use', 'base', 'create', 'datum', 'query', 'time', 'set', 'currently']
13412674	HUDI	ensure single lock commit metadata table datum table table service	ensure single lock commit metadata table datum table table service	['pull-request-available']	1	4	Resolved	8	['metadata', 'path', 'commit', 'datum', 'run', 'add', 'base', 'create', 'enable', 'test']
13473916	HUDI	fix handle corrupt avro file properly	fix handling corupt file feedback give catch require exception stacktrace entire exception mean thing	['pull-request-available']	2	4	Closed	6	['test', 'metadata', 'partition', 'path', 'commit', 'cause', 'record', 'query', 'run', 'update']
13483927	HUDI	read metadata table fail complete commit	metadata table getting initialize commit fully complete read metadata table fail stacktrace code java error client remotedriver fail run client job hoodieexception error fetch partition path metadata table scala cause hoodiemetadataexception fail retrieve list partition metadata cause nosuchelementexception value present option info client remotedriver shut spark remote driver info server abstractconnector stop info sparkui stop spark web info yarn yarnallocator driver request total number info cluster yarnclusterschedulerbackend shut executor info cluster ask executor shut info cluster schedulerextensionservice stop schedulerextensionservice serviceoption service list start false info spark mapoutputtrackermasterendpoint mapoutputtrackermasterendpoint stop info memory memorystore memorystore clear code	['pull-request-available']	1	1	Closed	8	['metadata', 'path', 'commit', 'datum', 'run', 'add', 'base', 'create', 'enable', 'test']
13593001	HUDI	fix logrecord reader account rollback block high timestamp	logrecordreader configure maxintant time read rollback block high timestamp compare maxinstant set lead datum inconsistency let illustration crash mid way current layout base commit datum instant time start start hudi detect pende commit trigger rollback rollback instant time note rollback commit time great current ongoing delta commit rollback complete layout base file partially fail rollback command block complete layout look like base file partially fail rollback command block point time trigger snapshot read try trigger taglocation global index maxinstant set entry commits timeline logrecordreader process log block reach detect timestamp max instant time bail loop essence read scenario refer delete block lead datum consistency issue global index record move partition	['pull-request-available']	1	4	Closed	9	['partition', 'log', 'metadata', 'time', 'read', 'commit', 'path', 'datum', 'issue', 'new']
13447108	HUDI	fix incorrect partition schema pass hadoopfsrelation	currently incorrect partition schema pass hadoopfsrelation affect spark optimization partitioned table	['pull-request-available']	1	1	Closed	9	['partition', 'log', 'metadata', 'time', 'read', 'commit', 'path', 'datum', 'issue', 'new']
13593895	HUDI	use filegroup reader cluster row writer	use datasource reader api specify file read probably need implement update	['pull-request-available']	3	4	Patch Available	12	['record', 'read', 'use', 'base', 'create', 'datum', 'query', 'time', 'set', 'currently']
13519949	HUDI	file write commit delta commit fail detect valid datum file	method hoodiefilegroup detect file group commit timeline check return true code java fileslice consider commit following true commit data file log file base commit delta commit private boolean slice return false return code hoodiedefaulttimeline code java public boolean instant return code need fix	['pull-request-available']	2	1	Closed	4	['commit', 'run', 'update', 'time', 'need', 'base', 'cause', 'partition', 'issue', 'write']
13484318	HUDI	update docker demo website page explain run mac	update website reflect change fix	['pull-request-available']	3	4	Closed	4	['commit', 'run', 'update', 'time', 'need', 'base', 'cause', 'partition', 'issue', 'write']
13473375	HUDI	optimize file list path	review file list path try optimize file list path possible	['pull-request-available']	1	1	Closed	8	['metadata', 'path', 'commit', 'datum', 'run', 'add', 'base', 'create', 'enable', 'test']
13334843	HUDI	improving hudi test suite framework support proper validation long running test	improve hudi test suite framework support proper validation long running test	['pull-request-available']	3	4	Closed	2	['test', 'run', 'add', 'cause', 'support', 'use', 'time', 'base', 'commit', 'query']
13510843	HUDI	troubleshoot testmetadatacolumnstatsindexpartialprojection flakiness	test periodically fail try repro locally able fail valuecount flip flopping single file dozen run example fail run	['pull-request-available']	4	1	Open	2	['test', 'run', 'add', 'cause', 'support', 'use', 'time', 'base', 'commit', 'query']
13583712	HUDI	remove share hfile reader hoodienativeavrohfilereader	shared hfile reader hoodienativeavrohfilereader use significant memory read meta info hfile avoid keep reference shared hfile reader cache meta info	['pull-request-available']	1	4	Closed	12	['record', 'read', 'use', 'base', 'create', 'datum', 'query', 'time', 'set', 'currently']
13524396	HUDI	improve deploy script release artifact	current script inefficient artifact repeatedly upload waste time	['pull-request-available']	1	4	Closed	9	['partition', 'log', 'metadata', 'time', 'read', 'commit', 'path', 'datum', 'issue', 'new']
13478073	HUDI	remove code duplicate spark	present lot code hoodieanalysis unnecessarily duplicate resolution logic spark lead interference normal operation spark analyzer lead non trivial issue like deal spark spark sql minimize logic code localize spark hudi strictly necessary address issue alternative upstreaming spark port feature new spark version old one	['pull-request-available']	1	1	Closed	1	['metadata', 'issue', 'case', 'partition', 'base', 'path', 'datum', 'read', 'use', 'create']
13480922	HUDI	commit metadata json contain redundant information	commit metadata json write hudi timeline contain redundant field trim show set write stat write partitiontowritestat writestat double size increase serde overhead field like totalrecordsdeleted writepartitionpath fileidandrelativepath etc remove derive partitiontowritestat directly hoodiecommitmetadata class example commit metadata code java partitiontowritestat fileid path prevcommit numwrites numdelete numupdatewrite numinsert totalwritebyte totalwriteerror temppath null partitionpath totallogrecord totallogfilescompacte totallogsizecompacte totalupdatedrecordscompacte totallogblock totalcorruptlogblock totalrollbackblocks filesizeinbyte mineventtime null maxeventtime null compact false extrametadata schema operationtype insert writestat fileid path prevcommit numwrites numdelete numupdatewrite numinsert totalwritebyte totalwriteerrors temppath null partitionpath totallogrecord totallogfilescompacte totallogsizecompacte totalupdatedrecordscompacte totallogblock totalcorruptlogblock totalrollbackblocks filesizeinbyte mineventtime null maxeventtime null totalrecordsdelete totallogfilessize totalscantime totalcreatetime totalupserttime minandmaxeventtime val null present false writepartitionpath fileidandrelativepath totallogrecordscompacte totallogfilescompacte totalcompactedrecordsupdate code	['pull-request-available']	2	1	Closed	8	['metadata', 'path', 'commit', 'datum', 'run', 'add', 'base', 'create', 'enable', 'test']
13348541	HUDI	support incrementally read clustering commit spark datasource deltastreamer	read instant replace commit cluster	['pull-request-available']	1	3	Resolved	0	['type', 'support', 'base', 'record', 'time', 'read', 'enable', 'new', 'use', 'log']
13438055	HUDI	add separate config control multi modal index usage write indexing	set config mdt multi modal indexing control write update metadata table partition query engine use multi modal indexing datum skipping indexing tagging write pipeline use mdt index	['pull-request-available']	1	3	Closed	5	['write', 'config', 'partition', 'support', 'add', 'path', 'need', 'use', 'record', 'metadata']
13575548	HUDI	datasourcewriteoption work	datasourcewriteoption set write fail say table miss	['pull-request-available', 'starter']	2	1	Closed	13	['set', 'query', 'enable', 'config', 'read', 'write', 'add', 'test', 'path', 'run']
13595148	HUDI	avoid filesystem view use commit metadata partition file slice pair functional index update	logic apache hudi hudi client hudi client common src main java org apache hudi metadata problematic cow end recompute index file touch commit fix solely rely commit metadata	['pull-request-available']	1	3	Closed	4	['commit', 'run', 'update', 'time', 'need', 'base', 'cause', 'partition', 'issue', 'write']
13545430	HUDI	new file format work memory index	indextype file index need file glob path	['pull-request-available']	3	4	In Progress	3	['new', 'record', 'read', 'partition', 'commit', 'base', 'metadata', 'type', 'add', 'use']
13523394	HUDI	fix partitioner avoid assume parallelism present	currently partitioner impls assume go parallelism level issue previously following reason rdd inherent parallelism level define partition operate dataset sparkplan necessarily case som sparkplans report output partitioning additionally default parallelism level set config mean prefer actual incoming dataset recently remove default parallelism value configs need fix partitioner sure assume parallelism go present	['pull-request-available']	1	1	Open	5	['write', 'config', 'partition', 'support', 'add', 'path', 'need', 'use', 'record', 'metadata']
13526627	HUDI	table service client override timeline service write config regular write client	late master table service client basehoodietableserviceclient instantiate timeline server instance regular write client cause table service client start new embed timeline server overwrite write config pass constructor write config point newly start timeline server regular write client sparkrddwriteclient directly pass writeconfig instance regular write client write config affect cause regular write client use newly start embed timeline server instead timeline server instance pass constructor instantiate regular write client mean deltastreamer long live timeline server go issue code java basehoodietableserviceclient protect context hoodiewriteconfig clientconfig clientconfig basehoodieclient protect context hoodiewriteconfig clientconfig option timelineserver startembeddedserverview private synchronize void startembeddedserverview run embedded timeline server try timelineserver config catch ioexception start timeline service proceed embed server disabled server run restart service timeline server disabled start timeline service public static synchronize option createembeddedtimelineservice hoodieenginecontext context hoodiewriteconfig config throw ioexception config config return return config return public static void timelineserver hoodiewriteconfig config allow executor find newly instantiated timeline service code sparkrddwriteclient code java public context hoodiewriteconfig writeconfig option timelineservice writeconfig timelineservice new writeconfig code	['pull-request-available']	1	1	Closed	5	['write', 'config', 'partition', 'support', 'add', 'path', 'need', 'use', 'record', 'metadata']
13559593	HUDI	support query table write partitionby sync non partitioned	add support sync table non partitioned table able query spark performance benefit partition table ticket extend functionality end end user execute logical partitioning sync non partitioned table catalog able query efficiently	['hudi-1.0.0-beta2', 'pull-request-available']	3	3	Closed	5	['write', 'config', 'partition', 'support', 'add', 'path', 'need', 'use', 'record', 'metadata']
13482923	HUDI	fix flaky		['pull-request-available']	2	4	Closed	6	['test', 'metadata', 'partition', 'path', 'commit', 'cause', 'record', 'query', 'run', 'update']
13561462	HUDI	delete newhoodieparquetfileformat reference	hoodiefilegroupreaderbasedparquetfileformat feature parity newhoodieparquetfileformat new work newhoodieparquetfileformat	['pull-request-available']	3	4	Closed	3	['new', 'record', 'read', 'partition', 'commit', 'base', 'metadata', 'type', 'add', 'use']
13509313	HUDI	fix bulk insert columnsortpartitioners	currently custom bulk insert columnsortpartitioner impls incorrectly return true arepartitionrecordssorted method record necessarily sort partition path column require method case partitioner datum sort list column start partition one lead parquet writer close prematurely write file create lot small file	['pull-request-available']	2	1	Closed	1	['metadata', 'issue', 'case', 'partition', 'base', 'path', 'datum', 'read', 'use', 'create']
13561581	HUDI	enable completion time file group reader	query type enable completion time semantic safely snapshot mor cow incremental mor cow timetravel mor cow cdc mor cow bootstrap similar file group reader read datum completion time get list file file group reader log file ordering tackle separately	['pull-request-available']	1	3	Closed	0	['type', 'support', 'base', 'record', 'time', 'read', 'enable', 'new', 'use', 'log']
13380698	HUDI	cluster fail generate unfinished replacecommit timeline	cluster fail generate unfinished replacecommit restart job generate delta commit commit contain cluster group file task fail allow update cluster file group pende clustering operation go support update need ensure unfinished replacecommit file delete perform cluster generate delta commit	['pull-request-available']	1	3	Closed	4	['commit', 'run', 'update', 'time', 'need', 'base', 'cause', 'partition', 'issue', 'write']
13412984	HUDI	address issue order layout optimization	extensive testing follow issue discover plan addre upcoming data skip seq incorrectly handle case column sorted present query simply ignore fact abandon prune exception file prune seq affect overall query bad case fallback scan merging seq prefer record old index table prefer new cluster column change index simply overwrite index currently actually opposite skip update index case old new table diverge schemas incorrect type conversion decimal convert double additionally plan beef current index implementation test suite make sure critical flow indexing appropriate coverage actually advanced analysis prune search space require substantial sophistication analysis conduct current focus	['pull-request-available']	1	3	Closed	1	['metadata', 'issue', 'case', 'partition', 'base', 'path', 'datum', 'read', 'use', 'create']
13558469	HUDI	improve script	remove unnecessary bundle validation task rebalance azure task	['pull-request-available']	3	4	Closed	6	['test', 'metadata', 'partition', 'path', 'commit', 'cause', 'record', 'query', 'run', 'update']
13433731	HUDI	attempt fail cleaning mdt fail	try apply mdt crash pipeline restart clean ahead retry pende clean trigger rollback like compaction clustering fail mdt check complete operation avoid call sparkhoodiemetadatatablewriter code java new commit apply metadata time code path refer attempt commit got commit metadata table fail datatable lets compaction attempt succeed metadata table fail commit datatable retry datum table rollback pende compaction apply metadata table change upsert metadata table new delta commit create rollback complete compaction retry eventually hit code block respective commit complete commit manually remove complete instant proceed reason enable withallowmultiwriteonsameinstant metadata table hoodieinstant alreadycompletedinstant alreadycompletedinstant list status code code snippet condition fix check instant timeline complete block complete instant delete	['pull-request-available']	1	1	Closed	8	['metadata', 'path', 'commit', 'datum', 'run', 'add', 'base', 'create', 'enable', 'test']
13568147	HUDI	align mdt clean config data table	metadata table retain history datum table follow similar policy datum table set retention metadata table	['pull-request-available']	3	3	Closed	8	['metadata', 'path', 'commit', 'datum', 'run', 'add', 'base', 'create', 'enable', 'test']
13438669	HUDI	evaluate column stats performance	update identify bottleneck avro regression generate builder class rely load correspond model class reflection able bring similar setting runtime read column stats index contain record follow comment update previously evaluate data skipping runtime emr set measure reading column stats index record take record give total size log file involve like performance bottleneck investigate release	['pull-request-available']	1	1	Closed	12	['record', 'read', 'use', 'base', 'create', 'datum', 'query', 'time', 'set', 'currently']
13532356	HUDI	auto capitalize config value	auto capitalize config value soon input hudi minimize have deal capitalization internally block config value capitalize	['pull-request-available']	4	4	In Progress	13	['set', 'query', 'enable', 'config', 'read', 'write', 'add', 'test', 'path', 'run']
13274542	HUDI	use columnindex parquet speed scan		['help-requested']	3	4	Closed	12	['record', 'read', 'use', 'base', 'create', 'datum', 'query', 'time', 'set', 'currently']
13473389	HUDI	improve metadata table base file list presto hive connector	improve latency improve metadata table base file list metadata table enable hive connector presto	['pull-request-available']	1	4	Closed	8	['metadata', 'path', 'commit', 'datum', 'run', 'add', 'base', 'create', 'enable', 'test']
13511201	HUDI	fix flaky test testcleanerinsertandcleanbycommit	test clean policy policy figure early commit retain base config number retain commit file group version early commit retain keep clean commit version different file group current validation logic statically pick commit early commit retain hudi timeline file group match clean policy	['pull-request-available']	1	4	Closed	4	['commit', 'run', 'update', 'time', 'need', 'base', 'cause', 'partition', 'issue', 'write']
13399275	HUDI	metadata test lean consistent	metadata test lean consistent hoodietesttable	['pull-request-available']	3	3	Resolved	6	['test', 'metadata', 'partition', 'path', 'commit', 'cause', 'record', 'query', 'run', 'update']
13505322	HUDI	use proper parallelism engine context apis	global search api similar one parallelism lot occurrence number item parallelism affect performance parallelism base num core available cluster set user parallelism config	['pull-request-available']	2	4	Patch Available	12	['record', 'read', 'use', 'base', 'create', 'datum', 'query', 'time', 'set', 'currently']
13320088	HUDI	implement marker file timeline server	argue consolidated metadata remove need delete partial file write spark task failure stage retrie leave extra file inside table user pay month need marker mechanism able delete partial file explore improve current marker file mechanism create marker file data file write delegate createmarker driver timeline server create marker metadata single file handle flush durability guarantee tempt think spark listener mechanism help deal failed task guarantee writer job die delete partial file improve thing provide guarantee	['pull-request-available']	1	4	Resolved	5	['write', 'config', 'partition', 'support', 'add', 'path', 'need', 'use', 'record', 'metadata']
13474802	HUDI	diff tool compare metadata snapshot give time range	tool diff snapshot table partition level info new file id got create delete update track change capture write stat	['pull-request-available']	1	3	Closed	9	['partition', 'log', 'metadata', 'time', 'read', 'commit', 'path', 'datum', 'issue', 'new']
13438013	HUDI	request rollback plan stay timeline forever	corrupted parse run getpendingrollbackinfos go skip corrupted request rollback instant rollback instant go stay timeline forever prevent metadata table archival	['pull-request-available']	1	1	Closed	8	['metadata', 'path', 'commit', 'datum', 'run', 'add', 'base', 'create', 'enable', 'test']
13411424	HUDI	avoid duplicate streaming read mor table	imagine commit timeline noformat commit delta datum set read second read range noformat instant successful non compaction delta commit instant successful compaction instant inc read consume instant second read consume instant instant second read consume commit file instant consume duplicate reading happen condition trigger compaction instant schedule complete consume range	['release-0.14.0-blocker']	2	4	Closed	3	['new', 'record', 'read', 'partition', 'commit', 'base', 'metadata', 'type', 'add', 'use']
13591080	HUDI	rename hoodiefilegroupreader fileslice reader	read file slice need hoodie hudi concept later create reader wrap file slice reader cdc reader	['pull-request-available']	3	4	Closed	12	['record', 'read', 'use', 'base', 'create', 'datum', 'query', 'time', 'set', 'currently']
13435481	HUDI	revisit hudi utility bundle build wrt spark version	build hudi utility bundle spark profile affect bundle jar cause incompatibility hudi utility bundle spark version hudi utility bundle build spark version go ingestion error example run deltastreamer spark ingestion job throw classnotfoundexception code java ethan work lib bin bin spark submit memory memory executor core kryoserializer hive true true ethan work datum hudi spark log spark ethan work repo hudi benchmark target hudi hoodiedeltastreamer ethan work lib hudi utility ethan work script hbase upgrade testing class benchmarkdatasource order field base path ethan work script hbase upgrade testing table type insert code code java exception thread main classnotfoundexception method code late master run deltastreamer spark ingestion job throw different exception different spark profile code java classnotfoundexception code code java runtimeexception hoodieexception hoodieexception executionexception noclassdeffounderror org apache parquet schema code	['pull-request-available']	1	3	Closed	8	['metadata', 'path', 'commit', 'datum', 'run', 'add', 'base', 'create', 'enable', 'test']
13397868	HUDI	fix tab spark quick start page esply spark sql	fix tab spark quick start page esply spark sql	['pull-request-available']	3	4	Resolved	6	['test', 'metadata', 'partition', 'path', 'commit', 'cause', 'record', 'query', 'run', 'update']
13524122	HUDI	mor table delete block readable compactable	delete block mor log block hudi version read fail kryo serialization deser similar sense compaction work set user impact mor table uncompacted file group delete block delete block possible follow scenario delete operation update partition path true chance result delete block root cause hoodiekey kryoserializable guess miss register code java false warn objectstore fail database return nosuchobjectexception warn kryo unable load class kryo classloader retry current error abstracthoodielogrecordreader get exception read log file kryoexception unable find class serialization trace orderingval deleterecord cause classnotfoundexception method cause classnotfoundexception error executor exception task stage tid hoodieexception exception read log file cause kryoexception unable find class serialization trace orderingval deleterecord cause classnotfoundexception method cause classnotfoundexception warn tasksetmanager lose task stage tid localhost executor driver hoodieexception exception read log file cause kryoexception unable find class serialization trace orderingval deleterecord cause classnotfoundexception method cause classnotfoundexception error tasksetmanager task stage fail time abort job sparkexception job abort stage failure task stage fail time recent failure lose task stage tid localhost executor driver hoodieexception exception read log file cause kryoexception unable find class serialization trace orderingval deleterecord cause classnotfoundexception method cause classnotfoundexception driver stacktrace scala elide cause hoodieexception exception read log file cause kryoexception unable find class serialization trace orderingval deleterecord cause classnotfoundexception method cause classnotfoundexception code run book reproduce	['pull-request-available']	1	1	Closed	10	['cause', 'time', 'read', 'type', 'update', 'commit', 'log', 'use', 'config', 'support']
13417265	HUDI	enable metadata file list presto directory lister	let land number show query stabilize metadata	['pull-request-available']	1	3	Closed	8	['metadata', 'path', 'commit', 'datum', 'run', 'add', 'base', 'create', 'enable', 'test']
13526593	HUDI	update release note hoodiemetadatafilesystemview regression	relevant bug fix	['pull-request-available']	1	1	Closed	4	['commit', 'run', 'update', 'time', 'need', 'base', 'cause', 'partition', 'issue', 'write']
13591530	HUDI	fix colstat collection record type spark	record type spark introduce nested field map byte type field handle properly build colstat metadata	['pull-request-available']	1	3	Closed	11	['type', 'record', 'support', 'set', 'create', 'write', 'issue', 'base', 'test', 'partition']
13521900	HUDI	enable schema reconciliation default	turn schema reconciliation allow wide superset schema select write schema	['pull-request-available']	1	3	Patch Available	13	['set', 'query', 'enable', 'config', 'read', 'write', 'add', 'test', 'path', 'run']
13522546	HUDI	deduceshuffleparallelism return happen	test code java sortmode bulkinsertsortmode val sortmodename bulk insert bulkinsertsortmode sortmodename withtempdir basepath sortmodename def file sortmodename string unit val tablename generatetablename parallelism mean global sort record end different spark partition file create set parallelism spark partition contain hudi partition val parallelism table tablename int string price double string hudi tblpropertie primarykey precombinefield type cow parallelism sortmodename partition location true non strict tablename value distinct code fail code java requirement fail number partition positive illegalargumentexception requirement fail number partition positive scala code image	['pull-request-available']	1	1	Closed	6	['test', 'metadata', 'partition', 'path', 'commit', 'cause', 'record', 'query', 'run', 'update']
13595146	HUDI	avoid glob path use log record reader build functonal index	buil functional index spark spark sql function apply dataset load glob path inefficiency glob path list use usual hoodieunmergedlogrecordreader load dataset hoodierecord fetch explicit col value interest rquire functional index attache file create row directly rowfactory create dataset apply functional index	['pull-request-available']	1	3	Closed	12	['record', 'read', 'use', 'base', 'create', 'datum', 'query', 'time', 'set', 'currently']
13524734	HUDI	use single connection push gateway	addition metric instance table end create pushgateway table connect hostname port lead issue	['pull-request-available']	3	1	Open	12	['record', 'read', 'use', 'base', 'create', 'datum', 'query', 'time', 'set', 'currently']
13479511	HUDI	add compliance check action	investigate action add job run test job matrix check hudi repo template description sure hudi repo pr jira title hudi xxxx minor checklist clean committer guide protect master branch squash merge	['pull-request-available']	3	4	Closed	2	['test', 'run', 'add', 'cause', 'support', 'use', 'time', 'base', 'commit', 'query']
13514762	HUDI	spark sql guide say precombine field require mor require	remove line say precombine field require mor	['pull-request-available']	3	4	Closed	6	['test', 'metadata', 'partition', 'path', 'commit', 'cause', 'record', 'query', 'run', 'update']
13318766	HUDI	mor append slow file list executor find log file	place list executor source source	['perf']	3	3	Open	9	['partition', 'log', 'metadata', 'time', 'read', 'commit', 'path', 'datum', 'issue', 'new']
13481792	HUDI	bootstrap table deltastreamer read spark	code java scala val hoodieexception file find read user provide path scala elide code	['pull-request-available']	1	1	Closed	3	['new', 'record', 'read', 'partition', 'commit', 'base', 'metadata', 'type', 'add', 'use']
13403349	HUDI	tune hoodierotablepathfilter cache aim reduce unnecessary list request	cache hoodietablefilesystemview basedir level hoodietablemetaclient	['pull-request-available']	1	3	Resolved	6	['test', 'metadata', 'partition', 'path', 'commit', 'cause', 'record', 'query', 'run', 'update']
13557253	HUDI	hoodiebasefilegrouprecordbuffer check option	option exception throw call happen reader enable test testbasefileandlogfileupdatematchesdeleteblock code java cause nosuchelementexception value present option code	['pull-request-available']	3	1	Closed	7	['commit', 'metadata', 'cause', 'issue', 'enable', 'query', 'test', 'update', 'set', 'read']
13328894	HUDI	umbrella metadata table file listing table metadata	umbrella ticket track overall implementation	['hudi-umbrellas', 'pull-request-available']	1	15	Closed	8	['metadata', 'path', 'commit', 'datum', 'run', 'add', 'base', 'create', 'enable', 'test']
13454521	HUDI	test flaky		['pull-request-available']	3	1	Closed	6	['test', 'metadata', 'partition', 'path', 'commit', 'cause', 'record', 'query', 'run', 'update']
13581212	HUDI	resolve conflict mixed hdf local path flink test	bump depdency mitigate vulnerability	['pull-request-available']	3	1	Open	6	['test', 'metadata', 'partition', 'path', 'commit', 'cause', 'record', 'query', 'run', 'update']
13480198	HUDI	find partition column query bootstrappe table spark	bootstrap table code java val srcpath testing partition parquet table date val basepath testing bootstrap hudi val bootstrapdf datasourcewriteoptions key partition srcpath overwrite code code java scala partition count group partition analysisexception resolve partition give input column line pos aggregate partition partition subqueryalias view relation elide code	['pull-request-available']	3	1	Closed	6	['test', 'metadata', 'partition', 'path', 'commit', 'cause', 'record', 'query', 'run', 'update']
13521845	HUDI	hive sync fail noclassdeffounderror	url jdbc hive hive path hive warehouse default value extractor slashencodeddaypartitionvalueextractor throw follow exception code java info main close connection metastore current connection exception thread main noclassdeffounderror com esotericsoftware kryo kryoserializable method method cause classnotfoundexception kryoserializable code work version	['pull-request-available']	1	1	Closed	10	['cause', 'time', 'read', 'type', 'update', 'commit', 'log', 'use', 'config', 'support']
13410662	HUDI	rollback partially fail commit new partition fail metadata table	commit rolledback commit new partition present table file pertain new partition rollback plan file end dangle clean commit file file file file file partial fail write trigger rollback generate rollback plan fetch partition tablefilesystemview hit metadata table enable return complete filter file match case miss rollback file add	['pull-request-available']	1	3	Resolved	3	['new', 'record', 'read', 'partition', 'commit', 'base', 'metadata', 'type', 'add', 'use']
13421844	HUDI	unify hive mor inputformat implementation parquet hfile	essentially hive different mor implementation differ file format actual base file write today case currently hive mor inputformat implementation inherit respective cow file format counterpart hoodieparquetinputformat hoodiehfileinputformat instead unify mor impls common base class separate file format specific impls extend parquet hfile override getrecordreader method	['pull-request-available']	1	4	Closed	1	['metadata', 'issue', 'case', 'partition', 'base', 'path', 'datum', 'read', 'use', 'create']
13562047	HUDI	mit fail attempt change partition	follow code java drop table exists table exists create table parquetpartitioned version timestamp birthdate create table int version int string birthdate timestamp string hudi partitioned tblproperties primarykey type cow insert version timestamp birthdate date select set true merge select match update set code exception code java fail upsert commit time hoodieupsertexception fail upsert commit time sparkexception job abort stage failure task stage fail time recent failure lost task stage tid jonathan mbp executor driver nullpointerexception driver stacktrace scala morecause nullpointerexception code	['pull-request-available']	1	1	Closed	4	['commit', 'run', 'update', 'time', 'need', 'base', 'cause', 'partition', 'issue', 'write']
13375691	HUDI	investigate hive sync work expect quickstart environment	hive sync fail user report slack example need investigate real issue	['sev:critical']	3	1	Open	4	['commit', 'run', 'update', 'time', 'need', 'base', 'cause', 'partition', 'issue', 'write']
13510670	HUDI	fix merge performance trap	merge currently rely sparksqltypedrecord abstraction field record lookup cache key avro schema incur bear non trivial overhead lead compute waste	['performance', 'pull-request-available']	1	1	Closed	12	['record', 'read', 'use', 'base', 'create', 'datum', 'query', 'time', 'set', 'currently']
13563263	HUDI	fallback key base merging position log header	turn merge record position position header log block reader fall key base merging	['pull-request-available']	1	4	Closed	0	['type', 'support', 'base', 'record', 'time', 'read', 'enable', 'new', 'use', 'log']
13518366	HUDI	set class loader parquet datum block	set hoodiehfiledatablock set hoodieparquetdatablock cause code java runtimeexception classnotfoundexception class inlinefilesystem find scala classnotfoundexception class inlinefilesystem find code	['pull-request-available']	1	1	Closed	13	['set', 'query', 'enable', 'config', 'read', 'write', 'add', 'test', 'path', 'run']
13545617	HUDI	add downgrade step detect new delete block	table version introduce new delete block format avro serde downgrade table need perform compaction handle delete block create new format addition record index field metadata table schema downgrade need delete metadata table avoid column drop error downgrade	['pull-request-available']	3	4	Open	3	['new', 'record', 'read', 'partition', 'commit', 'base', 'metadata', 'type', 'add', 'use']
13574309	HUDI	break schema evolution add schema evolution change port spark	large review need break small prs create add necessary schema evolution spark minor version compatibility port spark reader code	['pull-request-available']	3	7	Closed	5	['write', 'config', 'partition', 'support', 'add', 'path', 'need', 'use', 'record', 'metadata']
13468374	HUDI	sure hoodiestorageconfig specify writer	currently apache hudi matter user specify explicitly rely default value config value overridden potentially revert specify user way presently enforce config write schema contain decimaltype fit range instead behavior override default config value case decimaltype expect range config specify user overridden	['pull-request-available']	1	1	Closed	5	['write', 'config', 'partition', 'support', 'add', 'path', 'need', 'use', 'record', 'metadata']
13596390	HUDI	spark read enum avro log block	spark read enum string avro log block fail	['pull-request-available']	2	1	Closed	9	['partition', 'log', 'metadata', 'time', 'read', 'commit', 'path', 'datum', 'issue', 'new']
13437912	HUDI	ensure heart beat client health check rollback threadsafe multiple writer	multiple writer check partially fail commit rollback ensure thread safe overstepping happen wrt writer roll commit	['pull-request-available']	1	1	Closed	4	['commit', 'run', 'update', 'time', 'need', 'base', 'cause', 'partition', 'issue', 'write']
13519998	HUDI	support auto record key generation spark sql	add support auto record key generation spark dataframe jira aim add support spark sql change require point need handle case mode set strict insert fail essentially base patch want ensure spark sql write support auto generation record key	['release-0.14.0-blocker']	2	1	Closed	5	['write', 'config', 'partition', 'support', 'add', 'path', 'need', 'use', 'record', 'metadata']
13584881	HUDI	partition create correctly sql multiple partition specify order	multiple partition specify order compare order field create table command partitioning storage incorrect test script notice create table insert command city state partition clause state city code java drop table exists create table bigint string rider string driver string fare double city string state string hudi option primarykey precombinefield partitioned state insert values insert values insert values insert values code create partition follow note city state value swap screenshot query filter result code java spark sql select result time take second code test master recent regression	['pull-request-available', 'spark-sql']	3	1	Closed	6	['test', 'metadata', 'partition', 'path', 'commit', 'cause', 'record', 'query', 'run', 'update']
13515862	HUDI	improve performance savepoint mdt	metadata table enable savepoint operation slow large number partition root cause partition metadata table scan unnecessary	['pull-request-available']	1	4	Closed	6	['test', 'metadata', 'partition', 'path', 'commit', 'cause', 'record', 'query', 'run', 'update']
13489022	HUDI	fix flaky testcleaner test testinsertandcleanbycommit	see flakiness testinsertandcleanbycommit test testcleaner	['pull-request-available']	1	1	Closed	6	['test', 'metadata', 'partition', 'path', 'commit', 'cause', 'record', 'query', 'run', 'update']
13477964	HUDI	avoid illegal reflective access code	java certain kind reflective access long allow check jep strong encapsulation detail example code usage objectsizecalculator code throw inaccessibleobjectexception run high avoid illegal reflective access	['jdk', 'pull-request-available', 'reflection', 'writer']	2	3	Closed	4	['commit', 'run', 'update', 'time', 'need', 'base', 'cause', 'partition', 'issue', 'write']
13595156	HUDI	fix partition stat update async comapction	case compaction set istightbound true async compction possible deltacommit complete compaction compaction complete recompute stat base compaction metadata info commit happen compaction case stat file add deltacommit async compaction progress ignore	['pull-request-available']	1	3	Closed	1	['metadata', 'issue', 'case', 'partition', 'base', 'path', 'datum', 'read', 'use', 'create']
13592385	HUDI	fix partition stat compaction cluster	consider partition file slice compaction trigger file slice partition stat update file slice key partition path old partition stat record partition path account file slice old stat final read value merge version file slice account late version compaction clustering partition stat recompute old record partition invalidate add validation test	['pull-request-available']	1	1	Closed	6	['test', 'metadata', 'partition', 'path', 'commit', 'cause', 'record', 'query', 'run', 'update']
13535294	HUDI	fix lock identity inprocesslockprovider	extend inprocesslockprovider support multiple table process have memory static final map store mapping table base path read write reentrant lock writer use correspond lock base base path close lock provider close remove lock entry close call close write client lock remove subsequent concurrent writer different lock instance table cause locking mechanism table useless following example writer write table concurrently need acquire process lock writer lock unlock close writer try lock lock unlock close writer try lock lock unlock close writer release lock close lock provider lock instance remove map writer different lock instance compare writer	['pull-request-available']	1	1	Closed	5	['write', 'config', 'partition', 'support', 'add', 'path', 'need', 'use', 'record', 'metadata']
13515120	HUDI	add support write record level index mdt	add support write record level index partition mdt	['pull-request-available']	1	4	Closed	5	['write', 'config', 'partition', 'support', 'add', 'path', 'need', 'use', 'record', 'metadata']
13479179	HUDI	fix inflight clean action prevent clean service continue multiple clean allow	hudi deltastreamer async cleaning spark job fail middle cleaning leave clean instant inflight spark job retry time resume inflight clean action false multiple clean schedule disable bug code relevant logic basehoodiewriteclient code java public hoodiecleanmetadata cleaninstanttime boolean scheduleinline boolean skiplocking throw hoodieioexception return null final timer context timercontext hoodietimeline hoodiecleanmetadata metadata null hoodietable table hadoopconf start proceed multiple clean schedule enable pende clean scheduleinline tableservicetype clean metadata cleaninstanttime skiplocke timercontext null metadata null long durationms file earliest retained instant cleanerelapsedms durationms return metadata code	['pull-request-available']	1	1	Closed	8	['metadata', 'path', 'commit', 'datum', 'run', 'add', 'base', 'create', 'enable', 'test']
13392640	HUDI	reduce run time deltastreamer bulk insert row writer test	reduce run time deltastreamer bulk insert row writer test testhoodiemultitabledeltastreamer testhoodiedatasourceinternalbatchwrite testhoodiedeltastreamer testhoodiebulkinsertdatainternalwriter	['pull-request-available']	3	6	Resolved	2	['test', 'run', 'add', 'cause', 'support', 'use', 'time', 'base', 'commit', 'query']
13357740	HUDI	fix archival max log size potentially bug archival	gist issue udit take deep look happen archival code path hoodietimelinearchivelog need write log file commit record similar log file write mor table code notice couple issue default maximum log block size define apache hudi blob master hudi client hudi client common src main java org apache hudi config utilize class mor log block write case result real control block size end writing potentially overflow bytearrayoutputstream maximum size integer happen scenario integer overflow follow code path inside bytearrayoutputstream need use maximum block size concept addition bug code apache hudi blob master hudi client hudi client common src main java org apache hudi table flush record file batch size default clear list go accumulate record logically wrong duplication apart fact increase log file block size write reference	['core-flow-ds', 'sev:high', 'user-support-issues']	3	1	Open	9	['partition', 'log', 'metadata', 'time', 'read', 'commit', 'path', 'datum', 'issue', 'new']
13422027	HUDI	optimize record payload handling	gap need fill new record merge api extend merge api support merge operation insert update delete include customize getinsertvalue option old schema oldschema option new schema newschema typedproperties prop add merge mode allow differentiation dedup logic add new argument merge mode pre combine update merge api customized dedup merge log record instead operationmodeawareness simplify compatibility hoodierecord conversion hoodierecordcompatibilityinterface provide adaption representation type avro row etc guarantee type end end avro row spark rowdata flink avro log block need conversion avro row spark revisit hoodierecord design affect row writing hoodierecord merely wrap engine specific datum structure contain java object store record key location etc end end row writing use engine specific type internalrow instead hoodierecord append key location etc row field well leverage spark optimization dataframe internalrow bug fix hoodiesparkparquetreader append partition path value nice have critical path merge logic engine agnostic different engine need implement merge logic base engine specific datum structure spark internalrow flink rowdata etc different hoodierecordmerger implementation class provide getfield api hoodierecord allow engine agnostic merge logic implement mdt payload new merge api necessary use parquet base log file format mdt existing engine specific reader use hoodierecord implement new file group reader writer need fix exist reader old plan currently hudi biased assumption particular payload representation avro long term like steer away record payload completely opaque record payload representation engine specific avoid unnecessary serde loop engine specific avro engine specific binary proposal phase revisit record handling shirt week goal avoid tight coupling particular record representation read path currently avro enable revisit recordpayload api deprecate getinsertvalue combineandgetupdatevalue api replace new opaque api return avro payload rebase recordpayload hierarchy engine specific common engine specific base abstract common functionality spark flink java feature specific semantic implement engine introduce new api access key record partition convert record avro bwc revisit recordpayload handling writehandle api accept opaque recordpayload avro conversion opaque record merging necessary pass filewriter filewriters accept recordpayload interface engine specific handle internal record representation recordreader api provide opaque recordpayload avro conversion	['hudi-umbrellas', 'pull-request-available']	2	15	In Progress	3	['new', 'record', 'read', 'partition', 'commit', 'base', 'metadata', 'type', 'add', 'use']
13441639	HUDI	fix upgrade step wrt precombine field	relate detail bug explicitly set precombine field hudi fall back default value go read mor table project require column add precombine field original table basic read fail log file base file mor upgrade step need update precombine field user set precombine field remove user set field update	['pull-request-available']	1	1	Closed	13	['set', 'query', 'enable', 'config', 'read', 'write', 'add', 'test', 'path', 'run']
13436063	HUDI	add metric async indexer	add metric async metadata indexer time base file initialization time catch etc	['pull-request-available']	3	3	Closed	2	['test', 'run', 'add', 'cause', 'support', 'use', 'time', 'base', 'commit', 'query']
13407322	HUDI	ability clean dangle data file hudi cli	scenario commit archived data file clean cleaning frequency less tha archival	['sev:normal', 'user-support-issues']	2	3	Open	4	['commit', 'run', 'update', 'time', 'need', 'base', 'cause', 'partition', 'issue', 'write']
13554327	HUDI	hoodieavroparquetreader set config wrong prevent schema evolution non row writer	tryoverridedefaultconfig set wrong config object inside reader different config object set config like code java parquetreader reader new false false code set correct object believe	['pull-request-available']	2	1	Closed	13	['set', 'query', 'enable', 'config', 'read', 'write', 'add', 'test', 'path', 'run']
13552984	HUDI	fix integration test failure	code java error failure error find output expect number time expect error command hoodie hudi spark datasource hudi spark sync path url jdbc type table multi partition key expect succeed exit expect error command hoodie hudi spark datasource hudi spark sync path url jdbc type table multi partition key source path streaming source checkpointe path streaming ckpt expect succeed exit expect error command hoodie hudi spark datasource hudi spark sync path url jdbc type table expect succeed exit expect info error test run failure error skip code	['pull-request-available']	1	6	Closed	8	['metadata', 'path', 'commit', 'datum', 'run', 'add', 'base', 'create', 'enable', 'test']
13436292	HUDI	hudi raise exception provide	issue parse ddb config	['pull-request-available']	3	1	Closed	1	['metadata', 'issue', 'case', 'partition', 'base', 'path', 'datum', 'read', 'use', 'create']
13425062	HUDI	unable merge hoodiemetadatapayload illegalargumentexception combine	run integration test mvn test verify test fail retrieve list partition metadata table stacktrace code java cause hoodieexception error fetch partition path metadata table method method cause hoodiemetadataexception fail retrieve list partition metadata cause hoodieexception exception read log file cause illegalargumentexception combine method	['hudi-bug']	1	1	Closed	6	['test', 'metadata', 'partition', 'path', 'commit', 'cause', 'record', 'query', 'run', 'update']
13470042	HUDI	fix hoodiedroppartitionstool base refactore meta sync	cause master fail refactoring meta sync	['pull-request-available']	3	4	Closed	10	['cause', 'time', 'read', 'type', 'update', 'commit', 'log', 'use', 'config', 'support']
13438745	HUDI	datum skipping work correctly presence schema evolution	currently data skipping handle correctly case column stat align column file combination miss csi occur different scenario schema evolution csi config change	['pull-request-available']	1	1	Closed	1	['metadata', 'issue', 'case', 'partition', 'base', 'path', 'datum', 'read', 'use', 'create']
13593603	HUDI	fix mor query hive integration test	mor query integration test hive fail run	['pull-request-available']	1	1	Closed	2	['test', 'run', 'add', 'cause', 'support', 'use', 'time', 'base', 'commit', 'query']
13524702	HUDI	handle payload abstractdebeziumavropayload	hoodiemergehandle decide long need copy old record handle properly abstractdebeziumavropayload	['pull-request-available']	3	4	Closed	12	['record', 'read', 'use', 'base', 'create', 'datum', 'query', 'time', 'set', 'currently']
13579400	HUDI	defaulthoodierecordpayload projection compatible	defaulthoodierecordpayload list projection compatible relation reader end read column mor read	['pull-request-available']	1	1	Closed	12	['record', 'read', 'use', 'base', 'create', 'datum', 'query', 'time', 'set', 'currently']
13409695	HUDI	upgrade java toolset runtime	upgrade preferably current late lts plan migration compilation compile source code source target stay require sure migrate add dependency feature compatible migrate toolset happen later point stop provide assurance code able run runtime run code jvm compatibility issue run code compile dependency compatibility sure test suite run	['performance']	1	4	Closed	2	['test', 'run', 'add', 'cause', 'support', 'use', 'time', 'base', 'commit', 'query']
13593000	HUDI	fix bootstrap index type setting metaclient	hoodietablemetaclient payload class wrongly set instead bootstrap index class	['pull-request-available']	3	1	Closed	11	['type', 'record', 'support', 'set', 'create', 'write', 'issue', 'base', 'test', 'partition']
13567639	HUDI	add config custom write support parquet row writer	hoodieavrowritesupport allow custom write support avro writing feature exist spark row writer add new config add custom write support	['pull-request-available']	3	2	Closed	5	['write', 'config', 'partition', 'support', 'add', 'path', 'need', 'use', 'record', 'metadata']
13537187	HUDI	add bundle validation base release candidate	check code validation bundle release candidate release process easy	['pull-request-available']	2	4	Open	2	['test', 'run', 'add', 'cause', 'support', 'use', 'time', 'base', 'commit', 'query']
13507199	HUDI	npe collumn stat null value	apache hudi hudi common src main java org apache hudi metadata throw npe avro util process null value	['pull-request-available']	1	1	Closed	8	['metadata', 'path', 'commit', 'datum', 'run', 'add', 'base', 'create', 'enable', 'test']
13489158	HUDI	add support rollback residual clustering disable clustering	user enable clustering disabled reason chance pende clustering leave timeline clustering disabled lie affect metadata table compaction whcih turn affect data table archival need way fix	['pull-request-available']	1	1	Patch Available	5	['write', 'config', 'partition', 'support', 'add', 'path', 'need', 'use', 'record', 'metadata']
13579434	HUDI	bootstrap read try parse partition bootstrap base path	bootstrap get partition path value bootstrap base path read base file hudi table case use hudi path case partition parse simple	['pull-request-available']	3	1	Closed	1	['metadata', 'issue', 'case', 'partition', 'base', 'path', 'datum', 'read', 'use', 'create']
13514290	HUDI	rollback mdt effective	rare condition rollback mdt effective apparenlty set clean policy lazy rollbacks happen clean kick start new commit give mdt single writer table rollback block effective commit rollback prior rollback block scenario fail inline compaction code java datum table timeline mdt timeline code attempt mdt roll crash mid way word log block write mdt deem invalid happen log block lay attempt crash roll read log block abstractlogrecordreader ideally want ignore encounter rollback block check previous log block match commit rollback match assume duplicate rollback deem valid log block mdt serve data file valid base listing standpoint impact log block ignore consider valid fix	['pull-request-available']	1	1	Closed	9	['partition', 'log', 'metadata', 'time', 'read', 'commit', 'path', 'datum', 'issue', 'new']
13448884	HUDI	read metadata table spark throw nullpointerexception createhfilereader	environment emr oss spark hudi master storage load metadata table spark shell follow code throw nullpointerexception case metadata table base file hfile format happen follow combination spark hudi spark hudi code java code code java cause nullpointerexception code spark shell code java spark shell yarn mode client memory memory executor core kryoserializer hadoop hudi true log spark app hoodiesparksessionextension hoodiecatalog code	['pull-request-available']	1	1	Closed	1	['metadata', 'issue', 'case', 'partition', 'base', 'path', 'datum', 'read', 'use', 'create']
13539934	HUDI	automatically decide archival boundary base clean config	throw error archival aggressive hour base cleaning improve automatically decide archival boundary hour base cleaning	['pull-request-available']	3	4	Closed	0	['type', 'support', 'base', 'record', 'time', 'read', 'enable', 'new', 'use', 'log']
13483531	HUDI	add config allow partition column type inference bootstrap	currently assume partition column string type bootstrap operation fail date partition column type inference partition column turn need add config allow partition column inference bootstrap type partition column support hoodiesparkbootstrapschemaprovider code java private static schema writeconfig hoodieenginecontext context path filepath note type inference partition column parquet table turn explicitly consistent exist bootstrap behavior partition column string type hudi table hoodiesparkenginecontext false structtype parquetschema hoodiesparkenginecontext code	['pull-request-available']	3	4	Patch Available	5	['write', 'config', 'partition', 'support', 'add', 'path', 'need', 'use', 'record', 'metadata']
13537841	HUDI	fix maven build	maven build break master code java mvn clean package	['pull-request-available']	1	1	Closed	6	['test', 'metadata', 'partition', 'path', 'commit', 'cause', 'record', 'query', 'run', 'update']
13413503	HUDI	archive metadata timeline crash timeline contain	commit showarchive cli fail present archived timeline code java hudi showarchive spring shell error simpleexecutionstrategy command fail hoodieioexception unknown action metadata replacecommit spring shell warn unknown action metadata replacecommit hoodieioexception unknown action metadata replacecommit code	['pull-request-available']	1	1	Closed	8	['metadata', 'path', 'commit', 'datum', 'run', 'add', 'base', 'create', 'enable', 'test']
13423359	HUDI	spark datasource read mor table write kafka connect sink	hit master spark datasource read mor table kafka connect sink code java scala val basepath hoodie hudi test topic basepath string hoodie hudi test topic scala val incompatibleschemaexception unexpected type null scala elide code hit exception spark	['pull-request-available']	1	1	Closed	6	['test', 'metadata', 'partition', 'path', 'commit', 'cause', 'record', 'query', 'run', 'update']
13568601	HUDI	meta sync consider clean commit sync partition	cleaner delete partition meta sync fail drop partition case cause query engine depend catalog fail	['pull-request-available']	3	3	Closed	6	['test', 'metadata', 'partition', 'path', 'commit', 'cause', 'record', 'query', 'run', 'update']
13405638	HUDI	late arrive record global index partition path update set true	incase global index config update partition path set true incoming record new partition compare storage old record delete new incoming record route new partition run issue new incoming late arrive record expect behavior old record retain new discard low precombine value case honor	['sev:normal', 'user-support-issues']	3	4	Open	3	['new', 'record', 'read', 'partition', 'commit', 'base', 'metadata', 'type', 'add', 'use']
13377494	HUDI	schema post processor default disabled	default value apache hudi schema post processor require mandatory	['core-flow-ds', 'pull-request-available', 'sev:high', 'triaged']	3	4	Patch Available	6	['test', 'metadata', 'partition', 'path', 'commit', 'cause', 'record', 'query', 'run', 'update']
13484891	HUDI	spark row write bulk insert produce incorrect bloom filter metadata	troubleshoot duplicate issue abhishek modi notion find min max record key stat currently persist incorrectly parquet metadata lead duplicate record produce pipeline initial bulk insert	['pull-request-available']	1	1	Closed	1	['metadata', 'issue', 'case', 'partition', 'base', 'path', 'datum', 'read', 'use', 'create']
13241363	HUDI	replace generator class cli arg hoodiedeltastreamer correspond datasource property	hudi datasource use option generate keygenerator class deltastreamer use cli argument generator class configure need remove cli argument instead use datasource option	['new-to-hudi', 'pull-request-available']	4	3	Closed	12	['record', 'read', 'use', 'base', 'create', 'datum', 'query', 'time', 'set', 'currently']
13404496	HUDI	multi writer deltastreamer spark datasource work	multi writer deltastreamer spark datasource work subsequent commit deltastreamer fail relate issue	['pull-request-available', 'sev:critical', 'user-support-issues']	1	4	Closed	7	['commit', 'metadata', 'cause', 'issue', 'enable', 'query', 'test', 'update', 'set', 'read']
13579726	HUDI	allow hoodietablemetaclient hoodiestorage instance directly	need functionality meta client	['hoodie-storage', 'pull-request-available']	3	4	Closed	5	['write', 'config', 'partition', 'support', 'add', 'path', 'need', 'use', 'record', 'metadata']
13468956	HUDI	add example configuration hoodiecleaner docs	add example configs property file illustrate configure hoodiecleaner different policy	['pull-request-available']	4	3	Closed	2	['test', 'run', 'add', 'cause', 'support', 'use', 'time', 'base', 'commit', 'query']
13484264	HUDI	unit test run mac	compatible mac version additionally spark compatible mac version rocksdb jini compatible version	['pull-request-available']	3	4	Closed	2	['test', 'run', 'add', 'cause', 'support', 'use', 'time', 'base', 'commit', 'query']
13500958	HUDI	action azure test run trivial fix	need run action azure necessary take resource important fix	['pull-request-available']	4	4	Closed	4	['commit', 'run', 'update', 'time', 'need', 'base', 'cause', 'partition', 'issue', 'write']
13420790	HUDI	support index action async metadata indexing	add new writeoperationtype handle conflict concurrent writer async table service implement protocol	['metadata', 'pull-request-available']	1	2	Closed	2	['test', 'run', 'add', 'cause', 'support', 'use', 'time', 'base', 'commit', 'query']
13425901	HUDI	conversion write stat metadata index record use hoodiedata	hoodiemetadatatableutil convertmetadatatorecords convert write stat metadata index record list hoodierecord pass engine specific commit prep record oom driver need use hoodiedata	['pull-request-available']	1	3	Closed	12	['record', 'read', 'use', 'base', 'create', 'datum', 'query', 'time', 'set', 'currently']
13523090	HUDI	col drop config honor schema validation disabled	look like col drop flag tightly couple schema validation flag schema validation enable col drop flag honor succeed table schema new incoming schema col drop config set false mean col drop support schema validation set false commit succeed expectation commit fail new batch	['pull-request-available']	1	1	Closed	13	['set', 'query', 'enable', 'config', 'read', 'write', 'add', 'test', 'path', 'run']
13427440	HUDI	ensure immutable hudi configuration set properly change later		['pull-request-available']	1	4	Closed	13	['set', 'query', 'enable', 'config', 'read', 'write', 'add', 'test', 'path', 'run']
13377097	HUDI	cluster support external index	want support record stay fileid cluster example sort file remove column file	['pull-request-available']	1	3	Closed	0	['type', 'support', 'base', 'record', 'time', 'read', 'enable', 'new', 'use', 'log']
13575250	HUDI	add api create hoodiestorage hoodieiofactory	use hoodieiofactory create hoodiestorage instance replace hardcode reflection logic	['hoodie-storage', 'pull-request-available']	3	3	Closed	12	['record', 'read', 'use', 'base', 'create', 'datum', 'query', 'time', 'set', 'currently']
13530139	HUDI	cluster bootstrap table fail row writer disabled	point cluster bootstrap table fail row writer disabled non row writer path handle bootstrap file path attemp fix succeed spark version	['pull-request-available']	3	1	Closed	8	['metadata', 'path', 'commit', 'datum', 'run', 'add', 'base', 'create', 'enable', 'test']
13327324	HUDI	update apache hudi website doc clarify property	context follow section need update required primary key nested field specify dot notation multiple column primary key use comma separate notation single multiple column primary key specify property default value uuid	['user-support-issues']	3	4	Closed	4	['commit', 'run', 'update', 'time', 'need', 'base', 'cause', 'partition', 'issue', 'write']
13313144	HUDI	umbrella support cluster filegroup		['hudi-umbrellas']	3	15	Closed	0	['type', 'support', 'base', 'record', 'time', 'read', 'enable', 'new', 'use', 'log']
13582176	HUDI	bump aws sdk version	current version aws sdk year old	['pull-request-available']	3	4	Closed	6	['test', 'metadata', 'partition', 'path', 'commit', 'cause', 'record', 'query', 'run', 'update']
13502975	HUDI	address checkstyle warning build hudi	lot checkstyle warning build hudi need look exactly fix stab fix possible controllable number suppress checkstyle warning excerpt log code java info nsb document personal project hudi hudi utility src test java org apache hudi utility source logmanager separate previous import importorder info nsb document personal project hudi hudi utility src test java org apache hudi utility source miss javadoc comment javadoctype info nsb document personal project hudi hudi utility src test java org apache hudi utility source miss javadoc comment javadoctype info nsb document personal project hudi hudi utility src test java org apache hudi utility source miss javadoc comment javadoctype info nsb document personal project hudi hudi utility src test java org apache hudi utility source import typedpropertie appear import precede importorder info nsb document personal project hudi hudi utility src test java org apache hudi utility source miss javadoc comment javadoctype info nsb document personal project hudi hudi utility src test java org apache hudi utility source miss javadoc comment javadoctype info nsb document personal project hudi hudi utility src test java org apache hudi utility source helper import kafkaoffsetgen checkpointutil appear import precede importorder info nsb document personal project hudi hudi utility src test java org apache hudi utility source helper miss javadoc comment javadoctype info nsb document personal project hudi hudi utility src test java org apache hudi utility source helper import timestamps appear import precede importorder info nsb document personal project hudi hudi utility src test java org apache hudi utility source helper miss javadoc comment javadoctype info nsb document personal project hudi hudi utility src test java org apache hudi utility source helper miss javadoc comment javadoctype info nsb document personal project hudi hudi utility src test java org apache hudi utility source helper miss javadoc comment javadoctype info nsb document personal project hudi hudi utility src test java org apache hudi utility source helper miss javadoc comment javadoctype info nsb document personal project hudi hudi utility src test java org apache hudi utility source debezium miss javadoc comment javadoctype info nsb document personal project hudi hudi utility src test java org apache hudi utility source debezium miss javadoc comment javadoctype info nsb document personal project hudi hudi utility src test java org apache hudi utility source debezium miss javadoc comment javadoctype info nsb document personal project hudi hudi utility src test java org apache hudi utility checkpointing miss javadoc comment javadoctype info nsb document personal project hudi hudi utility src test java org apache hudi utility miss javadoc comment javadoctype info nsb document personal project hudi hudi utility src test java org apache hudi utility miss javadoc comment javadoctype info nsb document personal project hudi hudi utility src test java org apache hudi utility transform miss javadoc comment javadoctype info nsb document personal project hudi hudi utility src test java org apache hudi utility transform miss javadoc comment javadoctype info nsb document personal project hudi hudi utility src test java org apache hudi utility transform miss javadoc comment javadoctype info nsb document personal project hudi hudi utility src test java org apache hudi utility transform miss javadoc comment javadoctype info nsb document personal project hudi hudi utility src test java org apache hudi utility functional miss javadoc comment javadoctype info nsb document personal project hudi hudi utility src test java org apache hudi utility functional miss javadoc comment javadoctype info nsb document personal project hudi hudi utility src test java org apache hudi utility functional miss javadoc comment javadoctype info nsb document personal project hudi hudi utility src test java org apache hudi utility functional miss javadoc comment javadoctype info nsb document personal project hudi hudi utility src test java org apache hudi utility functional miss javadoc comment javadoctype info nsb document personal project hudi hudi utility src test java org apache hudi utility functional miss javadoc comment javadoctype info nsb document personal project hudi hudi utility src test java org apache hudi utility functional miss javadoc comment javadoctype info nsb document personal project hudi hudi utility src test java org apache hudi utility functional miss javadoc comment javadoctype info nsb document personal project hudi hudi utility src test java org apache hudi utility functional miss javadoc comment javadoctype info nsb document personal project hudi hudi utility src test java org apache hudi utility functional miss javadoc comment javadoctype code	['pull-request-available']	2	4	Closed	6	['test', 'metadata', 'partition', 'path', 'commit', 'cause', 'record', 'query', 'run', 'update']
13580491	HUDI	fix bundle validation script	issue bundle validation packaging bundle validation fail branch script issue script release need include additional bundle add release candidate validation scala bundle disable release candidate validation default	['pull-request-available']	3	1	Closed	1	['metadata', 'issue', 'case', 'partition', 'base', 'path', 'datum', 'read', 'use', 'create']
13393118	HUDI	refactor spark datasource functional test	change run test like hoodiesparksqlwritersuite huge pain modularize reuse code possible common setup tear method hoodiesparksqlwriter testcowdatasource testmordatasource	['pull-request-available']	3	3	Closed	2	['test', 'run', 'add', 'cause', 'support', 'use', 'time', 'base', 'commit', 'query']
13557364	HUDI	use exist relation logic query read base file spark	fail new file group reader base parquet file format fix temporarily fallback exist logic query read base file	['pull-request-available']	1	1	Closed	12	['record', 'read', 'use', 'base', 'create', 'datum', 'query', 'time', 'set', 'currently']
13397067	HUDI	add test functionality		['pull-request-available']	4	6	Resolved	2	['test', 'run', 'add', 'cause', 'support', 'use', 'time', 'base', 'commit', 'query']
13582058	HUDI	bump apache rat plugin eliminate thread safe warning maven parallel build	follow warning throw maven parallel build mvn code java warning enable debug precisely goal mark thread safe warning warning build request parallel execution warning project contain follow goal warning mark thread safe support parallel execution warning work fine look plugin update warning request plugin thread safe warning report issue report plugin warning question apache maven warning warning follow plugin mark thread safe hudi hadoop warning apache rat code	['pull-request-available']	3	4	Closed	7	['commit', 'metadata', 'cause', 'issue', 'enable', 'query', 'test', 'update', 'set', 'read']
13408289	HUDI	fix test failure testhoodielogformat	break	['pull-request-available']	1	4	Resolved	6	['test', 'metadata', 'partition', 'path', 'commit', 'cause', 'record', 'query', 'run', 'update']
13521798	HUDI	improve usability hudi cli bundle	ability specify exist hudi cli bundle hudi spark bundle automatically download aux jar jakarta hudi cli	['pull-request-available']	1	4	Closed	6	['test', 'metadata', 'partition', 'path', 'commit', 'cause', 'record', 'query', 'run', 'update']
13411947	HUDI	enable timeline server base marker type default	enable timeline server base marker type default	['pull-request-available']	1	4	Closed	0	['type', 'support', 'base', 'record', 'time', 'read', 'enable', 'new', 'use', 'log']
13440800	HUDI	add config fallback extract partition value partition path	aftermath fix want add fallback config allow user fallback exist behavior avoid pipeline breakage compensate issue way setup config false default	['pull-request-available']	1	1	Closed	5	['write', 'config', 'partition', 'support', 'add', 'path', 'need', 'use', 'record', 'metadata']
13425273	HUDI	parquetutil fail extract parquet column range metadata	discover follow issue test flow fail code java executor task launch worker task error hoodietablemetadatautil fail read column stat folder classcastexception cast integer code	['pull-request-available']	1	1	Closed	1	['metadata', 'issue', 'case', 'partition', 'base', 'path', 'datum', 'read', 'use', 'create']
13436303	HUDI	fix translation isnotnull predicate datum skipping	right isnotnull predicate translate incorrectly code java filter cola null translate index lookup case attributereference indexschema code instead condition	['pull-request-available']	1	1	Closed	1	['metadata', 'issue', 'case', 'partition', 'base', 'path', 'datum', 'read', 'use', 'create']
13418288	HUDI	fix flaky testhoodieclientmultiwriter testhoodieclientbasicmultiwriter	ref code java info run testhoodieclientmultiwriter main warn hoodiebackedtablemetadata metadata table find path metadata dispatcher event warn tasksetmanager stage contain task large size maximum recommend task size dispatcher event warn tasksetmanager stage contain task large size maximum recommend task size main warn hoodiebackedtablemetadata metadata table find path metadata main warn hoodiebackedtablemetadata metadata table find path metadata main warn hoodieclienttestharness closing file system instance previous test run main warn hoodieclienttestharness closing file system instance previous test run main warn hoodiebackedtablemetadata metadata table find path metadata dispatcher event warn tasksetmanager stage contain task large size maximum recommend task size dispatcher event warn tasksetmanager stage contain task large size maximum recommend task size main warn hoodiebackedtablemetadata metadata table find path metadata main warn hoodiebackedtablemetadata metadata table find path metadata main warn hoodieclienttestharness closing file system instance previous test run main warn hoodiebackedtablemetadata metadata table find path metadata dispatcher event warn tasksetmanager stage contain task large size maximum recommend task size dispatcher event warn tasksetmanager stage contain task large size maximum recommend task size main warn hoodiebackedtablemetadata metadata table find path metadata main warn hoodiebackedtablemetadata metadata table find path metadata main warn hoodieclienttestharness closing file system instance previous test run main warn hoodieclienttestharness closing file system instance previous test run main warn hoodiebackedtablemetadata metadata table find path metadata dispatcher event warn tasksetmanager stage contain task large size maximum recommend task size dispatcher event warn tasksetmanager stage contain task large size maximum recommend task size main warn hoodiebackedtablemetadata metadata table find path metadata main warn hoodiebackedtablemetadata metadata table find path metadata main warn hoodieclienttestharness closing file system instance previous test run main warn hoodiebackedtablemetadata metadata table find path metadata dispatcher event warn tasksetmanager stage contain task large size maximum recommend task size dispatcher event warn tasksetmanager stage contain task large size maximum recommend task size main warn hoodiebackedtablemetadata metadata table find path metadata main warn hoodiebackedtablemetadata metadata table find path metadata main warn hoodieclienttestharness closing file system instance previous test run main warn hoodieclienttestharness closing file system instance previous test run main warn hoodiebackedtablemetadata metadata table find path metadata dispatcher event warn tasksetmanager stage contain task large size maximum recommend task size dispatcher event warn tasksetmanager stage contain task large size maximum recommend task size main warn hoodiebackedtablemetadata metadata table find path metadata main warn hoodiebackedtablemetadata metadata table find path metadata main warn hoodieclienttestharness closing file system instance previous test run main warn hoodiebackedtablemetadata metadata table find path metadata main warn hoodiebackedtablemetadata metadata table find path metadata main warn hoodiebackedtablemetadata metadata table find path metadata main warn hoodieclienttestharness closing file system instance previous test run main warn hoodieclienttestharness closing file system instance previous test run main warn hoodiebackedtablemetadata metadata table find path metadata main warn hoodiebackedtablemetadata metadata table find path metadata main warn hoodiebackedtablemetadata metadata table find path metadata main warn hoodieclienttestharness closing file system instance previous test run error test run failure error skip time elapse failure testhoodieclientmultiwriter error time elapse error executionexception runtimeexception hoodiewriteconflictexception concurrentmodificationexception resolve conflict overlap write cause runtimeexception hoodiewriteconflictexception concurrentmodificationexception resolve conflict overlap write cause hoodiewriteconflictexception concurrentmodificationexception resolve conflict overlap write cause concurrentmodificationexception resolve conflict overlap write code	['pull-request-available']	1	6	Closed	8	['metadata', 'path', 'commit', 'datum', 'run', 'add', 'base', 'create', 'enable', 'test']
13521829	HUDI	fix hoodiesparkrecord performance bottleneck	currently follow issue current hoodiesparkrecord implementation rewrite record rewriterecord rewriterecordwithnewschema schema traversal record instead schema traversal produce transformer directly create new record old record currently copy executor simple actually buffer record require record copy	['pull-request-available']	1	1	Closed	12	['record', 'read', 'use', 'base', 'create', 'datum', 'query', 'time', 'set', 'currently']
13417266	HUDI	add support start incremental consumption begin time late commit time	begin time provide consume meta table fallback late commit time support start early instant	['core-flow-ds', 'pull-request-available', 'sev:normal']	3	4	Resolved	4	['commit', 'run', 'update', 'time', 'need', 'base', 'cause', 'partition', 'issue', 'write']
13413458	HUDI	configuration cli property file interoperable	currently specify command cli property file inter operate seamlessly config go siloe original format config parse cli property object sync lead problem like report noformat set true inside property file throw error check conf	['pull-request-available']	1	1	Closed	13	['set', 'query', 'enable', 'config', 'read', 'write', 'add', 'test', 'path', 'run']
13449349	HUDI	getallpartition metadata regress perf	look like getallpartitonpath regress performance ref issue	['pull-request-available']	1	4	Closed	1	['metadata', 'issue', 'case', 'partition', 'base', 'path', 'datum', 'read', 'use', 'create']
13412095	HUDI	async cluster deltstreamer fail illegalstateexception duplicate key	setup start deltastreamer parquet dfs source source folder datum enable async cluster prop type add file source folder deltastreamer fail commit go fine look like replace commit go fine deltastreamer fail need understand deltastreamer try schedule replace commit run continuous mode go round immediately datum sync note partition file group entire dataset clustering plan replace commit request meta file code java hudi deltastreamer code java hudi deltastreamer code timeline screen shot stacktrace code java warn hoodiedeltastreamer round warn deltasync extra metadata schema warn hoodiedeltastreamer start async clustering service require warn hoodiedeltastreamer schedule async cluster instant warn hoodiedeltastreamer round warn deltasync extra metadata schema warn hoodiedeltastreamer schedule async cluster instant warn hoodiedeltastreamer round warn deltasync extra metadata schema error executor exception task stage tid illegalstateexception duplicate key warn tasksetmanager lose task stage tid localhost executor driver illegalstateexception duplicate key code try add sec delay continuous mode thing fine sec delay clustering complete round trigger scheduling try sec delay run exception time scheduling happen	['core-flow-ds', 'pull-request-available', 'sev:high']	1	4	Closed	8	['metadata', 'path', 'commit', 'datum', 'run', 'add', 'base', 'create', 'enable', 'test']
13522141	HUDI	metadata bootstrap flow result npe	add simple statement force test read bootstrappe table code java code follow npe observe master testbulkinsertsandupsertswithbootstrap code java sparkexception job abort stage failure task stage fail time recent failure lose task stage tid localhost executor driver nullpointerexception source source source stacktrace scala method cause nullpointerexception source source source code	['pull-request-available']	1	1	Closed	10	['cause', 'time', 'read', 'type', 'update', 'commit', 'log', 'use', 'config', 'support']
13360957	HUDI	implement spark datasource option read hudi configs property file	provide config option like load option file	['sev:high', 'user-support-issues']	3	4	Resolved	13	['set', 'query', 'enable', 'config', 'read', 'write', 'add', 'test', 'path', 'run']
13571067	HUDI	classify exception schema exception convert avro spark row format	issue relate schema throw exception hoodieschemaexception classify exception convert avro spark row format schema compatibility exception illegal schema record incompatible provide schema	['pull-request-available']	3	4	Closed	12	['record', 'read', 'use', 'base', 'create', 'datum', 'query', 'time', 'set', 'currently']
13256787	HUDI	add jdbc source support hudi deltastreamer	mirror rdbms hudi basic use case hudi use case deltastreamer provide inbuilt support deltasteamer accept like user define rdbms connection property timestamp column interval allow user express frequently hudi check rdbms datum source new insert update detail document	['pull-request-available', 'sev:normal']	5	3	Closed	2	['test', 'run', 'add', 'cause', 'support', 'use', 'time', 'base', 'commit', 'query']
13486988	HUDI	add support wild card	expect comma separate list partition delete like support wild card assume hour base partitioning ref	['pull-request-available']	3	4	Closed	5	['write', 'config', 'partition', 'support', 'add', 'path', 'need', 'use', 'record', 'metadata']
13482987	HUDI	sure logrecordreader flush cache lookup	currently hoodiemetadatamergedlogrecordreader flush internal record cache lookup make lookup essentially processing log block stack avoid parse incrementally key cache	['pull-request-available']	1	1	Closed	12	['record', 'read', 'use', 'base', 'create', 'datum', 'query', 'time', 'set', 'currently']
13396222	HUDI	implement scheduling clustering kafka connect	implement clustering etc java client schedule coordinator	['pull-request-available']	1	3	Closed	6	['test', 'metadata', 'partition', 'path', 'commit', 'cause', 'record', 'query', 'run', 'update']
13550555	HUDI	docs add info partially fail write handle hudi	page discuss partially fail write handle hudi good	['pull-request-available']	3	4	Closed	5	['write', 'config', 'partition', 'support', 'add', 'path', 'need', 'use', 'record', 'metadata']
13482833	HUDI	fix incompatibility spark	report user spark projectionoverschema argument spark spark projectionoverschema argument compatible spark context	['pull-request-available']	1	1	Closed	6	['test', 'metadata', 'partition', 'path', 'commit', 'cause', 'record', 'query', 'run', 'update']
